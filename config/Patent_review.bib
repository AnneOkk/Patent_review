
@article{sendak_etal20,
	title = {A path for translation of machine learning products into healthcare delivery},
	issn = {2513-8634},
	url = {https://www.emjreviews.com/innovations/article/a-path-for-translation-of-machine-learning-products-into-healthcare-delivery/},
	doi = {10.33590/emjinnov/19-00172},
	abstract = {Despite enormous enthusiasm, machine learning models are rarely translated into clinical care and there is minimal evidence of clinical or economic impact. New conference venues and academic journals have emerged to promote the proliferating research; however, the translational path remains unclear. This review undertakes the first in-depth study to identify how machine learning models that ingest structured electronic health record data can be applied to clinical decision support tasks and translated into clinical practice. The authors complement their own work with the experience of 21 machine learning products that address problems across clinical domains and across geographic populations. Four phases of translation emerge: design and develop, evaluate and validate, diffuse and scale, and continuing monitoring and maintenance. The review highlights the varying approaches taken across each phase by teams building machine learning products and presents a discussion of challenges and opportunities. The translational path and associated findings are instructive to researchers and developers building machine learning products, policy makers regulating machine learning products, and health system leaders who are considering adopting a machine learning product.},
	journaltitle = {{EMJ} Innovations},
	shortjournal = {{EMJ} Innov},
	author = {Sendak, Mark P. and D’Arcy, Joshua and Kashyap, Sehj and Gao, Michael and Nichols, Marshall and Corey,, Kristin and Ratliff, William and Balu, Suresh},
	urldate = {2022-06-30},
	date = {2020-01-27},
	langid = {english},
	file = {2020 - A Path for Translation of Machine Learning Product.pdf:/Users/annekleine/Zotero/storage/ST7TGYA3/2020 - A Path for Translation of Machine Learning Product.pdf:application/pdf},
}

@article{shatte_etal19,
	title = {Machine learning in mental health: a scoping review of methods and applications},
	volume = {49},
	issn = {0033-2917, 1469-8978},
	url = {https://www.cambridge.org/core/journals/psychological-medicine/article/abs/machine-learning-in-mental-health-a-scoping-review-of-methods-and-applications/0B70B1C827B3A4604C1C01026049F7D9},
	doi = {10.1017/S0033291719000151},
	shorttitle = {Machine learning in mental health},
	abstract = {{BackgroundThis} paper aims to synthesise the literature on machine learning ({ML}) and big data applications for mental health, highlighting current research and applications in practice.{MethodsWe} employed a scoping review methodology to rapidly map the field of {ML} in mental health. Eight health and information technology research databases were searched for papers covering this domain. Articles were assessed by two reviewers, and data were extracted on the article's mental health application, {ML} technique, data type, and study results. Articles were then synthesised via narrative review.{ResultsThree} hundred papers focusing on the application of {ML} to mental health were identified. Four main application domains emerged in the literature, including: (i) detection and diagnosis; (ii) prognosis, treatment and support; (iii) public health, and; (iv) research and clinical administration. The most common mental health conditions addressed included depression, schizophrenia, and Alzheimer's disease. {ML} techniques used included support vector machines, decision trees, neural networks, latent Dirichlet allocation, and clustering.{ConclusionsOverall}, the application of {ML} to mental health has demonstrated a range of benefits across the areas of diagnosis, treatment and support, research, and clinical administration. With the majority of studies identified focusing on the detection and diagnosis of mental health conditions, it is evident that there is significant room for the application of {ML} to other areas of psychology and mental health. The challenges of using {ML} techniques are discussed, as well as opportunities to improve and advance the field.},
	pages = {1426--1448},
	number = {9},
	journaltitle = {Psychological Medicine},
	author = {Shatte, Adrian B. R. and Hutchinson, Delyse M. and Teague, Samantha J.},
	urldate = {2022-06-29},
	date = {2019-07},
	langid = {english},
	note = {Publisher: Cambridge University Press},
	keywords = {machine learning, Big data, health informatics, mental health},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/VGIFS2VS/Shatte et al. - 2019 - Machine learning in mental health a scoping revie.pdf:application/pdf;Submitted Version:/Users/annekleine/Zotero/storage/9D3NTKHZ/Shatte et al. - 2019 - Machine learning in mental health a scoping revie.pdf:application/pdf},
}

@article{aafjes-vandoorn_etal21,
	title = {A scoping review of machine learning in psychotherapy research},
	volume = {31},
	issn = {1050-3307, 1468-4381},
	url = {https://www.tandfonline.com/doi/full/10.1080/10503307.2020.1808729},
	doi = {10.1080/10503307.2020.1808729},
	abstract = {Machine learning ({ML}) offers robust statistical and probabilistic techniques that can help to make sense of large amounts of data. This scoping review paper aims to broadly explore the nature of research activity using {ML} in the context of psychological talk therapies, highlighting the scope of current methods and considerations for clinical practice and directions for future research. Using a systematic search methodology, fifty-one studies were identified. A narrative synthesis indicates two types of studies, those who developed and tested an {ML} model (k=44), and those who reported on the feasibility of a particular treatment tool that uses an {ML} algorithm (k=7). Most model development studies used supervised learning techniques to classify or predict labeled treatment process or outcome data, whereas others used unsupervised techniques to identify clusters in the unlabeled patient or treatment data. Overall, the current applications of {ML} in psychotherapy research demonstrated a range of possible benefits for indications of treatment process, adherence, therapist skills and treatment response prediction, as well as ways to accelerate research through automated behavioral or linguistic process coding. Given the novelty and potential of this research field, these proof-of-concept studies are encouraging, however, do not necessarily translate to improved clinical practice (yet).},
	pages = {92--116},
	number = {1},
	journaltitle = {Psychotherapy Research},
	shortjournal = {Psychotherapy Research},
	author = {Aafjes-van Doorn, Katie and Kamsteeg, Céline and Bate, Jordan and Aafjes, Marc},
	urldate = {2022-06-29},
	date = {2021-01-02},
	langid = {english},
	keywords = {refs searched},
	file = {A scoping review of machine learning in psychotherapy research.pdf:/Users/annekleine/Zotero/storage/7PMHJXVD/A scoping review of machine learning in psychotherapy research.pdf:application/pdf},
}

@article{lee_etal21,
	title = {Artificial intelligence for mental health care: clinical applications, barriers, facilitators, and artificial wisdom},
	volume = {6},
	issn = {24519022},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S245190222100046X},
	doi = {10.1016/j.bpsc.2021.02.001},
	shorttitle = {Artificial Intelligence for Mental Health Care},
	pages = {856--864},
	number = {9},
	journaltitle = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
	shortjournal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
	author = {Lee, Ellen E. and Torous, John and De Choudhury, Munmun and Depp, Colin A. and Graham, Sarah A. and Kim, Ho-Cheol and Paulus, Martin P. and Krystal, John H. and Jeste, Dilip V.},
	urldate = {2022-06-23},
	date = {2021-09},
	langid = {english},
	file = {Full Text:/Users/annekleine/Zotero/storage/6VQSWKNI/Lee et al. - 2021 - Artificial Intelligence for Mental Health Care Cl.pdf:application/pdf},
}

@article{bzdok_meyer-lindenberg18,
	title = {Machine learning for precision psychiatry: opportunities and challenges},
	volume = {3},
	issn = {2451-9022},
	url = {https://www.sciencedirect.com/science/article/pii/S2451902217302069},
	doi = {10.1016/j.bpsc.2017.11.007},
	shorttitle = {Machine Learning for Precision Psychiatry},
	abstract = {The nature of mental illness remains a conundrum. Traditional disease categories are increasingly suspected to misrepresent the causes underlying mental disturbance. Yet psychiatrists and investigators now have an unprecedented opportunity to benefit from complex patterns in brain, behavior, and genes using methods from machine learning (e.g., support vector machines, modern neural-network algorithms, cross-validation procedures). Combining these analysis techniques with a wealth of data from consortia and repositories has the potential to advance a biologically grounded redefinition of major psychiatric disorders. Increasing evidence suggests that data-derived subgroups of psychiatric patients can better predict treatment outcomes than {DSM}/{ICD} diagnoses can. In a new era of evidence-based psychiatry tailored to single patients, objectively measurable endophenotypes could allow for early disease detection, individualized treatment selection, and dosage adjustment to reduce the burden of disease. This primer aims to introduce clinicians and researchers to the opportunities and challenges in bringing machine intelligence into psychiatric practice.},
	pages = {223--230},
	number = {3},
	journaltitle = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
	shortjournal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
	author = {Bzdok, Danilo and Meyer-Lindenberg, Andreas},
	urldate = {2022-08-24},
	date = {2018-03-01},
	langid = {english},
	keywords = {Artificial intelligence, Machine learning, Personalized medicine, Endophenotypes, Null-hypothesis testing, Predictive analytics, Research Domain Criteria ({RDoC}), Single-subject prediction},
	file = {Bzdok and Meyer-Lindenberg - 2018 - Machine Learning for Precision Psychiatry Opportu.pdf:/Users/annekleine/Zotero/storage/ZS5G4F2E/Bzdok and Meyer-Lindenberg - 2018 - Machine Learning for Precision Psychiatry Opportu.pdf:application/pdf;ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/WNJPFTQW/S2451902217302069.html:text/html},
}

@article{dwyer_etal18,
	title = {Machine learning approaches for clinical psychology and psychiatry},
	volume = {14},
	url = {https://doi.org/10.1146/annurev-clinpsy-032816-045037},
	doi = {10.1146/annurev-clinpsy-032816-045037},
	abstract = {Machine learning approaches for clinical psychology and psychiatry explicitly focus on learning statistical functions from multidimensional data sets to make generalizable predictions about individuals. The goal of this review is to provide an accessible understanding of why this approach is important for future practice given its potential to augment decisions associated with the diagnosis, prognosis, and treatment of people suffering from mental illness using clinical and biological data. To this end, the limitations of current statistical paradigms in mental health research are critiqued, and an introduction is provided to critical machine learning methods used in clinical studies. A selective literature review is then presented aiming to reinforce the usefulness of machine learning methods and provide evidence of their potential. In the context of promising initial results, the current limitations of machine learning approaches are addressed, and considerations for future clinical translation are outlined.},
	pages = {91--118},
	number = {1},
	journaltitle = {Annual Review of Clinical Psychology},
	author = {Dwyer, Dominic B. and Falkai, Peter and Koutsouleris, Nikolaos},
	urldate = {2022-08-24},
	date = {2018},
	pmid = {29401044},
	note = {\_eprint: https://doi.org/10.1146/annurev-clinpsy-032816-045037},
	keywords = {artificial intelligence, machine learning, psychiatry, mental health, personalized medicine, clinical psychology, translational psychiatry},
	file = {Dwyer et al. - 2018 - Machine Learning Approaches for Clinical Psycholog.pdf:/Users/annekleine/Zotero/storage/YIRRCS9N/Dwyer et al. - 2018 - Machine Learning Approaches for Clinical Psycholog.pdf:application/pdf},
}

@article{chekroud_etal21,
	title = {The promise of machine learning in predicting treatment outcomes in psychiatry},
	volume = {20},
	issn = {2051-5545},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wps.20882},
	doi = {10.1002/wps.20882},
	abstract = {For many years, psychiatrists have tried to understand factors involved in response to medications or psychotherapies, in order to personalize their treatment choices. There is now a broad and growing interest in the idea that we can develop models to personalize treatment decisions using new statistical approaches from the field of machine learning and applying them to larger volumes of data. In this pursuit, there has been a paradigm shift away from experimental studies to confirm or refute specific hypotheses towards a focus on the overall explanatory power of a predictive model when tested on new, unseen datasets. In this paper, we review key studies using machine learning to predict treatment outcomes in psychiatry, ranging from medications and psychotherapies to digital interventions and neurobiological treatments. Next, we focus on some new sources of data that are being used for the development of predictive models based on machine learning, such as electronic health records, smartphone and social media data, and on the potential utility of data from genetics, electrophysiology, neuroimaging and cognitive testing. Finally, we discuss how far the field has come towards implementing prediction tools in real-world clinical practice. Relatively few retrospective studies to-date include appropriate external validation procedures, and there are even fewer prospective studies testing the clinical feasibility and effectiveness of predictive models. Applications of machine learning in psychiatry face some of the same ethical challenges posed by these techniques in other areas of medicine or computer science, which we discuss here. In short, machine learning is a nascent but important approach to improve the effectiveness of mental health care, and several prospective clinical studies suggest that it may be working already.},
	pages = {154--170},
	number = {2},
	journaltitle = {World Psychiatry},
	author = {Chekroud, Adam M. and Bondar, Julia and Delgadillo, Jaime and Doherty, Gavin and Wasil, Akash and Fokkema, Marjolein and Cohen, Zachary and Belgrave, Danielle and {DeRubeis}, Robert and Iniesta, Raquel and Dwyer, Dominic and Choi, Karmel},
	urldate = {2022-08-24},
	date = {2021},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wps.20882},
	keywords = {Computational psychiatry, electronic health records, external validation, machine learning, pharmacotherapies, prediction, psy­chotherapies, smartphone data, treatment outcomes},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/J9SNDJV5/Chekroud et al. - 2021 - The promise of machine learning in predicting trea.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/YREGP9WL/wps.html:text/html},
}

@article{sutton_etal20a,
	title = {An overview of clinical decision support systems: benefits, risks, and strategies for success},
	volume = {3},
	rights = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-0221-y},
	doi = {10.1038/s41746-020-0221-y},
	shorttitle = {An overview of clinical decision support systems},
	abstract = {Computerized clinical decision support systems, or {CDSS}, represent a paradigm shift in healthcare today. {CDSS} are used to augment clinicians in their complex decision-making processes. Since their first use in the 1980s, {CDSS} have seen a rapid evolution. They are now commonly administered through electronic medical records and other computerized clinical workflows, which has been facilitated by increasing global adoption of electronic medical records with advanced capabilities. Despite these advances, there remain unknowns regarding the effect {CDSS} have on the providers who use them, patient outcomes, and costs. There have been numerous published examples in the past decade(s) of {CDSS} success stories, but notable setbacks have also shown us that {CDSS} are not without risks. In this paper, we provide a state-of-the-art overview on the use of clinical decision support systems in medicine, including the different types, current use cases with proven efficacy, common pitfalls, and potential harms. We conclude with evidence-based recommendations for minimizing risk in {CDSS} design, implementation, evaluation, and maintenance.},
	pages = {1--10},
	number = {1},
	journaltitle = {npj Digital Medicine},
	shortjournal = {npj Digit. Med.},
	author = {Sutton, Reed T. and Pincock, David and Baumgart, Daniel C. and Sadowski, Daniel C. and Fedorak, Richard N. and Kroeker, Karen I.},
	urldate = {2022-10-14},
	date = {2020-02-06},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Diagnosis, Medical imaging, Health services, Drug regulation},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/HDVGG7H2/Sutton et al. - 2020 - An overview of clinical decision support systems .pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/ETPBH6JR/s41746-020-0221-y.html:text/html},
}

@article{defreitas_etal22,
	title = {Benefits and Challenges of Virtual-Reality-Based Industrial Usability Testing and Design Reviews: A Patents Landscape and Literature Review},
	volume = {12},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/12/3/1755},
	doi = {10.3390/app12031755},
	shorttitle = {Benefits and Challenges of Virtual-Reality-Based Industrial Usability Testing and Design Reviews},
	abstract = {With the introduction of new devices, industries are turning to virtual reality to innovate their product development processes. However, before the technology’s possibilities can be fully harnessed, certain constraints must be overcome. This study identifies the benefits and challenges of virtual-reality-based usability testing and design reviews in industry through a patents and articles review. We searched Derwent Innovation, Scopus, and Web of Science and identified 7 patent filings and 20 articles. We discovered an increase in patent filings since 2016 and strong development in the technology space, offering opportunities to enter an area while it is still young. The most frequently researched field is the automotive industry and the most used device is the {HTC} {VIVE} head-mounted display, which is frequently paired with motion capture systems and Unity 3D game engines. Virtual reality benefits design reviews and usability testing by providing the visualization of new angles that stimulate novel insights, increasing team engagement, offering more intuitive interactions for non-{CAD} specialists, saving redesign cost and time, and increasing participants’ safety. The challenges faced by virtual-reality-based prototypes are a lack of realism due to unnatural tactile and visual interactions, latency and registration issues, communication difficulties between teams, and unpleasant symptoms. While these constraints prevent virtual reality from replacing conventional design reviews and usability testing in the near future, it is already a valuable contribution to the industrial product development process.},
	pages = {1755},
	number = {3},
	journaltitle = {Applied Sciences},
	author = {de Freitas, Fabio Vinicius and Gomes, Marcus Vinicius Mendes and Winkler, Ingrid},
	urldate = {2022-10-18},
	date = {2022-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {virtual reality, automotive industry, usability testing, design review, industrial product development, industry 4.0},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/VCMNUQV6/de Freitas et al. - 2022 - Benefits and Challenges of Virtual-Reality-Based I.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/SQDEXREY/1755.html:text/html},
}

@article{chao_etal21,
	title = {Emerging Technologies of Natural Language-Enabled Chatbots: A Review and Trend Forecast Using Intelligent Ontology Extraction and Patent Analytics},
	volume = {2021},
	issn = {1076-2787},
	url = {https://www.hindawi.com/journals/complexity/2021/5511866/},
	doi = {10.1155/2021/5511866},
	shorttitle = {Emerging Technologies of Natural Language-Enabled Chatbots},
	abstract = {Natural language processing ({NLP}) is a critical part of the digital transformation. {NLP} enables user-friendly interactions between machine and human by making computers understand human languages. Intelligent chatbot is an essential application of {NLP} to allow understanding of users’ utterance and responding in understandable sentences for specific applications simulating human-to-human conversations and interactions for problem solving or Q\&As. This research studies emerging technologies for {NLP}-enabled intelligent chatbot development using a systematic patent analytic approach. Some intelligent text-mining techniques are applied, including document term frequency analysis for key terminology extractions, clustering method for identifying the subdomains, and Latent Dirichlet Allocation for finding the key topics of patent set. This research utilizes the Derwent Innovation database as the main source for global intelligent chatbot patent retrievals.},
	pages = {e5511866},
	journaltitle = {Complexity},
	author = {Chao, Min-Hua and Trappey, Amy J. C. and Wu, Chun-Ting},
	urldate = {2022-10-18},
	date = {2021-05-25},
	langid = {english},
	note = {Publisher: Hindawi},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/E355BYUW/Chao et al. - 2021 - Emerging Technologies of Natural Language-Enabled .pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/L5FDMNIP/5511866.html:text/html},
}

@article{dalgleish_etal20,
	title = {Transdiagnostic approaches to mental health problems: Current status and future directions},
	volume = {88},
	issn = {0022-006X},
	url = {http://search.ebscohost.com.proxy-ub.rug.nl/login.aspx?direct=true&db=pdh&AN=2020-10232-001&site=ehost-live&scope=site},
	doi = {10.1037/ccp0000482},
	series = {Transdiagnostic Approaches to Mental Health},
	shorttitle = {Transdiagnostic approaches to mental health problems},
	abstract = {Despite a longstanding and widespread influence of the diagnostic approach to mental ill health, there is an emerging and growing consensus that such psychiatric nosologies may no longer be fit for purpose in research and clinical practice. In their place, there is gathering support for a 'transdiagnostic' approach that cuts across traditional diagnostic boundaries or, more radically, sets them aside altogether, to provide novel insights into how we might understand mental health difficulties. Removing the distinctions between proposed psychiatric taxa at the level of classification opens up new ways of classifying mental health problems, suggests alternative conceptualizations of the processes implicated in mental health, and provides a platform for novel ways of thinking about onset, maintenance, and clinical treatment and recovery from experiences of disabling mental distress. In this Introduction to a Special Section on Transdiagnostic Approaches to Psychopathology, we provide a narrative review of the transdiagnostic literature in order to situate the Special Section articles in context. We begin with a brief history of the diagnostic approach and outline several challenges it currently faces that arguably limit its applicability in current mental health science and practice. We then review several recent transdiagnostic approaches to classification, biopsychosocial processes, and clinical interventions, highlighting promising novel developments. Finally, we present some key challenges facing transdiagnostic science and make suggestions for a way forward. ({PsycInfo} Database Record (c) 2020 {APA}, all rights reserved)},
	pages = {179--195},
	number = {3},
	journaltitle = {Journal of Consulting and Clinical Psychology},
	shortjournal = {Journal of Consulting and Clinical Psychology},
	author = {Dalgleish, Tim and Black, Melissa and Johnston, David and Bevan, Anna},
	urldate = {2022-10-14},
	date = {2020-03},
	note = {Publisher: American Psychological Association},
	keywords = {mental health, classification, Intervention, Clinical Practice, Mental Health, Biopsychosocial Approach, biopsychosocial processes, clinical interventions, Cognitive Style, Maintenance Therapy, Mental Disorders, Psychodiagnostic Typologies, transdiagnostic},
	file = {EBSCO Full Text:/Users/annekleine/Zotero/storage/CF7NNWAQ/Dalgleish et al. - 2020 - Transdiagnostic approaches to mental health proble.pdf:application/pdf},
}

@article{zanardi_etal21,
	title = {Precision psychiatry in clinical practice},
	volume = {25},
	issn = {1365-1501, 1471-1788},
	url = {https://www.tandfonline.com/doi/full/10.1080/13651501.2020.1809680},
	doi = {10.1080/13651501.2020.1809680},
	abstract = {The treatment of depression represents a major challenge for healthcare systems and choosing among the many available drugs without objective guidance criteria is an error-prone process. Recently, pharmacogenetic biomarkers entered in prescribing guidelines, giving clinicians the possibility to use this additional tool to guide prescription and improve therapeutic outcomes. This marked an important step towards precision psychiatry, which aim is to integrate biological and environmental information to personalise treatments. Only genetic variants in cytochrome enzymes are endorsed by prescribing guidelines, but in the future polygenic predictors of treatment outcomes may be translated into the clinic. The integration of genetics with other relevant information (e.g., concomitant diseases and treatments, drug plasma levels) could be managed in a standardised way through ad hoc software. The overcoming of the current obstacles (e.g., staff training, genotyping and informatics facilities) can lead to a broad implementation of precision psychiatry and represent a revolution for psychiatric care.},
	pages = {19--27},
	number = {1},
	journaltitle = {International Journal of Psychiatry in Clinical Practice},
	shortjournal = {International Journal of Psychiatry in Clinical Practice},
	author = {Zanardi, Raffaella and Prestifilippo, Dario and Fabbri, Chiara and Colombo, Cristina and Maron, Eduard and Serretti, Alessandro},
	urldate = {2022-09-22},
	date = {2021-03-01},
	langid = {english},
	keywords = {artificial intelligence, psychiatry, depression, personalized medicine, review, clinical practice, human, practice guideline, clinical evaluation, mental health care, priority journal, pharmacogenetics, health practitioner, genotype, biological marker, clinical feature, health care system, standardization, staff training, antidepressant agent, genetic variability, cytochrome, drug monitoring},
	file = {Zanardi et al. - 2021 - Precision psychiatry in clinical practice.pdf:/Users/annekleine/Zotero/storage/W55Y7KJ9/Zanardi et al. - 2021 - Precision psychiatry in clinical practice.pdf:application/pdf},
}

@article{su_etal20,
	title = {Deep learning in mental health outcome research: A scoping review.},
	volume = {10},
	issn = {2158-3188},
	doi = {10.1038/s41398-020-0780-3},
	abstract = {Mental illnesses, such as depression, are highly prevalent and have been shown to impact an individual's physical health. Recently, artificial intelligence ({AI}) methods have been introduced to assist mental health providers, including psychiatrists and psychologists, for decision-making based on patients' historical data (e.g., medical records, behavioral data, social media usage, etc.). Deep learning ({DL}), as one of the most recent generation of {AI} technologies, has demonstrated superior performance in many real-world applications ranging from computer vision to healthcare. The goal of this study is to review existing research on applications of {DL} algorithms in mental health outcome research. Specifically, we first briefly overview the state-of-the-art {DL} techniques. Then we review the literature relevant to {DL} applications in mental health outcomes. According to the application scenarios, we categorize these relevant articles into four groups: diagnosis and prognosis based on clinical data, analysis of genetics and genomics data for understanding mental health conditions, vocal and visual expression data analysis for disease detection, and estimation of risk of mental illness using social media data. Finally, we discuss challenges in using {DL} algorithms to improve our understanding of mental health conditions and suggest several promising directions for their applications in improving mental health diagnosis and treatment.},
	pages = {116},
	number = {1},
	journaltitle = {Translational Psychiatry},
	shortjournal = {Transl Psychiatry},
	author = {Su, Chang and Xu, Zhenxing and Pathak, Jyotishman and Wang, Fei},
	date = {2020},
	note = {Place: United States
Su, Chang. Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, {NY}, {USA}.
Xu, Zhenxing. Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, {NY}, {USA}.
Pathak, Jyotishman. Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, {NY}, {USA}.
Wang, Fei. Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, {NY}, {USA}. few2001@med.cornell.edu.},
	keywords = {*Artificial Intelligence, *Deep Learning, Algorithms, Biomarkers, clinical outcome, convolutional neural network, deep learning, electroencephalography, electronic health record, feed forward neural network, functional magnetic resonance imaging, functional neuroimaging, genetics, genomics, human, Humans, mental disease, mental health, Mental Health, Outcome Assessment, Health Care, Psychiatric disorders, recurrent neural network, review, social media, systematic review},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/IQK395MI/Su et al. - 2020 - Deep learning in mental health outcome research a.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/SYIWAVNR/s41398-020-0780-3.html:text/html},
}

@article{chekroud_etal21a,
	title = {The promise of machine learning in predicting treatment outcomes in psychiatry.},
	volume = {20},
	issn = {1723-8617},
	doi = {10.1002/wps.20882},
	abstract = {For many years, psychiatrists have tried to understand factors involved in response to medications or psychotherapies, in order to personalize their treatment choices. There is now a broad and growing interest in the idea that we can develop models to personalize treatment decisions using new statistical approaches from the field of machine learning and applying them to larger volumes of data. In this pursuit, there has been a paradigm shift away from experimental studies to confirm or refute specific hypotheses towards a focus on the overall explanatory power of a predictive model when tested on new, unseen datasets. In this paper, we review key studies using machine learning to predict treatment outcomes in psychiatry, ranging from medications and psychotherapies to digital interventions and neurobiological treatments. Next, we focus on some new sources of data that are being used for the development of predictive models based on machine learning, such as electronic health records, smartphone and social media data, and on the potential utility of data from genetics, electrophysiology, neuroimaging and cognitive testing. Finally, we discuss how far the field has come towards implementing prediction tools in real-world clinical practice. Relatively few retrospective studies to-date include appropriate external validation procedures, and there are even fewer prospective studies testing the clinical feasibility and effectiveness of predictive models. Applications of machine learning in psychiatry face some of the same ethical challenges posed by these techniques in other areas of medicine or computer science, which we discuss here. In short, machine learning is a nascent but important approach to improve the effectiveness of mental health care, and several prospective clinical studies suggest that it may be working already. Copyright © 2021 World Psychiatric Association.},
	pages = {154--170},
	number = {2},
	journaltitle = {World psychiatry : official journal of the World Psychiatric Association ({WPA})},
	shortjournal = {World Psychiatry},
	author = {Chekroud, Adam M and Bondar, Julia and Delgadillo, Jaime and Doherty, Gavin and Wasil, Akash and Fokkema, Marjolein and Cohen, Zachary and Belgrave, Danielle and {DeRubeis}, Robert and Iniesta, Raquel and Dwyer, Dominic and Choi, Karmel},
	date = {2021},
	note = {Place: Italy
Chekroud, Adam M. Department of Psychiatry, Yale School of Medicine, New Haven, {CT}, {USA}.
Chekroud, Adam M. Spring Health, New York City, {NY}, {USA}.
Bondar, Julia. Spring Health, New York City, {NY}, {USA}.
Delgadillo, Jaime. Clinical Psychology Unit, Department of Psychology, University of Sheffield, Sheffield, {UK}.
Doherty, Gavin. School of Computer Science and Statistics, Trinity College Dublin, Dublin, Ireland.
Wasil, Akash. Department of Psychology, University of Pennsylvania, Philadelphia, {PA}, {USA}.
Fokkema, Marjolein. Department of Methods and Statistics, Institute of Psychology, Leiden University, Leiden, The Netherlands.
Cohen, Zachary. Department of Psychiatry and Biobehavioral Sciences, University of California, Los Angeles, Los Angeles, {CA}, {USA}.
Belgrave, Danielle. Microsoft Research, Cambridge, {UK}.
{DeRubeis}, Robert. Department of Psychology, University of Pennsylvania, Philadelphia, {PA}, {USA}.
Iniesta, Raquel. Department of Biostatistics and Health Informatics, Institute of Psychiatry, Psychology and Neurosciences, King's College London, London, {UK}.
Dwyer, Dominic. Department of Psychiatry and Psychotherapy, Section for Neurodiagnostic Applications, Ludwig-Maximilian University, Munich, Germany.
Choi, Karmel. Harvard T.H. Chan School of Public Health, Boston, {MA}, {USA}.
Choi, Karmel. Department of Psychiatry, Massachusetts General Hospital, Harvard Medical School, Boston, {MA}, {USA}.},
}

@article{su_etal20b,
	title = {Deep learning in mental health outcome research: a scoping review},
	volume = {10},
	issn = {2158-3188},
	doi = {10.1038/s41398-020-0780-3},
	abstract = {Mental illnesses, such as depression, are highly prevalent and have been shown to impact an individual's physical health. Recently, artificial intelligence ({AI}) methods have been introduced to assist mental health providers, including psychiatrists and psychologists, for decision-making based on patients' historical data (e.g., medical records, behavioral data, social media usage, etc.). Deep learning ({DL}), as one of the most recent generation of {AI} technologies, has demonstrated superior performance in many real-world applications ranging from computer vision to healthcare. The goal of this study is to review existing research on applications of {DL} algorithms in mental health outcome research. Specifically, we first briefly overview the state-of-the-art {DL} techniques. Then we review the literature relevant to {DL} applications in mental health outcomes. According to the application scenarios, we categorize these relevant articles into four groups: diagnosis and prognosis based on clinical data, analysis of genetics and genomics data for understanding mental health conditions, vocal and visual expression data analysis for disease detection, and estimation of risk of mental illness using social media data. Finally, we discuss challenges in using {DL} algorithms to improve our understanding of mental health conditions and suggest several promising directions for their applications in improving mental health diagnosis and treatment.},
	number = {1},
	journaltitle = {{TRANSLATIONAL} {PSYCHIATRY}},
	author = {Su, C and Xu, {ZX} and Pathak, J and Wang, F},
	date = {2020-04-22},
}

@article{marco_etal19,
	title = {Patent claims and patent scope},
	volume = {48},
	issn = {0048-7333},
	url = {https://www.sciencedirect.com/science/article/pii/S0048733319301052},
	doi = {10.1016/j.respol.2019.04.014},
	abstract = {Patent scope is one of the important aspects in the debates over “patent quality.” The purported decrease in patent quality over the last decade or two has supposedly led to granting patents of increased breadth, decreased clarity, and questionable validity (in part due to over-breadth). Such patents allegedly diminish the incentives for innovation due to increased transaction costs in the market for technology, more frequent disputes and litigation, trolling behavior, and breakdowns in bargaining. This paper focuses on the patent examination process at the {PTO}, highlighting the relationship between patent scope and the patent examination process. We develop and validate two measurements of patent scope: independent claim length and independent claim count. These metrics—in contrast to other measurements of patent scope—can be calculated before and after examination and enable us to provide the first large-scale analysis of trends in patent scope changes during the examination process. Our results show that applications with narrower scope are associated with a higher probability of grant and a shorter and less intense examination period in comparison to applications with broader scope. Further, we find that the examination process itself tends to narrow the scope of patents relative to the scope at filing, and that the changes are more significant when the duration and intensity of examination is increased. We explain our metrics and make our data available in a public use dataset, which we hope will encourage more research in the evaluation of patent scope, patent examination, and patent quality more broadly.},
	pages = {103790},
	number = {9},
	journaltitle = {Research Policy},
	shortjournal = {Research Policy},
	author = {Marco, Alan C. and Sarnoff, Joshua D. and {deGrazia}, Charles A. W.},
	urldate = {2022-12-22},
	date = {2019-11-01},
	langid = {english},
	keywords = {Patents, Patent claims, Patent examination, Patent quality, Patent scope, {USPTO}},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/9YI3LFAU/S0048733319301052.html:text/html},
}

@misc{WIPOIFIA,
	title = {{WIPO}-{IFIA} {INTERNATIONAL} {SYMPOSIUM} {ON} {THE} {COMMERCIALIZATION} {OF} {PATENTED} {INVENTIONS}},
	file = {wipo_ifia_kul_96_1.doc:/Users/annekleine/Zotero/storage/XVJ3LKAR/wipo_ifia_kul_96_1.doc:application/msword},
}

@article{joo_etal22,
	title = {Technology originality and convergence analysis in the wind power field using patents},
	volume = {15},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1996-1073},
	url = {https://www.mdpi.com/1996-1073/15/9/3316},
	doi = {10.3390/en15093316},
	abstract = {Currently, the world is moving rapidly toward carbon neutrality, and renewable energy technology is very important in carbon neutrality. Among various renewable energy technologies, wind power is attracting much attention due to its sustainability, resource abundance, and high applicability. This study analyzed wind power patents from 2010 to 2021 to derive current global originality and convergence information. For {IP}5 countries, the growth stages of technology and the patent convergence networks were inferred by time series analysis and an association rule mining algorithm, respectively. The results showed that, during the analysis period, about 5000 patents were applied on annual average, and it was analyzed that China held the most patents at 48\%, followed by the {US}, Europe, Korea, and Japan. According to the technology convergence network of patent codes from all the {IP}5 countries, patents related to ‘wind turbines with rotation axes in the wind direction’ occupied a very central position, and ‘power conversion electric or electronic aspects’ and ‘integration of patents related to renewable energy sources in buildings with wind power’ were found to show high connection strength. By country, it was analyzed that the {US} and China showed high patent competitiveness onshore and possessed many ‘independent power conversion cluster’ technologies. The research hypothesis was that technology development trends can be analyzed and the characteristics of each country can be understood through patent analysis in the wind power field. This hypothesis was analyzed through various patent analysis techniques, and this paper has novelty in that it presents the global megatrend in the wind power field through patent analysis and quantitatively presents the current status of technology development in five major countries.},
	pages = {3316},
	number = {9},
	journaltitle = {Energies},
	author = {Joo, Kyungwon and Lee, Mina and Lee, Gooyong},
	urldate = {2022-12-03},
	date = {2022-01},
	langid = {english},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {patent, climate change, association rule mining, technology convergence, wind power},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/3S2Q94J3/Joo et al. - 2022 - Technology Originality and Convergence Analysis in.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/RIH6XF54/3316.html:text/html},
}

@article{oh_etal20a,
	title = {Predicting product development directions for new product planning using patent classification-based link prediction},
	volume = {125},
	issn = {0138-9130, 1588-2861},
	url = {https://link.springer.com/10.1007/s11192-020-03709-w},
	doi = {10.1007/s11192-020-03709-w},
	abstract = {Predicting the possible development directions of a product is useful for planning innovative products. Therefore, a systematic approach based on link prediction is proposed in this study to predict possible development directions of a product. In this approach, a target product is represented as a set of cooperative patent classifications (i.e., product {CPCs}) contained in the patents related to the product, and the new {CPCs} identified by link prediction are considered possible directions for product development. The approach analyzes cooccurrences of {CPCs} in the entire the united states patent and trademark office database to construct a universal {CPC} network, which contains the technological combination records with high potential of success already tried and qualified through patent registration. Next, it constructs a sub-network of the universal network consisting of the product {CPCs} and their adjacent {CPCs} (i.e., candidate {CPC}) and then creates a product-centered network by introducing an artificial product node, which means the target product itself, to the subnetwork. Lastly, applying our link prediction approach, this approach calculates the possibility of entering the product {CPCs} for all candidate {CPCs}. Consequently, we can discover possible technical elements that can flow into the target product. To show the workings of the approach, this study applies it to a case of smartphones and validates its performance. We expect that this approach can provide hints on a product’s future development directions and assist experts and firms in establishing strategic product planning or identifying the new functional development of products.},
	pages = {1833--1876},
	number = {3},
	journaltitle = {Scientometrics},
	shortjournal = {Scientometrics},
	author = {Oh, Seunghyun and Choi, Jaewoong and Ko, Namuk and Yoon, Janghyeok},
	urldate = {2022-12-05},
	date = {2020-12},
	langid = {english},
	file = {Oh et al. - 2020 - Predicting product development directions for new .pdf:/Users/annekleine/Zotero/storage/7R6Y86R7/Oh et al. - 2020 - Predicting product development directions for new .pdf:application/pdf},
}

@article{montecchi_etal13,
	title = {Searching in cooperative patent classification: Comparison between keyword and concept-based search},
	volume = {27},
	issn = {1474-0346},
	url = {https://www.sciencedirect.com/science/article/pii/S1474034613000219},
	doi = {10.1016/j.aei.2013.02.002},
	shorttitle = {Searching in Cooperative Patent Classification},
	abstract = {International patent corpus is a gigantic source containing today about 80million of documents. Every patent is manually analyzed by patent officers and then classified by a specific code called Patent Class ({PC}). Cooperative Patent Classification {CPC} is the new classification system introduced since January 2013 in order to standardize the classification systems of all major patent offices. Like keywords for papers, {PCs} point to the core of the invention, describing concisely what they contain inside. Most of patents strategies are based on {PC} as filter for results therefore the selection of relevant {PCs} is often a primary and crucial activity. This task is considered particularly challenging and only few tools have been specially developed for this purpose. The most efficient tools are provided by patent offices of {EPO} and {WIPO}. This paper analyzes their {PCs} search strategy (mainly based on keyword-based engines) in order to identify main limitations in terms of missing relevant {PCs} (recall) and non-relevant results (precision). Patents have been processed by {KOM}, a semantic patent search tool developed by the authors. Unlike all other {PC} search tools, {KOM} uses semantic parser and many knowledge bases for carrying out a conceptual patent search. Its functioning is described step by step through a detailed analysis pointing out the benefits of a concept-based search vis-à-vis a keyword-based search. An exemplary case is proposed dealing with {CPCs} describing the sterilization of contact lenses. Comparison could be likewise conducted on other {PCs} such as International ({IPC}), European ({ECLA}) or United States ({USPC}) patent classification codes.},
	pages = {335--345},
	number = {3},
	journaltitle = {Advanced Engineering Informatics},
	shortjournal = {Advanced Engineering Informatics},
	author = {Montecchi, Tiziano and Russo, Davide and Liu, Ying},
	urldate = {2022-12-06},
	date = {2013-08-01},
	langid = {english},
	keywords = {Concept-based search, Patent classification, Patent mining},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/A6XUTEFS/S1474034613000219.html:text/html},
}

@article{wang_etal19k,
	title = {An approach to identify emergent topics of technological convergence: A case study for 3D printing},
	volume = {146},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162518301641},
	doi = {10.1016/j.techfore.2018.12.015},
	shorttitle = {An approach to identify emergent topics of technological convergence},
	abstract = {Technological Convergence ({TC}) reflects developmental processes that overlap different technological fields. It holds promise to yield outcomes that exceed the sum of its subparts. Measuring emergence for a {TC} environment can inform innovation management. This paper suggests a novel approach to identify Emergent Topics ({ETopics}) of the {TC} environment within a target technology domain using patent information. A non-{TC} environment is constructed as a comparison group. First, {TC} is operationalized as a co-classification of a given patent into multiple 4-digit {IPC} codes (≥2-{IPC}). We take a set of patents and parse those into three sub-datasets based on the number of {IPC} codes assigned 1-{IPC} (Non-{TC}), 2-{IPC} and ≥3-{IPC}. Second, a method is applied to identify emergent terms ({ETs}) and calculate emergence score for each term in each sub-dataset. Finally, we cluster those {ETs} using Principal Components Analysis ({PCA}) to generate a factor map with {ETopics}. A convergent domain -- 3D printing -- is selected to present the illustrative results. Results affirm that for 3D printing, emergent topics in {TC} patents are distinctly different from those in non-{TC} patents. The number of {ETs} in the {TC} environment is increasing annually.},
	pages = {723--732},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Wang, Zhinan and Porter, Alan L. and Wang, Xuefeng and Carley, Stephen},
	urldate = {2022-12-06},
	date = {2019-09},
	langid = {english},
	file = {Wang et al. - 2019 - An approach to identify emergent topics of technol.pdf:/Users/annekleine/Zotero/storage/ZS9IL2D9/Wang et al. - 2019 - An approach to identify emergent topics of technol.pdf:application/pdf},
}

@article{caviggioli16,
	title = {Technology fusion: identification and analysis of the drivers of technology convergence using patent data},
	volume = {55-56},
	issn = {01664972},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0166497216300293},
	doi = {10.1016/j.technovation.2016.04.003},
	shorttitle = {Technology fusion},
	abstract = {The concepts of technology convergence or technology fusion describe the phenomenon of technology overlap. Despite evidence of the higher value associated to interdisciplinary research and cross-industry innovation, few studies have investigated the characteristics of technology fusion based on patent data. This study identiﬁes new cases of convergence relying on the International Patent Classiﬁcation ({IPC}) of patents ﬁled at the European Patent Ofﬁce between 1991 and 2007: the ﬁrst occurrence of a patent incorporating a combination of {IPC} subclasses signals a new instance of fusion. Duration models are employed to investigate the impact of ﬁeld level characteristics derived from patent bibliometrics on the likelihood of identifying a new fusion. The results show that merges are more frequent if the focal technology ﬁelds are closely related (based on a higher number of cross citations), are characterized by wide technological scope, and are the result of an inter-ﬁrm collaboration. In contrast to previous ﬁndings, the results show that the more complex the technologies involved, the less the likelihood of their convergence or fusion. The correlation between fusion likelihood and the characteristics of the merging ﬁelds could help managers and policymakers to predict the emergence of new technology areas.},
	pages = {22--32},
	journaltitle = {Technovation},
	shortjournal = {Technovation},
	author = {Caviggioli, Federico},
	urldate = {2022-12-07},
	date = {2016-09},
	langid = {english},
	file = {Caviggioli - 2016 - Technology fusion Identification and analysis of .pdf:/Users/annekleine/Zotero/storage/7W4Z6J2N/Caviggioli - 2016 - Technology fusion Identification and analysis of .pdf:application/pdf},
}

@misc{oh_etal18,
	title = {A Study on the Technology Convergence of Artificial Intelligence through Patent Analysis},
	url = {https://doi.org/10.24507/icicel.12.07.699},
	doi = {10.24507/icicel.12.07.699},
	abstract = {Since the patents contain original information on technology, it can investigate changes in technology and the convergence phenomenon with co-classiﬁcation analysis of {IPC} (International Patent Classiﬁcation) code indicating the technology group of the patents. In this research, we analyzed the changes of technological convergence for artiﬁcial intelligence ({AI}) technology, which was recently studied actively. We collected Korean patent documents using {KIPRIS} (Korea Intellectual Property Rights Information Service) and analyzed social networks of {IPC} codes of the patents. Additionally, the convergence types could be reviewed using network centrality and clique analysis. {AI} technology mainly focuses on data processing systems (G06F, G06Q). Although there were many technologies that utilized telecommunication services (H04) in the past, technologies related to computing, calculating and counting (G06) have been mainly used in recent years. We also could ﬁnd that there was a change in the technology area where {AI} mainly focused.},
	number = {07},
	publisher = {{ICIC} International 学会},
	author = {Oh, {HoYeon} and Lee, Hong Joo and Chang, Tai-Woo},
	urldate = {2022-12-07},
	date = {2018},
	langid = {english},
	file = {Oh et al. - 2018 - A Study on the Technology Convergence of Artificia.pdf:/Users/annekleine/Zotero/storage/YFQRCV34/Oh et al. - 2018 - A Study on the Technology Convergence of Artificia.pdf:application/pdf},
}

@article{lee_etal15a,
	title = {Predicting the pattern of technology convergence using big-data technology on large-scale triadic patents},
	volume = {100},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162515002310},
	doi = {10.1016/j.techfore.2015.07.022},
	abstract = {Understanding technology convergence became crucial for pursuing innovation and economic growth. This paper attempts to predict the pattern of technology convergence by jointly applying the Association Rule and Link Prediction to entire {IPCs} related to triadic patents filed during the period from 1955 to 2011. We further use a topic model to discover emerging areas of the predicted technology convergence. The results show that the medical area is in the center of convergence, and we predict that technologies for treating respiratory system/blood/sense disorders are associated with the technologies of genetic engineering/peptide/heterocyclic compounds. After eliminating the majority of convergence, we found the convergence pattern among activating catalysts, printing, advanced networking, controlling devices, secured communication with in-memory system, television system with pattern recognition, and image processing and analyzing technologies. The results of our study are expected to contribute to firms that seek new innovative technological domain.},
	pages = {317--329},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Lee, Won Sang and Han, Eun Jin and Sohn, So Young},
	urldate = {2022-12-16},
	date = {2015-11-01},
	langid = {english},
	keywords = {Big data, Topic model, Association rule, Link prediction, Technology convergence, Triadic patents},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/SLQG2VRC/S0040162515002310.html:text/html},
}

@article{pavlopoulos_etal08,
	title = {Arena3D: visualization of biological networks in 3D},
	volume = {2},
	issn = {1752-0509},
	url = {https://doi.org/10.1186/1752-0509-2-104},
	doi = {10.1186/1752-0509-2-104},
	shorttitle = {Arena3D},
	abstract = {Complexity is a key problem when visualizing biological networks; as the number of entities increases, most graphical views become incomprehensible. Our goal is to enable many thousands of entities to be visualized meaningfully and with high performance.},
	pages = {104},
	number = {1},
	journaltitle = {{BMC} Systems Biology},
	shortjournal = {{BMC} Systems Biology},
	author = {Pavlopoulos, Georgios A. and O'Donoghue, Seán I. and Satagopam, Venkata P. and Soldatos, Theodoros G. and Pafilis, Evangelos and Schneider, Reinhard},
	urldate = {2022-12-25},
	date = {2008-11-28},
	keywords = {Affinity Propagation, Distance Geometry, Indirect Connection, Layout Algorithm, Visualization Tool},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/73SM8UIE/Pavlopoulos et al. - 2008 - Arena3D visualization of biological networks in 3.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/JBA5T9HL/1752-0509-2-104.html:text/html},
}

@article{kim_kim12,
	title = {On a patent analysis method for technological convergence},
	volume = {40},
	issn = {18770428},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877042812007124},
	doi = {10.1016/j.sbspro.2012.03.245},
	abstract = {An important feature in recent innovation trend is the merging and overlapping of technologies, i.e. the technological convergence. The paper proposes two approaches using patent data to examine the technological convergence. First, we conduct a patent network analysis using the patent citation, which can be considered as a knowledge flow among technological fields. Second, in order for more specific analysis, the co-classification among technologies is carried out to measure the convergence intensity, rate, and coverage. Finally, by using the coverage intensity and rate, we propose two portfolio matrices to manage the technological convergence.},
	pages = {657--663},
	journaltitle = {Procedia - Social and Behavioral Sciences},
	shortjournal = {Procedia - Social and Behavioral Sciences},
	author = {Kim, Moon-Soo and Kim, Chulhyun},
	urldate = {2023-01-06},
	date = {2012},
	langid = {english},
	file = {Kim and Kim - 2012 - On A Patent Analysis Method for Technological Conv.pdf:/Users/annekleine/Zotero/storage/6MS2KJIP/Kim and Kim - 2012 - On A Patent Analysis Method for Technological Conv.pdf:application/pdf},
}

@book{curran13,
	location = {London},
	title = {The anticipation of converging industries. a concept applied to nutraceuticals and Functional Foods},
	url = {https://link.springer.com/book/10.1007/978-1-4471-5170-8},
	publisher = {Springer},
	author = {Curran, C. S.},
	date = {2013},
	note = {https://doi.org/10.1007/978-1-4471-5170-8},
}

@article{no_park10,
	title = {Trajectory patterns of technology fusion: trend analysis and taxonomical grouping in nanobiotechnology},
	volume = {77},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162509000778},
	doi = {10.1016/j.techfore.2009.06.006},
	shorttitle = {Trajectory patterns of technology fusion},
	abstract = {The potential of technology fusion has been advanced as a promising breakthrough function to create hybrid technologies. Despite its importance, however, the evolutionary path of technology fusion is yet unexplored. In this paper, by employing the case of nanobiotechnology, we attempt to deepen understanding of the development trajectories of technology fusion in three important aspects. The first aspect is the development of an index that measures the degree of fusion of cross-disciplinary technology at the meso level. The second aspect is to classify the trajectory patterns of technology fusion in terms of fusion degree. We analyze fusion mechanism by utilizing citation network analysis. The third aspect is to visualize the relationship between patents and their backward and forward patent citations, at the patent class level, with their direction on a citation map. This facilitates understanding of the overview as well as fusion patterns. The changes in fusion patterns are analyzed using time series comparisons. An empirical analysis in the nanobiotechnology field shows no positive relationship between the inflow and outflow degree of fusion. We also observe changes in the trajectory patterns of fusion over time. Analysis demonstrates that each fusion pattern has evolved in such a way that technologies focus more on their niche technologies, and that those technologies which cannot incorporate the technology fusion have been eliminated during the development process.},
	pages = {63--75},
	number = {1},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {No, Hyun Joung and Park, Yongtae},
	urldate = {2023-01-08},
	date = {2010-01-01},
	langid = {english},
	keywords = {Cross-disciplinarity, Fusion degree, Patent citation networks, Taxonomical grouping, Technology fusion},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/SMWA9FWL/S0040162509000778.html:text/html},
}

@online{Derwent,
	title = {Derwent Innovations Index Help},
	url = {https://images.webofknowledge.com/WOKRS535R100/help/DII/hs_glossary.html},
	urldate = {2022-11-03},
	file = {Derwent Innovations Index Help:/Users/annekleine/Zotero/storage/IX4YQBZW/hs_glossary.html:text/html},
}

@article{fujii_managi18,
	title = {Trends and priority shifts in artificial intelligence technology invention: A global patent analysis},
	volume = {58},
	issn = {03135926},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0313592617302539},
	doi = {10.1016/j.eap.2017.12.006},
	shorttitle = {Trends and priority shifts in artificial intelligence technology invention},
	abstract = {Artificial intelligence ({AI}) technology can play a critical role in economic development, resource conservation, and environmental protection by increasing efficiency. This study is the first to apply a decomposition framework to clarify the determinants of {AI} technology invention. Exploiting data from the World Intellectual Property Organization, this study clarifies the determining factors that contribute to {AI} technology patent publications based on technology type. Consisting of 13,567 {AI} technology patents for the 2000-2016 period, our worldwide dataset includes patent publication data from the United States, Japan, China, Europe, and the Patent Cooperation Treaty ({PCT}). We find that priority has shifted from biological- and knowledge-based models to specific mathematical models and other {AI} technologies, particularly in the United States and Japan. Our technology type and country comparison shows that the characteristics of {AI} technology patent publication differ among companies and countries.},
	pages = {60--69},
	journaltitle = {Economic Analysis and Policy},
	shortjournal = {Economic Analysis and Policy},
	author = {Fujii, Hidemichi and Managi, Shunsuke},
	urldate = {2022-12-06},
	date = {2018-06},
	langid = {english},
	file = {Fujii and Managi - 2018 - Trends and priority shifts in artificial intellige.pdf:/Users/annekleine/Zotero/storage/QPDJU573/Fujii and Managi - 2018 - Trends and priority shifts in artificial intellige.pdf:application/pdf},
}

@article{baum_etal21,
	title = {Artificial Intelligence in Chemistry: Current Trends and Future Directions},
	abstract = {The application of artiﬁcial intelligence ({AI}) to chemistry has grown tremendously in recent years. In this Review, we studied the growth and distribution of {AI}-related chemistry publications in the last two decades using the {CAS} Content Collection. The volume of both journal and patent publications have increased dramatically, especially since 2015. Study of the distribution of publications over various chemistry research areas revealed that analytical chemistry and biochemistry are integrating {AI} to the greatest extent and with the highest growth rates. We also investigated trends in interdisciplinary research and identiﬁed frequently occurring combinations of research areas in publications. Furthermore, topic analyses were conducted for journal and patent publications to illustrate emerging associations of {AI} with certain chemistry research topics. Notable publications in various chemistry disciplines were then evaluated and presented to highlight emerging use cases. Finally, the occurrence of diﬀerent classes of substances and their roles in {AI}-related chemistry research were quantiﬁed, further detailing the popularity of {AI} adoption in the life sciences and analytical chemistry. In summary, this Review oﬀers a broad overview of how {AI} has progressed in various ﬁelds of chemistry and aims to provide an understanding of its future directions.},
	pages = {16},
	journaltitle = {J. Chem. Inf. Model.},
	author = {Baum, Zachary J and Yu, Xiang and Ayala, Philippe Y and Zhao, Yanan and Watkins, Steven P and Zhou, Qiongqiong},
	date = {2021},
	langid = {english},
	file = {Baum et al. - 2021 - Artificial Intelligence in Chemistry Current Tren.pdf:/Users/annekleine/Zotero/storage/MCLI2NUC/Baum et al. - 2021 - Artificial Intelligence in Chemistry Current Tren.pdf:application/pdf},
}

@misc{allison_etal03,
	location = {Rochester, {NY}},
	title = {Valuable patents},
	url = {https://papers.ssrn.com/abstract=426020},
	abstract = {While the theory of the patent system is premised on the idea that patents will be used to exclude competitors, only a tiny fraction of patents are ever enforced. Legal and economic scholars have theorized as to how to identify valuable patents based on their individual characteristics. In this paper, we present the results of the largest empirical study ever conducted of the patent system. We compare the characteristics of litigated patents to those of issued patents generally, and we find important differences in a range of dimensions. These data confirm some predictions in the literature regarding patent value and refute others. New patents are more likely to be litigated than old patents. Foreign patent owners are less likely to litigate than domestic patent owners. Patents that issue to individuals or small companies are much more likely to be litigated than those that issue to big companies, though many of those patents have changed hands by the time they are brought to court. Patents that cite more prior art are more likely to be litigated, and those that are litigated tend to be cited more elsewhere. Most significantly, there are substantial differences between industries in the likelihood of patent litigation.  Patents in the mechanical, computer, and medical device industries are significantly more likely to be litigated, for example, than patents in the chemical and semiconductor industries.},
	number = {426020},
	author = {Allison, John R. and Lemley, Mark A. and Moore, Kimberly A. and Trunkey, R. Derek},
	urldate = {2022-12-07},
	date = {2003-07-30},
	langid = {english},
	keywords = {intellectual property, patents, patent litigation, patent valuation},
	file = {delivery.pdf:/Users/annekleine/Zotero/storage/7KW8G95E/delivery.pdf:application/pdf;Full Text PDF:/Users/annekleine/Zotero/storage/5XG5EY5B/Allison et al. - 2003 - Valuable Patents.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/GM7CXGZR/papers.html:text/html},
}

@article{sichelman10,
	title = {Commercializing patents},
	volume = {62},
	url = {https://heinonline.org/HOL/LandingPage?handle=hein.journals/stflr62&div=12&id=&page=},
	journaltitle = {Stanford Law Review},
	author = {Sichelman, Ted},
	date = {2010},
	langid = {english},
	file = {Sichelman - COMMERCIALIZING PATENTS.pdf:/Users/annekleine/Zotero/storage/9ATWEUT8/Sichelman - COMMERCIALIZING PATENTS.pdf:application/pdf},
}

@article{boeing_mueller19,
	title = {Measuring China's patent quality: development and validation of {ISR} indices},
	volume = {57},
	issn = {1043-951X},
	url = {https://www.sciencedirect.com/science/article/pii/S1043951X19300926},
	doi = {10.1016/j.chieco.2019.101331},
	shorttitle = {Measuring China's patent quality},
	abstract = {Because China has become one of the largest applicants of {PCT} patents, it is of interest to compare the quality of Chinese and non-Chinese applications. We extend a quality index based on internationally comparable citation data from international search reports ({ISR}) to consider foreign, domestic, and self citations. Whereas foreign citations show that Chinese {PCT} patent applications reach only a third of the non-Chinese quality benchmark, the extension towards domestic and self citations suggests a higher quality level that converges to or even surpasses the benchmark. We investigate these differences based on firm-level regressions and find that in China, only foreign citations, but not domestic and self citations, have a significant and positive relation to R\&D stocks. Using Germany as a representative country without policy support for patenting, we show that all three citation types may be used as economic indicators if policy distortion is not a concern. Our results show that domestic and self citations suffer from an upward bias in China and should be employed with caution if they are to be interpreted as a measure of patent quality.},
	journaltitle = {China Economic Review},
	shortjournal = {China Economic Review},
	author = {Boeing, Philipp and Mueller, Elisabeth},
	urldate = {2023-01-09},
	date = {2019-10-01},
	langid = {english},
	keywords = {China, Patent quality, Cross-country comparison},
	file = {Submitted Version:/Users/annekleine/Zotero/storage/UVVDHSKB/Boeing and Mueller - 2019 - Measuring China's patent quality Development and .pdf:application/pdf},
}

@article{boeing_mueller16,
	title = {Measuring patent quality in cross-country comparison},
	volume = {149},
	issn = {0165-1765},
	url = {https://www.sciencedirect.com/science/article/pii/S0165176516304475},
	doi = {10.1016/j.econlet.2016.10.039},
	abstract = {Our novel quality index is based on citations from international search reports and provides internationally comparable, quality-adjusted figures for applications made under the Patent Cooperation Treaty ({PCT}). We show that China’s recent patent expansion has taken place to the detriment of patent quality. Weighting national {PCT} counts with our index reveals a widening gap between the technological capacities of China and the leading {USA}.},
	pages = {145--147},
	journaltitle = {Economics Letters},
	shortjournal = {Economics Letters},
	author = {Boeing, Philipp and Mueller, Elisabeth},
	urldate = {2023-01-09},
	date = {2016-12-01},
	langid = {english},
	keywords = {Patent quality, Cross-country comparison},
}

@article{torrance_west17,
	title = {All patents great and small: a big data network approach to valuation},
	volume = {20},
	pages = {468--504},
	number = {3},
	journaltitle = {Virginia Journal of Law and Technology},
	author = {Torrance, Andrew W and West, Jevin D},
	date = {2017},
	langid = {english},
	file = {Torrance and West - 2017 - All Patents Great and Small.pdf:/Users/annekleine/Zotero/storage/FZAGPZM6/Torrance and West - 2017 - All Patents Great and Small.pdf:application/pdf},
}

@article{jacoby00,
	title = {Loess:: a nonparametric, graphical tool for depicting relationships between variables},
	volume = {19},
	issn = {0261-3794},
	url = {https://www.sciencedirect.com/science/article/pii/S0261379499000281},
	doi = {10.1016/S0261-3794(99)00028-1},
	shorttitle = {Loess},
	abstract = {Loess is a powerful but simple strategy for fitting smooth curves to empirical data. The term “loess” is an acronym for “local regression” and the entire procedure is a fairly direct generalization of traditional least-squares methods for data analysis. Loess is nonparametric in the sense that the fitting technique does not require an a priori specification of the relationship between the dependent and independent variables. Although it is used most frequently as a scatterplot smoother, loess can be generalized very easily to multivariate data; there are also inferential procedures for confidence intervals and other statistical tests. For all of these reasons, loess is a useful tool for data exploration and analysis in the social sciences. And, loess should be particularly helpful in the field of elections and voting behavior because theories often lead to expectations of nonlinear empirical relationships even though prior substantive considerations provide very little guidance about precise functional forms.},
	pages = {577--613},
	number = {4},
	journaltitle = {Electoral Studies},
	shortjournal = {Electoral Studies},
	author = {Jacoby, William G.},
	urldate = {2022-12-25},
	date = {2000-12-01},
	langid = {english},
	keywords = {Generalized additive models, Loess, Lowess, Nonparametric regression, Scatterplot smoothing, Statistical graphics},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/7TLZ3K7D/S0261379499000281.html:text/html},
}

@article{krestel_etal21,
	title = {A survey on deep learning for patent analysis},
	volume = {65},
	issn = {0172-2190},
	url = {https://www.sciencedirect.com/science/article/pii/S017221902100017X},
	doi = {10.1016/j.wpi.2021.102035},
	abstract = {Patent document collections are an immense source of knowledge for research and innovation communities worldwide. The rapid growth of the number of patent documents poses an enormous challenge for retrieving and analyzing information from this source in an effective manner. Based on deep learning methods for natural language processing, novel approaches have been developed in the field of patent analysis. The goal of these approaches is to reduce costs by automating tasks that previously only domain experts could solve. In this article, we provide a comprehensive survey of the application of deep learning for patent analysis. We summarize the state-of-the-art techniques and describe how they are applied to various tasks in the patent domain. In a detailed discussion, we categorize 40 papers based on the dataset, the representation, and the deep learning architecture that were used, as well as the patent analysis task that was targeted. With our survey, we aim to foster future research at the intersection of patent analysis and deep learning and we conclude by listing promising paths for future work.},
	pages = {102035},
	journaltitle = {World Patent Information},
	shortjournal = {World Patent Information},
	author = {Krestel, Ralf and Chikkamath, Renukswamy and Hewel, Christoph and Risch, Julian},
	urldate = {2022-10-18},
	date = {2021-06-01},
	langid = {english},
	keywords = {Deep learning, Natural language processing, Patent analysis, Text mining},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/5DDUDTY7/S017221902100017X.html:text/html},
}

@article{zhang_etal21i,
	title = {Integrating patent analysis into technology roadmapping: A latent dirichlet allocation based technology assessment and roadmapping in the field of Blockchain},
	volume = {167},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S004016252100161X},
	doi = {10.1016/j.techfore.2021.120729},
	shorttitle = {Integrating patent analysis into technology roadmapping},
	abstract = {This study develops a new analysis method, the latent Dirichlet allocation topic model, and uses it to perform technology assessment and roadmapping analysis of the blockchain field based on patent data. Our results describe the current state of technology development and predict future development trends. The new analysis method is based on technology life cycle theory, the latent Dirichlet allocation topic model, and text similarity calculation, enabling a more effective analysis of the status of R\&D in the blockchain field. We find that research on the theory of blockchain, blockchain trading systems, blockchain system structure, and intelligent financial systems based on blockchain should be prioritized to realize the full benefits of this technology.},
	pages = {120729},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Zhang, Hao and Daim, Tugrul and Zhang, Yunqiu (Peggy)},
	urldate = {2022-11-03},
	date = {2021-06},
	langid = {english},
	file = {Zhang et al. - 2021 - Integrating patent analysis into technology roadma.pdf:/Users/annekleine/Zotero/storage/PL7FBNTP/Zhang et al. - 2021 - Integrating patent analysis into technology roadma.pdf:application/pdf},
}

@article{kim_bae17,
	title = {A novel approach to forecast promising technology through patent analysis},
	volume = {117},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162516307661},
	doi = {10.1016/j.techfore.2016.11.023},
	abstract = {Forecasting promising technology is a relevant opportunity for management of companies and countries. Furthermore, researchers in research and development (R\&D) have recently considered that patents include detailed information on developed technologies. For these reasons, we suggest a novel approach to forecasting {PT} using patent analysis. The overall process of the proposed methodology consists of three steps. First, to form technology clusters, we clustered patent documents on the basis of the cooperative patent classiﬁcation ({CPC}), which represents a more detailed technology classiﬁcation system than the international patent classiﬁcation ({IPC}). Second, regarding the process of deﬁning technology clusters, we examined the combination of {CPCs} of each formed clusters. Finally, patent indicators such as forward citations, triadic patent families, and independent claims are analyzed to assess whether the technology clusters are promising. We collected patent data on the wellness care industry from the United States Patent and Trademark Ofﬁce ({USPTO}) to verify the proposed methodology.},
	pages = {228--237},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Kim, Gabjo and Bae, Jinwoo},
	urldate = {2022-11-03},
	date = {2017-04},
	langid = {english},
	file = {Kim and Bae - 2017 - A novel approach to forecast promising technology .pdf:/Users/annekleine/Zotero/storage/UZLWMQIB/Kim and Bae - 2017 - A novel approach to forecast promising technology .pdf:application/pdf},
}

@article{breitzman_mogee02,
	title = {The many applications of patent analysis},
	volume = {28},
	issn = {0165-5515},
	url = {https://doi.org/10.1177/016555150202800302},
	doi = {10.1177/016555150202800302},
	abstract = {The use of patent analysis in many different contexts is discussed. Applications discussed range from intellectual property management, to merger and acquisition targeting and due diligence, to stock market valuation. The authors draw on 38 years of combined patent-related experience to discuss a number of techniques and metrics that have been found to work well in specific situations.},
	pages = {187--205},
	number = {3},
	journaltitle = {Journal of Information Science},
	author = {Breitzman, Anthony F. and Mogee, Mary Ellen},
	urldate = {2022-11-03},
	date = {2002-06-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd},
	file = {Breitzman and Mogee - 2002 - The many applications of patent analysis.pdf:/Users/annekleine/Zotero/storage/EGFR6QW2/Breitzman and Mogee - 2002 - The many applications of patent analysis.pdf:application/pdf},
}

@article{evangelista_etal20,
	title = {Unveiling the technological trends of augmented reality: A patent analysis},
	volume = {118},
	issn = {01663615},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0166361519310899},
	doi = {10.1016/j.compind.2020.103221},
	shorttitle = {Unveiling the technological trends of augmented reality},
	pages = {103221},
	journaltitle = {Computers in Industry},
	shortjournal = {Computers in Industry},
	author = {Evangelista, Alessandro and Ardito, Lorenzo and Boccaccio, Antonio and Fiorentino, Michele and Messeni Petruzzelli, Antonio and Uva, Antonio E.},
	urldate = {2022-11-03},
	date = {2020-06},
	langid = {english},
	file = {Evangelista et al. - 2020 - Unveiling the technological trends of augmented re.pdf:/Users/annekleine/Zotero/storage/U5W7QZER/Evangelista et al. - 2020 - Unveiling the technological trends of augmented re.pdf:application/pdf},
}

@article{ailia_etal22,
	title = {Current Trend of Artificial Intelligence Patents in Digital Pathology: A Systematic Evaluation of the Patent Landscape},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-6694},
	url = {https://www.mdpi.com/2072-6694/14/10/2400},
	doi = {10.3390/cancers14102400},
	shorttitle = {Current Trend of Artificial Intelligence Patents in Digital Pathology},
	abstract = {The integration of digital pathology ({DP}) with artificial intelligence ({AI}) enables faster, more accurate, and thorough diagnoses, leading to more precise personalized treatment. As technology is advancing rapidly, it is critical to understand the current state of {AI} applications in {DP}. Therefore, a patent analysis of {AI} in {DP} is required to assess the application and publication trends, major assignees, and leaders in the field. We searched five major patent databases, namely, those of the {USPTO}, {EPO}, {KIPO}, {JPO}, and {CNIPA}, from 1974 to 2021, using keywords such as {DP}, {AI}, machine learning, and deep learning. We discovered 6284 patents, 523 of which were used for trend analyses on time series, international distribution, top assignees; word cloud analysis; and subject category analyses. Patent filing and publication have increased exponentially over the past five years. The United States has published the most patents, followed by China and South Korea (248, 117, and 48, respectively). The top assignees were Paige.{AI}, Inc. (New York City, {NY}, {USA}) and Siemens, Inc. (Munich, Germany) The primary areas were whole-slide imaging, segmentation, classification, and detection. Based on these findings, we expect a surge in {DP} and {AI} patent applications focusing on the digitalization of pathological images and {AI} technologies that support the vital role of pathologists.},
	pages = {2400},
	number = {10},
	journaltitle = {Cancers},
	author = {Ailia, Muhammad Joan and Thakur, Nishant and Abdul-Ghafar, Jamshid and Jung, Chan Kwon and Yim, Kwangil and Chong, Yosep},
	urldate = {2022-07-06},
	date = {2022-01},
	langid = {english},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial intelligence, deep learning, digital pathology, intellectual property, patents},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/LV3FY9IG/Ailia et al. - 2022 - Current Trend of Artificial Intelligence Patents i.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/4XUYACUH/htm.html:text/html},
}

@article{altuntas_etal15,
	title = {Forecasting technology success based on patent data},
	volume = {96},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162515000700},
	doi = {10.1016/j.techfore.2015.03.011},
	abstract = {A novel method for forecasting technology success based on patent data is proposed. Four criteria, technology life cycle, diffusion speed, patent power, and expansion potential are considered for technology forecasting. Patent power and expansion potential are considered as technology scope indicators. A data fusion algorithm is applied to combine the results obtained from different criteria. The usefulness and potential of the proposed forecasting approach has been demonstrated using all U.S. patents related to three technologies, namely thin film transistor-liquid crystal display, flash memory system, and personal digital assistant. The results obtained from these patents demonstrate that the personal digital assistant technology is preferred over other technologies. Investments in thin film transistor liquid-crystal display and flash memory system technologies have equal priority.},
	pages = {202--214},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Altuntas, Serkan and Dereli, Turkay and Kusiak, Andrew},
	urldate = {2022-11-04},
	date = {2015-07-01},
	langid = {english},
	keywords = {Patent analysis, Condorcet method, Technology diffusion, Technology forecasting, Technology life cycle, Technology scope},
	file = {Altuntas et al. - 2015 - Forecasting technology success based on patent dat.pdf:/Users/annekleine/Zotero/storage/YNJ3CYEK/Altuntas et al. - 2015 - Forecasting technology success based on patent dat.pdf:application/pdf;ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/CMTKWCKJ/S0040162515000700.html:text/html},
}

@article{park_etal15,
	title = {A Network Analysis Model for Selecting Sustainable Technology},
	volume = {7},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/7/10/13126},
	doi = {10.3390/su71013126},
	abstract = {Most companies develop technologies to improve their competitiveness in the marketplace. Typically, they then patent these technologies around the world in order to protect their intellectual property. Other companies may use patented technologies to develop new products, but must pay royalties to the patent holders or owners. Should they fail to do so, this can result in legal disputes in the form of patent infringement actions between companies. To avoid such situations, companies attempt to research and develop necessary technologies before their competitors do so. An important part of this process is analyzing existing patent documents in order to identify emerging technologies. In such analyses, extracting sustainable technology from patent data is important, because sustainable technology drives technological competition among companies and, thus, the development of new technologies. In addition, selecting sustainable technologies makes it possible to plan their R\&D (research and development) efficiently. In this study, we propose a network model that can be used to select the sustainable technology from patent documents, based on the centrality and degree of a social network analysis. To verify the performance of the proposed model, we carry out a case study using actual patent data from patent databases.},
	pages = {13126--13141},
	number = {10},
	journaltitle = {Sustainability},
	author = {Park, Sangsung and Lee, Seung-Joo and Jun, Sunghae},
	urldate = {2022-11-04},
	date = {2015-10},
	langid = {english},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {centrality measure, egocentric network, international patent classification code, sustainable technology, technology analysis},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/VFSUK3TE/Park et al. - 2015 - A Network Analysis Model for Selecting Sustainable.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/FJZRHVM8/htm.html:text/html},
}

@article{jun_sungpark13,
	title = {Examining technological innovation of Apple using patent analysis},
	volume = {113},
	issn = {0263-5577},
	url = {https://doi.org/10.1108/IMDS-01-2013-0032},
	doi = {10.1108/IMDS-01-2013-0032},
	abstract = {Purpose – Apple is a representative company of technological innovation ({TI}) and management. It has launched new and innovative products since 1977, and many companies and business schools around the world have attempted to learn about the success story of Apple's innovation. However, most previous research works on Apple's innovation have been based on qualitative approaches such as experts' opinions. Such studies offer a subjective point of view. By contrast, in this paper the authors aim to study the {TI} and forecasting of Apple by analyzing its patent applications, which is an objective approach to examining the innovation of Apple from a technological perspective. Design/methodology/approach – {TI} is an important issue concerning technology management for companies and governments. To examine Apple's {TI}, the authors analyze all applied patents and construct analytical models according to three approaches. First, they build statistical models using the time series regression and multiple linear regression methods to create a technology map. Second, they cluster all Apple's patents to find its vacant technology domain. Lastly, they use social network analysis to search for technologies central to Apple's future. Findings – The authors' study shows the technological trends and relations between Apple's technologies. This research finds vacant technology areas and central technologies for Apple's {TI}. Practical implications – Using statistical and machine learning methods, the authors analyze all Apple's patents in order to predict the firm's future technologies. This research contributes to examining the {TI} of Apple. Therefore, the results of the patent analysis can highlight the technological opportunities for Apple's {TI}. Originality/value – Traditional {TI} models have been based on qualitative methods. Previous investigations of Apple's {TI} have also relied on traditional analytical approaches. In this paper, however, the authors develop a quantitative and objective approach for examining Apple's {TI}.},
	pages = {890--907},
	number = {6},
	journaltitle = {Industrial Management \& Data Systems},
	author = {Jun, Sunghae and Sung Park, Sang},
	urldate = {2022-11-04},
	date = {2013-01-01},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Regression, Social networks, Apple Inc, Innovation, Patent clustering, Patents, Regression analysis, Social network analysis, Technological innovation, Vacant and central technologies},
	file = {Jun and Sung Park - 2013 - Examining technological innovation of Apple using .pdf:/Users/annekleine/Zotero/storage/6EYQK88C/Jun and Sung Park - 2013 - Examining technological innovation of Apple using .pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/8UUGJA37/html.html:text/html},
}

@article{no_etal15,
	title = {A structured approach to explore knowledge flows through technology-based business methods by integrating patent citation analysis and text mining},
	volume = {97},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162514001280},
	doi = {10.1016/j.techfore.2014.04.007},
	abstract = {With information and communication technology ({ICT}) as an enabling platform, diversified new business methods ({BMs}) have been developed. These new technology-based {BMs} have played an important role in knowledge flow as they became a patentable subject matter. However, there are not many studies on knowledge flow through the technology-based {BMs} or {BM} patents in spite of its importance. As an attempt to provide a deeper understanding of technology-based {BMs} with regard to knowledge flow, this paper explores knowledge flows driven by the technology-based {BMs} through investigating both cited and citing patents. In order to explore the knowledge flows, this paper proposes an algorithm that utilizes both the citation and textual information of {BM} patents. In addition to citation information, text data in patent documents are used to measure the degree of knowledge flow in a more accurate way. A case study is conducted with the {BM} patents related to postage metering system and the analysis result is presented in a positioning map that shows different knowledge flow patterns of technological classes. Moreover, the technology-based {BM} patents as knowledge flow drivers are classified based on the amount of knowledge exchanged between the base {BM} patents and their patent citations.},
	pages = {181--192},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {No, Hyun Joung and An, Yoonjung and Park, Yongtae},
	urldate = {2022-11-04},
	date = {2015-08},
	langid = {english},
	file = {No et al. - 2015 - A structured approach to explore knowledge flows t.pdf:/Users/annekleine/Zotero/storage/LZ6XQVWJ/No et al. - 2015 - A structured approach to explore knowledge flows t.pdf:application/pdf},
}

@article{jurgens_clarke19,
	title = {Evolution of {CAR} T-cell immunotherapy in terms of patenting activity},
	volume = {37},
	issn = {1087-0156, 1546-1696},
	url = {http://www.nature.com/articles/s41587-019-0083-5},
	doi = {10.1038/s41587-019-0083-5},
	pages = {370--375},
	number = {4},
	journaltitle = {Nature Biotechnology},
	shortjournal = {Nat Biotechnol},
	author = {Jürgens, Björn and Clarke, Nigel S.},
	urldate = {2022-11-03},
	date = {2019-04},
	langid = {english},
	file = {Jürgens and Clarke - 2019 - Evolution of CAR T-cell immunotherapy in terms of .pdf:/Users/annekleine/Zotero/storage/6RUCH4EU/Jürgens and Clarke - 2019 - Evolution of CAR T-cell immunotherapy in terms of .pdf:application/pdf},
}

@article{arbach_etal21,
	title = {Recent patent applications in beverages enriched with plant proteins},
	volume = {5},
	rights = {2021 The Author(s)},
	issn = {2396-8370},
	url = {https://www.nature.com/articles/s41538-021-00112-4},
	doi = {10.1038/s41538-021-00112-4},
	abstract = {Recently, many consumers have been adding plant-based beverages to their diets, due to different reasons. The addition of plant proteins to enrich these products in order to make them more nutritionally balanced has become a trend, mainly because of their lower prices and reduced environmental damage. Thus, the aims of the present patent review are to discuss the potential of, and challenges posed by, plant proteins to the beverage industry, as well as to check market trends, focused on raw materials and beverage types. Based on the results, pea, rapeseed, bean, peanut, chickpea, lentil, hempseed, sunflower seed, and cottonseed were among the most often addressed raw materials. Furthermore, this enrichment process is not limited to create products that mimic dairy, therefore expansion in plant proteins used to enrich carbonated beverages, sports drinks, or even juices is expected to happen. Thus, plant-derived proteins have been promising to high-quality beverage production, as well as to ensure food security, animal welfare, and low environmental impacts.},
	pages = {28},
	number = {1},
	journaltitle = {npj Science of Food},
	shortjournal = {npj Sci Food},
	author = {Arbach, Clara Takayama and Alves, Izabel Almeida and Serafini, Mairim Russo and Stephani, Rodrigo and Perrone, Ítalo Tuler and de Carvalho da Costa, Juliana},
	urldate = {2022-11-01},
	date = {2021-11-01},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Sustainability, Nutrition, Science, technology and society},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/GUESEG5E/Arbach et al. - 2021 - Recent patent applications in beverages enriched w.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/IB8CM66W/s41538-021-00112-4.html:text/html},
}

@article{moher_etal09,
	title = {Preferred reporting items for systematic reviews and meta-analyses: the {PRISMA} statement},
	volume = {339},
	rights = {© Moher et al 2009. This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	issn = {1756-1833},
	url = {https://www.bmj.com/content/339/bmj.b2535},
	doi = {10.1136/bmj.b2535},
	shorttitle = {Preferred reporting items for systematic reviews and meta-analyses},
	abstract = {{\textless}p{\textgreater}\textbf{David Moher and colleagues} introduce {PRISMA}, an update of the {QUOROM} guidelines for reporting systematic reviews and meta-analyses{\textless}/p{\textgreater}},
	pages = {b2535},
	journaltitle = {{BMJ}},
	shortjournal = {{BMJ}},
	author = {Moher, David and Liberati, Alessandro and Tetzlaff, Jennifer and Altman, Douglas G.},
	urldate = {2022-12-22},
	date = {2009-07-21},
	langid = {english},
	pmid = {19622551},
	note = {Publisher: British Medical Journal Publishing Group
Section: Research Methods \&amp; Reporting},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/I8B5NYJJ/Moher et al. - 2009 - Preferred reporting items for systematic reviews a.pdf:application/pdf},
}

@book{wickham16,
	title = {ggplot2: elegant graphics for data analysis},
	isbn = {978-3-319-24277-4},
	url = {https://ggplot2.tidyverse.org},
	publisher = {Springer-Verlag New York},
	author = {Wickham, Hadley},
	date = {2016},
}

@report{schloerke_etal21,
	title = {{GGally}: extension to 'ggplot2'},
	url = {https://CRAN.R-project.org/package=GGally},
	author = {Schloerke, Barret and Cook, Di and Larmarange, Joseph and Briatte, Francois and Marbach, Moritz and Thoen, Edwin and Elberg, Amos and Crowley, Jason},
	date = {2021},
}

@report{butts15,
	title = {network: classes for relational data},
	url = {https://CRAN.R-project.org/package=network},
	author = {Butts, Carter T.},
	date = {2015},
	note = {tex.organization: The Statnet Project (http://www.statnet.org)},
}

@article{butts08,
	title = {network: a package for managing relational data in R.},
	volume = {24},
	doi = {10.18637/jss.v024.i02},
	number = {2},
	journaltitle = {Journal of Statistical Software},
	author = {Butts, Carter T.},
	date = {2008},
}

@software{csardi_nepusz06,
	title = {The igraph software package for complex network research},
	url = {https://igraph.org},
	author = {Csardi, Gabor and Nepusz, Tamas},
	date = {2006},
}

@article{silge_robinson16,
	title = {tidytext: Text mining and analysis using tidy data principles in R},
	volume = {1},
	url = {http://dx.doi.org/10.21105/joss.00037},
	doi = {10.21105/joss.00037},
	number = {3},
	journaltitle = {{JOSS}},
	author = {Silge, Julia and Robinson, David},
	date = {2016},
	note = {Publisher: The Open Journal},
}

@article{feinerer_etal08,
	title = {Text mining infrastructure in R},
	volume = {25},
	doi = {10.18637/jss.v025.i05},
	pages = {1--54},
	number = {5},
	journaltitle = {Journal of Statistical Software},
	author = {Feinerer, Ingo and Hornik, Kurt and Meyer, David},
	date = {2008-03},
}

@report{wijffels22,
	title = {udpipe: Tokenization, parts of speech tagging, lemmatization and dependency parsing with the '{UDPipe}' '{NLP}' toolkit},
	url = {https://CRAN.R-project.org/package=udpipe},
	type = {manual},
	author = {Wijffels, Jan},
	date = {2022},
}

@report{nikita20,
	title = {ldatuning: Tuning of the latent dirichlet allocation models parameters},
	url = {https://CRAN.R-project.org/package=ldatuning},
	type = {manual},
	author = {Nikita, Murzintcev},
	date = {2020},
}

@article{feinerer13,
	title = {Introduction to the tm Package Text Mining in R},
	url = {https://cran.uib.no/web/packages/tm/vignettes/tm.pdf},
	pages = {8},
	author = {Feinerer, Ingo},
	date = {2013},
	langid = {english},
	file = {Feinerer - Introduction to the tm Package Text Mining in R.pdf:/Users/annekleine/Zotero/storage/U92KC6BY/Feinerer - Introduction to the tm Package Text Mining in R.pdf:application/pdf},
}

@article{roberts_etal19,
	title = {stm: an R package for structural topic models},
	volume = {91},
	doi = {10.18637/jss.v091.i02},
	pages = {1--40},
	number = {2},
	journaltitle = {Journal of Statistical Software},
	author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin},
	date = {2019},
}

@article{cankaya_etal19,
	title = {Comparison of Least Squares, Ridge Regression and Principal Component Approaches in the Presence of Multicollinearity in Regression Analysis},
	volume = {7},
	rights = {Copyright (c) 2019 Turkish Journal of Agriculture - Food Science and Technology},
	issn = {2148-127X},
	url = {http://agrifoodscience.com/index.php/TURJAF/article/view/2515},
	doi = {10.24925/turjaf.v7i8.1166-1172.2515},
	abstract = {The aim of this study was to compare estimation methods: least squares method ({LS}), ridge regression ({RR}), Principal component regression ({PCR}) to estimate the parameters of multiple regression model in situations when the underlying assumptions of least squares estimation are untenable because of multicollinearity. For this aim, the effect of some body measurements on body weights (height at withers and rumps, body length, chest width, chest girth and chest depth, front, middle and hind rump width) obtained from totally 85 Karayaka lambs at weaning period raised at Research Farm of Ondokuz Mayis University was examined. Mean square error, R2 value and significance of parameters were used to evaluate estimator performance. The multicollinearity, between front and middle rump width which were used to estimate live weight, was eliminated by using {RR} and {PCR}. Although research findings showed that {RR} method had the smallest {MSE} and the highest R2 value, the estimates of {PCR} were determined to be more consistent when the importance tests of parameters were taken into account. The results showed that principal component regression approach should be used to estimate the live weight of Karayaka lambs at weaning period.},
	pages = {1166--1172},
	number = {8},
	journaltitle = {Turkish Journal of Agriculture - Food Science and Technology},
	author = {Çankaya, Soner and Eker, Samet and Abacı, Samet Hasan},
	urldate = {2022-12-07},
	date = {2019-08-09},
	langid = {english},
	note = {Number: 8},
	keywords = {Body Measurements, Least Squares, Multicollinearity, Principal Component Regression, Ridge Regression},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/8MT6UW7Q/Çankaya et al. - 2019 - Comparison of Least Squares, Ridge Regression and .pdf:application/pdf},
}

@article{shrestha20,
	title = {Detecting Multicollinearity in Regression Analysis},
	volume = {8},
	doi = {10.12691/ajams-8-2-1},
	abstract = {Multicollinearity occurs when the multiple linear regression analysis includes several variables that are significantly correlated not only with the dependent variable but also to each other. Multicollinearity makes some of the significant variables under study to be statistically insignificant. This paper discusses on the three primary techniques for detecting the multicollinearity using the questionnaire survey data on customer satisfaction. The first two techniques are the correlation coefficients and the variance inflation factor, while the third method is eigenvalue method. It is observed that the product attractiveness is more rational cause for the customer satisfaction than other predictors. Furthermore, advanced regression procedures such as principal components regression, weighted regression, and ridge regression method can be used to determine the presence of multicollinearity.
Keywords:
multicollinearity regression analysis variance inflation factor eigenvalue customer satisfaction},
	pages = {39--42},
	journaltitle = {American Journal of Applied Mathematics and Statistics},
	shortjournal = {American Journal of Applied Mathematics and Statistics},
	author = {Shrestha, Noora},
	date = {2020-06-15},
	file = {Full Text:/Users/annekleine/Zotero/storage/ZMLVZV9B/Shrestha - 2020 - Detecting Multicollinearity in Regression Analysis.pdf:application/pdf},
}

@article{krejcar_etal20,
	title = {Review of Available {SW} Solutions for Intellectual Property Management Systems from the Perspective of Open Innovation},
	volume = {6},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2199-8531},
	url = {https://www.mdpi.com/2199-8531/6/2/23},
	doi = {10.3390/joitmc6020023},
	abstract = {This piece of research is focused on providing a review of the software solutions that exist when it comes to mechanisms that govern the management of intellectual property. It takes a deeper look at requirements within the university transfer office domain. Universities are a genuine source of knowledge. They have been identified not just as knowledge hubs but also as the spaces where innovations are born. These innovations then make their way into the market through the different industries they serve, becoming products that gain the attention of actual consumers. Given the magnitude of the innovations being developed in different universities around the world, it is imperative that mechanisms for the safety of this knowledge also be put into place. The world has evolved into a knowledge economy, where knowledge is an asset and something that can create profitability. This means that not protecting the knowledge that is being created can only lead to a loss in the future. Managing intellectual property, therefore, is not only a matter of procedure but one of great importance. Solutions that are easily accessible, cost-effective, and time-effective are essential. Thus, the goal of this article is to provide an overview of existing software ({SW}) solutions suitable for managing technology and knowledge transfer at universities based on requirements from the technology transfer office at university and specified using the model of the whole process from inventor until patent office. University Technology Transfer ({TT}) is a bit different in comparison to {TT} at companies. This gap is shown in the article using modelling of process, states, and class diagrams of a university Technology Transfer Office ({TTO}). Based on process definition and {TTO} responsibilities, a review of available {SW} solutions is done for 10 selected examples, as well as a related literature analysis. Findings and implications are summarized at the end of article in the context of specific needs of a university {TTO}, while major implications are shown as a problem of priority definition of every university {TTO}, namely, in the sense of value of {SW} solutions for intellectual property ({IP}) management, reporting possibilities, and representing {IP} and know-how.},
	pages = {23},
	number = {2},
	journaltitle = {Journal of Open Innovation: Technology, Market, and Complexity},
	author = {Krejcar, Ondrej and Frischer, Robert and Hlavica, Robert and Kuca, Kamil and Maresova, Petra and Selamat, Ali},
	urldate = {2022-10-18},
	date = {2020-06},
	langid = {english},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {intellectual property, knowledge, software, technology transfer, management, open innovation, patent},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/YUJ9DZS4/Krejcar et al. - 2020 - Review of Available SW Solutions for Intellectual .pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/VSVSD43R/23.html:text/html},
}

@article{albalawi_etal20,
	title = {Using Topic Modeling Methods for Short-Text Data: A Comparative Analysis},
	volume = {3},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2020.00042},
	shorttitle = {Using Topic Modeling Methods for Short-Text Data},
	abstract = {With the growth of online social network platforms and applications, large amounts of textual user-generated content are created daily in the form of comments, reviews, and short-text messages. As a result, users often find it challenging to discover useful information or more on the topic being discussed from such content. Machine learning and natural language processing algorithms are used to analyze the massive amount of textual social media data available online, including topic modeling techniques that have gained popularity in recent years. This paper investigates the topic modeling subject and its common application areas, methods, and tools. Also, we examine and compare five frequently used topic modeling methods, as applied to short textual social data, to show their benefits practically in detecting important topics. These methods are latent semantic analysis, latent Dirichlet allocation, non-negative matrix factorization, random projection, and principal component analysis. Two textual datasets were selected to evaluate the performance of included topic modeling methods based on the topic quality and some standard statistical evaluation metrics, like recall, precision, F-score, and topic coherence. As a result, latent Dirichlet allocation and non-negative matrix factorization methods delivered more meaningful extracted topics and obtained good results. The paper sheds light on some common topic modeling methods in a short-text context and provides direction for researchers who seek to apply these methods.},
	journaltitle = {Frontiers in Artificial Intelligence},
	author = {Albalawi, Rania and Yeap, Tet Hin and Benyoucef, Morad},
	urldate = {2022-11-27},
	date = {2020},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/RWQHM9Q3/Albalawi et al. - 2020 - Using Topic Modeling Methods for Short-Text Data .pdf:application/pdf},
}

@article{erzurumlu_pachamanova20,
	title = {Topic modeling and technology forecasting for assessing the commercial viability of healthcare innovations},
	volume = {156},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162519315161},
	doi = {10.1016/j.techfore.2020.120041},
	abstract = {Developing technologies for a transfer from science to market is a key element of research-intensive organizations such as innovation management centers that work closely with inventors to commercialize their technological innovations. To advance the commercial viability of technological innovations, this paper proposes a framework that integrates topic modeling, survival analysis, and judgment of subject matter experts to forecast promising technologies using patents as data resources. Regarding the commercial viability of identified technologies, our empirical analysis focuses on patents and licensing data from a prominent innovation management center over a 20-year period. We are able to identify technologies that are statistically significant for predicting the likelihood and the time until a patent is commercialized, and suggest a way to assess their scope of technological impact. Our results contribute to the understanding of promising healthcare technologies and help R\& D managers to develop the knowledge they need to advocate technologies in support of commercial returns.},
	pages = {120041},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Erzurumlu, S. Sinan and Pachamanova, Dessislava},
	urldate = {2022-11-27},
	date = {2020-07},
	langid = {english},
	file = {Erzurumlu and Pachamanova - 2020 - Topic modeling and technology forecasting for asse.pdf:/Users/annekleine/Zotero/storage/Z5NKLHEU/Erzurumlu and Pachamanova - 2020 - Topic modeling and technology forecasting for asse.pdf:application/pdf},
}

@article{jelodar_etal19,
	title = {Latent Dirichlet Allocation ({LDA}) and topic modeling: models, applications, a survey},
	volume = {78},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-018-6894-4},
	doi = {10.1007/s11042-018-6894-4},
	shorttitle = {Latent Dirichlet allocation ({LDA}) and topic modeling},
	abstract = {Topic modeling is one of the most powerful techniques in text mining for data mining, latent data discovery, and finding relationships among data and text documents. Researchers have published many articles in the field of topic modeling and applied in various fields such as software engineering, political science, medical and linguistic science, etc. There are various methods for topic modelling; Latent Dirichlet Allocation ({LDA}) is one of the most popular in this field. Researchers have proposed various models based on the {LDA} in topic modeling. According to previous work, this paper will be very useful and valuable for introducing {LDA} approaches in topic modeling. In this paper, we investigated highly scholarly articles (between 2003 to 2016) related to topic modeling based on {LDA} to discover the research development, current trends and intellectual structure of topic modeling. In addition, we summarize challenges and introduce famous tools and datasets in topic modeling based on {LDA}.},
	pages = {15169--15211},
	number = {11},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Jelodar, Hamed and Wang, Yongli and Yuan, Chi and Feng, Xia and Jiang, Xiahui and Li, Yanchao and Zhao, Liang},
	urldate = {2022-12-07},
	date = {2019-06-01},
	langid = {english},
	keywords = {Topic modeling, Semantic web, Latent Dirichlet allocation, Gibbs sampling, Tag recommendation},
	file = {Submitted Version:/Users/annekleine/Zotero/storage/VGDZPRYN/Jelodar et al. - 2019 - Latent Dirichlet allocation (LDA) and topic modeli.pdf:application/pdf},
}

@article{dotsika_watkins17,
	title = {Identifying potentially disruptive trends by means of keyword network analysis},
	volume = {119},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162517303517},
	doi = {10.1016/j.techfore.2017.03.020},
	abstract = {Identifying potentially disruptive technologies is crucial to safeguarding competitive advantage by enabling stakeholders to assign resources in a manner that increases the chances of exploiting the disruption and/or mitigating the ensuing risks. However, disruptive technologies and emergent trends within known disruptive domains are mostly identified ex-post. This paper contributes to the ex-ante prediction of emergent technologies within disruptive domains by proposing a literature-driven method for the forecasting of potentially disruptive technological trends. It adopts a keyword network analysis and visualisation approach for uncovering emergent thematic, structural and temporal developments within publications and applies it as a forecasting tool to an empirical study of seven disruptive domains: 3D Printing, Big Data, Bitcoin, Cloud Technologies, Internet of Things, {MOOCs} and Social Media. Maturing trends were found to share influential common topics identified by high degree, betweenness and closeness centrality scores. Niche and potentially emerging trends within groups were detected by means of eccentricity and farness metrics. Visualisation techniques were found effective for further clarification and trend identification. Finally, potentially disruptive trends within domains were found to be associated with high closeness paired with low degree centrality. The findings were distilled into a framework for assisting the forecasting of potentially disruptive trends.},
	pages = {114--127},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Dotsika, Fefie and Watkins, Andrew},
	urldate = {2022-12-07},
	date = {2017-06-01},
	langid = {english},
	keywords = {Disruptive technologies, Emerging technologies forecasting, Keyword network analysis, Trend forecasting},
	file = {Accepted Version:/Users/annekleine/Zotero/storage/U32BM4BG/Dotsika and Watkins - 2017 - Identifying potentially disruptive trends by means.pdf:application/pdf;ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/SU423MZQ/S0040162517303517.html:text/html},
}

@article{cao_etal09,
	title = {A density-based method for adaptive {LDA} model selection},
	volume = {72},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S092523120800372X},
	doi = {10.1016/j.neucom.2008.06.011},
	series = {Advances in Machine Learning and Computational Intelligence},
	abstract = {Topic models have been successfully used in information classification and retrieval. These models can capture word correlations in a collection of textual documents with a low-dimensional set of multinomial distribution, called “topics”. However, it is important but difficult to select the appropriate number of topics for a specific dataset. In this paper, we study the inherent connection between the best topic structure and the distances among topics in Latent Dirichlet allocation ({LDA}), and propose a method of adaptively selecting the best {LDA} model based on density. Experiments show that the proposed method can achieve performance matching the best of {LDA} without manually tuning the number of topics.},
	pages = {1775--1781},
	number = {7},
	journaltitle = {Neurocomputing},
	shortjournal = {Neurocomputing},
	author = {Cao, Juan and Xia, Tian and Li, Jintao and Zhang, Yongdong and Tang, Sheng},
	urldate = {2022-12-07},
	date = {2009-03-01},
	langid = {english},
	keywords = {Latent Dirichlet allocation, Topic, Topic model},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/9MYGGA4L/S092523120800372X.html:text/html},
}

@article{griffiths_steyvers04,
	title = {Finding scientific topics},
	volume = {101},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.0307752101},
	doi = {10.1073/pnas.0307752101},
	abstract = {A first step in identifying the content of a document is determining which topics that document addresses. We describe a generative model for documents, introduced by Blei, Ng, and Jordan [Blei, D. M., Ng, A. Y. \& Jordan, M. I. (2003) J. Machine Learn. Res. 3, 993-1022], in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. We then present a Markov chain Monte Carlo algorithm for inference in this model. We use this algorithm to analyze abstracts from {PNAS} by using Bayesian model selection to establish the number of topics. We show that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying “hot topics” by examining temporal dynamics and tagging abstracts to illustrate semantic content.},
	pages = {5228--5235},
	issue = {suppl\_1},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Griffiths, Thomas L. and Steyvers, Mark},
	urldate = {2022-12-07},
	date = {2004-04-06},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/2QXCTUSQ/Griffiths and Steyvers - 2004 - Finding scientific topics.pdf:application/pdf},
}

@article{ponweiser12,
	title = {Latent Dirichlet Allocation in R},
	series = {Theses / Institute for Statistics and Mathematics},
	abstract = {Topic models are a new research field within the computer sciences information retrieval and text mining. They are generative probabilistic models of text corpora inferred by machine learning and they can be used for retrieval and text mining tasks. The most prominent topic model is latent Dirichlet allocation ({LDA}), which was introduced in 2003 by Blei et al. and has since then sparked off the development of other topic models for domain-specific purposes.
This thesis focuses on {LDA}'s practical application. Its main goal is the replication of the data analyses from the 2004 {LDA} paper "Finding scientific topics" by Thomas Griffiths and Mark Steyvers within the framework of the R statistical programming language and the R{\textasciitilde}package topicmodels by Bettina Grün and Kurt Hornik. The complete process, including extraction of a text corpus from the {PNAS} journal's website, data preprocessing, transformation into a document-term matrix, model selection, model estimation, as well as presentation of the results, is fully documented and commented. The outcome closely matches the analyses of the original paper, therefore the research by Griffiths/Steyvers can be reproduced. Furthermore, this thesis proves the suitability of the R environment for text mining with {LDA}.},
	journaltitle = {Latent Dirichlet Allocation in R},
	author = {Ponweiser, Martin},
	date = {2012-05-01},
	note = {Place: Vienna
Publisher: {WU} Vienna University of Economics and Business},
}

@article{blei03,
	title = {Latent Dirichlet Allocation},
	volume = {3},
	url = {https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?ref=https://githubhelp.com},
	abstract = {We describe latent Dirichlet allocation ({LDA}), a generative probabilistic model for collections of discrete data such as text corpora. {LDA} is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a ﬁnite mixture over an underlying set of topics. Each topic is, in turn, modeled as an inﬁnite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efﬁcient approximate inference techniques based on variational methods and an {EM} algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classiﬁcation, and collaborative ﬁltering, comparing to a mixture of unigrams model and the probabilistic {LSI} model.},
	pages = {993--1022},
	journaltitle = {Journal of Machine Learning Research},
	author = {Blei, David M},
	date = {2003},
	langid = {english},
	file = {Blei - Latent Dirichlet Allocation.pdf:/Users/annekleine/Zotero/storage/NKIHVUXI/Blei - Latent Dirichlet Allocation.pdf:application/pdf},
}

@article{grimmer_stewart13,
	title = {Text as data: the promise and pitfalls of automatic content analysis methods for political texts},
	volume = {21},
	issn = {1047-1987, 1476-4989},
	url = {https://www.cambridge.org/core/journals/political-analysis/article/text-as-data-the-promise-and-pitfalls-of-automatic-content-analysis-methods-for-political-texts/F7AAC8B2909441603FEB25C156448F20},
	doi = {10.1093/pan/mps028},
	shorttitle = {Text as Data},
	abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods—they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
	pages = {267--297},
	number = {3},
	journaltitle = {Political Analysis},
	author = {Grimmer, Justin and Stewart, Brandon M.},
	urldate = {2022-12-14},
	date = {2013},
	langid = {english},
	note = {Publisher: Cambridge University Press},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/YS4VFBAC/Grimmer and Stewart - 2013 - Text as Data The Promise and Pitfalls of Automati.pdf:application/pdf},
}

@inproceedings{wallach_etal09,
	location = {New York, {NY}, {USA}},
	title = {Evaluation methods for topic models},
	isbn = {978-1-60558-516-1},
	url = {https://doi.org/10.1145/1553374.1553515},
	doi = {10.1145/1553374.1553515},
	series = {{ICML} '09},
	abstract = {A natural evaluation metric for statistical topic models is the probability of held-out documents given a trained model. While exact computation of this probability is intractable, several estimators for this probability have been used in the topic modeling literature, including the harmonic mean method and empirical likelihood method. In this paper, we demonstrate experimentally that commonly-used methods are unlikely to accurately estimate the probability of held-out documents, and propose two alternative methods that are both accurate and efficient.},
	pages = {1105--1112},
	booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
	publisher = {Association for Computing Machinery},
	author = {Wallach, Hanna M. and Murray, Iain and Salakhutdinov, Ruslan and Mimno, David},
	urldate = {2022-12-14},
	date = {2009-06-14},
	file = {Submitted Version:/Users/annekleine/Zotero/storage/GVR72XTE/Wallach et al. - 2009 - Evaluation methods for topic models.pdf:application/pdf},
}

@inproceedings{taddy12,
	title = {On estimation and selection for topic models},
	url = {https://proceedings.mlr.press/v22/taddy12.html},
	abstract = {This article describes posterior maximization for topic models, identifying computational and   conceptual gains from inference under a non-standard    parametrization.  We then show that fitted parameters can be used  as the basis for a novel approach to marginal likelihood estimation,   via block-diagonal approximation to the information matrix, that facilitates choosing the number of latent topics.  This   likelihood-based model selection is complemented with a goodness-of-fit analysis built around estimated residual dispersion.  Examples are provided to illustrate model selection as well as to compare our estimation against standard alternative techniques.},
	eventtitle = {Artificial Intelligence and Statistics},
	pages = {1184--1193},
	booktitle = {Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics},
	publisher = {{PMLR}},
	author = {Taddy, Matt},
	urldate = {2022-12-14},
	date = {2012-03-21},
	langid = {english},
	note = {{ISSN}: 1938-7228},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/UB23FWH9/Taddy - 2012 - On Estimation and Selection for Topic Models.pdf:application/pdf},
}

@inproceedings{mimno_etal11,
	location = {Edinburgh, Scotland, {UK}.},
	title = {Optimizing semantic coherence in topic models},
	url = {https://aclanthology.org/D11-1024},
	eventtitle = {{EMNLP} 2011},
	pages = {262--272},
	booktitle = {Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing},
	publisher = {Association for Computational Linguistics},
	author = {Mimno, David and Wallach, Hanna and Talley, Edmund and Leenders, Miriam and {McCallum}, Andrew},
	urldate = {2022-12-14},
	date = {2011-07},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/G4F5WJJT/Mimno et al. - 2011 - Optimizing Semantic Coherence in Topic Models.pdf:application/pdf},
}

@article{choi_song18,
	title = {Exploring technological trends in logistics: topic modeling-based patent analysis},
	volume = {10},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/10/8/2810},
	doi = {10.3390/su10082810},
	shorttitle = {Exploring Technological Trends in Logistics},
	abstract = {With the strategic importance of discerning opportunities and threats from technological development to achieve sustainable competitiveness, exploring technological trends becomes critical for a successful technology strategy in logistics. Given the rapid pace of development and varying technological options, logistics also increasingly requires methodological support and appropriate data to reduce the complexity and burden of exploring technology trends. While previous research has largely relied on experts’ insights, the value of patent-based approaches for exploring technological trends has been underestimated in logistics. To address this gap, this study proposes a topic modeling-based approach using logistics-related patents registered at the United States Patents and Trademark Office ({USPTO}). The core of the suggested approach is latent Dirichlet allocation ({LDA}), allowing the identification of logistics-related technological topics behind patents. The topics identified by {LDA} are further investigated regarding both filed-level and firm-level trends. The suggested approach is expected to offer implications of the use of patents for the purpose of exploring the trends of technology development outside the organization in logistics. In addition, we believe that the information on the technological topics and their trends generated by the suggested approach can offer an enhanced understanding of the technological landscape in logistics.},
	pages = {2810},
	number = {8},
	journaltitle = {Sustainability},
	author = {Choi, Donghyun and Song, Bomi},
	urldate = {2022-12-16},
	date = {2018-08},
	langid = {english},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {patent analysis, topic modeling, latent dirichlet allocation, technological trends in logistics, technology trend exploration},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/W8THFIVU/Choi and Song - 2018 - Exploring Technological Trends in Logistics Topic.pdf:application/pdf},
}

@book{buhinpandur_etal20,
	title = {Topic Modelling in Social Sciences: Case Study of Web of Science},
	author = {Buhin Pandur, Maja and Dobša, Jasminka and Kronegger, Luka},
	date = {2020-10-07},
}

@misc{schulze_etal21,
	title = {Exploring Topic-Metadata Relationships with the {STM}: A Bayesian Approach},
	url = {http://arxiv.org/abs/2104.02496},
	shorttitle = {Exploring Topic-Metadata Relationships with the {STM}},
	abstract = {Topic models such as the Structural Topic Model ({STM}) estimate latent topical clusters within text. An important step in many topic modeling applications is to explore relationships between the discovered topical structure and metadata associated with the text documents. Methods used to estimate such relationships must take into account that the topical structure is not directly observed, but instead being estimated itself. The authors of the {STM}, for instance, perform repeated {OLS} regressions of sampled topic proportions on metadata covariates by using a Monte Carlo sampling technique known as the method of composition. In this paper, we propose two improvements: first, we replace {OLS} with more appropriate Beta regression. Second, we suggest a fully Bayesian approach instead of the current blending of frequentist and Bayesian methods. We demonstrate our improved methodology by exploring relationships between Twitter posts by German members of parliament ({MPs}) and different metadata covariates.},
	number = {{arXiv}:2104.02496},
	publisher = {{arXiv}},
	author = {Schulze, P. and Wiegrebe, S. and Thurner, P. W. and Heumann, C. and Aßenmacher, M. and Wankmüller, S.},
	urldate = {2022-12-17},
	date = {2021-04-06},
	eprinttype = {arxiv},
	eprint = {2104.02496 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/annekleine/Zotero/storage/TJRV9A4R/Schulze et al. - 2021 - Exploring Topic-Metadata Relationships with the ST.pdf:application/pdf;arXiv.org Snapshot:/Users/annekleine/Zotero/storage/DMZQ2Q63/2104.html:text/html},
}

@article{abbas_etal14,
	title = {A literature review on the state-of-the-art in patent analysis},
	volume = {37},
	issn = {0172-2190},
	url = {https://www.sciencedirect.com/science/article/pii/S0172219013001634},
	doi = {10.1016/j.wpi.2013.12.006},
	abstract = {The rapid growth of patent documents has called for the development of sophisticated patent analysis tools. Currently, there are various tools that are being utilized by organizations for analyzing patents. These tools are capable of performing wide range of tasks, such as analyzing and forecasting future technological trends, conducting strategic technology planning, detecting patent infringement, determining patents quality and the most promising patents, and identifying technological hotspots and patent vacuums. This literature review presents the state-of-the-art in patent analysis and also presents taxonomy of patent analysis techniques. Moreover, the key features and weaknesses of the discussed tools and techniques are presented and several directions for future research are highlighted. The literature review will be helpful for the researchers in finding the latest research efforts pertaining to the patent analysis in a unified form.},
	pages = {3--13},
	journaltitle = {World Patent Information},
	shortjournal = {World Patent Information},
	author = {Abbas, Assad and Zhang, Limin and Khan, Samee U.},
	urldate = {2022-10-12},
	date = {2014-06-01},
	langid = {english},
	keywords = {Natural language processing, Patent analysis, Text mining, Visualization techniques},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/F9XHE83U/S0172219013001634.html:text/html},
}

@book{mcguffin_etal04,
	title = {Psychiatric genetics and genomics},
	isbn = {978-0-19-856486-7},
	abstract = {Revised for paperback edition, with new appendices Genetics promises to provide one of the most powerful approaches to understanding the functional pathology of the human brain. This book presents a critical review of the evidence for a genetic contribution to common psychiatric conditions and the rarer single-gene disorders that may have psychiatric presentations. The first section of the book introduces the reader to molecular biology and the techniques of molecular genetics. The coverage then moves on to consider the genetics of normal and abnormal development, followed by a look at the genetics of abnormal behaviour in adults. This section includes, amongst others, consideration of personality disorders, schizophrenia and the dementias. The final section considers the applications of the work and covers issues such as counselling and ethics, closing with a look to the future. The editors are internationally renowned figures in this field and they have invited a team of equally eminent chapter authors.},
	pagetotal = {508},
	publisher = {{OUP} Oxford},
	author = {{McGuffin}, Peter and Owen, Michael J. and Gottesman, Irving I.},
	date = {2004-09-23},
	langid = {english},
	note = {Google-Books-{ID}: {SFO}0YUqiaFMC},
	keywords = {Medical / Ethics, Medical / Genetics, Medical / Neurology, Medical / Psychiatry / General, Psychology / Clinical Psychology, Psychology / Psychopathology / General, Science / Life Sciences / Neuroscience},
}

@article{libbrecht_noble15,
	title = {Machine learning in genetics and genomics},
	volume = {16},
	issn = {1471-0056},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5204302/},
	doi = {10.1038/nrg3920},
	abstract = {The field of machine learning promises to enable computers to assist humans in making sense of large, complex data sets. In this review, we outline some of the main applications of machine learning to genetic and genomic data. In the process, we identify some recurrent challenges associated with this type of analysis and provide general guidelines to assist in the practical application of machine learning to real genetic and genomic data.},
	pages = {321--332},
	number = {6},
	journaltitle = {Nature reviews. Genetics},
	shortjournal = {Nat Rev Genet},
	author = {Libbrecht, Maxwell W. and Noble, William Stafford},
	urldate = {2023-01-09},
	date = {2015-06},
	pmid = {25948244},
	pmcid = {PMC5204302},
	file = {PubMed Central Full Text PDF:/Users/annekleine/Zotero/storage/RQMKJJ7H/Libbrecht and Noble - 2015 - Machine learning in genetics and genomics.pdf:application/pdf},
}

@article{abd-alrazaq_etal22,
	title = {The performance of artificial intelligence-driven technologies in diagnosing mental disorders: an umbrella review},
	volume = {5},
	rights = {2022 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-022-00631-8},
	doi = {10.1038/s41746-022-00631-8},
	shorttitle = {The performance of artificial intelligence-driven technologies in diagnosing mental disorders},
	abstract = {Artificial intelligence ({AI}) has been successfully exploited in diagnosing many mental disorders. Numerous systematic reviews summarize the evidence on the accuracy of {AI} models in diagnosing different mental disorders. This umbrella review aims to synthesize results of previous systematic reviews on the performance of {AI} models in diagnosing mental disorders. To identify relevant systematic reviews, we searched 11 electronic databases, checked the reference list of the included reviews, and checked the reviews that cited the included reviews. Two reviewers independently selected the relevant reviews, extracted the data from them, and appraised their quality. We synthesized the extracted data using the narrative approach. We included 15 systematic reviews of 852 citations identified. The included reviews assessed the performance of {AI} models in diagnosing Alzheimer’s disease (n = 7), mild cognitive impairment (n = 6), schizophrenia (n = 3), bipolar disease (n = 2), autism spectrum disorder (n = 1), obsessive-compulsive disorder (n = 1), post-traumatic stress disorder (n = 1), and psychotic disorders (n = 1). The performance of the {AI} models in diagnosing these mental disorders ranged between 21\% and 100\%. {AI} technologies offer great promise in diagnosing mental health disorders. The reported performance metrics paint a vivid picture of a bright future for {AI} in this field. Healthcare professionals in the field should cautiously and consciously begin to explore the opportunities of {AI}-based tools for their daily routine. It would also be encouraging to see a greater number of meta-analyses and further systematic reviews on performance of {AI} models in diagnosing other common mental disorders such as depression and anxiety.},
	pages = {1--12},
	number = {1},
	journaltitle = {npj Digital Medicine},
	shortjournal = {npj Digit. Med.},
	author = {Abd-alrazaq, Alaa and Alhuwail, Dari and Schneider, Jens and Toro, Carla T. and Ahmed, Arfan and Alzubaidi, Mahmood and Alajlani, Mohannad and Househ, Mowafa},
	urldate = {2023-01-09},
	date = {2022-07-07},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Health care, Psychiatric disorders, Diseases, Medical research},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/NB8VS8L7/Abd-alrazaq et al. - 2022 - The performance of artificial intelligence-driven .pdf:application/pdf},
}

@article{bennett_etal12,
	title = {{EHRs} connect research and practice: where predictive modeling, artificial intelligence, and clinical decision support intersect},
	volume = {1},
	issn = {22118837},
	url = {http://arxiv.org/abs/1204.4927},
	doi = {10.1016/j.hlpt.2012.03.001},
	shorttitle = {{EHRs} Connect Research and Practice},
	abstract = {Objectives: Electronic health records ({EHRs}) are only a first step in capturing and utilizing health-related data - the challenge is turning that data into useful information. Furthermore, {EHRs} are increasingly likely to include data relating to patient outcomes, functionality such as clinical decision support, and genetic information as well, and, as such, can be seen as repositories of increasingly valuable information about patients' health conditions and responses to treatment over time. Methods: We describe a case study of 423 patients treated by Centerstone within Tennessee and Indiana in which we utilized electronic health record data to generate predictive algorithms of individual patient treatment response. Multiple models were constructed using predictor variables derived from clinical, financial and geographic data. Results: For the 423 patients, 101 deteriorated, 223 improved and in 99 there was no change in clinical condition. Based on modeling of various clinical indicators at baseline, the highest accuracy in predicting individual patient response ranged from 70-72\% within the models tested. In terms of individual predictors, the Centerstone Assessment of Recovery Level - Adult ({CARLA}) baseline score was most significant in predicting outcome over time (odds ratio 4.1 + 2.27). Other variables with consistently significant impact on outcome included payer, diagnostic category, location and provision of case management services. Conclusions: This approach represents a promising avenue toward reducing the current gap between research and practice across healthcare, developing data-driven clinical decision support based on real-world populations, and serving as a component of embedded clinical artificial intelligences that "learn" over time.},
	pages = {105--114},
	number = {2},
	journaltitle = {Health Policy and Technology},
	shortjournal = {Health Policy and Technology},
	author = {Bennett, Casey and Doub, Tom and Selove, Rebecca},
	urldate = {2023-01-09},
	date = {2012-06},
	eprinttype = {arxiv},
	eprint = {1204.4927 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Machine Learning, Computer Science - Databases},
	file = {arXiv Fulltext PDF:/Users/annekleine/Zotero/storage/8YW7FRX2/Bennett et al. - 2012 - EHRs Connect Research and Practice Where Predicti.pdf:application/pdf;arXiv.org Snapshot:/Users/annekleine/Zotero/storage/WB6NL5BH/1204.html:text/html},
}

@inproceedings{liu_etal17f,
	location = {Melbourne, Australia},
	title = {Deep Neural Networks for High Dimension, Low Sample Size Data},
	isbn = {978-0-9992411-0-3},
	url = {https://www.ijcai.org/proceedings/2017/318},
	doi = {10.24963/ijcai.2017/318},
	abstract = {Deep neural networks ({DNN}) have achieved breakthroughs in applications with large sample size. However, when facing high dimension, low sample size ({HDLSS}) data, such as the phenotype prediction problem using genetic data in bioinformatics, {DNN} suffers from overﬁtting and high-variance gradients. In this paper, we propose a {DNN} model tailored for the {HDLSS} data, named Deep Neural Pursuit ({DNP}). {DNP} selects a subset of high dimensional features for the alleviation of overﬁtting and takes the average over multiple dropouts to calculate gradients with low variance. As the ﬁrst {DNN} method applied on the {HDLSS} data, {DNP} enjoys the advantages of the high nonlinearity, the robustness to high dimensionality, the capability of learning from a small number of samples, the stability in feature selection, and the end-to-end training. We demonstrate these advantages of {DNP} via empirical results on both synthetic and real-world biological datasets.},
	eventtitle = {Twenty-Sixth International Joint Conference on Artificial Intelligence},
	pages = {2287--2293},
	booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Liu, Bo and Wei, Ying and Zhang, Yu and Yang, Qiang},
	urldate = {2023-01-09},
	date = {2017-08},
	langid = {english},
	file = {Liu et al. - 2017 - Deep Neural Networks for High Dimension, Low Sampl.pdf:/Users/annekleine/Zotero/storage/EDKB5MII/Liu et al. - 2017 - Deep Neural Networks for High Dimension, Low Sampl.pdf:application/pdf},
}

@article{dadi_etal21,
	title = {Population modeling with machine learning can enhance measures of mental health},
	volume = {10},
	issn = {2047-217X},
	url = {https://doi.org/10.1093/gigascience/giab071},
	doi = {10.1093/gigascience/giab071},
	abstract = {Biological aging is revealed by physical measures, e.g., {DNA} probes or brain scans. In contrast, individual differences in mental function are explained by psychological constructs, e.g., intelligence or neuroticism. These constructs are typically assessed by tailored neuropsychological tests that build on expert judgement and require careful interpretation. Could machine learning on large samples from the general population be used to build proxy measures of these constructs that do not require human intervention?Here, we built proxy measures by applying machine learning on multimodal {MR} images and rich sociodemographic information from the largest biomedical cohort to date: the {UK} Biobank. Objective model comparisons revealed that all proxies captured the target constructs and were as useful, and sometimes more useful, than the original measures for characterizing real-world health behavior (sleep, exercise, tobacco, alcohol consumption). We observed this complementarity of proxy measures and original measures at capturing multiple health-related constructs when modeling from, both, brain signals and sociodemographic data.Population modeling with machine learning can derive measures of mental health from heterogeneous inputs including brain signals and questionnaire data. This may complement or even substitute for psychometric assessments in clinical populations.},
	pages = {giab071},
	number = {10},
	journaltitle = {{GigaScience}},
	shortjournal = {{GigaScience}},
	author = {Dadi, Kamalaker and Varoquaux, Gaël and Houenou, Josselin and Bzdok, Danilo and Thirion, Bertrand and Engemann, Denis},
	urldate = {2022-11-16},
	date = {2021-10-01},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/BQR33G27/Dadi et al. - 2021 - Population modeling with machine learning can enha.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/VXVHK2D6/6396189.html:text/html},
}

@article{holsboer99,
	title = {The rationale for corticotropin-releasing hormone receptor ({CRH}-R) antagonists to treat depression and anxiety},
	volume = {33},
	issn = {0022-3956},
	url = {https://www.sciencedirect.com/science/article/pii/S0022395698900565},
	doi = {10.1016/S0022-3956(98)90056-5},
	abstract = {Neuroendocrine studies strongly suggest that dysregulation of the hypothalamic–pituitary–adrenocortical ({HPA}) system plays a causal role in the development and course of depression. Whereas the initial mechanism resulting in {HPA} hyperdrive remains to be elucidated, evidence has emerged that corticosteroid receptor function is impaired in many patients with depression and in many healthy individuals at increased genetic risk for an depressive disorder. Assuming such impaired receptor function, then central secretion of {CRH} would be enhanced in many brain areas, which would account for a variety of depressive symptoms. As shown in rats and also in transgenic mice with impaired glucocorticoid receptor function, antidepressants enhance the signaling through corticosteroid receptors. This mechanism of action can be amplified through blocking central mechanisms that drive the {HPA} system. Animal experiments using antisense oligodeoxynucleotides directed against the {mRNA} of both {CRH} receptor subtypes identified the {CRH}1 receptor as the mediator of the anxiogenic effects of {CRH}. Studies in mouse mutants in which this receptor subtype had been deleted extended these findings as the animals were less anxious than wild-type mice when experimentally stressed. Thus, patients with clinical conditions that are causally related to {HPA} hyperactivity may profit from treatment with a {CRH}1 receptor antagonist.},
	pages = {181--214},
	number = {3},
	journaltitle = {Journal of Psychiatric Research},
	shortjournal = {Journal of Psychiatric Research},
	author = {Holsboer, F},
	urldate = {2023-01-07},
	date = {1999-05-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:/Users/annekleine/Zotero/storage/GAGFZHU4/Holsboer - 1999 - The rationale for corticotropin-releasing hormone .pdf:application/pdf;ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/R54WQXUI/S0022395698900565.html:text/html},
}

@article{kamariah_etal11,
	title = {The commercialisation process of patents by universities},
	volume = {5},
	issn = {1993-8233},
	url = {http://academicjournals.org/journal/AJBM/article-abstract/713F78A15410},
	doi = {10.5897/AJBM09.255},
	abstract = {The commercialisation process of university patents and how the decisions were made to patent new scientific discoveries and to commercialise them have not been studied extensively. This paper attempts to understand in detail, the process of commercialisation of university patents from the initial scientific disclosures through patent filings to the choice of commercialisation routes. A series of interviews were conducted with seven directors of technology transfer offices ({TTO}) of {UK} universities. The interviews were structured in a way so as to discover how new disclosures in their universities were chosen to be patented and how the patents were commercialised. The interviews were recorded, transcribed and analysed with the help of Nvivo software. Then, case and cross case analysis were done. The result of the study showed that there are variations in practices between universities in how they decide to patent and in the routes of exploitation. Universities do differ on which inventions need to be patented and which route to go for their commercialisation. Universities that practice very highly selective procedures would only patent an invention after a very thorough market analysis. But there are universities that practiced low selective procedures; as such, they file for patent as long as the invention fulfils an expectation of potential value. Decisions on which route to commercialise are sought after the patent filings. Overall, only one university practice a very systematic selection procedure, from which, inventions were patented and specific route of commercialisation was chosen. Most of the universities based their selection criteria on motivations of the inventors, either to patent and which commercialisation route to utilise for their inventions.},
	pages = {7198--7208},
	number = {17},
	journaltitle = {African Journal of Business Management},
	shortjournal = {Afr. J. Bus. Manage.},
	author = {Kamariah, Ismail and Wan, Zaidi Wan Omar and Izaidin, Abdul Majid},
	urldate = {2022-12-07},
	date = {2011-09-04},
	langid = {english},
	file = {Kamariah et al. - 2011 - The commercialisation process of patents by univer.pdf:/Users/annekleine/Zotero/storage/UCEIPGJW/Kamariah et al. - 2011 - The commercialisation process of patents by univer.pdf:application/pdf},
}

@article{harryson08,
	title = {Entrepreneurship through relationships – navigating from creativity to commercialisation},
	volume = {38},
	issn = {0033-6807, 1467-9310},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9310.2008.00516.x},
	doi = {10.1111/j.1467-9310.2008.00516.x},
	pages = {290--310},
	number = {3},
	journaltitle = {R\&D Management},
	shortjournal = {R \& D Management},
	author = {Harryson, Sigvald J.},
	urldate = {2022-12-07},
	date = {2008-06},
	langid = {english},
	file = {Harryson - 2008 - Entrepreneurship through relationships – navigatin.pdf:/Users/annekleine/Zotero/storage/LQ95T8RL/Harryson - 2008 - Entrepreneurship through relationships – navigatin.pdf:application/pdf},
}

@article{szulczewska-remi_nowak-mizgalska21,
	title = {Who really acts as an entrepreneur in the science commercialisation process: the role of knowledge transfer intermediary organisations},
	issn = {2053-4604},
	url = {https://doi.org/10.1108/JEEE-09-2020-0334},
	doi = {10.1108/JEEE-09-2020-0334},
	shorttitle = {Who really acts as an entrepreneur in the science commercialisation process},
	abstract = {Purpose Consistent with the knowledge spillover theory of entrepreneurship, the purpose of this paper is to recognise the complementary entrepreneurial role of knowledge transfer intermediary organisations in the context of two Central and Eastern European ({CEE}) countries: Poland and the Czech Republic. Design/methodology/approach The aim was achieved through empirical studies relying on multiple-case study methodology and cross-case analysis covering 21 cases of commercialisation intermediary institutions. It was assumed that institutional and geographical conditions can impact the knowledge-based opportunity exploitation between different national economies. Findings Research confirmed that scientists in Poland and the Czech Republic are the central figures of the commercialisation process in terms of entrepreneurial opportunity recognition; however, they need support from intermediary organisations in many other entrepreneurial activities. The history of knowledge commercialisation and its intermediating entities in these countries is relatively young and spin-off company creation is not a common practice. Expertise knowledge, creativity and self-confidence admitted, by the respondents in both countries, can be an optimistic sign for the future efforts in fostering innovativeness of {CEE} countries. Stronger support of formal institutional framework and policies in those countries is expected. Originality/value Science commercialisation has lately attracted much attention, but only a few studies have tried to develop conceptual frameworks considering knowledge-based entrepreneurship and knowledge commercialisation in their relations and subsequential roles. Also, over the past couple of years literature in this area has expanded mainly relying on observations in the {USA} and Western European countries. Hence, this study allowed to collect findings from {CEE} countries for which data are still insufficient but can significantly contribute to the theory development. Also, some recommendations for policymakers arise from this study. Further research could validate the results in an extensive quantitative study.},
	journaltitle = {Journal of Entrepreneurship in Emerging Economies},
	author = {Szulczewska-Remi, Aleksandra and Nowak-Mizgalska, Hanna},
	urldate = {2022-12-07},
	date = {2021-01-01},
	keywords = {Commercialisation, Entrepreneurial university, Intermediary organisations, Knowledge-based entrepreneurship, Technology transfer},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/5MPAALMB/Szulczewska-Remi and Nowak-Mizgalska - 2021 - Who really acts as an entrepreneur in the science .pdf:application/pdf},
}

@article{yoon_etal17,
	title = {Identifying product opportunities using collaborative filtering-based patent analysis},
	volume = {107},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835216301127},
	doi = {10.1016/j.cie.2016.04.009},
	abstract = {One practical and low-risk approach to product planning for technology-based firms is to identify application products based on their existing product portfolios. Previous studies, however, have tended to neglect the current product development capabilities of target firms and to apply the technical data of specific fields to their methods, thereby failing to quantify a way of identifying various product opportunities. As a remedy, this paper proposes a new multi-step approach to product recommendation. The steps include (1) generating assignee–product portfolio vectors using text mining on a large-scale sample of patents, (2) recommending untapped products for a target firm by using latent Dirichlet allocation and collaborative filtering, (3) producing a visual map based on the promise and domain heterogeneity of the recommended products. To validate the practicability, we applied our approach to a Korean high-tech manufacturer by using all of the patents registered in the United States Patent and Trademark Office database during the period of time from 2009 to 2013. This study contributes to the systematic discovery of new product opportunities across various domains using the existing product portfolios of firms, and could become the basis for a future product opportunity analysis system.},
	pages = {376--387},
	journaltitle = {Computers \& Industrial Engineering},
	shortjournal = {Computers \& Industrial Engineering},
	author = {Yoon, Janghyeok and Seo, Wonchul and Coh, Byoung-Youl and Song, Inseok and Lee, Jae-Min},
	urldate = {2022-12-07},
	date = {2017-05-01},
	langid = {english},
	keywords = {Patent analysis, Text mining, Collaborative filtering, Latent Dirichlet allocation, Product opportunity, Product portfolio},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/NHA8ZKR3/S0360835216301127.html:text/html},
}

@article{zha_chen10,
	title = {Study on early warning of competitive technical intelligence based on the patent map},
	volume = {5},
	issn = {1796-203X},
	url = {http://academypublisher.com/ojs/index.php/jcp/article/view/584},
	doi = {10.4304/jcp.5.2.274-281},
	abstract = {The patent documentation has a higher technical value than the general scientific documents. Through analyzing the content of technical intelligence of patent documentation, enterprises may find out some effective solutions, having access to new ideas about Research and Development (R\&D) and avoiding existing patent landmines at the same time. In this paper, with the help of database Derwent Innovations Index ({DII}) and the corresponding software-Thomson Data Analyzer({TDA}), a series of patent maps of Web2.0 technologies were built up through basic statistical analysis, trend analysis and correlation analysis. These patent maps could offer important reference value for the R\&D activities of enterprises.},
	pages = {274--281},
	number = {2},
	journaltitle = {Journal of Computers},
	shortjournal = {{JCP}},
	author = {Zha, Xianjin and Chen, Minghong},
	urldate = {2022-12-07},
	date = {2010-02-01},
	langid = {english},
	file = {Zha and Chen - 2010 - Study on Early Warning of Competitive Technical In.pdf:/Users/annekleine/Zotero/storage/TDFBYUHC/Zha and Chen - 2010 - Study on Early Warning of Competitive Technical In.pdf:application/pdf},
}

@article{trappey_etal11,
	title = {Using patent data for technology forecasting: China {RFID} patent analysis},
	volume = {25},
	issn = {1474-0346},
	url = {https://www.sciencedirect.com/science/article/pii/S1474034610000340},
	doi = {10.1016/j.aei.2010.05.007},
	series = {{RFID} and sustainable value chains},
	shorttitle = {Using patent data for technology forecasting},
	abstract = {China is one of the world’s largest manufacturers and consumers of Radio Frequency Identification ({RFID}) applications. Current estimates show that China will need over 3billion {RFID} tags to satisfy demand in the year 2009. The applications for {RFID} patents have spread across a very diverse range of inventions and in the future it is likely that most products manufactured in China will contain an {RFID} tag. China’s {RFID} industry has grown along with the demand and researchers are making significant technological advances. In this research, patent data from the State Intellectual Property Office of the People’s Republic of China ({SIPO}) have been used to explore {RFID} technology development and its trends. Patent abstracts containing the keyword and phrase “{RFID}” and “Radio Frequency Identification” were collected for analysis, content extraction, and clustering. In total, 1389 patents from the {SIPO} database covering the years 1995–2008 were retrieved and archived for analysis. Patents provide exclusive rights and legal protection for inventors, play an important role in the development and fair diffusion of technology, and contain detailed specifications necessary to define and protect the boundaries of an invention. Through patent analysis, companies monitor the development of technology and evaluate the position of potential competitors in the market. This research introduce a methodology which combines patent content clustering and technology life cycle forecasting to find a niche space of {RFID} technology development in China. A patent content clustering method is used to cluster different patent documents into homogenous groups, and then technology forecasting is applied to evaluate possible market opportunities for future inventors and investors. The results suggest that the cluster called {RFID} wireless communication devices has entered the saturation stage and thus provides limited opportunity for development. Four other clusters; {RFID} concepts and applications, {RFID} architecture, {RFID} tracking implementation, and {RFID} transmission apparatus, have entered the mature stage. The {RFID} frequency and waves cluster appears to be in early growth stage with good development potential. Since the technology related to basic {RFID} concepts and devices has reached a mature stage in China, the research and development seems to be targeting the improvement of the {RFID} frequencies and waves as a means to develop more reliable {RFID} systems and applications.},
	pages = {53--64},
	number = {1},
	journaltitle = {Advanced Engineering Informatics},
	shortjournal = {Advanced Engineering Informatics},
	author = {Trappey, Charles V. and Wu, Hsin-Ying and Taghaboni-Dutta, Fataneh and Trappey, Amy J. C.},
	urldate = {2022-12-07},
	date = {2011-01-01},
	langid = {english},
	keywords = {Patent analysis, Clustering, China patents, Patent mapping, Radio Frequency Identification ({RFID})},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/RMFIQ3PS/S1474034610000340.html:text/html},
}

@book{Diagnostic22,
	edition = {5th ed., text rev.},
	title = {Diagnostic and statistical manual of mental disorders},
	url = {https://doi.org/10.1176/appi.books.9780890425787},
	publisher = {American Psychiatric Association},
	date = {2022},
}

@article{salazardepablo_etal21,
	title = {Implementing precision psychiatry: a systematic review of individualized prediction models for clinical practice},
	volume = {47},
	issn = {0586-7614, 1745-1701},
	url = {https://academic.oup.com/schizophreniabulletin/article/47/2/284/5903901},
	doi = {10.1093/schbul/sbaa120},
	shorttitle = {Implementing Precision Psychiatry},
	abstract = {Abstract
            
              Background
              The impact of precision psychiatry for clinical practice has not been systematically appraised. This study aims to provide a comprehensive review of validated prediction models to estimate the individual risk of being affected with a condition (diagnostic), developing outcomes (prognostic), or responding to treatments (predictive) in mental disorders.
            
            
              Methods
              {PRISMA}/{RIGHT}/{CHARMS}-compliant systematic review of the Web of Science, Cochrane Central Register of Reviews, and Ovid/{PsycINFO} databases from inception until July 21, 2019 ({PROSPERO} {CRD}42019155713) to identify diagnostic/prognostic/predictive prediction studies that reported individualized estimates in psychiatry and that were internally or externally validated or implemented. Random effect meta-regression analyses addressed the impact of several factors on the accuracy of prediction models.
            
            
              Findings
              Literature search identified 584 prediction modeling studies, of which 89 were included. 10.4\% of the total studies included prediction models internally validated (n = 61), 4.6\% models externally validated (n = 27), and 0.2\% (n = 1) models considered for implementation. Across validated prediction modeling studies (n = 88), 18.2\% were diagnostic, 68.2\% prognostic, and 13.6\% predictive. The most frequently investigated condition was psychosis (36.4\%), and the most frequently employed predictors clinical (69.5\%). Unimodal compared to multimodal models (β = .29, P = .03) and diagnostic compared to prognostic (β = .84, p \&lt; .0001) and predictive (β = .87, P = .002) models were associated with increased accuracy.
            
            
              Interpretation
              To date, several validated prediction models are available to support the diagnosis and prognosis of psychiatric conditions, in particular, psychosis, or to predict treatment response. Advancements of knowledge are limited by the lack of implementation research in real-world clinical practice. A new generation of implementation research is required to address this translational gap.},
	pages = {284--297},
	number = {2},
	journaltitle = {Schizophrenia Bulletin},
	author = {Salazar de Pablo, Gonzalo and Studerus, Erich and Vaquerizo-Serrano, Julio and Irving, Jessica and Catalan, Ana and Oliver, Dominic and Baldwin, Helen and Danese, Andrea and Fazel, Seena and Steyerberg, Ewout W and Stahl, Daniel and Fusar-Poli, Paolo},
	urldate = {2022-07-10},
	date = {2021-03-16},
	langid = {english},
	file = {Salazar de Pablo et al. - 2021 - Implementing Precision Psychiatry A Systematic Re.pdf:/Users/annekleine/Zotero/storage/ZV49MVS6/Salazar de Pablo et al. - 2021 - Implementing Precision Psychiatry A Systematic Re.pdf:application/pdf},
}

@article{yahata_etal16,
	title = {A small number of abnormal brain connections predicts adult autism spectrum disorder},
	volume = {7},
	rights = {2016 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/ncomms11254},
	doi = {10.1038/ncomms11254},
	abstract = {Although autism spectrum disorder ({ASD}) is a serious lifelong condition, its underlying neural mechanism remains unclear. Recently, neuroimaging-based classifiers for {ASD} and typically developed ({TD}) individuals were developed to identify the abnormality of functional connections ({FCs}). Due to over-fitting and interferential effects of varying measurement conditions and demographic distributions, no classifiers have been strictly validated for independent cohorts. Here we overcome these difficulties by developing a novel machine-learning algorithm that identifies a small number of {FCs} that separates {ASD} versus {TD}. The classifier achieves high accuracy for a Japanese discovery cohort and demonstrates a remarkable degree of generalization for two independent validation cohorts in the {USA} and Japan. The developed {ASD} classifier does not distinguish individuals with major depressive disorder and attention-deficit hyperactivity disorder from their controls but moderately distinguishes patients with schizophrenia from their controls. The results leave open the viable possibility of exploring neuroimaging-based dimensions quantifying the multiple-disorder spectrum.},
	pages = {11254},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Yahata, Noriaki and Morimoto, Jun and Hashimoto, Ryuichiro and Lisi, Giuseppe and Shibata, Kazuhisa and Kawakubo, Yuki and Kuwabara, Hitoshi and Kuroda, Miho and Yamada, Takashi and Megumi, Fukuda and Imamizu, Hiroshi and Náñez Sr, José E. and Takahashi, Hidehiko and Okamoto, Yasumasa and Kasai, Kiyoto and Kato, Nobumasa and Sasaki, Yuka and Watanabe, Takeo and Kawato, Mitsuo},
	urldate = {2022-08-17},
	date = {2016-04-14},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Autism spectrum disorders, Nerve conduction studies},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/SNWIS87V/Yahata et al. - 2016 - A small number of abnormal brain connections predi.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/GCQG9EE6/ncomms11254.html:text/html},
}

@article{lutz_etal22,
	title = {Prospective evaluation of a clinical decision support system in psychological therapy},
	volume = {90},
	issn = {1939-2117},
	doi = {10.1037/ccp0000642},
	abstract = {Objective: Thus far, most applications in precision mental health have not been evaluated prospectively. This article presents the results of a prospective randomized-controlled trial investigating the effects of a digital decision support and feedback system, which includes two components of patient-specific recommendations: (a) a clinical strategy recommendation and (b) adaptive recommendations for patients at risk for treatment failure. Method: Therapist–patient dyads (N = 538) in a cognitive behavioral therapy outpatient clinic were randomized to either having access to a decision support system (intervention group; n = 335) or not (treatment as usual; n = 203). First, treatment strategy recommendations (problem-solving, motivation-oriented, or a mix of both strategies) for the first 10 sessions were evaluated. Second, the effect of psychometric feedback enhanced with clinical problem-solving tools on treatment outcome was investigated. Results: The prospective evaluation showed a differential effect size of about 0.3 when therapists followed the recommended treatment strategy in the first 10 sessions. Moreover, the linear mixed models revealed therapist symptom awareness and therapist attitude and confidence as significant predictors of an outcome as well as therapist-rated usefulness of feedback as a significant moderator of the feedback—outcome and the not on track—outcome associations. However, no main effects were found for feedback. Conclusions: The results demonstrate the importance of prospective studies and the high-quality implementation of digital decision support tools in clinical practice. Therapists seem to be able to learn from such systems and incorporate them into their clinical practice to enhance patient outcomes, but only when implementation is successful. ({PsycInfo} Database Record (c) 2022 {APA}, all rights reserved)},
	pages = {90--106},
	number = {1},
	journaltitle = {Journal of Consulting and Clinical Psychology},
	author = {Lutz, Wolfgang and Deisenhofer, Anne-Katharina and Rubel, Julian and Bennemann, Björn and Giesemann, Julia and Poster, Kaitlyn and Schwartz, Brian},
	date = {2022},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Psychotherapy, Treatment, Clinical Practice, Decision Support Systems, Feedback, Mental Health, Problem Solving, Therapists, Treatment Outcomes},
	file = {Snapshot:/Users/annekleine/Zotero/storage/E4DGQEQS/2021-58431-001.html:text/html},
}

@article{trivedi_etal06,
	title = {Evaluation of outcomes with citalopram for depression using measurement-based care in {STAR}*D: Implications for clinical practice},
	volume = {163},
	issn = {0002-953X},
	url = {https://ajp.psychiatryonline.org/doi/full/10.1176/appi.ajp.163.1.28},
	doi = {10.1176/appi.ajp.163.1.28},
	shorttitle = {Evaluation of Outcomes With Citalopram for Depression Using Measurement-Based Care in {STAR}*D},
	abstract = {{OBJECTIVE}: Selective serotonin reuptake inhibitors ({SSRIs}) are widely used to treat depression, but the rates, timing, and baseline predictors of remission in “real world” patients are not established. The authors’ primary objectives in this study were to evaluate the effectiveness of citalopram, an {SSRI}, using measurement-based care in actual practice, and to identify predictors of symptom remission in outpatients with major depressive disorder. {METHOD}: This clinical study included outpatients with major depressive disorder who were treated in 23 psychiatric and 18 primary care “real world” settings. The patients received flexible doses of citalopram prescribed by clinicians for up to 14 weeks. The clinicians were assisted by a clinical research coordinator in the application of measurement-based care, which included the routine measurement of symptoms and side effects at each treatment visit and the use of a treatment manual that described when and how to modify medication doses based on these measures. Remission was defined as an exit score of ≤7 on the 17-item Hamilton Depression Rating Scale ({HAM}-D) (primary outcome) or a score of ≤5 on the 16-item Quick Inventory of Depressive Symptomatology, Self-Report ({QIDS}-{SR}) (secondary outcome). Response was defined as a reduction of ≥50\% in baseline {QIDS}-{SR} score. {RESULTS}: Nearly 80\% of the 2,876 outpatients in the analyzed sample had chronic or recurrent major depression; most also had a number of comorbid general medical and psychiatric conditions. The mean exit citalopram dose was 41.8 mg/day. Remission rates were 28\% ({HAM}-D) and 33\% ({QIDS}-{SR}). The response rate was 47\% ({QIDS}-{SR}). Patients in primary and psychiatric care settings did not differ in remission or response rates. A substantial portion of participants who achieved either response or remission at study exit did so at or after 8 weeks of treatment. Participants who were Caucasian, female, employed, or had higher levels of education or income had higher {HAM}-D remission rates; longer index episodes, more concurrent psychiatric disorders (especially anxiety disorders or drug abuse), more general medical disorders, and lower baseline function and quality of life were associated with lower {HAM}-D remission rates. {CONCLUSIONS}: The response and remission rates in this highly generalizable sample with substantial axis I and axis {III} comorbidity closely resemble those seen in 8-week efficacy trials. The systematic use of easily implemented measurement-based care procedures may have assisted in achieving these results.},
	pages = {28--40},
	number = {1},
	journaltitle = {American Journal of Psychiatry},
	shortjournal = {{AJP}},
	author = {Trivedi, Madhukar H. and Rush, A. John and Wisniewski, Stephen R. and Nierenberg, Andrew A. and Warden, Diane and Ritz, Louise and Norquist, Grayson and Howland, Robert H. and Lebowitz, Barry and {McGrath}, Patrick J. and Shores-Wilson, Kathy and Biggs, Melanie M. and Balasubramani, G. K. and Fava, Maurizio},
	urldate = {2022-09-22},
	date = {2006-01},
	note = {Publisher: American Psychiatric Publishing},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/C9T24BXL/Trivedi et al. - 2006 - Evaluation of Outcomes With Citalopram for Depress.pdf:application/pdf},
}

@article{souery_etal11,
	title = {Switching antidepressant class does not improve response or remission in treatment-resistant depression},
	volume = {31},
	issn = {0271-0749},
	url = {https://journals.lww.com/psychopharmacology/Abstract/2011/08000/Switching_Antidepressant_Class_Does_Not_Improve.17.aspx},
	doi = {10.1097/JCP.0b013e3182228619},
	abstract = {Objective: 
        The management of treatment-resistant depression is a much debated issue. In particular, the evidence supporting the commonly suggested sequential use of antidepressants from 2 different pharmacological classes is weak.
        This retrospective study was undertaken to investigate whether there is a better response in nonresponders switched to a different class of antidepressants (across-class) compared with nonresponders switched to an antidepressant from the same class (within-class).
        Methods: 
        Three hundred forty patients with primary major depressive disorder were recruited in the context of a European multicenter project. Subjects whose current depressive episode had failed to respond to a first antidepressant trial of adequate dose and duration were included.
        Results: 
        There was no significant difference in response or remission rates between the across-class and within-class groups after controlling for possible confounders.
        Conclusions: 
        In depressed nonresponders to a previous antidepressant treatment, switching to a different class of antidepressants was not associated with a better response or remission rate.},
	pages = {512--516},
	number = {4},
	journaltitle = {Journal of Clinical Psychopharmacology},
	author = {Souery, Daniel and Serretti, Alessandro and Calati, Raffaella and Oswald, Pierre and Massat, Isabelle and Konstantinidis, Anastasios and Linotte, Sylvie and Bollen, Joseph and Demyttenaere, Koen and Kasper, Siegfried and Lecrubier, Yves and Montgomery, Stuart and Zohar, Joseph and Mendlewicz, Julien},
	urldate = {2022-09-22},
	date = {2011-08},
	langid = {american},
	file = {Snapshot:/Users/annekleine/Zotero/storage/ASXAY3XM/Switching_Antidepressant_Class_Does_Not_Improve.17.html:text/html},
}

@article{vanos16,
	title = {“Schizophrenia” does not exist},
	volume = {352},
	issn = {0959-8138},
	url = {https://www.jstor.org/stable/26943638},
	journaltitle = {{BMJ}: British Medical Journal},
	author = {van Os, Jim},
	urldate = {2022-10-18},
	date = {2016},
	note = {Publisher: {BMJ}},
}

@article{rush_etal06,
	title = {Acute and longer-term outcomes in depressed outpatients requiring one or several treatment steps: A {STAR}*D report},
	volume = {163},
	issn = {0002-953X},
	url = {https://ajp.psychiatryonline.org/doi/full/10.1176/ajp.2006.163.11.1905},
	doi = {10.1176/ajp.2006.163.11.1905},
	shorttitle = {Acute and Longer-Term Outcomes in Depressed Outpatients Requiring One or Several Treatment Steps},
	abstract = {Objective: This report describes the participants and compares the acute and longer-term treatment outcomes associated with each of four successive steps in the Sequenced Treatment Alternatives to Relieve Depression ({STAR}*D) trial. Method: A broadly representative adult outpatient sample with nonpsychotic major depressive disorder received one (N=3,671) to four (N=123) successive acute treatment steps. Those not achieving remission with or unable to tolerate a treatment step were encouraged to move to the next step. Those with an acceptable benefit, preferably symptom remission, from any particular step could enter a 12-month naturalistic follow-up phase. A score of ≤5 on the Quick Inventory of Depressive Symptomatology–Self-Report ({QIDS}-{SR} 16 ) (equivalent to ≤7 on the 17-item Hamilton Rating Scale for Depression [{HRSD} 17 ]) defined remission; a {QIDS}-{SR} 16 total score of ≥11 ({HRSD} 17 ≥14) defined relapse. Results: The {QIDS}-{SR} 16 remission rates were 36.8\%, 30.6\%, 13.7\%, and 13.0\% for the first, second, third, and fourth acute treatment steps, respectively. The overall cumulative remission rate was 67\%. Overall, those who required more treatment steps had higher relapse rates during the naturalistic follow-up phase. In addition, lower relapse rates were found among participants who were in remission at follow-up entry than for those who were not after the first three treatment steps. Conclusions: When more treatment steps are required, lower acute remission rates (especially in the third and fourth treatment steps) and higher relapse rates during the follow-up phase are to be expected. Studies to identify the best multistep treatment sequences for individual patients and the development of more broadly effective treatments are needed.},
	pages = {1905--1917},
	number = {11},
	journaltitle = {American Journal of Psychiatry},
	shortjournal = {{AJP}},
	author = {Rush, A.  John and Trivedi, Madhukar  H. and Wisniewski, Stephen  R. and Nierenberg, Andrew  A. and Stewart, Jonathan  W. and Warden, Diane and Niederehe, George and Thase, Michael  E. and Lavori, Philip  W. and Lebowitz, Barry  D. and {McGrath}, Patrick  J. and Rosenbaum, Jerrold  F. and Sackeim, Harold  A. and Kupfer, David  J. and Luther, James and Fava, Maurizio},
	urldate = {2022-10-18},
	date = {2006-11},
	note = {Publisher: American Psychiatric Publishing},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/4SN7ZTSR/Rush et al. - 2006 - Acute and Longer-Term Outcomes in Depressed Outpat.pdf:application/pdf},
}

@article{passos_etal22,
	title = {Precision psychiatry: the future is now},
	volume = {67},
	issn = {0706-7437},
	url = {https://doi.org/10.1177/0706743721998044},
	doi = {10.1177/0706743721998044},
	shorttitle = {Precision Psychiatry},
	pages = {21--25},
	number = {1},
	journaltitle = {The Canadian Journal of Psychiatry},
	shortjournal = {Can J Psychiatry},
	author = {Passos, Ives Cavalcante and Ballester, Pedro and Rabelo-da-Ponte, Francisco Diego and Kapczinski, Flavio},
	urldate = {2022-10-18},
	date = {2022-01-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc},
	file = {SAGE PDF Full Text:/Users/annekleine/Zotero/storage/89CCQ2AH/Passos et al. - 2022 - Precision Psychiatry The Future Is Now.pdf:application/pdf},
}

@article{newson_etal20,
	title = {The heterogeneity of mental health assessment},
	volume = {11},
	issn = {1664-0640},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyt.2020.00076},
	abstract = {Across the landscape of mental health research and diagnosis, there is a diverse range of questionnaires and interviews available for use by clinicians and researchers to determine patient treatment plans or investigate internal and external etiologies. Although individually, these tools have each been assessed for their validity and reliability, there is little research examining the consistency between them in terms of what symptoms they assess, and how they assess those symptoms. Here, we provide an analysis of 126 different questionnaires and interviews commonly used to diagnose and screen for 10 different disorder types including depression, anxiety, obsessive compulsive disorder ({OCD}), post-traumatic stress disorder ({PTSD}), attention deficit/hyperactivity disorder ({ADHD}), autism spectrum disorder ({ASD}), addiction, bipolar disorder, eating disorder, and schizophrenia, as well as comparator questionnaires and interviews that offer an all-in-one cross-disorder assessment of mental health. We demonstrate substantial inconsistency in the inclusion and emphasis of symptoms assessed within disorders as well as considerable symptom overlap across disorder-specific tools. Within the same disorder, similarity scores across assessment tools ranged from 29\% for assessment of bipolar disorder to a maximum of 58\% for {OCD}. Furthermore, when looking across disorders, 60\% of symptoms were assessed in at least half of all disorders illustrating the extensive overlap in symptom profiles between disorder-specific assessment tools. Biases in assessment toward emotional, cognitive, physical or behavioral symptoms were also observed, further adding to the heterogeneity across assessments. Analysis of other characteristics such as the time period over which symptoms were assessed, as well as whether there was a focus toward frequency, severity or duration of symptoms also varied substantially across assessment tools. The consequence of this inconsistent and heterogeneous assessment landscape is that it hinders clinical diagnosis and treatment and frustrates understanding of the social, environmental, and biological factors that contribute to mental health symptoms and disorders. Altogether, it underscores the need for standardized assessment tools that are more disorder agnostic and span the full spectrum of mental health symptoms to aid the understanding of underlying etiologies and the discovery of new treatments for psychiatric dysfunction.},
	journaltitle = {Frontiers in Psychiatry},
	author = {Newson, Jennifer J. and Hunter, Daniel and Thiagarajan, Tara C.},
	urldate = {2022-10-18},
	date = {2020},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/ZH3MYP4V/Newson et al. - 2020 - The Heterogeneity of Mental Health Assessment.pdf:application/pdf},
}

@article{kendler16,
	title = {The nature of psychiatric disorders},
	volume = {15},
	issn = {2051-5545},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wps.20292},
	doi = {10.1002/wps.20292},
	abstract = {A foundational question for the discipline of psychiatry is the nature of psychiatric disorders. What kinds of things are they? In this paper, I review and critique three major relevant theories: realism, pragmatism and constructivism. Realism assumes that the content of science is real and independent of human activities. I distinguish two “flavors” of realism: chemistry-based, for which the paradigmatic example is elements of the periodic table, and biology-based, for which the paradigm is species. The latter is a much better fit for psychiatry. Pragmatism articulates a sensible approach to psychiatric disorders just seeking categories that perform well in the world. But it makes no claim about the reality of those disorders. This is problematic, because we have a duty to advocate for our profession and our patients against other physicians who never doubt the reality of the disorders they treat. Constructivism has been associated with anti-psychiatry activists, but we should admit that social forces play a role in the creation of our diagnoses, as they do in many sciences. However, truly socially constructed psychiatric disorders are rare. I then describe powerful arguments against a realist theory of psychiatric disorders. Because so many prior psychiatric diagnoses have been proposed and then abandoned, can we really claim that our current nosologies have it right? Much of our current nosology arose from a series of historical figures and events which could have gone differently. If we re-run the tape of history over and over again, the {DSM} and {ICD} would not likely have the same categories on every iteration. Therefore, we should argue more confidently for the reality of broader constructs of psychiatric illness rather than our current diagnostic categories, which remain tentative. Finally, instead of thinking that our disorders are true because they correspond to clear entities in the world, we should consider a coherence theory of truth by which disorders become more true when they fit better into what else we know about the world. In our ongoing project to study and justify the nature of psychiatric disorders, we ought to be broadly pragmatic but not lose sight of an underlying commitment, despite the associated difficulties, to the reality of psychiatric illness.},
	pages = {5--12},
	number = {1},
	journaltitle = {World Psychiatry},
	author = {Kendler, Kenneth S.},
	urldate = {2022-10-18},
	date = {2016},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wps.20292},
	keywords = {Psychiatric disorders, {DSM}-5, {ICD}-10, constructivism, homeostatic property clusters, pragmatism, realism},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/XJ85FPEB/Kendler - 2016 - The nature of psychiatric disorders.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/7PZB3EAS/wps.html:text/html},
}

@article{fernandes_etal17,
	title = {The new field of ‘precision psychiatry’},
	volume = {15},
	issn = {1741-7015},
	url = {https://doi.org/10.1186/s12916-017-0849-x},
	doi = {10.1186/s12916-017-0849-x},
	abstract = {Precision medicine is a new and important topic in psychiatry. Psychiatry has not yet benefited from the advanced diagnostic and therapeutic technologies that form an integral part of other clinical specialties. Thus, the vision of precision medicine as applied to psychiatry – ‘precision psychiatry’ – promises to be even more transformative than in other fields of medicine, which have already lessened the translational gap.},
	pages = {80},
	number = {1},
	journaltitle = {{BMC} Medicine},
	shortjournal = {{BMC} Medicine},
	author = {Fernandes, Brisa S. and Williams, Leanne M. and Steiner, Johann and Leboyer, Marion and Carvalho, André F. and Berk, Michael},
	urldate = {2022-10-18},
	date = {2017-04-13},
	keywords = {Big data, Precision medicine, Research domain criteria, Biomarkers, Omics, Personalised medicine, Precision psychiatry, Systems biology},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/ABMJGR8E/Fernandes et al. - 2017 - The new field of ‘precision psychiatry’.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/P4NQ83KH/s12916-017-0849-x.html:text/html},
}

@article{drysdale_etal17,
	title = {Resting-state connectivity biomarkers define neurophysiological subtypes of depression},
	volume = {23},
	issn = {1078-8956},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5624035/},
	doi = {10.1038/nm.4246},
	abstract = {Biomarkers have transformed modern medicine but remain largely elusive in psychiatry, partly because there is a weak correspondence between diagnostic labels and their neurobiological substrates. Like other neuropsychiatric disorders, depression is not a unitary disease, but rather a heterogeneous syndrome that encompasses varied, co-occurring symptoms and divergent responses to treatment. By using functional magnetic resonance imaging ({fMRI}) in a large multisite sample (n = 1,188), we show here that patients with depression can be subdivided into four neurophysiological subtypes (‘biotypes’) defined by distinct patterns of dysfunctional connectivity in limbic and frontostriatal networks. Clustering patients on this basis enabled the development of diagnostic classifiers (biomarkers) with high (82–93\%) sensitivity and specificity for depression subtypes in multisite validation (n = 711) and out-of-sample replication (n = 477) data sets. These biotypes cannot be differentiated solely on the basis of clinical features, but they are associated with differing clinical-symptom profiles. They also predict responsiveness to transcranial magnetic stimulation therapy (n = 154). Our results define novel subtypes of depression that transcend current diagnostic boundaries and may be useful for identifying the individuals who are most likely to benefit from targeted neurostimulation therapies.},
	pages = {28--38},
	number = {1},
	journaltitle = {Nature medicine},
	shortjournal = {Nat Med},
	author = {Drysdale, Andrew T and Grosenick, Logan and Downar, Jonathan and Dunlop, Katharine and Mansouri, Farrokh and Meng, Yue and Fetcho, Robert N and Zebley, Benjamin and Oathes, Desmond J and Etkin, Amit and Schatzberg, Alan F and Sudheimer, Keith and Keller, Jennifer and Mayberg, Helen S and Gunning, Faith M and Alexopoulos, George S and Fox, Michael D and Pascual-Leone, Alvaro and Voss, Henning U and Casey, {BJ} and Dubin, Marc J and Liston, Conor},
	urldate = {2022-10-18},
	date = {2017-01},
	pmid = {27918562},
	pmcid = {PMC5624035},
	keywords = {Depression, Diagnostic markers, Predictive markers},
	file = {Accepted Version:/Users/annekleine/Zotero/storage/FNAERM4H/Drysdale et al. - 2017 - Resting-state connectivity biomarkers define neuro.pdf:application/pdf;PubMed Central Full Text PDF:/Users/annekleine/Zotero/storage/HGMVH8KU/Drysdale et al. - 2017 - Resting-state connectivity biomarkers define neuro.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/LPQCRVJ7/nm.html:text/html},
}

@article{baglieri_cesaroni13,
	title = {Capturing the real value of patent analysis for R\&D strategies},
	volume = {25},
	issn = {0953-7325},
	url = {https://doi.org/10.1080/09537325.2013.823149},
	doi = {10.1080/09537325.2013.823149},
	abstract = {Patent information can be used for strategic planning purposes. Conventional patent analysis has commonly focused on factual information and, in particular, on information extraction, visualisation and interpretation. Less scholarly attention has been devoted to the strategic role of an integrated system of patent intelligence in supporting decision-making in R\&D investments. Our paper addresses this gap and explores how patent analysis may benefit those firms that intend capturing the beneficial effects of Open Innovation. We also critically discuss the intrinsic limits of both patent information and patent analysis, which should be taken into account by systems of patent intelligence.},
	pages = {971--986},
	number = {8},
	journaltitle = {Technology Analysis \& Strategic Management},
	author = {Baglieri, Daniela and Cesaroni, Fabrizio},
	urldate = {2022-12-07},
	date = {2013-09-01},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09537325.2013.823149},
	keywords = {patent analysis, patent information, R\&D strategies},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/RRL7J94G/Baglieri and Cesaroni - 2013 - Capturing the real value of patent analysis for R&.pdf:application/pdf},
}

@article{fusar-poli_etal19,
	title = {Transdiagnostic psychiatry: a systematic review},
	volume = {18},
	issn = {2051-5545},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wps.20631},
	doi = {10.1002/wps.20631},
	shorttitle = {Transdiagnostic psychiatry},
	abstract = {The usefulness of current psychiatric classification, which is based on {ICD}/{DSM} categorical diagnoses, remains questionable. A promising alternative has been put forward as the “transdiagnostic” approach. This is expected to cut across existing categorical diagnoses and go beyond them, to improve the way we classify and treat mental disorders. This systematic review explores whether self-defining transdiagnostic research meets such high expectations. A multi-step Web of Science literature search was performed according to an a priori protocol, to identify all studies that used the word “transdiagnostic” in their title, up to May 5, 2018. Empirical variables which indexed core characteristics were extracted, complemented by a bibliometric and conceptual analysis. A total of 111 studies were included. Most studies were investigating interventions, followed by cognition and psychological processes, and neuroscientific topics. Their samples ranged from 15 to 91,199 (median 148) participants, with a mean age from 10 to more than 60 (median 33) years. There were several methodological inconsistencies relating to the definition of the gold standard ({DSM}/{ICD} diagnoses), of the outcome measures and of the transdiagnostic approach. The quality of the studies was generally low and only a few findings were externally replicated. The majority of studies tested transdiagnostic features cutting across different diagnoses, and only a few tested new classification systems beyond the existing diagnoses. About one fifth of the studies were not transdiagnostic at all, because they investigated symptoms and not disorders, a single disorder, or because there was no diagnostic information. The bibliometric analysis revealed that transdiagnostic research largely restricted its focus to anxiety and depressive disorders. The conceptual analysis showed that transdiagnostic research is grounded more on rediscoveries than on true innovations, and that it is affected by some conceptual biases. To date, transdiagnostic approaches have not delivered a credible paradigm shift that can impact classification and clinical care. Practical “{TRANSD}”iagnostic recommendations are proposed here to guide future research in this field.},
	pages = {192--207},
	number = {2},
	journaltitle = {World Psychiatry},
	author = {Fusar-Poli, Paolo and Solmi, Marco and Brondino, Natascia and Davies, Cathy and Chae, Chungil and Politi, Pierluigi and Borgwardt, Stefan and Lawrie, Stephen M. and Parnas, Josef and {McGuire}, Philip},
	urldate = {2023-01-08},
	date = {2019},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wps.20631},
	keywords = {classification, diagnosis, depression, Transdiagnostic, anxiety, bibliometric analysis, conceptual analysis, psychosis, recommendations},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/QPC9QJ4V/Fusar-Poli et al. - 2019 - Transdiagnostic psychiatry a systematic review.pdf:application/pdf;Snapshot:/Users/annekleine/Zotero/storage/JEFS4WUG/wps.html:text/html},
}

@misc{rosenfeld_etal19,
	title = {Big data analytics and {AI} in mental healthcare},
	url = {http://arxiv.org/abs/1903.12071},
	abstract = {Mental health conditions cause a great deal of distress or impairment; depression alone will affect 11\% of the world's population. The application of Artificial Intelligence ({AI}) and big-data technologies to mental health has great potential for personalizing treatment selection, prognosticating, monitoring for relapse, detecting and helping to prevent mental health conditions before they reach clinical-level symptomatology, and even delivering some treatments. However, unlike similar applications in other fields of medicine, there are several unique challenges in mental health applications which currently pose barriers towards the implementation of these technologies. Specifically, there are very few widely used or validated biomarkers in mental health, leading to a heavy reliance on patient and clinician derived questionnaire data as well as interpretation of new signals such as digital phenotyping. In addition, diagnosis also lacks the same objective 'gold standard' as in other conditions such as oncology, where clinicians and researchers can often rely on pathological analysis for confirmation of diagnosis. In this chapter we discuss the major opportunities, limitations and techniques used for improving mental healthcare through {AI} and big-data. We explore both the computational, clinical and ethical considerations and best practices as well as lay out the major researcher directions for the near future.},
	number = {{arXiv}:1903.12071},
	publisher = {{arXiv}},
	author = {Rosenfeld, Ariel and Benrimoh, David and Armstrong, Caitrin and Mirchi, Nykan and Langlois-Therrien, Timothe and Rollins, Colleen and Tanguay-Sela, Myriam and Mehltretter, Joseph and Fratila, Robert and Israel, Sonia and Snook, Emily and Perlman, Kelly and Kleinerman, Akiva and Saab, Bechara and Thoburn, Mark and Gabbay, Cheryl and Yaniv-Rosenfeld, Amit},
	urldate = {2023-01-08},
	date = {2019-03-12},
	eprinttype = {arxiv},
	eprint = {1903.12071 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computers and Society},
	file = {arXiv Fulltext PDF:/Users/annekleine/Zotero/storage/Y2WAW5TI/Rosenfeld et al. - 2019 - Big Data Analytics and AI in Mental Healthcare.pdf:application/pdf;arXiv.org Snapshot:/Users/annekleine/Zotero/storage/ZKPB2K7U/1903.html:text/html},
}

@article{chekroud_etal16,
	title = {Cross-trial prediction of treatment outcome in depression: a machine learning approach},
	volume = {3},
	issn = {22150366},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S221503661500471X},
	doi = {10.1016/S2215-0366(15)00471-X},
	shorttitle = {Cross-trial prediction of treatment outcome in depression},
	pages = {243--250},
	number = {3},
	journaltitle = {The Lancet Psychiatry},
	shortjournal = {The Lancet Psychiatry},
	author = {Chekroud, Adam Mourad and Zotti, Ryan Joseph and Shehzad, Zarrar and Gueorguieva, Ralitza and Johnson, Marcia K and Trivedi, Madhukar H and Cannon, Tyrone D and Krystal, John Harrison and Corlett, Philip Robert},
	urldate = {2022-06-23},
	date = {2016-03},
	langid = {english},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/SYH32R7S/S221503661500471X.html:text/html},
}

@report{strategicmarketresearch21,
	title = {Behavioral Health Software Market Trends},
	url = {https://www.strategicmarketresearch.com/market-report/behavioural-health-software-market},
	abstract = {The global behavioral health software market size in 2021 was \$2.44 Bn as estimated by {SMR} and will propel at a {CAGR} of 13.39\%. It is poised to project a value of \$7.61 Bn by 2030.},
	number = {39728966},
	author = {Strategic Market Research, Base},
	urldate = {2022-11-02},
	date = {2021},
	file = {Snapshot:/Users/annekleine/Zotero/storage/IGCMCX8T/behavioural-health-software-market.html:text/html},
}

@report{globalindustryanalytics22,
	title = {Mental health software - global market trajectory \& analytics},
	url = {https://www.researchandmarkets.com/reports/5140364/mental-health-software-global-market-trajectory#product--adaptive},
	author = {Global Industry Analytics, Inc.},
	urldate = {2022-12-07},
	date = {2022},
}

@online{researchandmarkets22,
	title = {Mental Health Software - Global Market Trajectory \& Analytics},
	url = {https://www.researchandmarkets.com/reports/5140364/mental-health-software-global-market-trajectory},
	abstract = {This report features 18 companies, including Meditab Software, The Echo Group, {AdvancedMD}, Welligent, Netsmart Technologies, Kareo, Core Solutions, Inc., Qualifacts Systems},
	author = {Research \{and\} Markets},
	urldate = {2022-10-18},
	date = {2022},
	file = {Snapshot:/Users/annekleine/Zotero/storage/3LJ6M976/mental-health-software-global-market-trajectory.html:text/html},
}

@online{insights22,
	title = {Global Mental Health Market is estimated to be {US}\$ 527.44 billion by 2030 with a {CAGR} of 3.40\% during the forecast period - By {PMI}},
	url = {https://www.globenewswire.com/en/news-release/2022/06/22/2467263/0/en/Global-Mental-Health-Market-is-estimated-to-be-US-527-44-billion-by-2030-with-a-CAGR-of-3-40-during-the-forecast-period-By-PMI.html},
	abstract = {Mental Health Market, By Disorder (Schizophrenia, Post-Traumatic Stress Disorder, Depression Anxiety, Bipolar Disorder, Alcohol Use Disorders and Other...},
	titleaddon = {{GlobeNewswire} News Room},
	author = {insights, Prophecy Market},
	urldate = {2022-10-18},
	date = {2022-06-22},
	langid = {english},
}

@online{Mental,
	title = {Mental Health Market Size, Share{\textbar} Key Analysis {\textbar} Forecast - 2030},
	url = {https://www.alliedmarketresearch.com/mental-health-market-A11770},
	abstract = {Mental health market size is projected to reach \$537.97 billion by 2030, The report presents information related to key drivers \& restraints, and opportunities.},
	titleaddon = {Allied Market Research},
	urldate = {2022-10-18},
	langid = {english},
	file = {Snapshot:/Users/annekleine/Zotero/storage/NKBK8U6V/mental-health-market-A11770.html:text/html},
}

@online{researchandmarkets22a,
	title = {Mental Health Software - Global Market Trajectory \& Analytics},
	url = {https://www.researchandmarkets.com/reports/5140364/mental-health-software-global-market-trajectory},
	abstract = {This report features 18 companies, including Meditab Software, The Echo Group, {AdvancedMD}, Welligent, Netsmart Technologies, Kareo, Core Solutions, Inc., Qualifacts Systems},
	author = {Research \{and\} Markets},
	urldate = {2022-10-18},
	date = {2022},
	file = {Snapshot:/Users/annekleine/Zotero/storage/4GAQWZPT/mental-health-software-global-market-trajectory.html:text/html},
}

@patent{mate*kainien_etal18,
	title = {警觉性预测系统和方法},
	url = {https://patents.google.com/patent/CN108697391A/en?oq=CN108697391A},
	holder = {Curaegis Technology Co},
	type = {patent},
	number = {{CN}108697391A},
	author = {马特·凯尼恩 and 科林·佩恩-罗杰斯 and 乔希·琼斯},
	urldate = {2023-01-13},
	date = {2018-10-23},
	langid = {pinyin},
	keywords = {data, circadian rhythm, individual, information signal, processor},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/YYQRVNP9/马特·凯尼恩 et al. - 2018 - 警觉性预测系统和方法.pdf:application/pdf},
}

@patent{zotero-49746,
	type = {patent},
}

@patent{kohn_etal21,
	title = {Application for tracking progression and isolating causes of adverse medical conditions},
	url = {https://patents.google.com/patent/WO2021034677A1/en?oq=WO2021034677A1},
	holder = {{OptimDosing}, {LLC}},
	type = {patent},
	number = {{WO}2021034677A1},
	author = {Kohn, Kenneth I. and Inwald, David and Brown, Caitlin Joline},
	urldate = {2023-01-13},
	date = {2021-02-25},
	langid = {english},
	keywords = {data, application, disease, trackers, user},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/KFFXSWV9/Kohn et al. - 2021 - Application for tracking progression and isolating.pdf:application/pdf},
}

@patent{casey19,
	title = {Device and method for instilling intrinsic motivation regarding eye contact in children affected by eye contact disorders},
	url = {https://patents.google.com/patent/US10363192B2/en?oq=US10363192B2},
	holder = {Matthew Casey},
	type = {patentus},
	number = {10363192B2},
	author = {Casey, Matthew},
	urldate = {2023-01-13},
	date = {2019-07-30},
	langid = {english},
	keywords = {eye, gaze, subject, eye contact, eyes},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/LNMNMMA4/Casey - 2019 - Device and method for instilling intrinsic motivat.pdf:application/pdf},
}

@patent{liu_etal22s,
	title = {System and method for identifying transdiagnostic features shared across mental health disorders},
	url = {https://patents.google.com/patent/US11244762B2/en?oq=US11244762B2},
	holder = {Blackthorn Therapeutics Inc},
	type = {patentus},
	number = {11244762B2},
	author = {Liu, Yuelu and Mellem, Monika Sharma and Ahammad, Parvez and Cabezas, Humberto Andres {GONZALEZ} and Kollada, Matthew},
	urldate = {2023-01-13},
	date = {2022-02-08},
	langid = {english},
	keywords = {machine learning, data, features, median, mse},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/RDJ9RDGY/LIU et al. - 2022 - System and method for identifying transdiagnostic .pdf:application/pdf},
}

@patent{siekmeier_etal22,
	title = {Method of increasing cognitive function with glutamate receptor agonist},
	url = {https://patents.google.com/patent/US20220313170A1/en?oq=US20220313170A1},
	holder = {Individual},
	type = {patentus},
	number = {20220313170A1},
	author = {Siekmeier, Peter J. and Lowen, Steven B. and Coyle, Joseph T.},
	urldate = {2023-01-13},
	date = {2022-10-06},
	langid = {english},
	keywords = {eeg, frequency domain, glutamate receptor, receptor agonist, transform},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/XRTWSY9B/Siekmeier et al. - 2022 - Method of increasing cognitive function with gluta.pdf:application/pdf},
}

@patent{lyoo_etal21,
	title = {Method and apparatus for predicting posttraumatic behavior problem},
	url = {https://patents.google.com/patent/US20210113144A1/en?oq=US20210113144A1},
	holder = {Industry Collaboration Foundation of Ewha University},
	type = {patentus},
	number = {20210113144A1},
	author = {Lyoo, In Kyoon and Cho, Han Byul and Hong, Ga Hae},
	urldate = {2023-01-13},
	date = {2021-04-22},
	langid = {english},
	keywords = {phenotype, individual, physical, posttraumatic, traumatic event},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/W4XHFKXH/LYOO et al. - 2021 - Method and apparatus for predicting posttraumatic .pdf:application/pdf},
}

@online{WO2021076960A1,
	title = {{WO}2021076960A1 - Live virus vaccine injury risk - Google Patents},
	url = {https://patents.google.com/patent/WO2021076960A1/en?oq=WO2021076960A1},
	urldate = {2023-01-13},
	file = {WO2021076960A1 - Live virus vaccine injury risk - Google Patents:/Users/annekleine/Zotero/storage/WZWPSZ37/en.html:text/html},
}

@online{US20210358623A1,
	title = {{US}20210358623A1 - A Method for Determining a {DHEA} Intensity Dose for Specific Patient - Google Patents},
	url = {https://patents.google.com/patent/US20210358623A1/en?oq=US20210358623A1},
	urldate = {2023-01-13},
	file = {US20210358623A1 - A Method for Determining a DHEA Intensity Dose for Specific Patient - Google Patents:/Users/annekleine/Zotero/storage/4KESS75I/en.html:text/html},
}

@online{US20210236032A1,
	title = {{US}20210236032A1 - Robot-aided system and method for diagnosis of autism spectrum disorder - Google Patents},
	url = {https://patents.google.com/patent/US20210236032A1/en?oq=US20210236032A1},
	urldate = {2023-01-13},
	file = {US20210236032A1 - Robot-aided system and method for diagnosis of autism spectrum disorder - Google Patents:/Users/annekleine/Zotero/storage/45AQ4S3P/en.html:text/html},
}

@online{US20210383924A1,
	title = {{US}20210383924A1 - Methods and machine learning for disease diagnosis - Google Patents},
	url = {https://patents.google.com/patent/US20210383924A1/en?oq=US20210383924A1},
	urldate = {2023-01-13},
	file = {US20210383924A1 - Methods and machine learning for disease diagnosis - Google Patents:/Users/annekleine/Zotero/storage/ZLLN67UD/en.html:text/html},
}

@online{US20150278438A1,
	title = {{US}20150278438A1 - Genetic predictors of response to treatment with crhr1 antagonists - Google Patents},
	url = {https://patents.google.com/patent/US20150278438A1/en?oq=US20150278438A1},
	urldate = {2023-01-13},
	file = {US20150278438A1 - Genetic predictors of response to treatment with crhr1 antagonists - Google Patents:/Users/annekleine/Zotero/storage/XPU2EPHU/en.html:text/html},
}

@online{US10837062B2,
	title = {{US}10837062B2 - Method for predicting a treatment response to a {CRHR}1 antagonist and/or a V1B antagonist in a patient with depressive and/or anxiety symptoms - Google Patents},
	url = {https://patents.google.com/patent/US10837062B2/en?oq=US10837062B2},
	urldate = {2023-01-13},
	file = {US10837062B2 - Method for predicting a treatment response to a CRHR1 antagonist and/or a V1B antagonist in a patient with depressive and/or anxiety symptoms - Google Patents:/Users/annekleine/Zotero/storage/UV5VECQQ/en.html:text/html},
}

@online{US10477342B2,
	title = {{US}10477342B2 - Systems and methods of using wireless location, context, and/or one or more communication networks for monitoring for, preempting, and/or mitigating pre-identified behavior - Google Patents},
	url = {https://patents.google.com/patent/US10477342B2/en?oq=US10477342B2},
	urldate = {2023-01-13},
	file = {US10477342B2 - Systems and methods of using wireless location, context, and/or one or more communication networks for monitoring for, preempting, and/or mitigating pre-identified behavior - Google Patents:/Users/annekleine/Zotero/storage/H6AYFI8E/en.html:text/html},
}

@online{US20200320363A1,
	title = {{US}20200320363A1 - Artificial intelligence advisory systems and methods for vibrant constitutional guidance - Google Patents},
	url = {https://patents.google.com/patent/US20200320363A1/en?oq=US20200320363A1},
	urldate = {2023-01-13},
	file = {US20200320363A1 - Artificial intelligence advisory systems and methods for vibrant constitutional guidance - Google Patents:/Users/annekleine/Zotero/storage/TZ4GBHCG/en.html:text/html},
}

@online{US10748644B2,
	title = {{US}10748644B2 - Systems and methods for mental health assessment - Google Patents},
	url = {https://patents.google.com/patent/US10748644B2/en?oq=US10748644B2},
	urldate = {2023-01-13},
	file = {US10748644B2 - Systems and methods for mental health assessment - Google Patents:/Users/annekleine/Zotero/storage/GMU4FPW6/en.html:text/html},
}

@online{US11273283B2,
	title = {{US}11273283B2 - Method and apparatus for neuroenhancement to enhance emotional response - Google Patents},
	url = {https://patents.google.com/patent/US11273283B2/en?oq=US11273283B2},
	urldate = {2023-01-13},
	file = {US11273283B2 - Method and apparatus for neuroenhancement to enhance emotional response - Google Patents:/Users/annekleine/Zotero/storage/GF8EJWE7/en.html:text/html},
}

@online{US11406316B2,
	title = {{US}11406316B2 - Apparatus and method for electroencephalographic measurement - Google Patents},
	url = {https://patents.google.com/patent/US11406316B2/en?oq=US11406316B2},
	urldate = {2023-01-13},
	file = {US11406316B2 - Apparatus and method for electroencephalographic measurement - Google Patents:/Users/annekleine/Zotero/storage/XKQ6GI77/en.html:text/html},
}

@online{US11392198B2,
	title = {{US}11392198B2 - Methods and systems of extended reality environment interaction based on eye motions - Google Patents},
	url = {https://patents.google.com/patent/US11392198B2/en?oq=US11392198B2},
	urldate = {2023-01-13},
	file = {US11392198B2 - Methods and systems of extended reality environment interaction based on eye motions - Google Patents:/Users/annekleine/Zotero/storage/7N57Q58P/en.html:text/html},
}

@online{US10966605B2,
	title = {{US}10966605B2 - Health assessment via eye movement biometrics - Google Patents},
	url = {https://patents.google.com/patent/US10966605B2/en?oq=US10966605B2},
	urldate = {2023-01-13},
	file = {US10966605B2 - Health assessment via eye movement biometrics - Google Patents:/Users/annekleine/Zotero/storage/C35YLFAX/en.html:text/html},
}

@online{US11284797B2,
	title = {{US}11284797B2 - Remote examination through augmented reality - Google Patents},
	url = {https://patents.google.com/patent/US11284797B2/en?oq=US11284797B2},
	urldate = {2023-01-13},
	file = {US11284797B2 - Remote examination through augmented reality - Google Patents:/Users/annekleine/Zotero/storage/PH5HBJB3/en.html:text/html},
}

@online{US11107591B1,
	title = {{US}11107591B1 - Method and system for describing and recommending optimal treatment plans in adaptive telemedical or other contexts - Google Patents},
	url = {https://patents.google.com/patent/US11107591B1/en?oq=US11107591B1},
	urldate = {2023-01-13},
	file = {US11107591B1 - Method and system for describing and recommending optimal treatment plans in adaptive telemedical or other contexts - Google Patents:/Users/annekleine/Zotero/storage/I645GD5Z/en.html:text/html},
}

@online{US20200143922A1,
	title = {{US}20200143922A1 - Methods and apparatus for predicting depression treatment outcomes - Google Patents},
	url = {https://patents.google.com/patent/US20200143922A1/en?oq=US20200143922A1},
	urldate = {2023-01-13},
	file = {US20200143922A1 - Methods and apparatus for predicting depression treatment outcomes - Google Patents:/Users/annekleine/Zotero/storage/88XDQ4CK/en.html:text/html},
}

@online{US11388546B2,
	title = {{US}11388546B2 - Systems and methods for monitoring for and lowering the risk of addiction-related or restriction violation-related behavior(s) - Google Patents},
	url = {https://patents.google.com/patent/US11388546B2/en?oq=US11388546B2},
	urldate = {2023-01-13},
	file = {US11388546B2 - Systems and methods for monitoring for and lowering the risk of addiction-related or restriction violation-related behavior(s) - Google Patents:/Users/annekleine/Zotero/storage/8ZU77JMD/en.html:text/html},
}

@patent{voss_etal20,
	title = {Mobile and body-wearable video recording and feedback platforms for the treatment of mental diseases},
	url = {https://patents.google.com/patent/EP3452935A4/de?oq=EP3452935A4},
	holder = {Leland Stanford Junior University},
	type = {patenteu},
	number = {3452935A4},
	author = {Voss, Catalin and Haber, Nicholas Joseph and Wall, Dennis Paul and Kline, Aaron Scott and Winograd, Terry Allen},
	urldate = {2023-01-13},
	date = {2020-01-08},
	langid = {english},
	keywords = {therapy, feedback, mobile, forms, plat},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/NKHHMJU5/VOSS et al. - 2020 - MOBILE AND BODY-WEARABLE VIDEO RECORDING AND FEEDB.pdf:application/pdf},
}

@patent{zhangyanyi_etal20,
	title = {Child {ADHD} screening and evaluating system based on multi-modal deep learning technology},
	url = {https://patents.google.com/patent/CN111528859A/en?oq=CN111528859A},
	holder = {Deqing Institute Of Artificial Intelligence Zhejiang University},
	type = {patent},
	number = {{CN}111528859A},
	author = {张雁翼 and 浦世亮 and 朱强 and 孔鸣 and 洪文琛 and 赵天琦},
	urldate = {2023-01-13},
	date = {2020-08-14},
	langid = {pinyin},
	keywords = {attention, expression, test, tester, vector},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/XQF6TGJ6/张雁翼 et al. - 2020 - 基于多模态深度学习技术的儿童adhd筛查评估系统.pdf:application/pdf},
}

@patent{lixiaotao_etal19,
	title = {Brain stimulation system, method, equipment and storage medium based on artificial intelligence},
	url = {https://patents.google.com/patent/CN110522983A/en?oq=CN110522983A},
	holder = {Shenzhen Institute of Advanced Technology of {CAS}},
	type = {patent},
	number = {{CN}110522983A},
	author = {李晓涛 and 李娟� and 杨海洋 and 王立平},
	urldate = {2023-01-13},
	date = {2019-12-03},
	langid = {pinyin},
	keywords = {artificial intelligence, psychological, brain stimulation, parameter, target object},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/9W2MBNHX/李晓涛 et al. - 2019 - 基于人工智能的脑刺激系统、方法、设备和存储介质.pdf:application/pdf},
}

@patent{dilorenzo16,
	title = {Methods and systems for determining subject-specific parameters for a neuromodulation therapy},
	url = {https://patents.google.com/patent/US9320900B2/en?oq=US9320900B2},
	holder = {Cyberonics Inc},
	type = {patentus},
	number = {9320900B2},
	author = {{DiLorenzo}, Daniel John},
	urldate = {2023-01-13},
	date = {2016-04-26},
	langid = {english},
	keywords = {parameters, recording, control, subject, stimulating},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/WNWYYV9U/DiLorenzo - 2016 - Methods and systems for determining subject-specif.pdf:application/pdf},
}

@patent{moturu_madan18,
	title = {Method and system for improving care determination},
	url = {https://patents.google.com/patent/US10014077B2/en?oq=US10014077B2},
	holder = {Ginger io Inc},
	type = {patentus},
	number = {10014077B2},
	author = {Moturu, Sai and Madan, Anmol},
	urldate = {2023-01-13},
	date = {2018-07-03},
	langid = {english},
	keywords = {care, user, care provider, medical status, status analysis},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/VYGMHLBV/Moturu und Madan - 2018 - Method and system for improving care determination.pdf:application/pdf},
}

@patent{perez_etal19,
	title = {Systems and methods for using transcutaneous electrical stimulation to enable dietary interventions},
	url = {https://patents.google.com/patent/US10335302B2/en?oq=US10335302B2},
	holder = {Elira Inc},
	type = {patentus},
	number = {10335302B2},
	author = {Perez, Raul E. and Hong, Peter I. and Diianni, Steven and Malave, Luis Jose and Stengel, Brad},
	urldate = {2023-01-13},
	date = {2019-07-02},
	langid = {english},
	keywords = {patient, appetite, electrical, optionally, stimulation},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/VMAFRYEB/Perez et al. - 2019 - Systems and methods for using transcutaneous elect.pdf:application/pdf},
}

@patent{mate*kainien_etal18a,
	title = {Alertness forecasting system and method},
	url = {https://patents.google.com/patent/CN108697391A/en?oq=CN108697391A},
	holder = {Curaegis Technology Co},
	type = {patent},
	number = {{CN}108697391A},
	author = {马特·凯尼恩 and 科林·佩恩-罗杰斯 and 乔希·琼斯},
	urldate = {2023-01-13},
	date = {2018-10-23},
	langid = {pinyin},
	keywords = {data, circadian rhythm, individual, information signal, processor},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/BIUNRDFM/马特·凯尼恩 et al. - 2018 - 警觉性预测系统和方法.pdf:application/pdf},
}

@patent{kohn_etal21a,
	title = {Application for tracking progression and isolating causes of adverse medical conditions},
	url = {https://patents.google.com/patent/WO2021034677A1/en?oq=WO2021034677A1},
	holder = {{OptimDosing}, {LLC}},
	type = {patent},
	number = {{WO}2021034677A1},
	author = {Kohn, Kenneth I. and Inwald, David and Brown, Caitlin Joline},
	urldate = {2023-01-13},
	date = {2021-02-25},
	langid = {english},
	keywords = {data, application, disease, trackers, user},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/49EDMHXP/Kohn et al. - 2021 - Application for tracking progression and isolating.pdf:application/pdf},
}

@patent{casey19a,
	title = {Device and method for instilling intrinsic motivation regarding eye contact in children affected by eye contact disorders},
	url = {https://patents.google.com/patent/US10363192B2/en?oq=US10363192B2},
	holder = {Matthew Casey},
	type = {patentus},
	number = {10363192B2},
	author = {Casey, Matthew},
	urldate = {2023-01-13},
	date = {2019-07-30},
	langid = {english},
	keywords = {eye, gaze, subject, eye contact, eyes},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/GUIN9RCC/Casey - 2019 - Device and method for instilling intrinsic motivat.pdf:application/pdf},
}

@patent{liu_etal22t,
	title = {System and method for identifying transdiagnostic features shared across mental health disorders},
	url = {https://patents.google.com/patent/US11244762B2/en?oq=US11244762B2},
	holder = {Blackthorn Therapeutics Inc},
	type = {patentus},
	number = {11244762B2},
	author = {Liu, Yuelu and Mellem, Monika Sharma and Ahammad, Parvez and Gonzales Cabezas, Humberto Andres and Kollada, Matthew},
	urldate = {2023-01-13},
	date = {2022-02-08},
	langid = {english},
	keywords = {machine learning, data, features, median, mse},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/U2S8MS2Z/LIU et al. - 2022 - System and method for identifying transdiagnostic .pdf:application/pdf},
}

@patent{siekmeier_etal22a,
	title = {Method of increasing cognitive function with glutamate receptor agonist},
	url = {https://patents.google.com/patent/US20220313170A1/en?oq=US20220313170A1},
	holder = {Individual},
	type = {patentus},
	number = {20220313170A1},
	author = {Siekmeier, Peter J. and Lowen, Steven B. and Coyle, Joseph T.},
	urldate = {2023-01-13},
	date = {2022-10-06},
	langid = {english},
	keywords = {eeg, frequency domain, glutamate receptor, receptor agonist, transform},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/BC9KEA63/Siekmeier et al. - 2022 - Method of increasing cognitive function with gluta.pdf:application/pdf},
}

@patent{lyoo_etal21a,
	title = {Method and apparatus for predicting posttraumatic behavior problem},
	url = {https://patents.google.com/patent/US20210113144A1/en?oq=US20210113144A1},
	holder = {Industry Collaboration Foundation of Ewha University},
	type = {patentus},
	number = {20210113144A1},
	author = {Lyoo, In Kyoon and Cho, Han Byul and Hong, Ga Hae},
	urldate = {2023-01-13},
	date = {2021-04-22},
	langid = {english},
	keywords = {phenotype, individual, physical, posttraumatic, traumatic event},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/IX9WGMZK/LYOO et al. - 2021 - Method and apparatus for predicting posttraumatic .pdf:application/pdf},
}

@patent{west_etal15,
	title = {Biomarkers of autism spectrum disorder},
	url = {https://patents.google.com/patent/WO2015006160A2/en},
	holder = {Stemina Biomarker Discovery, Inc.},
	abstract = {Methods for identifying metabolic signatures in blood plasma which are unique to autism are described herein. Samples are analyzed using multiple chromatographic-mass spectrometry-based techniques to orthogonally measure a broad range of small molecular weight metabolites differentially produced in autistic patient samples versus non-autistic control samples. These individual metabolites or a panel of such metabolites serve as metabolic signatures of autism. Such metabolic signatures are used in diagnostic methods to accurately identify individuals with autism spectrum disorder ({ASD}).},
	type = {patent},
	number = {{WO}2015006160A2},
	author = {West, Paul and Burrier, Robert E. and Egnash, Laura and Smith, Alan and Bais, Preeti},
	urldate = {2023-01-13},
	date = {2015-01-15},
	langid = {english},
	keywords = {autism, acid, autistic, metabolites, twenty},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/QDDZ7ARZ/West et al. - 2015 - Biomarkers of autism spectrum disorder.pdf:application/pdf},
}

@patent{eckstein21,
	title = {A method for determining a {DHEA} intensity dose for specific patient},
	url = {https://patents.google.com/patent/US20210358623A1/en?oq=US20210358623A1},
	holder = {Individual},
	type = {patentus},
	number = {20210358623A1},
	author = {Eckstein, Eitan Nathan},
	urldate = {2023-01-13},
	date = {2021-11-18},
	langid = {english},
	keywords = {psychological, parameters, dhea, providing, specific patient},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/CGTCNQFZ/Eckstein - 2021 - A Method for Determining a DHEA Intensity Dose for.pdf:application/pdf},
}

@patent{lixiaotao_etal19a,
	title = {Brain stimulation system, method, equipment and storage medium based on artificial intelligence},
	url = {https://patents.google.com/patent/CN110522983A/en?oq=CN110522983A},
	holder = {Shenzhen Institute of Advanced Technology of {CAS}},
	type = {patent},
	number = {{CN}110522983A},
	author = {李晓涛 and 李娟� and 杨海洋 and 王立平},
	urldate = {2023-01-13},
	date = {2019-12-03},
	langid = {pinyin},
	keywords = {artificial intelligence, psychological, brain stimulation, parameter, target object},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/KHGY47NZ/李晓涛 et al. - 2019 - 基于人工智能的脑刺激系统、方法、设备和存储介质.pdf:application/pdf},
}

@patent{voss_etal20a,
	title = {Mobile and body-wearable video recording and feedback platforms for the treatment of mental diseases},
	url = {https://patents.google.com/patent/EP3452935A4/de?oq=EP3452935A4},
	holder = {Leland Stanford Junior University},
	type = {patenteu},
	number = {3452935A4},
	author = {Voss, Catalin and Haber, Nicholas Joseph and Wall, Dennis Paul and Kline, Aaron Scott and Winograd, Terry Allen},
	urldate = {2023-01-13},
	date = {2020-01-08},
	langid = {english},
	keywords = {therapy, feedback, mobile, forms, plat},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/D2Q2XMSU/VOSS et al. - 2020 - MOBILE AND BODY-WEARABLE VIDEO RECORDING AND FEEDB.pdf:application/pdf},
}

@patent{zhangyanyi_etal20a,
	title = {Child {ADHD} screening and evaluating system based on multi-modal deep learning technology},
	url = {https://www.derwentinnovation.com/tip-innovation/recordView.do?hideHighlightPanel=true&idType=uid/recordid&datasource=T3&databaseIds=PATENT&category=PAT&recordKeys=CN111528859A_20200814&TYPE=RECORDVIEW&fromExternalLink=true&fromLocation=external&isDAJImageAllowed=false},
	holder = {Deqing Institute Of Artificial Intelligence Zhejiang University},
	type = {patent},
	number = {{CN}111528859A},
	author = {张雁翼 and 浦世亮 and 朱强 and 孔鸣 and 洪文琛 and 赵天琦},
	urldate = {2023-01-13},
	date = {2020-08-14},
	langid = {pinyin},
	keywords = {attention, expression, test, tester, vector},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/KRKZEJ3C/张雁翼 et al. - 2020 - 基于多模态深度学习技术的儿童adhd筛查评估系统.pdf:application/pdf},
}

@patent{muller-myhsok_etal15,
	title = {Genetic predictors of response to treatment with crhr1 antagonists},
	url = {https://patents.google.com/patent/US20150278438A1/en?oq=US20150278438A1},
	holder = {Max Planck Gesellschaft zur Foerderung der Wissenschaften {eV}},
	type = {patentus},
	number = {20150278438A1},
	author = {Müller-Myhsok, Bertram and Binder, Elisabeth and Holsboer, Florian},
	urldate = {2023-01-13},
	date = {2015-10-01},
	keywords = {patient, crh, nucleotide, seq, snp},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/3YWDGNHN/Müller-Myhsok et al. - 2015 - Genetic predictors of response to treatment with c.pdf:application/pdf},
}

@patent{holsboer_muller-myhsok20,
	title = {Method for predicting a treatment response to a {CRHR}1 antagonist and/or a V1B antagonist in a patient with depressive and/or anxiety symptoms},
	url = {https://patents.google.com/patent/US10837062B2/en?oq=US10837062B2},
	holder = {Max Planck Gesellschaft zur Foerderung der Wissenschaften {eV}},
	type = {patentus},
	number = {10837062B2},
	author = {Holsboer, Florian and Müller-Myhsok, Bertram},
	urldate = {2023-01-13},
	date = {2020-11-17},
	langid = {english},
	keywords = {nucleotide, seq, snp, alleles, wild},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/WJEEKFPE/Holsboer und Müller-Myhsok - 2020 - Method for predicting a treatment response to a CR.pdf:application/pdf},
}

@patent{dilorenzo16a,
	title = {Methods and systems for determining subject-specific parameters for a neuromodulation therapy},
	url = {https://patents.google.com/patent/US9320900B2/en?oq=US9320900B2},
	holder = {Cyberonics Inc},
	type = {patentus},
	number = {9320900B2},
	author = {{DiLorenzo}, Daniel John},
	urldate = {2023-01-13},
	date = {2016-04-26},
	langid = {english},
	keywords = {parameters, recording, control, subject, stimulating},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/J52QURHL/DiLorenzo - 2016 - Methods and systems for determining subject-specif.pdf:application/pdf},
}

@patent{perez_etal19b,
	title = {Systems and methods for using transcutaneous electrical stimulation to enable dietary interventions},
	url = {https://patents.google.com/patent/US10335302B2/en?oq=US10335302B2},
	holder = {Elira Inc},
	type = {patentus},
	number = {10335302B2},
	author = {Perez, Raul E. and Hong, Peter I. and Diianni, Steven and Malave, Luis Jose and Stengel, Brad},
	urldate = {2023-01-13},
	date = {2019-07-02},
	langid = {english},
	keywords = {patient, appetite, electrical, optionally, stimulation},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/AMM5YQ3K/Perez et al. - 2019 - Systems and methods for using transcutaneous elect.pdf:application/pdf},
}

@patent{poltorak22,
	title = {Method and apparatus for neuroenhancement to enhance emotional response},
	url = {https://patents.google.com/patent/US11273283B2/en?oq=US11273283B2},
	holder = {Neuroenhancement Lab {LLC}},
	type = {patentus},
	number = {11273283B2},
	author = {Poltorak, Alexander},
	urldate = {2023-01-13},
	date = {2022-03-15},
	langid = {english},
	keywords = {brain, subject, stimulation, emotional state, stimulus},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/CFIHF7AJ/Poltorak - 2022 - Method and apparatus for neuroenhancement to enhan.pdf:application/pdf},
}

@patent{karam_etal17,
	title = {Mood monitoring of bipolar disorder using speech analysis},
	url = {https://patents.google.com/patent/US9685174B2/en?oq=US9685174B2US9685174B2},
	holder = {University of Michigan},
	type = {patentus},
	number = {9685174B2},
	author = {Karam, Zahi N. and Baveja, Satinder Singh and Mcinnis, Melvin and Provost, Emily Mower},
	urldate = {2023-01-13},
	date = {2017-06-20},
	langid = {english},
	keywords = {data, speech, level feature, segment, subject},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/PFEKCGVA/Karam et al. - 2017 - Mood monitoring of bipolar disorder using speech a.pdf:application/pdf},
}

@patent{shriberg_etal20,
	title = {Systems and methods for mental health assessment},
	url = {https://patents.google.com/patent/US10748644B2/en?oq=US10748644B2},
	holder = {Ellipsis Health Inc},
	type = {patentus},
	number = {10748644B2},
	author = {Shriberg, Elizabeth E. and Aratow, Michael and Islam, Mainul and Torbati, Amir Hossein Harati Nejad and Rutowski, Tomasz and Lin, David and Lu, Yang and Haque, Farshid and Rogers, Robert D.},
	urldate = {2023-01-13},
	date = {2020-08-18},
	langid = {english},
	keywords = {patient, data, model, subject, models},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/6D3B5J6B/Shriberg et al. - 2020 - Systems and methods for mental health assessment.pdf:application/pdf},
}

@patent{moturu_madan18a,
	title = {Method and system for improving care determination},
	url = {https://patents.google.com/patent/US10014077B2/en?oq=US10014077B2},
	holder = {Ginger io Inc},
	type = {patentus},
	number = {10014077B2},
	author = {Moturu, Sai and Madan, Anmol},
	urldate = {2023-01-13},
	date = {2018-07-03},
	langid = {english},
	keywords = {care, user, care provider, medical status, status analysis},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/3CYNLYC4/Moturu und Madan - 2018 - Method and system for improving care determination.pdf:application/pdf},
}

@patent{neumann20,
	title = {Artificial intelligence advisory systems and methods for vibrant constitutional guidance},
	url = {https://patents.google.com/patent/US20200320363A1/en?oq=US20200320363A1},
	holder = {{KPN} Innovations {LLC}},
	type = {patentus},
	number = {20200320363A1},
	author = {Neumann, Kenneth},
	urldate = {2023-01-13},
	date = {2020-10-08},
	langid = {english},
	keywords = {data, user, ameliorative, label, prognostic},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/XF9MEW45/Neumann - 2020 - Artificial intelligence advisory systems and metho.pdf:application/pdf},
}

@patent{williams19,
	title = {Systems and methods of using wireless location, context, and/or one or more communication networks for monitoring for, preempting, and/or mitigating pre-identified behavior},
	url = {https://patents.google.com/patent/US10477342B2/en?oq=US10477342B2},
	holder = {Individual},
	type = {patentus},
	number = {10477342B2},
	author = {Williams, David H.},
	urldate = {2023-01-13},
	date = {2019-11-12},
	langid = {english},
	keywords = {addiction, behavior, location, addict, identified},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/58RQQ2DC/Williams - 2019 - Systems and methods of using wireless location, co.pdf:application/pdf},
}

@patent{williams22,
	title = {Systems and methods for monitoring for and lowering the risk of addiction-related or restriction violation-related behavior(s)},
	url = {https://patents.google.com/patent/US11388546B2/en?oq=US11388546B2},
	holder = {Conquer your Addiction {LLC}},
	type = {patentus},
	number = {11388546B2},
	author = {Williams, David H.},
	urldate = {2023-01-13},
	date = {2022-07-12},
	langid = {english},
	keywords = {behavior, context, location, addict, person},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/ZH8LAJ93/Williams - 2022 - Systems and methods for monitoring for and lowerin.pdf:application/pdf},
}

@patent{chekroud_etal20,
	title = {Methods and apparatus for predicting depression treatment outcomes},
	url = {https://patents.google.com/patent/US20200143922A1/en?oq=US20200143922A1},
	holder = {Spring Care Inc, Yale University},
	type = {patentus},
	number = {20200143922A1},
	author = {Chekroud, Adam and Krystal, John H. and Gueorguieva, Ralitza and Chandra, Abhishek},
	urldate = {2023-01-13},
	date = {2020-05-07},
	keywords = {information, patient, statistical model, symptom, treatment},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/B8WNVHZ3/Chekroud et al. - 2020 - Methods and apparatus for predicting depression tr.pdf:application/pdf},
}

@patent{mason21,
	title = {Method and system for describing and recommending optimal treatment plans in adaptive telemedical or other contexts},
	url = {https://patents.google.com/patent/US11107591B1/en?oq=US11107591B1},
	holder = {Rom Technologies Inc},
	type = {patentus},
	number = {11107591B1},
	author = {Mason, Steven},
	urldate = {2023-01-13},
	date = {2021-08-31},
	keywords = {patient, medical, information, people, treatment plan},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/7B6VMRFU/Mason - 2021 - Method and system for describing and recommending .pdf:application/pdf},
}

@patent{mason_etal22,
	title = {Remote examination through augmented reality},
	url = {https://patents.google.com/patent/US11284797B2/en?oq=US11284797B2},
	holder = {Rom Technologies Inc},
	type = {patentus},
	number = {11284797B2},
	author = {Mason, Steven and Posnack, Daniel and Arn, Peter and Para, Wendy and Hacking, S. Adam and Mueller, Micheal and {GUANERI}, Joseph and Greene, Jonathan},
	urldate = {2023-01-13},
	date = {2022-03-29},
	langid = {english},
	keywords = {patient, slave, pressure, master, sensor data},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/SH3JDB8R/Mason et al. - 2022 - Remote examination through augmented reality.pdf:application/pdf},
}

@patent{komogortsev21,
	title = {Health assessment via eye movement biometrics},
	url = {https://patents.google.com/patent/US10966605B2/en?oq=US10966605B2},
	holder = {Texas State University San Marcos},
	type = {patentus},
	number = {10966605B2},
	author = {Komogortsev, Oleg V.},
	urldate = {2023-01-13},
	date = {2021-04-06},
	langid = {english},
	keywords = {eye, eye movement, person, saccade, saccades},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/QINTGL65/Komogortsev - 2021 - Health assessment via eye movement biometrics.pdf:application/pdf},
}

@patent{saito22,
	title = {Methods and systems of extended reality environment interaction based on eye motions},
	url = {https://patents.google.com/patent/US11392198B2/en?oq=US11392198B2},
	holder = {Rovi Guides Inc},
	type = {patentus},
	number = {11392198B2},
	author = {Saito, Sakura},
	urldate = {2023-01-13},
	date = {2022-07-19},
	langid = {english},
	keywords = {time, user, display, field, view},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/9XIFKKRC/Saito - 2022 - Methods and systems of extended reality environmen.pdf:application/pdf},
}

@patent{vayrynen_kortelainen22,
	title = {Apparatus and method for electroencephalographic measurement},
	url = {https://patents.google.com/patent/US11406316B2/en?oq=US11406316B2},
	holder = {Cerenion Oy},
	type = {patentus},
	number = {11406316B2},
	author = {Väyrynen, Eero and Kortelainen, Jukka},
	urldate = {2023-01-13},
	date = {2022-08-09},
	langid = {english},
	keywords = {brain, information, comparison, coupling, phase},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/Y3XUGGGZ/VÄYRYNEN und KORTELAINEN - 2022 - Apparatus and method for electroencephalographic m.pdf:application/pdf},
}

@article{keck_holsboer01,
	title = {Hyperactivity of {CRH} neuronal circuits as a target for therapeutic interventions in affective disorders},
	volume = {22},
	issn = {0196-9781},
	doi = {10.1016/s0196-9781(01)00398-9},
	abstract = {Increasing evidence suggests that the neuroendocrine changes seen in psychiatric patients, especially in those suffering from affective disorders, may be causally related to the psychopathology and course of these clinical conditions. The most robustly confirmed neuroendocrine finding among psychiatric patients with affective disorders is hyperactivity of the hypothalamic-pituitary-adrenocortical ({HPA}) system, resulting from hyperactive hypothalamic corticotropin-releasing hormone ({CRH}) neurons. A large body of preclinical and clinical evidence suggests that both genetic and environmental factors contribute to the development of these {HPA} system abnormalities. Further, normalization of {HPA} system regulation was shown to be a prerequisite for favorable treatment response and stable remission among depressives. Preclinical data based on animal models including selectively bred rat lines and mouse mutants support the notion that {CRH} neurons are hyperactive also in neuroanatomical regions that are involved in behavioral regulation but are located outside the neuroendocrine system. This raises the question of whether more direct interventions such as {CRH} receptor antagonists would open a new lead in the treatment of stress-related disorders such as depression, anxiety and sleep disorders. Recent clinical observations support this possibility.},
	pages = {835--844},
	number = {5},
	journaltitle = {Peptides},
	shortjournal = {Peptides},
	author = {Keck, M. E. and Holsboer, F.},
	date = {2001-05},
	pmid = {11337098},
	keywords = {Humans, Animals, Neurons, Mice, Rats, Antidepressive Agents, Corticotropin-Releasing Hormone, Disease Models, Animal, Hypothalamo-Hypophyseal System, Mice, Transgenic, Mood Disorders, Oligoribonucleotides, Antisense, Receptors, Corticotropin-Releasing Hormone, Stress, Physiological},
}

@article{pesapane_etal18,
	title = {Artificial intelligence as a medical device in radiology: ethical and regulatory issues in Europe and the United States},
	volume = {9},
	issn = {1869-4101},
	url = {https://doi.org/10.1007/s13244-018-0645-y},
	doi = {10.1007/s13244-018-0645-y},
	shorttitle = {Artificial intelligence as a medical device in radiology},
	abstract = {Worldwide interest in artificial intelligence ({AI}) applications is growing rapidly. In medicine, devices based on machine/deep learning have proliferated, especially for image analysis, presaging new significant challenges for the utility of {AI} in healthcare. This inevitably raises numerous legal and ethical questions. In this paper we analyse the state of {AI} regulation in the context of medical device development, and strategies to make {AI} applications safe and useful in the future. We analyse the legal framework regulating medical devices and data protection in Europe and in the United States, assessing developments that are currently taking place. The European Union ({EU}) is reforming these fields with new legislation (General Data Protection Regulation [{GDPR}], Cybersecurity Directive, Medical Devices Regulation, In Vitro Diagnostic Medical Device Regulation). This reform is gradual, but it has now made its first impact, with the {GDPR} and the Cybersecurity Directive having taken effect in May, 2018. As regards the United States (U.S.), the regulatory scene is predominantly controlled by the Food and Drug Administration. This paper considers issues of accountability, both legal and ethical. The processes of medical device decision-making are largely unpredictable, therefore holding the creators accountable for it clearly raises concerns. There is a lot that can be done in order to regulate {AI} applications. If this is done properly and timely, the potentiality of {AI} based technology, in radiology as well as in other fields, will be invaluable.},
	pages = {745--753},
	number = {5},
	journaltitle = {Insights into Imaging},
	shortjournal = {Insights Imaging},
	author = {Pesapane, Filippo and Volonté, Caterina and Codari, Marina and Sardanelli, Francesco},
	urldate = {2023-01-20},
	date = {2018-10-01},
	langid = {english},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/HLXT2JFJ/Pesapane et al. - 2018 - Artificial intelligence as a medical device in rad.pdf:application/pdf},
}

@article{almeida_etal22,
	title = {The ethics of facial recognition technologies, surveillance, and accountability in an age of artificial intelligence: a comparative analysis of {US}, {EU}, and {UK} regulatory frameworks},
	volume = {2},
	issn = {2730-5961},
	url = {https://doi.org/10.1007/s43681-021-00077-w},
	doi = {10.1007/s43681-021-00077-w},
	shorttitle = {The ethics of facial recognition technologies, surveillance, and accountability in an age of artificial intelligence},
	abstract = {The rapid development of facial recognition technologies ({FRT}) has led to complex ethical choices in terms of balancing individual privacy rights versus delivering societal safety. Within this space, increasingly commonplace use of these technologies by law enforcement agencies has presented a particular lens for probing this complex landscape, its application, and the acceptable extent of citizen surveillance. This analysis focuses on the regulatory contexts and recent case law in the United States ({USA}), United Kingdom ({UK}), and European Union ({EU}) in terms of the use and misuse of {FRT} by law enforcement agencies. In the case of the {USA}, it is one of the main global regions in which the technology is being rapidly evolved, and yet, it has a patchwork of legislation with less emphasis on data protection and privacy. Within the context of the {EU} and the {UK}, there has been a critical focus on the development of accountability requirements particularly when considered in the context of the {EU}’s General Data Protection Regulation ({GDPR}) and the legal focus on Privacy by Design ({PbD}). However, globally, there is no standardised human rights framework and regulatory requirements that can be easily applied to {FRT} rollout. This article contains a discursive discussion considering the complexity of the ethical and regulatory dimensions at play in these spaces including considering data protection and human rights frameworks. It concludes that data protection impact assessments ({DPIA}) and human rights impact assessments together with greater transparency, regulation, audit and explanation of {FRT} use, and application in individual contexts would improve {FRT} deployments. In addition, it sets out ten critical questions which it suggests need to be answered for the successful development and deployment of {FRT} and {AI} more broadly. It is suggested that these should be answered by lawmakers, policy makers, {AI} developers, and adopters.},
	pages = {377--387},
	number = {3},
	journaltitle = {{AI} and Ethics},
	shortjournal = {{AI} Ethics},
	author = {Almeida, Denise and Shmarko, Konstantin and Lomas, Elizabeth},
	urldate = {2023-01-20},
	date = {2022-08-01},
	langid = {english},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/XVQMD6JP/Almeida et al. - 2022 - The ethics of facial recognition technologies, sur.pdf:application/pdf},
}

@article{joyce_etal23,
	title = {Explainable artificial intelligence for mental health through transparency and interpretability for understandability},
	volume = {6},
	rights = {2023 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-023-00751-9},
	doi = {10.1038/s41746-023-00751-9},
	abstract = {The literature on artificial intelligence ({AI}) or machine learning ({ML}) in mental health and psychiatry lacks consensus on what “explainability” means. In the more general {XAI} ({eXplainable} {AI}) literature, there has been some convergence on explainability meaning model-agnostic techniques that augment a complex model (with internal mechanics intractable for human understanding) with a simpler model argued to deliver results that humans can comprehend. Given the differing usage and intended meaning of the term “explainability” in {AI} and {ML}, we propose instead to approximate model/algorithm explainability by understandability defined as a function of transparency and interpretability. These concepts are easier to articulate, to “ground” in our understanding of how algorithms and models operate and are used more consistently in the literature. We describe the {TIFU} (Transparency and Interpretability For Understandability) framework and examine how this applies to the landscape of {AI}/{ML} in mental health research. We argue that the need for understandablity is heightened in psychiatry because data describing the syndromes, outcomes, disorders and signs/symptoms possess probabilistic relationships to each other—as do the tentative aetiologies and multifactorial social- and psychological-determinants of disorders. If we develop and deploy {AI}/{ML} models, ensuring human understandability of the inputs, processes and outputs of these models is essential to develop trustworthy systems fit for deployment.},
	pages = {1--7},
	number = {1},
	journaltitle = {npj Digital Medicine},
	shortjournal = {npj Digit. Med.},
	author = {Joyce, Dan W. and Kormilitzin, Andrey and Smith, Katharine A. and Cipriani, Andrea},
	urldate = {2023-01-23},
	date = {2023-01-18},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Health care, Computational biology and bioinformatics},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/28MMUQL2/Joyce et al. - 2023 - Explainable artificial intelligence for mental hea.pdf:application/pdf},
}

@patent{anand_mckay21a,
	location = {{WO}},
	title = {Live virus vaccine injury risk},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {Methods for assessing the risk of autism from the use of live virus-vaccines in neonates and toddlers are disclosed. {\textbar}   {\textbar} L'invention concerne des procédés pour évaluer le risque d'autisme lié à l'utilisation de vaccins à virus vivant chez des nouveaux-nés et des jeunes enfants.
L'invention concerne des procédés pour évaluer le risque d'autisme lié à l'utilisation de vaccins à virus vivant chez des nouveaux-nés et des jeunes enfants.
Methods for assessing the risk of autism from the use of live virus-vaccines in neonates and toddlers are disclosed.},
	type = {patent},
	author = {Anand, Rene and {McKay}, Susan},
	urldate = {2020-10-16},
	date = {2021-04-22},
	note = {Edition: A61K0039275 {\textbar} C12N001586 {CPC} - C12Q00016883 {\textbar} C12N00050619 {\textbar} G01N00336896 {\textbar} C12N2501727 {\textbar} C12N250302 {\textbar} C12N250645 {\textbar} C12N251300 {\textbar} C12N253354 {\textbar} C12N253390 {\textbar} C12Q2600136 {\textbar} C12Q2600142 {\textbar} C12Q2600158 {\textbar} G01N280030 {\textbar} G01N280052 {EP} {EP} {WHAT} {IS} {CLAIMED} {IS}: {\textbar} {\textbar} 1. A method for treating autism in a human, using a patient-specific pharmacotherapy, the method comprising: a) procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; b) reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; c) treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; d) collecting a biological sample from the patient specific neural organoid; e) detecting changes in autism biomarker expression from the patient specific neural organoid sample that are differentially expressed in humans with autism; f) performing assays on the patient specific neural organoid to identify therapeutic agents that alter the differentially expressed autism biomarkers in the patient-specific neural organoid sample; and g) administering a therapeutic agent for autism to treat the human. {\textbar} 2. The method of claim 1 , wherein at least one cell sample reprogrammed to the induced pluripotent stem cell is a fibroblast derived from skin or blood cells from humans. {\textbar} 3. The method of claim 2, wherein the fibroblast derived skin or blood cells from humans is identified with the genes identified in Table 1 , Table 2, Table 9, or Table 11. {\textbar} 4. The method of claim 1 , wherein the measured biomarkers comprise nucleic acids, encoded proteins, or metabolites. {\textbar} 5. The method of claim 1 , wherein the measured biomarkers comprise one or a plurality of biomarkers identified in Table 1 , Table 2, Table 9 or Table 11 or variants thereof. {\textbar} 6. The method of claim 5, further wherein a combination of biomarkers is detected, the combination comprising a nucleic acid encoding human {TSC}1, {TSC}2, or a {TSC}2 variant; and one or a plurality of biomarkers comprising a nucleic acid encoding human genes identified in Table 1. {\textbar} 7. The method of claim 1 , wherein the neural organoid biological sample is collected after about one hour up to about 12 weeks post inducement. {\textbar} 8. The method of claim 7, wherein the neural organoid sample is procured from structures of the neural organoid that mimic structures developed in utero at about 5 weeks. {\textbar} 9. The method of claim 7, wherein the neural organoid at about twelve weeks post inducement comprises encoded structures and cell types of retina, cortex, midbrain, hindbrain, brain stem, or spinal cord. {\textbar} 10. The method of claim 7, wherein the neural organoid contains microglia, and one or a plurality of autism biomarkers as identified in Table 1 and Table 11. {\textbar} 11. A patient-specific pharmacotherapeutic method for reducing risk for developing autism- associated co-morbidities in a human, the method comprising: a) procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; b) reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; c) treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; d) collecting a biological sample from the patient specific neural organoid; e) detecting biomarkers of an autism related co-morbidity in the patient specific neural organoid sample; f) administering an anti-autism therapeutic agent to the human. {\textbar} 12. The patient specific pharmacotherapeutic method of claim 10, wherein the measured biomarkers comprise biomarkers identified in Table 1 , Table 2, Table 9 or Table 11. {\textbar} 13. The method of claim 11 further wherein the measured biomarker is a gene, protein, or metabolite encoding the biomarkers identified in Table 1 , Table 2, Table 9 or Table 11. {\textbar} 14. A plurality of biomarkers comprising a diagnostic panel for predicting a risk for developing autism in a human, comprising one or a plurality subset of the biomarkers as identified in Table 1 , Table 2, Table 9, or Table 11. {\textbar} 15. The diagnostic panel of claim 14, further wherein the subset of measured biomarkers comprise nucleic acids encoding a genes, proteins, or metabolites as identified in Table 1 , Table 2, Table 9 or Table 11. {\textbar} 16. A method of pharmaceutical testing for drug screening, toxicity, safety, and/or pharmaceutical efficacy studies using a patient specific neural organoid. {\textbar} 17. A method for detecting at least one biomarker of any of claims 6, 7, 12, 13, 14, or 15, the method comprising: a) obtaining a biological sample from a human patient; and b) contacting the biological sample with an array comprising specific-binding molecules for the at least one biomarker and detecting binding between the at least one biomarker and the specific binding molecules. {\textbar} 18. The method of claim 17, wherein the biomaker is a gene therapy target. {\textbar} 19. A kit comprising an array containing the sequences of one or a plurality of biomarkers of claims 6, 7, 12, 13, 14, or 15 in a human patient. {\textbar} 20. The kit of claim 19 containing a container for collection of a tissue sample from a human. {\textbar} 21. The kit of claim 20 wherein reagents required for {RNA} isolation from a human tissue sample are included. {\textbar} 22. The kit of claim 19 containing biomarkers for a tuberous sclerosis genetic disorder. {\textbar} 23. A kit, comprising the container of any of the claims 18-21 and a label or instructions for collection of a sample from a human, isolation of cells, inducement of cells to become pluripotent stem cells, growth of patient-specific neural organoids, isolation of {RNA}, execution of the array and calculation of gene expression change and prediction of concurrent or future disease risk. {\textbar} 24. The method of claim 1 , wherein the biomarkers are nucleotides, proteins, or metabolites. {\textbar} 25. The method of claim 1 , wherein the method is used to detect environmental factors that cause or exacerbate autism. {\textbar} 26. The method of claim 1 , wherein the method is used in predictive toxicology for factors as that cause or exacerbate autism. {\textbar} 27. The method of claim 1 , wherein the method is used to identify causes or accelerators of autism. {\textbar} 28. The method of claim 1 , wherein the method is used to identify nutritional factors or supplements for treating autism. {\textbar} 29. The method of claim 28, wherein the nutritional factor or supplement is zinc, manganese, or cholesterol or other nutritional factors related to pathways regulated by genes identified in Tables {\textbar} 1, 2, 5 or 7. {\textbar} {\textbar} 30. A method for detecting one or a plurality of biomarkers from different human chromosomes associated with autism or autism comorbidity susceptibility using data analytics that obviates the need for whole genome sequence analysis of patient genomes. {\textbar} 31. The method of claim 30, wherein the gene expression level changes are used to determine clinically relevant symptoms and treatments, time of disease onset, and disease severity. {\textbar} 32. The method of claim 30, wherein the neural organoids are used to identify novel biomarkers that serve as data input for development of algorithm techniques as predictive analytics. {\textbar} 33. The method of claim 30, wherein algorithmic techniques include artificial intelligence, machine and deep learning as predictive analytics tools for identifying biomarkers for diagnostic, therapeutic target and drug development process for disease. {\textbar} 34. A method for predicting a risk for developing autism in a human, the method comprising: a) procuring one or a plurality of cell samples from the human, comprising one or a plurality of cell types; b) reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; c) treating the one or the plurality of induced pluripotent stem cell samples to obtain a neural organoid; d) collecting a biological sample from the neural organoid; e) measuring biomarkers in the neural organoid sample; and f) detecting measured biomarkers from the neural organoid sample that are differentially expressed in humans with autism. {\textbar} 35. The method of claim 34, wherein the at least one cell sample reprogrammed to the induced pluripotent stem cell is a fibroblast. {\textbar} 36. The method of claim 34, wherein the measured biomarkers comprise nucleic acids, proteins, or metabolites. {\textbar} 37. The method of claim 34, wherein the measured biomarker is a nucleic acid encoding human {TSC}1 , {TSC}2 or a {TSC}2 variant. {\textbar} 38. The method of claim 34, wherein the measured biomarkers comprise one or a plurality of genes as identified in Tables 1 , 2, 5 or 6. {\textbar} 39. The method of claim 34, wherein the neural organoid sample is procured from minutes to hours up to 15 weeks post inducement. {\textbar} 40. The method of claim 1 , wherein the biomarkers to be tested are one or a plurality of biomarkers in Table 9. {\textbar} 41. The method of claim 34, wherein the biomarkers to be tested are one or a plurality of biomarkers in Table 10. {\textbar} 42. A method for predicting risk of live virus vaccine injury risk in a human, the method comprising: a) procuring one or a plurality of human tissue samples from the human, comprising one or a plurality of cell types; b) determining the expression of one or more disease genes listed in Tables 3-6; c) calculating the fold change in gene, protein, or metabolite expression compared to a gene, protein, or metabolite expression of a sample from an autism patient; and d) calculating a risk score for live virus vaccine inury. {\textbar} 43. The method of claim 42, wherein the tissue sample is obtained from skin, muscle, connective tissue, umbilical cord, or the neonate oral cavity. {\textbar} 44. The method of claim 42, wherein the disease is mumps. {\textbar} 45. The method of claim 42, wherein the disease is measles. {\textbar} 46. The method of claim 42, wherein the disease is rubella. {\textbar} 47. The method of claim 42, wherein the metabolite expression includes fumurate, and tricyclic acid cycle metabolites citrate, lactate, malate, isocitrate, and succinate. {\textbar} 48. The method of claim 42, wherein the administration schedule of a live virus vaccine is altered for an individual at risk for live vaccine injury. {\textbar} 49. The method of claim 48, wherein an individual at risk for live virus vaccine injury for mumps, measles, or rubella are administered these vaccines individually. {\textbar} 50. The method of claim 48, wherein an individual at risk for live vaccine injury for mumps, measles, or rubella are administered two of the vaccines together and a third vaccine independent of the two vaccines. {\textbar} 51. The method of claim 48, wherein an individual at risk for live vaccine injury for mumps, measles, or rubella does not receive any vaccinations. {\textbar} 52. The method of claim 48, wherein the live virus vaccine injury includes the co-morbidites in {\textbar} Table 11. {WHAT} {IS} {CLAIMED} {IS}: {\textbar} {\textbar} 1. A method for treating autism in a human, using a patient-specific pharmacotherapy, the method comprising: a) procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; b) reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; c) treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; d) collecting a biological sample from the patient specific neural organoid; e) detecting changes in autism biomarker expression from the patient specific neural organoid sample that are differentially expressed in humans with autism; f) performing assays on the patient specific neural organoid to identify therapeutic agents that alter the differentially expressed autism biomarkers in the patient-specific neural organoid sample; and g) administering a therapeutic agent for autism to treat the human. {\textbar} 2. The method of claim 1 , wherein at least one cell sample reprogrammed to the induced pluripotent stem cell is a fibroblast derived from skin or blood cells from humans. {\textbar} 3. The method of claim 2, wherein the fibroblast derived skin or blood cells from humans is identified with the genes identified in Table 1 , Table 2, Table 9, or Table 11. {\textbar} 4. The method of claim 1 , wherein the measured biomarkers comprise nucleic acids, encoded proteins, or metabolites. {\textbar} 5. The method of claim 1 , wherein the measured biomarkers comprise one or a plurality of biomarkers identified in Table 1 , Table 2, Table 9 or Table 11 or variants thereof. {\textbar} 6. The method of claim 5, further wherein a combination of biomarkers is detected, the combination comprising a nucleic acid encoding human {TSC}1, {TSC}2, or a {TSC}2 variant; and one or a plurality of biomarkers comprising a nucleic acid encoding human genes identified in Table 1. {\textbar} 7. The method of claim 1 , wherein the neural organoid biological sample is collected after about one hour up to about 12 weeks post inducement. {\textbar} 8. The method of claim 7, wherein the neural organoid sample is procured from structures of the neural organoid that mimic structures developed in utero at about 5 weeks. {\textbar} 9. The method of claim 7, wherein the neural organoid at about twelve weeks post inducement comprises encoded structures and cell types of retina, cortex, midbrain, hindbrain, brain stem, or spinal cord. {\textbar} 10. The method of claim 7, wherein the neural organoid contains microglia, and one or a plurality of autism biomarkers as identified in Table 1 and Table 11. {\textbar} 11. A patient-specific pharmacotherapeutic method for reducing risk for developing autism- associated co-morbidities in a human, the method comprising: a) procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; b) reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; c) treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; d) collecting a biological sample from the patient specific neural organoid; e) detecting biomarkers of an autism related co-morbidity in the patient specific neural organoid sample; f) administering an anti-autism therapeutic agent to the human. {\textbar} 12. The patient specific pharmacotherapeutic method of claim 10, wherein the measured biomarkers comprise biomarkers identified in Table 1 , Table 2, Table 9 or Table 11. {\textbar} 13. The method of claim 11 further wherein the measured biomarker is a gene, protein, or metabolite encoding the biomarkers identified in Table 1 , Table 2, Table 9 or Table 11. {\textbar} 14. A plurality of biomarkers comprising a diagnostic panel for predicting a risk for developing autism in a human, comprising one or a plurality subset of the biomarkers as identified in Table 1 , Table 2, Table 9, or Table 11. {\textbar} 15. The diagnostic panel of claim 14, further wherein the subset of measured biomarkers comprise nucleic acids encoding a genes, proteins, or metabolites as identified in Table 1 , Table 2, Table 9 or Table 11. {\textbar} 16. A method of pharmaceutical testing for drug screening, toxicity, safety, and/or pharmaceutical efficacy studies using a patient specific neural organoid. {\textbar} 17. A method for detecting at least one biomarker of any of claims 6, 7, 12, 13, 14, or 15, the method comprising: a) obtaining a biological sample from a human patient; and b) contacting the biological sample with an array comprising specific-binding molecules for the at least one biomarker and detecting binding between the at least one biomarker and the specific binding molecules. {\textbar} 18. The method of claim 17, wherein the biomaker is a gene therapy target. {\textbar} 19. A kit comprising an array containing the sequences of one or a plurality of biomarkers of claims 6, 7, 12, 13, 14, or 15 in a human patient. {\textbar} 20. The kit of claim 19 containing a container for collection of a tissue sample from a human. {\textbar} 21. The kit of claim 20 wherein reagents required for {RNA} isolation from a human tissue sample are included. {\textbar} 22. The kit of claim 19 containing biomarkers for a tuberous sclerosis genetic disorder. {\textbar} 23. A kit, comprising the container of any of the claims 18-21 and a label or instructions for collection of a sample from a human, isolation of cells, inducement of cells to become pluripotent stem cells, growth of patient-specific neural organoids, isolation of {RNA}, execution of the array and calculation of gene expression change and prediction of concurrent or future disease risk. {\textbar} 24. The method of claim 1 , wherein the biomarkers are nucleotides, proteins, or metabolites. {\textbar} 25. The method of claim 1 , wherein the method is used to detect environmental factors that cause or exacerbate autism. {\textbar} 26. The method of claim 1 , wherein the method is used in predictive toxicology for factors as that cause or exacerbate autism. {\textbar} 27. The method of claim 1 , wherein the method is used to identify causes or accelerators of autism. {\textbar} 28. The method of claim 1 , wherein the method is used to identify nutritional factors or supplements for treating autism. {\textbar} 29. The method of claim 28, wherein the nutritional factor or supplement is zinc, manganese, or cholesterol or other nutritional factors related to pathways regulated by genes identified in Tables {\textbar} 1, 2, 5 or 7. {\textbar} {\textbar} 30. A method for detecting one or a plurality of biomarkers from different human chromosomes associated with autism or autism comorbidity susceptibility using data analytics that obviates the need for whole genome sequence analysis of patient genomes. {\textbar} 31. The method of claim 30, wherein the gene expression level changes are used to determine clinically relevant symptoms and treatments, time of disease onset, and disease severity. {\textbar} 32. The method of claim 30, wherein the neural organoids are used to identify novel biomarkers that serve as data input for development of algorithm techniques as predictive analytics. {\textbar} 33. The method of claim 30, wherein algorithmic techniques include artificial intelligence, machine and deep learning as predictive analytics tools for identifying biomarkers for diagnostic, therapeutic target and drug development process for disease. {\textbar} 34. A method for predicting a risk for developing autism in a human, the method comprising: a) procuring one or a plurality of cell samples from the human, comprising one or a plurality of cell types; b) reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; c) treating the one or the plurality of induced pluripotent stem cell samples to obtain a neural organoid; d) collecting a biological sample from the neural organoid; e) measuring biomarkers in the neural organoid sample; and f) detecting measured biomarkers from the neural organoid sample that are differentially expressed in humans with autism. {\textbar} 35. The method of claim 34, wherein the at least one cell sample reprogrammed to the induced pluripotent stem cell is a fibroblast. {\textbar} 36. The method of claim 34, wherein the measured biomarkers comprise nucleic acids, proteins, or metabolites. {\textbar} 37. The method of claim 34, wherein the measured biomarker is a nucleic acid encoding human {TSC}1 , {TSC}2 or a {TSC}2 variant. {\textbar} 38. The method of claim 34, wherein the measured biomarkers comprise one or a plurality of genes as identified in Tables 1 , 2, 5 or 6. {\textbar} 39. The method of claim 34, wherein the neural organoid sample is procured from minutes to hours up to 15 weeks post inducement. {\textbar} 40. The method of claim 1 , wherein the biomarkers to be tested are one or a plurality of biomarkers in Table 9. {\textbar} 41. The method of claim 34, wherein the biomarkers to be tested are one or a plurality of biomarkers in Table 10. {\textbar} 42. A method for predicting risk of live virus vaccine injury risk in a human, the method comprising: a) procuring one or a plurality of human tissue samples from the human, comprising one or a plurality of cell types; b) determining the expression of one or more disease genes listed in Tables 3-6; c) calculating the fold change in gene, protein, or metabolite expression compared to a gene, protein, or metabolite expression of a sample from an autism patient; and d) calculating a risk score for live virus vaccine inury. {\textbar} 43. The method of claim 42, wherein the tissue sample is obtained from skin, muscle, connective tissue, umbilical cord, or the neonate oral cavity. {\textbar} 44. The method of claim 42, wherein the disease is mumps. {\textbar} 45. The method of claim 42, wherein the disease is measles. {\textbar} 46. The method of claim 42, wherein the disease is rubella. {\textbar} 47. The method of claim 42, wherein the metabolite expression includes fumurate, and tricyclic acid cycle metabolites citrate, lactate, malate, isocitrate, and succinate. {\textbar} 48. The method of claim 42, wherein the administration schedule of a live virus vaccine is altered for an individual at risk for live vaccine injury. {\textbar} 49. The method of claim 48, wherein an individual at risk for live virus vaccine injury for mumps, measles, or rubella are administered these vaccines individually. {\textbar} 50. The method of claim 48, wherein an individual at risk for live vaccine injury for mumps, measles, or rubella are administered two of the vaccines together and a third vaccine independent of the two vaccines. {\textbar} 51. The method of claim 48, wherein an individual at risk for live vaccine injury for mumps, measles, or rubella does not receive any vaccinations. {\textbar} 52. The method of claim 48, wherein the live virus vaccine injury includes the co-morbidites in {\textbar} Table 11. 1. A method for treating autism in a human, using a patient-specific pharmacotherapy, the method comprising: a) procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; b) reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; c) treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; d) collecting a biological sample from the patient specific neural organoid; e) detecting changes in autism biomarker expression from the patient specific neural organoid sample that are differentially expressed in humans with autism; f) performing assays on the patient specific neural organoid to identify therapeutic agents that alter the differentially expressed autism biomarkers in the patient-specific neural organoid sample; and g) administering a therapeutic agent for autism to treat the human. 1. A method for treating autism in a human, using a patient-specific pharmacotherapy, the method comprising: a) procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; b) reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; c) treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; d) collecting a biological sample from the patient specific neural organoid; e) detecting changes in autism biomarker expression from the patient specific neural organoid sample that are differentially expressed in humans with autism; f) performing assays on the patient specific neural organoid to identify therapeutic agents that alter the differentially expressed autism biomarkers in the patient-specific neural organoid sample; and g) administering a therapeutic agent for autism to treat the human. {LIVE} {VIRUS} {VACCINE} {INJURY} {RISK} {\textbar} {\textbar} [0001] This application claims priority to U.S. Provisional Patent Application No. 62/916,201 filed on October 16, 2019 and U.S. Provisional Patent Application No. 62/916,659 filed on October 17, 2020, both of which are hereby incorporated in their entireties. {\textbar} {\textbar} [0002] “A computer readable form of the Sequence Listing is filed with this application by electronic submission and is incorporated into this application by reference in its entirety. The Sequence Listing is contained in the file created on October 15, 2019 having the file name “19- 1954-{WO} {ST}25 {FINAL}.txt” and is 533 kb in size.” {\textbar} {\textbar} {FIELD} {OF} {THE} {INVENTION} {\textbar} {\textbar} [0003] This disclosure relates to the use of production and use of human stem cell derived neural organoids to identify and treat autism in a human, using a patient-specific pharmacotherapy. The invention also provides insights into live virus injuries such as autism related to the use of live virus-vaccines in neonates and toddlers. Further disclosed are patient-specific pharmacotherapeutic methods for reducing risk for developing autism-associated co-morbidities in a human from live virus vaccines. Also disclosed are methods to predict onset risk of autism (and identified comorbidities) in an individual. In particular the inventive processes disclosed herein provide neural organoid reagents produced from an individual’s induced pluripotent stem cells ({iPSCs}) for identifying patient-specific pharmacotherapy, predictive biomarkers, and developmental and pathogenic gene expression patterns and dysregulation thereof in disease onset and progression due to live virus vaccine injuries, and methods for diagnosing prospective and concurrent risk of development or establishment of autism (and comorbidities) in the individual. {\textbar} {\textbar} {BACKGROUND} {OF} {THE} {INVENTION} {\textbar} {\textbar} [0004] The human brain, and diseases associated with it have been the object of investigation and study by scientists for decades. Throughout this time, neurobiologists have attempted to increase their understanding of the brain’s capabilities and functions. Neuroscience has typically relied on the experimental manipulation of living brains or tissue samples, but scientific progress has been limited by a number of factors. For ethical and practical reasons, obtaining human brain tissue is difficult while most invasive techniques are impossible to use on live humans. Experiments in animals are expensive and time-consuming and many animal experiments are conducted in rodents, which have a brain structure and development that vary greatly from l humans. Results obtained in animals must be verified in long and expensive human clinical trials and much of the time the animal disease models are not fully representative of disease pathology in the human brain. {\textbar} {\textbar} [0005] Improved experimental models of the human brain are urgently required to understand disease mechanisms and test potential therapeutics. The ability to detect and diagnose various neurological diseases in their early stages could prove critical in the effective management of such diseases, both at times before disease symptoms appear and thereafter. Neuropathology is a frequently used diagnostic method; however, neuropathology is usually based on autopsy results. Molecular diagnostics in theory can provide a basis for early detection and a risk of early onset of neurological disease. However, molecular diagnostic methods in neurological diseases are limited in accuracy, specificity, and sensitivity. Therefore, there is a need in the art for non-invasive, patient specific molecular diagnostic methods to be developed. {\textbar} {\textbar} [0006] Consistent with this need, neural organoids hold significant promise for studying neurological diseases and disorders. Neural organoids are developed from cell lineages that have been first been induced to become pluripotent stem cells. Thus, the neural organoid is patient specific. Importantly, such models provide a method for studying neurological diseases and disorders that can overcome previous limitations. Thus, there is a need in the art to develop individual-specific reagents and methods based on predictive biomarkers for diagnosing current and future risk of neurological disease. {\textbar} {\textbar} {SUMMARY} {OF} {THE} {INVENTION} {\textbar} {\textbar} [0007] This disclosure provides neural reagents and methods for treating autism in a human, using patient-specific pharmacotherapies, the methods comprising: procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; collecting a biological sample from the patient specific neural organoid; detecting changes in autism biomarker expression from the patient specific neural organoid sample that are differentially expressed in humans with autism; performing assays on the patient specific neural organoid to identify therapeutic agents that alter the differentially expressed autism biomarkers in the patient-specific neural organoid sample; and administering a therapeutic agent for autism to treat the human. More specifically, the disclosure provides a screening tool for determining risk of autism and associated co-morbidites associated with live vaccine injury. {\textbar} {\textbar} [0008] In one aspect at least one cell sample reprogrammed to the induced pluripotent stem cell is a fibroblast derived from skin or blood cells from humans. In another aspect the fibroblast derived skin or blood cells from humans is identified with the genes identified in Table 1 (Novel Autism Biomarkers), Table 2 (Biomarkers for Autism), Table 9 (Therapeutic Neural Organoid Authentication Genes), or Table 11 (Genes and Acession Numbers for Co-Morbidities Associated with Autism). In yet another aspect, the measured biomarkers comprise nucleic acids, proteins, or metabolites. In another aspect the measured biomarkers comprise one or a plurality of biomarkers identified in Table 1 , Table 2, Table 9 or Table 11 or variants thereof. In yet another aspect, a combination of biomarkers is detected, the combination comprising a nucleic acid encoding human {TSC}1 , {TSC}2, or a {TSC}2 variant; and one or a plurality of biomarkers comprising a nucleic acid encoding human genes identified in Table 1. {\textbar} {\textbar} [0009] In still another aspect, the neural organoid biological sample is collected after about one hour up to about 12 weeks post inducement. In another aspect the neural organoid sample is procured from structures of the neural organoid that mimic structures developed in utero at about 5 weeks. In yet another aspect the neural organoid at about twelve weeks post-inducement comprises structures and cell types of retina, cortex, midbrain, hindbrain, brain stem, or spinal cord. In one aspect the neural organoid contains microglia, and one or a plurality of autism biomarkers as identified in Table 1 and Table 2. {\textbar} {\textbar} [0010] In another embodiment, the disclosure provides methods for treating autism in a human using patient specific pharmacotherapies, comprising procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; collecting a biological sample from the patient specific neural organoid; detecting changes in autism biomarker expression from the patient specific neural organoid sample that are differentially expressed in humans with autism; performing assays on the patient specific neural organoid to identify therapeutic agents that alter the differentially expressed autism biomarkers in the patient-specific neural organoid sample; and administering a therapeutic agent to treat autism. [0011] In one aspect the measured biomarkers comprise biomarkers identified in Table 1 , {\textbar} {\textbar} Table 2, Table 9 or Table 11 and can be genes, proteins, or metabolites encoding the biomarkers identified in Table 1 , Table 2, Table 9 or Table 11. In a further aspect the invention provides diagnostic methods for predicting risk for developing autism in a human, comprising one or a plurality subset of the biomarkers as identified in Table 1 , Table 2, Table 9, or Table 11. In a third aspect, the subset of measured biomarkers comprise nucleic acids encoding genes or proteins, or metabolites as identified in Table 1 , Table 2, Table 9 or Table 11. {\textbar} {\textbar} [0012] In yet another embodiment are methods of pharmaceutical testing for drug screening, toxicity, safety, and/or pharmaceutical efficacy studies using patient-specific neural organoids. [0013] In still another embodiment, methods are provided for detecting at least one biomarker of autism, the method comprising, obtaining a biological sample from a human patient; and contacting the biological sample with an array comprising specific-binding molecules for the at least one biomarker and detecting binding between the at least one biomarker and the specific binding molecules. {\textbar} {\textbar} [0014] In a further embodiment, the biomaker detected is a gene therapy target. {\textbar} {\textbar} [0015] In another embodiment the disclosure provides a kit comprising an array containing sequences of biomarkers from Table 1 or Table 2 for use in a human patient. In one aspect the kit further contains reagents for {RNA} isolation and biomarkers for tuberous sclerosis genetic disorder. In a further aspect, the kit further advantageously comprises a container and a label or instructions for collection of a sample from a human, isolation of cells, inducement of cells to become pluripotent stem cells, growth of patient-specific neural organoids, isolation of {RNA}, execution of the array and calculation of gene expression change and prediction of concurrent or future disease risk. {\textbar} {\textbar} [0016] In another embodiment the biomarkers for autism include human nucleic acids, proteins, or metabolites as listed in Table 1. These are biomarkers that are found within small or large regions of the human chromosome that change and are associated with autism, but within which chromosomal regions specific genes with mutations have not be identified as causative for autism. The genes are listed by unique identifiers as found in the Simons Foundation Autism Research Initiative ({SFARI}) {\textbar} {\textbar} {TABLE} 1. Novel Autism Biomarkers {\textbar} {\textbar} [0017] In one embodiment, the biomarkers can include biomarkers listed in Table 2. In another embodiment, biomarkers can comprise any markers or combination of markers in Tables 1 and 2 or variants thereof. {\textbar} {\textbar} [0018] In another embodiment of the first aspect, the measured biomarkers include human nucleic acids, proteins, or metabolites of Table 1 or variants thereof. {\textbar} {\textbar} [0019] In another embodiment the method is used to detect environmental factors that cause or exacerbate autism, or accelerators of autism. In a further aspect the method is used to identify nutritional factors or supplements for treating autism. In a further aspect the nutritional factor or supplement is zinc, manganese, or cholesterol or other nutritional factors related to pathways regulated by genes identified in Tables 1 , 2, 9, or 11. {\textbar} {\textbar} [0020] In yet another embodiment the methods are used to determine gene expression level changes that are used to identifly clinically relevant symptoms and treatments, time of disease onset, and disease severity. In yet another aspect the neural organoids are used to identify novel biomarkers that serve as data input for development of algorithm techniques as predictive analytics. In one aspect the algorithmic techniques include artificial intelligence, machine and deep learning as predictive analytics tools for identifying biomarkers for diagnostic, therapeutic target and drug development process for disease. {\textbar} {\textbar} [0021] In another embodiment the invention provides methods for predicting risk of co-morbidity onset that accompanies autism. Said methods first determines gene expression changes in neural organoids from a normal human individual versus an autistic human individual. Genes that change greater than 1.4 fold are associated with co-morbidities as understood by those skilled in the art. [0022] In a further embodiment, the invention provides kit for predicting the risk of current or future onset of autism. Said kits provide reagents and methods for identifying from a patient sample gene expression changes for one or a plurality of disease-informative genes for individuals without a neurological disease that is autism. {\textbar} {\textbar} [0023] In a further embodiment, the invention provides methods for identifying therapeutic agents for treating autism. Such embodiments comprise using the neural organoids provided herein, particularly, but not limited to said neural organoids from {iPSCs} from an individual or from a plurality or population of individuals. The inventive methods include assays on said neural organoids to identify therapeutic agents that alter disease-associated changes in gene expression of genes identified as having altered expression patterns in disease, so as to express gene expression patterns more closely resembling expression patterns for disease-informative genes for individuals without a neurological disease that is autism. {\textbar} {\textbar} [0024] In yet another embodiment, the invention provides methods for predicting a risk for developing autism in a human, comprising procuring one or a plurality of cell samples from a human, comprising one or a plurality of cell types; reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; treating the one or the plurality of induced pluripotent stem cell samples to obtain one or more patient specific neural organoids; collecting a biological sample from the patient specific neural organoid; measuring biomarkers in the neural organoid sample; and detecting measured biomarkers from the neural organoid sample that are differentially expressed in humans with autism. In certain embodiments, the at least one cell sample reprogrammed to the induced pluripotent stem cell is a fibroblast. In certain embodiments, the measured biomarkers comprise nucleic acids, proteins, or metabolites. {\textbar} {\textbar} In certain embodiments, the measured biomarker is a nucleic acid encoding human {TSC}1 , {TSC}2 or a {TSC}2 variant. In certain embodiments, the measured biomarkers comprise one or a plurality of genes as identified in Tables 1, 2, 9 or 10. In certain embodiments, the neural organoid sample is procured from minutes to hours up to 15 weeks post inducement. In certain embodiments, the biomarkers to be tested are one or a plurality of biomarkers in Table 10 (Diagnostic Neural Organoid Authentication Genes). {\textbar} {\textbar} [0025] In a further emobiment ,the invention discloses a screening tool for assessing the risk of the onset of autism and related neurological disorders including, but not limited to, Alzheimer's disease, Parkinson's Disease, and brain and cental nervous system cancers. More particularly, the risk of onset of these conditions is predicted via the screening tool, by utilizing the vaccine content (live {RNA} viruses in vaccination) and health of the neonate or toddler when the vaccine is given. {\textbar} {\textbar} [0026] These and other data findings, features, and advantages of the present invention will be more fully understood from the following detailed description taken together with the accompanying claims. It is noted that the scope of the claims is defined by the recitations therein and not by the specific discussion of features and advantages set forth in the present description. {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {FIGURES} {\textbar} {\textbar} [0027] Fig 1A is a micrograph showing a 4X dark field image of Brain Organoid Structures typical of approximately 5 week in utero development achieved in 12 weeks in vitro. Average size: 2-3 mm long. A brain atlas is provided for reference (left side). {\textbar} {\textbar} [0028] {FIG}. 1B shows immuno-fluorescence images of sections of {iPSC}-derived human brain organoid after approximately 12 weeks in culture. Z-stack of thirty three optical sections, 0.3 microns thick were obtained using laser confocal imaging with a 40X lens. Stained with Top panel: beta {III} tubulin (green: axons); {MAP}2 (red: dendrites); Hoechst (blue: nuclei); Bottom panel: Doublecortin (red). {\textbar} {\textbar} [0029] {FIG}. 2 is a micrograph showing immunohistochemical staining of brain organoid section with the midbrain marker tyrosine hydroxylase. Paraformaldehyde fixed sections of a 8- week old brain organoid was stained with an antibody to tyrosine hydroxylase and detected with Alexa 488 conjugated secondary Abs (green) and counter stained with Hoechst to mark cell nuclei (blue). Spinning disc confocal image (40X lens) of section stained with an antibody that binds tyrosine hydroxylase and Hoechst (scale bar: 10pm). [0030] {FIG}. 3: Spinning disc confocal image (40X lens) of section. Astrocytes stained with {GFAP} (red) and mature neurons with {NeuN} (green). {\textbar} {\textbar} [0031] {FIG}. 4 is a schematic showing in the upper panel a Developmental Expression Profile for transcripts as Heat Maps of {NKCC} 1 and {KCC}2 expression at week 1 , 4 and 12 of organoid culture as compared to approximate known profiles (lower panel). {NKCCI}: Na(+)- K(+)-{CI}(-) cotransporter isoform 1. {KCC}2: K(+)-{CI}(-) cotransporter isoform 2. {\textbar} {\textbar} [0032] Fig 5A is a schematic showing {GABAergic} chloride gradient regulation by {NKCC} 1 and {KCC}2. {\textbar} {\textbar} [0033] {FIG}. 5B provides a table showing a representative part of the entire transcriptomic profile of brain organoids in culture for 12 weeks measured using a transcriptome sequencing approach that is commercially available ({AmpliSeq}™). The table highlights the expression of neuronal markers for diverse populations of neurons and other cell types that are comparable to those expressed in an adult human brain reference ({HBR}; Clontech) and the publicly available embryonic human brain ({BRAINSCAN}) atlas of the Allen Institute database. {\textbar} {\textbar} [0034] {FIG}. 5C provides a table showing {ArnpliSeq} {\textbar} {\textbar} Tm {\textbar} gene expression data comparing gene expression in an organoid (column 2) at 12 weeks in vitro versus Human Brain Reference ({HBR}; column 3). A concordance of greater than 98\% was observed. {\textbar} [0035] {FIG}. 5D provides a table showing {AmpliSeq}™ gene expression data comparing organoids generated during two independent experiments after 12 weeks in culture (column 2 and 3). Gene expression reproducibility between the two organoids was greater than 99\%. Note that values are {CPM} (Counts Per Kilo Base per Million reads) in the tables and {\textless}1 is background. {\textbar} {\textbar} [0036] {FIG}. 6A is a schematic showing results of developmental transcriptomics. Brain organoid development in vitro follows {KNOWN} Boolean logic for the expression pattern of transcription factors during initiation of developmental programs of the brain. Time Points: 1 , 4 and 12 Weeks. {PITX}3 and {NURRI} ({NR}4A) are transcription factors that initiate midbrain development (early; at week 1), {DLKI}, {KLHLI}, {PTPRU}, and {ADH}2 respond to these two transcription factors to further promote midbrain development (mid; at week 4 \&12), and {TH}, {VMAT}2, {DAT} and D2R define dopamine neuron functions mimicking in vivo development expression patterns. The organoid expresses genes previously known to be involved in the development of dopaminergic neurons (Blaess S, Ang {SL}. Genetic control of midbrain dopaminergic neuron development. Wiley Interdiscip Rev Dev Biol. 2015 Jan 6. doi: 10.1002/wdev. 169). [0037] {FIG}. 6B is a table showing {AmpliSeq}™ gene expression data for genes not expressed in organoid (column 2 in 6B1 , 6B2, and 6B3) and Human Brain Reference (column 3 in 6B1, 6B2, and 6B3). This data indicates that the organoids generated do not express genes that are characteristic of non-neural tissues. This gene expression concordance is less than 5\% for approximately 800 genes that are considered highly enriched or specifically expressed in a non- neural tissue. The olfactory receptor genes expressed in the olfactory epithelium shown are a representative example. Gene expression for most genes in table is less than one or zero. {\textbar} {\textbar} [0038] {FIG}. 7 includes schematics showing developmental heat maps of transcription factors ({TF}) expressed in cerebellum development and of specific Markers {GRID} 2. {\textbar} {\textbar} [0039] {FIG}. 8 provides a schematic and a developmental heat map of transcription factors expressed in Hippocampus Dentate Gyms. {\textbar} {\textbar} [0040] {FIG}. 9 provides a schematic and a developmental heat map of transcription factors expressed in {GABAergic} Interneuron Development. {GABAergic} Interneurons develop late in vitro. {\textbar} {\textbar} [0041] {FIG}. 10 provides a schematic and a developmental heat map of transcription factors expressed in Serotonergic Raphe Nucleus Markers of the Pons. {\textbar} {\textbar} [0042] {FIG}. 11 provides a schematic and a developmental heat map of transcription factor transcriptomics ({FIG}. 11-1). Hox genes involved in spinal cord cervical, thoracic and lumbar region segmentation are expressed at discrete times in utero. The expression pattern of these Hox gene in organoids as a function of in vitro developmental time (1 week; 4 weeks; 12 weeks; ; Figures 11-2 and 11-3) {\textbar} {\textbar} [0043] {FIG}. 12 is a graph showing the replicability of brain organoid development from two independent experiments. Transcriptomic results were obtained by Ampliseq analysis of normal 12 week old brain organoids. The coefficient of determination was 0.6539. {\textbar} {\textbar} [0044] {FIG}. 13 provides a schematic and gene expression quantification of markers for astrocytes, oligodendrocytes, microglia and vasculature cells. {\textbar} {\textbar} [0045] {FIG}. 14 includes scatter plots of Ampliseq whole genome transcriptomics data from technical replicates for Normal ({WT}), Tuberous Sclerosis ({TSC}2) and {TSC}2 versus {WT} at 1 week in culture. Approximately 13, 000 gene transcripts are represented in each replicate. {\textbar} {\textbar} [0046] {FIG}. 15 shows developmental heat maps of transcription factors ({TF}) expressed in retina development and other specific Markers. Retinal markers are described, for example, in Farkas et al. ({BMC} Genomics 2013, 14:486). [0047] {FIG}. 16 shows developmental heat maps of transcription factors ({TF}) and Markers expressed in radial glial cells and neurons of the cortex during development {\textbar} {\textbar} [0048] {FIG}. 17 is a schematic showing the brain organoid development in vitro. {iPSC} stands for induced pluripotent stem cells. {NPC} stands for neural progenitor cell. {\textbar} {\textbar} [0049] {FIG}. 18 is a graph showing the replicability of brain organoid development from two independent experiments. {\textbar} {\textbar} [0050] {FIG}. 19 (19A, 19B, and 19C) is a table showing the change in the expression level of certain genes in {TSC}2 ({ARGI} 743GLN) organoid. {\textbar} {\textbar} [0051] {FIG}. 20 is a schematic showing the analysis of gene expression in {TSC}2 ({ARGI} 743GLN) organoid. About 13,000 genes were analyzed, among which 995 genes are autism related and 121 genes are cancer related. {\textbar} {\textbar} [0052] {FIGS}. 21 A and 21 B are tables showing the change in the expression level of certain genes in {APP} gene duplication organoid. {\textbar} {\textbar} [0053] {FIG}. 22 is a schematic showing corroboration of the Neural Organoid autism Model by a Swedish twin study for metal ions in their baby teeth in which one twin is normal and the other is autistic. {\textbar} {\textbar} {DETAILED} {DESCRIPTION} {\textbar} {\textbar} [0054] Unless defined otherwise, all technical and scientific terms used herein have the same meaning as is commonly understood by one of ordinary skill in the art. The following references provide one of skill with a general definition of many of the terms used in this disclosure: Singleton et al., Dictionary of Microbiology and Molecular Biology (2nd ed. 1994); The Cambridge Dictionary of Science and Technology (Walker ed., 1988); The Glossary of Genetics, 5th Ed., R. Rieger et al. (eds.), Springer Verlag (1991 ); and Hale \& Marham, The Harper Collins Dictionary of Biology (1991). These references are intended to be exemplary and illustrative and not limiting as to the source of information known to the worker of ordinary skill in this art. As used herein, the following terms have the meanings ascribed to them below, unless specified otherwise. {\textbar} {\textbar} (0055] It is noted here that as used in this specification and the appended claims, the singular forms ”a,” ”an,” and ’’the” also include plural reference, unless the context clarity dictates otherwise. [0056] The term “about” or “approximately” means within 25\%, such as within 20\% (or 5\% or less) of a given value or range. [0057] As used herein, the terms “or” and “and/or” are utilized to describe multiple components in combination or exclusive of one another. For example, “x, y, and/or z” can refer to “x” alone, “y” alone, “z” alone, “x, y, and z,” “(x and y) or z,” “x or (y and z),” or “x or y or z.” {\textbar} {\textbar} [0058] It is noted that terms like “preferably,” “commonly,” and “typically” are not utilized herein to limit the scope of the claimed invention or to imply that certain features are critical, essential, or even important to the structure or function of the claimed invention. Rather, these terms are merely intended to highlight alternative or additional features that can or cannot be utilized in a particular embodiment of the present invention. {\textbar} {\textbar} [0059] For the purposes of describing and defining the present invention, it is noted that the term “substantially” is utilized herein to represent the inherent degree of uncertainty that can be attributed to any quantitative comparison, value, measurement, or other representation. The term “substantially” is also utilized herein to represent the degree by which a quantitative representation can vary from a stated reference without resulting in a change in the basic function of the subject matter at issue. {\textbar} {\textbar} [0060] A ’’neural organoid” means a non-naturally occurring three-dimensional organized cell mass that is cultured in vitro from a human induced pluripotent stem cell and develops similaly to the human nervous system in terms of neural marker expression and structure. Further a neural organoid has two or more regions. The first region expresses cortical or retinal marker or markers. The remaining regions each express markers of the brain stem, cerebellum, and/or spinal cord. [0061] Neural markers are any protein or polynucleotide expressed consistent with a cell lineage. By 'heural marker" it is meant any protein or polynucleotide, the expression of which is associated with a neural cell fate. Exemplary neural markers include markers associated with the hindbrain, midbrain, forebrain, or spinal cord. One skilled in the art will understand that neural markers are representative of the cerebrum, cerebellum and brainstem regions. Exemplary brain structures that express neural markers include the cortex, hyopthalamus, thalamus, retina, medulla, pons, and lateral ventricles. Further, one skilled in the art will recognize that within the brain regions and structures, granular neurons, dopaminergic neurons, {GABAergic} neurons, cholinergic neurons, glutamatergic neurons, serotonergic neurons, dendrites, axons, neurons, neuronal, cilia, purkinje fibers, pyramidal cells, spindle cells, express neuronal markers. One skilled in the art will recognize that this list is not all encompassing and that neural markers are found throughout the central nervous system including other brain regions, structures, and cell types. {\textbar} {\textbar} [0062] Exemplary cerebellar markers include but are not limited to {ATOH}1 , {PAX}6, {SOX}2, {LHX}2, and {GRID}2. Exemplary markers of dopaminergic neurons include but are not limited to tyrosine hydroxylase, vesicular monoamine transporter 2 ({VMAT}2), dopamine active transporter ({DAT}) and Dopamine receptor D2 (D2R). Exemplary cortical markers include, but are not limited to, doublecortin, {NeuN}, {FOXP}2, {CNTN}4, and {TBR}1. Exemplary retinal markers include but are not limited to retina specific Guanylate Cyclases ({GUY}2D, {GUY}2F), Retina and Anterior Neural Fold Homeobox ({RAX}), and retina specific Amine Oxidase, Copper Containing 2 ({RAX}). Exemplary granular neuron markers include, but are not limited to {SOX}2, {NeuroDI} , {DCX}, {EMX}2, {FOXG}1I, and {PROX}1. Exemplary brain stem markers include, but are not limited to {FGF}8, {INSM}1 , {GATA}2, {ASCL} I, {GAT} A3. Exemplary spinal cord markers include, but are not limited to homeobox genes including but not limited to {HOXA}1 , {HOXA}2, {HOXA}3, {HOXB}4, {HOXA}5, {HOXCS}, or {HOXDI}3. Exemplary {GABAergic} markers include, but are not limited to {NKCCI} or {KCC}2. Exemplary astrocytic markers include, but are not limited to {GFAP}. Exemplary oliogodendrocytic markers include, but are not limited to {OLIG}2 or {MBP}. Exemplary microglia markers include, but are not limited to {AIF}1 or {CD}4. In one embodiment the measured biomarkers listed above have at least 70\% homology to the sequences in the Appendix. One skilled in the art will understand that the list is exemplary and that additional biomarkers exist. {\textbar} {\textbar} [0063] Diagnostic or informative alteration or change in a biomarker is meant as an increase or decrease in expression level or activity of a gene or gene product as detected by conventional methods known in the art such as those described herein. As used herein, such an alteration can include a 10\% change in expression levels, a 25\% change, a 40\% change, or even a 50\% or greater change in expression levels. {\textbar} {\textbar} [0064] A mutation is meant to include a change in one or more nucleotides in a nucleotide sequence, particularly one that changes an amino acid residue in the gene product. The change may or may not have an impact (negative or positive) on activity of the gene. {\textbar} {\textbar} {NEURAL} {ORGANOIDS} {\textbar} {\textbar} [0065] Neural organoids are generated in vitro from patient tissue samples. Neural organoids were previously disclosed in {WO}2017123791A1 {\textbar} {\textbar} (https://patents.google.com/patent/{WO}2017123791A1/en), incorporated herein, in its entirety. A variety of tissues can be used including skin cells, hematopoietic cells, or peripheral blood mononuclear cells ({PBMCs}) or in vivo stem cells directly. One of skill in the art will further recognize that other tissue samples can be used to generate neural organoids. Use of neural organoids permits study of neural development in vitro. In one embodiment skin cells are collected in a petri dish and induced to an embryonic-like pluripotent stem cell ({iPSC}) that have high levels of developmental plasticity. {iPSCs} are grown into neural organoids in said culture under appropriate conditions as set forth herein and the resulting neural organoids closely resemble developmental patterns similar to human brain. In particular, neural organoids develop anatomical features of the retina, forebrain, midbrain, hindbrain and spinal cord. Importantly, neural organoids express {\textgreater}98\% of the about 15,000 transcripts found in the adult human brain. {iPSCs} can be derived from the skin or blood cells of humans identified with the genes listed in Table 1 (Novel Markers of Autism), Table 2 (Markers of Autism), Table 9 (Neural Organoid Autism Authenticating Genes) and Table 11 (Comorbidities of Autism). {\textbar} {\textbar} \{0066] In one embodiment, the about 12-week old {iPSC}-derived human neural organoid has ventricles and other anatomical features characteristic of a 35-40 day old neonate. In an additional embodiment the about 12 week old neural organoid expresses beta 3-tubulin, a marker of axons as well as somato-dendritic Puncta staining for {MAP}2, consistent with dendrites. In yet another embodiment, at about 12 weeks the neural organoid displays laminar organization of cortical structures. Cells within the laminar structure stain positive for doublecortin (cortical neuron cytosol), Beta3 tubulin (axons) and nuclear staining. The neural organoid, by 12 weeks, also displays dopaminergic neurons and astrocytes. {\textbar} {\textbar} [0067] Accordingly as noted, neural organoids permit study of human neural development in vitro. Further, the neural organoid offers the advantages of replicability, reliability and robustness, as shown herein using replicate neural organoids from the same source of {iPSCs}. {\textbar} {\textbar} {DEVELOPMENTAL} {TRANSCRIPTOMICS} {\textbar} {\textbar} [0068] A “transcriptome” is a collection of all {RNA} including messenger {RNA} ({mRNA}), long non-coding {RNAs} ({IncRNA}), {microRNAs} ({miRNA}) and, small nucleolar {RNA} {snoRNA}), other regulatory polynucleotides, and regulatory {RNA} ({IncRNA}, {miRNA}) molecules expressed from the genome of an organism through transcription therefrom. Thus, transcriptomics is the study of the {mRNA} transcripts produced by the genome at a given tie in any particular cell or tissue of the organism. Transcriptomics employs high-throughput techniques to analyze genome expression changes associated with development or disease. In certain embodiments, transcriptomic studies can be used to compare normal, healthy tissues and diseased tissue gene expression. In further embodiments, mutated genes or variants associated with disease or the environment can be identified. {\textbar} {\textbar} [0069] Consistent with this, the aim of developmental transcriptomics is identifying genes associated with, or significant in, organismal development and disease and dysfunctions associated with development. During development, genes undergo up- and down-regulation as the organism develops. Thus, transcriptomics provides insight into cellular processes, and the biology of the organism. [0070] Generally, in one embodiment {RNA} is sampled from the neural organoid described herein within at about one week, about four weeks, or about twelve weeks of development; most particularly {RNA} from all three time periods are samples. However, {RNA} from the neural organoid can be harvested at minutes, hours, days or weeks after reprogramming. For instance, {RNA} can be harvested at about 10 minutes, 20 minutes, 30 minutes, 40 minutes, 50 minutes and 60 minutes. In a further embodiment the {RNA} can be harvested 1 hour, 2 hours, 3 hours, 4 hours, 5 hours, 6 hours, 7 hours, 8 hours, 9 hours, 10 hours, 11 hours, 12 hours, 13 hours, 14 hours, 15 hours, 16 hours, 17 hours, 18 hours, 19 hours, 20 hours, 21 hours, 22 hours, 23 hours, or 24 hours. In a further embodiment the {RNA} can be harvested at 1 day, 2 days, 3 days, 4 days, 5 days, 6 days, 7 days, 8 days, 9 days, 10 days, 11 days, 12 days, 13 days, 14 days, 15 days, 16 days, 17 days, 18 days, 19 days, 20 days, 21 days, or 1 week, 2 weeks, 3 weeks, 4 weeks, 5 weeks, 6 weeks, 7 weeks, 8 weeks, 9 weeks 10 weeks, 11 weeks, 12 weeks or more in culture. After enriching for {RNA} sequences, an expressed sequence tag ({EST}) library is generated and quantitated using the {AmpliSeq}™ technique from {ThermoFisher}. Exemplars of alternate technologies include {RNASeq} and chip based hybridization methods. Transcript abundance in such experiments is compared in control neural organoids from healthy individuals vs. neural organoids generated from individuals with disease and the fold change in gene expression calculated and reported. {\textbar} {\textbar} [0071] Furthermore, in one embodiment {RNA} from neural organoids for autism, are converted to {DNA} libraries and then the representative {DNA} libraries are sequenced using exon-specific primers for 20,814 genes using the {AmpliSeq}™ technique available commercially from {ThermoFisher}. Reads in cpm {\textless}1 are considered background noise. All cpm data are normalized data and the reads are a direct representation of the abundance of the {RNA} for each gene. {\textbar} {\textbar} [0072] Briefly, in one embodiment, the array consists of one or a plurality of genes used to predict risk. In an alternative embodiment reads contain a plurality of genes, known to be associated with autism. In yet another embodiment the genes on the libraries can be comprised of disease-specific gene as provided in Tables 1 and 2 or a combination of genes in Table 1 or Table 2 with alternative disease specific genes. Exemplarily, changes in expression or mutation of disease-specific genes are detected using such sequencing, and differential gene expression detected thereby, qualitatively by detecting a pattern of gene expression or quantitatively by detecting the amount or extent of expression of one or a plurality of disease-specific genes or mutations thereof. Results of said assays using the {AmpliSeq}™ technique can be used to identify genes that can predict disease risk or onset and can be targets of therapeutic intervention. In further embodiments, hybridization assays can be used, including but not limited to sandwich hybridization assays, competitive hybridization assays, hybridization-ligation assays, dual ligation hybridization assays, or nuclease assays. {\textbar} {\textbar} Neural Organoids and Pharmaceutical Testing {\textbar} {\textbar} [0073] Neural organoids are useful for pharmaceutical testing. Currently, drug screening studies including toxicity, safety and or pharmaceutical efficacy, are performed using a combination of in vitro work, rodent / primate studies and computer modeling. Collectively, these studies seek to model human responses, in particular physiological responses of the central nervous system. {\textbar} {\textbar} [0074] Human neural organoids are advantageous over current pharmaceutical testing methods for several reasons. First neural the organoids are easily derived from healthy and diseased patients, mitigating the need to conduct expensive clinical trials. Second, rodent models of human disease are unable to mimic the physiological nuances unique to human growth and development. Third, the use of primates creates ethical concerns. Finally, current methods are indirect indices of drug safety. Alternatively, neural organoids offer an inexpensive, easily accessible model of human brain development. The model permits direct, and thus more thorough, understanding of the safety, efficacy and toxicity of pharmaceutical compounds. {\textbar} {\textbar} [0075] Starting material for neural organoids is easily obtained from healthy and diseased patients. Further, because human organoids are easily grown they can be produced en mass. This permits efficient screening of pharmaceutical compounds. {\textbar} {\textbar} [0076] Neural organoids are advantageous for identifying biomarkers of a disease or a condition, the method comprising a) obtaining a biological sample from a human patient; and b) detecting whether at least one biomarker is present in the biological sample by contacting the biological sample with an array comprising binding molecules specific for the biomarkers and detecting binding between the at least one biomarker and the specific binding molecules. In further embodiments, the biomarker serves as a gene therapy target. {\textbar} {\textbar} {DEVELOPMENTAL} {TRANSCRIPTOMICS} {AND} {PREDICTIVE} {MEDICINE} {\textbar} {\textbar} [0077] Changes in gene expression of specific genes when compared to those from non- diseased samples by {\textgreater}1.4 fold identify candidate genes correlating with a disease. Further searches of these genes in data base searches (e.g. Genecard, Malacard, Pubmed {SFARI} gene data base (https://gene.sfari.org/database/gene-scoring/); Human Protein Atlas (https://www.proteinatlas.org/{ENSG}00000115091-{ACTR}3/pathology) identify known diseases correlated previously with the disease state. In one embodiment {AmpliSeq}™ quantification of fold expression change allows for determination of fold change from control. {\textbar} {\textbar} {AUTISM} {\textbar} {\textbar} [0078] Autism is a development disorder that negatively impacts social interactions and day-to- day activities. The disorder is characterized by repetitive and unusual behaviors and reduced tolerance for sensory stimulation and gastrointestinal distress. The signs of autism occur early in life, usually around age 2 or 3. Autism affects approximately 1 in 68 children in the United States and approximately one third of people with autism remain non-verbal for their entire life. Many autism-predictive genes are associated with brain development, growth, and/or organization of neurons and synapses. {\textbar} {\textbar} [0079] Early detection of autism is critical to providing therapy and tailored learning to minimize the effects of autism. The current inventive process, in one particular embodiment is a method for predicting a risk for developing autism in a human, the method comprising: procuring one or a plurality of cell samples from the human, comprising one or a plurality of cell types; reprogramming the one or the plurality of cell samples to produce one or a plurality of induced pluripotent stem cell samples; treating the one or the plurality of induced pluripotent stem cell samples to obtain a neural organoid; collecting a biological sample from the neural organoid; measuring biomarkers in the neural organoid sample; and detecting measured biomarkers from the neural organoid sample that are differentially expressed in humans with autism. {\textbar} {\textbar} [0080] In a further particular embodiment, at least one cell sample such as a fibroblast is reprogrammed to become a pluripotent stem cell. In one embodiment the fibroblast is a skin cell that is induced to become a neural organoid after being reprogrammed to become a pluripotent stem cell. In a particular embodiment the neural organoid is harvested at about 1 week. In an alternate embodiment the neural organoid is harvested at about 4 weeks, and about 12 weeks. In another aspect the neural organoid can be harvested at days or weeks after reprogramming. At each time point the {RNA} is isolated and the gene biomarkers measured. The measured biomarkers comprise nucleic acids, proteins, or metabolites. In a particular embodiment the measured biomarker is a nucleic acid encoding human {TSC}1 , {TSC}2 or a {TSC}2 variant. {\textbar} {\textbar} [0081] In one embodiment the measured biomarker for human {TSC}1 , {TSC}2, or a {TSC}2 variant means any nucleic acid sequence encoding a human {TSC}1 or {TSC}2 polypeptide having at least 70\% homology to the sequence for human {TSC}1 or {TSC}2. [0082] In a further embodiment additional measured biomarkers are nucleic acids encoding human genes, proteins, and metabolites as provided in Tables 1 and 2. {\textbar} {\textbar} [0083] Although expression of multiple genes is altered in autism, in one embodiment lead candidate genes can be used to predict risk of autism onset later in life. In a particular embodiment a combination of biomarkers is detected, the combination comprising a nucleic acid encoding human {TSC}1 , {TSC}2 or a {TSC}2 variant; and one or a plurality of biomarkers comprising genes, proteins, or metabolites as presented in Table 2. In a further embodiment the measured biomarkers mean any nucleic acid sequence encoding the respective polypeptide having at least 70\% homology to the gene accession numbers listed in Table 2. Genes in Table 1 have specific mutations identified with them for autism and constitute likely causative biomarkers for autism. {\textbar} {\textbar} {TABLE} 2: Biomarkers for Autism {\textbar} {\textbar} [0084] The skilled worker will recognize these markers as set forth exemplarily herein to be - specific marker proteins as identified, inter alia, in genetic information repositories such as {GenBank} or the {SFARI} database. One skilled in the art will recognize that Accession Numbers are obtained using {GeneCards}, the {NCBI} database, or {SFARI} for example. One skilled in the art will recognize that alternative gene combinations can be used to predict autism. In addition autism risk can be predicted using detection of a combination of biomarkers the combination comprising a nucleic acid encoding human {TSC}1 , {TSC}2, or a {TSC}2 variant; and one or a plurality of biomarkers comprising comprise human nucleic acids, proteins, or metabolites as listed in Tables 1 and 2. {\textbar} [0085] In a further embodiment a combination of biomarkers is detected, the combination comprising human {TSC}1 , {TSC}2, or a variant of {TSC}2; and one or a plurality of biomarkers comprising the biomarkers provided in Table 2 or a variant thereof. {\textbar} {\textbar} [0086] In a further embodiment the combination comprises a nucleic acid encoding human {TSC}1, {TSC}2, or a {TSC}2 variant; and one or a plurality of biomarkers comprising a nucleic acid encoding biomarkers listed in Table 2 or variants thereof. The lead genes noted set forth herein are not exhaustive. One skilled in the art will recognize that other gene combinations can also be used to predict the risk of future autism onset. {\textbar} {\textbar} [0087] One significant inventive advantage / advance in medicine demonstrated herein is the use of a neural organoid for a process to determine the risk of autism onset at birth and detection of environmental factors (e.g. heavy metals, infectious agents or biological toxins) and nutritional factors (e.g. nutritional factor, vitamin, mineral, and supplement deficiencies) that are causes or accelerators of autism. An accelerator of autism is an environmental or nutritional factor that specifically interactions with an autism specific biomarker to affect downstream process related to these biomarkers biological function such that a subclinical or milder state of autism becomes a full blown clinical state earlier or more severe in nature. These can be determined, without whole genome sequence analysis of patient genomes, solely from comparative differential gene expression analyses of in vitro neural organoids as models of brain development, only in conjunction with an inventive process that reproducibly and robustly promotes development of all the major brain regions and cell types. {\textbar} {\textbar} [0088] Autism is difficult to diagnose before twenty-four months of age using currently available methods. An advantage of the current method is the identification of individuals susceptible to or having autism shortly after birth. The detection of novel biomarkers, as presented in Table 1 and/or Tables 2, 9, and 10 can be used to identify individuals who should be provided prophylactic treatment. In one aspect such treatments can include avoidance of environmental stimuli and accelerators that exacerbate autism. In a further aspect early diagnosis can be used in a personalized medicine approach to identify new patient specific pharmacotherapies for autism based on biomarker data. In a further aspect, the neural organoid model can be used to test the effectiveness of currently utilized autism therapies. For instance, the neural organoid can be used to test the effectiveness of currently utilized autism pharmacological agents such as Balovaptan (antagonist of vasopressin 1 A receptor) and Aripiprazole (antagonist for 5-{HT}2A receptor). In one aspect the neural organoid could be used to identify the risk and/or onset of autism and additionally, provide patient-specific insights into the efficacy of using known pharmacological agents to treat autism. This allows medical professionals to identify and determine the most effective treatment for an individual autism patient, before symptoms arise. Furthermore, one skilled in the art will recognize that the effectiveness of additional {FDA}-approved, as well as novel drugs under development could be tested using the methods disclose herein. In a further aspect the method allows for development and testing of non-individualized, global treatment strategies for mitigating the effects and onset of autism. {\textbar} {\textbar} (0089] An accelerator of autism is an environmental or nutritional factor that specifically interactions with an autism specific biomarker to affect downstream process related to this biomarker biological function such that a subclinical or milder state of autism becomes a full blown clinical state earlier or more severe in nature. In a particular embodiment, the neural organoid is about twelve weeks post-inducement and comprises the encoded structures and cell types of the retina, cortex, midbrain, hindbrain, brain stem, and spinal cord. However, because transcriptomics provides a snapshot in time, in one embodiment the neural organoid is procured after about one- week post inducement, four-week post inducement, and/or 12 weeks post inducement. However, the tissues from a neural organoid can be procured at any time after reprogramming. In a further embodiment, the neural organoid sample is procured from structures of the neural organoid that mimic structures developed in utero at about 5 weeks. {\textbar} {\textbar} [0090] Gene expression measured in autism can encode a variant of a biomarker alteration encoding a nucleic acid variant associated with autism. In one embodiment the nucleic acid encoding the variant is comprised of one or more missense variants, missense changes, or enriched gene pathways with common or rare variants. {\textbar} {\textbar} [0091] In an alternative embodiment the method for predicting a risk for developing autism in a human, comprising: collecting a biological sample; measuring biomarkers in the biological sample; and detecting measured biomarkers from the sample that are differentially expressed in humans with autism wherein the measured biomarkers comprise those biomarkers listed in Table 2. {\textbar} {\textbar} [0092] In a further embodiment the measured biomarker is a nucleic acid encoding human biomarkers or variants listed as listed in Table 1. [0093] In yet another embodiment a plurality of biomarkers comprising a diagnostic panel for predicting a risk for developing autism in a human, comprising biomarkers listed in Tables 1 and 2, or variants thereof. In one aspect of the embodiment a subset of marker can be used, wherein the subset comprises a plurality of biomarkers from 2 to 200, or 2-150, 2-100, 2-50, 2-25, 2-20, 2-15, 2-10, or 2-5 genes. {\textbar} {\textbar} [0094] In yet an alternative embodiment the measured biomarker is a nucleic acid panel for predicting risk of autism in humans. The genes encoding the biomarkers listed in Table 1 or variants thereof. {\textbar} {\textbar} [0095] Said panel can be provided according to the invention as an array of diagnostically relevant portions of one or a plurality of these genes, wherein the array can comprise any method for immobilizing, permanently or transiently, said diagnostically relevant portions of said one or a plurality of these genes, sufficient for the array to be interrogated and changes in gene expression detected and, if desired, quantified. In alternative embodiments the array comprises specific binding compounds for binding to the protein products of the one or a plurality of these genes. In yet further alternative embodiments, said specific binding compounds can bind to metabolic products of said protein products of the one or a plurality of these genes. In one aspect the presence of autism is detected by detection of one or a plurality of biomarkers as identified in Table 10. {\textbar} {\textbar} [0096] Another alternative embodiment of the invention disclosed herein uses the neural organoids derived from the human patient in the non-diagnostic realm. The neural organoids express markers characteristic of a large variety of neurons and also include markers for astrocytic, oligodendritic, microglial, and vascular cells. The neural organoids form all the major regions of the brain including the retina, cortex, midbrain, brain stem, and the spinal cord in a single brain structure expressing greater than 98\% of the genes known to be expressed in the human brain. Such characteristics enable the neural organoid to be used as a biological platform / device for drug screening, toxicity, safety, and/or pharmaceutical efficacy studies understood by those having skill in the art. Additionally, since the neural organoid is patient specific, pharmaceutical testing using the neural organoid allows for patient specific pharmacotherapy. In one aspect measured biomarkers comprise biomarkers in Table 2, further wherein the measured biomarker is a gene, protein, or metabolite. {\textbar} {\textbar} [0097] In yet another alternative embodiment neural organoids can be used to detect environmental factors as causes or accelerators of autism. The neural organoid can also be used in predictive toxicology to identify factors as causes or accelerators of autism. Examples in Table 1, Table 9, Table 11 include, but are not limited to lead, infectious agents or biological toxins. In still another aspect the method can be used to identify treatments that are causes or accelerators of autism and nutritional factors/supplements for treating autism. Examples in Table 1 , Table 9, Table 11 include, but are not limited to nutritional factors, vitamins, minerals, and supplements such as zinc, manganese, or cholesterol. One of skill in the art will recognize that this list is not exhaustive and can include other known and unknown nutritional factors, vitamins, minerals, and supplements. {\textbar} {\textbar} [0098] In a further embodiment neural organoids can be used to identify novel biomarkers that serve as data input for development of algorithm techniques such artificial intelligence, machine and deep learning, including biomarkers for diagnostic, therapeutic target and drug development process for disease. The use of data analytics for relevant biomarker analysis permits detection of autism and comorbidity susceptibility, thereby obviating the need for whole genome sequence analysis of patient genomes. {\textbar} {\textbar} {LIVE} {VIRUS} {VACCINE} {INJURY} {SUSCEPTIBILITY} {\textbar} {\textbar} [0099] Vaccines, in particular those for the prevention of mumps, measles, and rubella ({MMR}), are made using a weakened live {RNA} virus, also known as an attenuated virus. Injection of the weakened {MMR} virus in a human generates a weak infection to which the immune system mounts an immune response thereby producing immunity to the three conditions. However, immune system health is of paramount importance in establishing life-long immunity to {MMR}. The {MMR} vaccine is initially administered at children between the ages of 12-15 months with a second dose given around 4 - 6 years of age. Despite being administered to toddlers, the immune system health of the toddler is often overlooked. In two percent of patients this is a significant oversight as excess live {RNA} virus content of the attenuated virus and a weakened state of the immune system can expose toddlers to significant risk for brain damage, autism and autism-related co-morbidities. As shown below, the autism neural organoid also expressed markers of {MMR} and immunodeficiency as shown in Tables 3 - 6 below. {\textbar} {\textbar} [00100] In a second aspect, excess live vaccine content and a weakened immune system increase the risk of Dementia, Parkinson's disease, and brain and central nervous system cancer onset later in life. In another aspect the risk of co-morbidities associated with each of these conditions is increased. Consistent with this, the current invention, including the associated examples, support a clinical diagnostic test for assessing the risk of live vaccine injury in newborns. In another aspect of the disclosure is a method for predicting risk of live virus vaccine injury risk in a human, the method comprising: procuring one or a plurality of human tissue samples from the human, comprising one or a plurality of cell types; determining the expression of one or more disease genes listed in Tables 3-6; calculating the fold change in gene, protein, or metabolite expression compared to a gene, protein, or metabolite expression of a sample from an autism patient; and calculating a risk score for live virus vaccine inury. In one aspect the metabolites are fumurate and succinate. In another aspect, the vaccine injury can result from any vaccine, including, but not limited to mumps, measles, and rubella. In yet another aspect the live vaccine injury can be associated with a co-morbidity such as those listed in Table 11. {\textbar} {\textbar} [00101] Tissue samples for asessing the risk of live vaccine injury can be obtained from any body tissue. Examples include, but are not limited to skin, muscle, connective tissues, umbilical cord and the neonate oral cavity. {\textbar} {\textbar} [00102] In one aspect of the current invention, the Rab-11 A gene, a gene that is responsible for intracellular transport of the measles virus (Nakatsu et al. J. Virology, 2013, 87(8): 4683-4693) is upregulated 1.6 fold in nerual organoid model of autism as shown in Table 3 below. {\textbar} {\textbar} Table 3: {RAB}11A Gene Expression Change in an Autism Neural Organoid Model {\textbar} {\textbar} [00103] In another aspect of the current invention, the C1 {QBP} gene, a gene involved in replication of the Rubella virus and a target gene for rendering Rubella ineffective (Mohan et al. Virus Res, 2002, 85(2): 151-161) is upregulated 1.8 fold in nerual organoid model of autism as shown in Table 4 below. {\textbar} {\textbar} Table 4: C1QBP Gene Expression Change in an Autism Neural Organoid Model {\textbar} {\textbar} [00104] In yet another aspect of the current invention, the {STAT}2 gene, a gene that interacts with mumps virus (Rosas-Murrieeta etal. Virol J., 2010, 7: 262) is upregulated 1.7 fold in neural organoid model of autism as shown in Table 5 below. {\textbar} {\textbar} Table 5: {STAT}2 Gene Expression Change in an Autism Neural Organoid Model {\textbar} {\textbar} [00105] In yet another aspect of the current invention, immunodeficiency is associated with expression of the genes expressed in a nerual organoid model of autism as shown in Table 6 below. {\textbar} Table 6: Genes Associated with Immunodeficiency in an Autism Neural Organoid Model {\textbar} {\textbar} [00106] In another embodiment, when a patient is determined to be susceptible to live vaccine injury the vaccination protocol is altered to reduce the susceptibility. In one aspect, the vaccination scheduled can be altered such that the vaccines for mumps, measles, and rubella are administered individually. In another aspect two of the three vaccines can be administered at the same time and the third on a different day. The two vaccine combination can be any two of measles, mumps, or rubella. One of skill in the art will understand that other arrangements of administration could also be used. In another aspect, the patient can choose to avoid vaccination altogether based on their tolerance to risk. {\textbar} {\textbar} {EXAMPLES} {\textbar} {\textbar} [00107] The Examples that follow are illustrative of specific embodiments of the invention, and the use thereof. It is set forth for explanatory purposes only and is not taken as limiting the invention. In particular, the example demonstrates the effectiveness of neural organoids in predicting future disease risk. {MATERIALS} {AND} {METHODS} {\textbar} {\textbar} [00108] The neural organoids described above were developed using the following materials and methods. {\textbar} {\textbar} Summary of Methods: {\textbar} {\textbar} [00109] Neural Organoids derived from induced pluripotent stem cells derived from adult skin cells of patients were grown in vitro for 4 weeks as previous described in our {PCT} Application ({PCT}/{US}2017/013231). Transcriptomic data from these neural organoids were obtained. Differences in expression of 20,814 genes expressed in the human genome were determined between these neural organoids and those from neural organoids from a normal individual human. Detailed data analysis using Gene Card and Pubmed data bases were performed. Genes that were expressed at greater than 1.4 fold were found to be highly significant because a vast majority were correlated with genes previously associated with a multitude of neurodevelopmental and neurodegenerative diseases as well as those found to be dysregulated in post mortem patient brains. These genes comprise a suite of biomarkers for autism. {\textbar} {\textbar} [00110] The invention advantageously provides many uses, including but not limited to a) early diagnosis of these diseases at birth from new born skin cells; b) Identification of biochemical pathways that increase environmental and nutritional deficiencies in new born infants; c) discovery of mechanisms of disease mechanisms; d) discovery of novel and early therapeutic targets for drug discovery using timed developmental profiles; e) testing of safety, efficacy and toxicity of drugs in these pre-clinical models. {\textbar} {\textbar} [00111] Cells used in these methods include human {iPSCs}, feeder-dependent (System Bioscience. {WT} {SC}600A-W) and {CF}-1 mouse embryonic fibroblast feeder cells, gamma-irradiated (Applied {StemCell}, lnc \#{ASF}- 1217) {\textbar} {\textbar} [00112] Growth media, or {DMEM} media, used in the examples contained the supplements as provided in Table 7 (Growth Media and Supplements used in Examples). {\textbar} {\textbar} Table 7: Growth Media and Supplements used in Examples {\textbar} {\textbar} [00113] One skilled in the art will recognize that additional formulations of media and supplements can be used to culture, induce and maintain pluripotent stem cells and neural organoids. {\textbar} {\textbar} [00114] Experimental protocols required the use of multiple media compositions including {MEF} Media, {IPSC} Media, {EB} Media, Neural Induction Media, and Differentiation Medias 1 , 2, and 3. {\textbar} {\textbar} [00115] Mouse embryonic fibroblast ({MEF}) was used in cell culture experiments. {MEF} Media comprised {DMEM} media supplemented with 10\% Feta Bovine Serum, 100 units/ml penicillin, 100 microgram/ml streptomycin, and 0.25 microgram/ml Fungizone. {\textbar} {\textbar} [00116] Induction media for pluripotent stem cells ({IPSC} Media) comprised {DMEM}/F12 media supplemented with 20\% Knockout Replacement Serum, 3\% Fetal Bovine Serum with 2mM Glutamax, {IX} Minimal Essential Medium Nonessential Amino Acids, and 20 nanogram/ml basic Fibroblast Growth Factor [00117] Embryoid Body ({EB}) Media comprised Dulbecco's Modified Eagle's Medium ({DMEM}) ({DMEM})/Ham's F-12 media, supplemented with 20\% Knockout Replacement Serum, 3\% Fetal Bovine Serum containing 2mM Glutamax, {IX} Minimal Essential Medium containing Nonessential Amino Acids, 55microM beta-mercaptoethanol, and 4ng/ml basic Fibroblast Growth Factor. {\textbar} {\textbar} [00118] Neural Induction Media contained {DMEM}/F12 media supplemented with: a 1 :50 dilution N2 Supplement, a 1:50 dilution {GlutaMax}, a 1 :50 dilution {MEM}-{NEAA}, and 10 microgram/ml Heparin {\textbar} {\textbar} ' {\textbar} [00119] Three differentiation medias were used to produce and grow neural organoids. Differentiation Media 1 contained {DMEM}/F12 media and Neurobasal media in a 1 :1 dilution. Each media is commercially available from Invitrogen. The base media was supplemented with a 1:200 dilution N2 supplement, a 1 :100 dilution B27 - vitamin A, 2.5microgram/ml insulin, 55microM beta- mercaptoethanol kept under nitrogen mask and frozen at -20°C, 100 units/ml penicillin, 100 microgram/ml streptomycin, and 0.25microgram/ml Fungizone. {\textbar} {\textbar} [00120] Differentiation Media 2 contained {DMEM}/F12 media and Neurobasal media in a 1 :1 dilution supplemented with a 1 :200 dilution N2 supplement, a 1 :100 dilution B27 containing vitamin A, 2.5microgram/ml Insulin, 55umicroMolar beta-mercaptoethanol kept under nitrogen mask and frozen at -20°C, 100units/ml penicillin, 100microgram/ml streptomycin, and 0.25microgram/ml Fungizone. {\textbar} {\textbar} [00121] Differentiation Media 3 consisted of {DMEM}/F12 media: Neurobasal media in a 1:1 dilution supplemented with 1:200 dilution N2 supplement, a 1 :100 dilution B27 containing vitamin A), 2.5microgram/ml insulin, 55microMolar beta-mercaptoethanol kept under nitrogen mask and frozen at -20°C, 100 units/ml penicillin, 100 microgram/ml streptomycin, 0.25microgram/ml Fungizone, {TSH}, and Melatonin. {\textbar} {\textbar} [00122] The equipment used in obtaining, culturing and inducing differentiation of pluripotent stem cells is provided in Table 8 (Equipment used in Experimental Procedures). One skilled in the art would recognize that the list is not at all exhaustive but merely exemplary. {\textbar} {\textbar} Table 8: Equipment used in Experimental Procedures. {\textbar} {\textbar} Example 1 : Generation of human induced pluripotent stem cell-derived neural organoids. {\textbar} {\textbar} [00123] Human induced pluripotent stem cell-derived neural organoids were generated according to the following protocol, as set forth in International Application No. {\textbar} {\textbar} {PCT}/{US}2017/013231 incorporated herein by reference. Briefly, irradiated murine embryonic fibroblasts ({MEF}) were plated on a gelatin coated substrate in {MEF} media (Dulbecco’s Modified Eagle Medium ({DMEM}) supplemented with 10\% Feta Bovine Serum, 100 units/ml penicillin, 100 microgram/ml streptomycin, and 0.25 microgram/ml Fungizone) at a density of 2 x 10 {\textbar} {\textbar} 5 {\textbar} cells per well. The seeded plate was incubated at 37°C overnight. {\textbar} [00124] After incubation, the {MEFs} were washed with pre-warmed sterile phosphate buffered saline ({PBS}). The {MEF} media was replaced with 1 {mL} per well of induced pluripotent stem cell ({iPSC}) media containing Rho-associated protein kinase ({ROCK}) inhibitor. A culture plate with {iPSCs} was incubated at 37°C. The {iPSCs} were fed every other day with fresh {iPSC} media containing {ROCK} inhibitor. The {iPSC} colonies were lifted, divided, and transferred to the culture wells containing the {MEF} cultures so that the {iPSC} and {MEF} cells were present therein at a 1 :1 ratio. Embryoid bodies ({EB}) were then prepared. Briefly, a 100 mm culture dish was coated with 0.1 \% gelatin and the dish placed in a 37°C incubator for 20 minutes, after which the gelatin-coated dish was allowed to air dry in a biological safety cabinet. The wells containing {iPSCs} and {MEFs} were washed with pre-warmed {PBS} lacking Ca {\textbar} {\textbar} 2+/ {\textbar} Mg {\textbar} 2+ {\textbar} . A pre-warmed cell detachment solution of proteolytic and collagenolytic enzymes (1 {mL}/well) was added to the {iPSC}/{MEF} cells. The culture dishes were incubated at 37°C for 20 minutes until cells detached. Following detachment, pre- warmed {iPSC} media was added to each well and gentle agitation used to break up visible colonies. Cells and media were collected and additional pre-warmed media added, bringing the total volume to 15 ml\_. Cells were placed on a gelatin-coated culture plate at 37°C and incubated for 60 minutes, thereby allowing {MEFs} to adhere to the coated surface. The {iPSCs} present in the cell suspension were then counted. {\textbar} [00125] The suspension was then centrifuged at 300xg for 5 minutes at room temperature, the supernatant discarded, and cells re-suspended in {EB} media supplemented with {ROCK} inhibitor (50uM final concentration) and 4ng/ml basic Fibroblast Growth Factor to a volume of 9,000 cells/150 {mI}\_. {EB} media is a mixture of {DMEM}/Ham's F-12 media supplemented with 20\% {\textbar} {\textbar} Knockout Replacement Serum, 3\% Fetal Bovine Serum (2mM Glutamax), 1X Minimal Essential Medium Nonessential Amino Acids, and 55 {mM} beta-mercaptoethanol. The suspended cells were plated (150 {mI}\_) in a {LIPIDURE}® low-attachment U-bottom 96-well plate and incubated at 37°C. {\textbar} {\textbar} [00126] The plated cells were fed every other day during formation of the embryoid bodies by gently replacing three fourths of the embryoid body media without disturbing the embryoid bodies forming at the bottom of the well. Special care was taken in handling the embryoid bodies so as not to perturb the interactions among the {iPSC} cells within the {EB} through shear stress during pipetting. For the first four days of culture, the {EB} media was supplemented with 50uM {ROCK} inhibitor and 4ng/ml {bFGF}. During the remaining two to three days the embryoid bodies were cultured, no {ROCK} inhibitor or {bFGF} was added. {\textbar} {\textbar} [00127] On the sixth or seventh day of culture, the embryoid bodies were removed from the {LIPIDURE}® 96 well plate and transferred to two 24-well plates containing 500 {pL}/well Neural Induction media, {DMEM}/F12 media supplemented with a 1 :50 dilution N2 Supplement, a 1:50 dilution {GlutaMax}, a 1:50 dilution {MEM}-Non-Essential Amino Acids ({NEAA}), and 10 pg/ml Heparin. Two embryoid bodies were plated in each well and incubated at 37°C. The media was changed after two days of incubation. Embryoid bodies with a "halo" around their perimeter indicate neuroectodermal differentiation. Only embryoid bodies having a "halo" were selected for embedding in matrigel, remaining embryoid bodies were discarded. {\textbar} {\textbar} [00128] Plastic paraffin film ({PARAFILM}) rectangles (having dimensions of 5cm x 7cm) were sterilized with 3\% hydrogen peroxide to create a series of dimples in the rectangles. This dimpling was achieved, in one method, by centering the rectangles onto an empty sterile 200pL tip box press, and pressing the rectangles gently to dimple it with the impression of the holes in the box. The boxes were sprayed with ethanol and left to dry in the biological safety cabinet. {\textbar} {\textbar} [00129] Frozen Matrigel matrix aliquots (500 {pL}) were thawed on ice until equilibrated at 4°C. A single embryoid body was transferred to each dimple of the film. A single 7cm x 5cm rectangle holds approximately twenty (20) embryoid bodies. Twenty microliter (20pL) aliquots of Matrigel were transferred onto the embryoid bodies after removing extra media from the embryoid body with a pipette. The Matrigel was incubated at 37°C for 30 min until the Matrigel polymerized. The 20mI\_ droplet of viscous Matrigel was found to form an optimal three dimensional environment that supported the proper growth of the neural organoid from embryoid bodies by sequestering the gradients of morphogens and growth factors secreted by cells within the embryoid bodies during early developmental process. However, the Matrigel environment permitted exchange of essential nutrients and gases. Gentle oscillation by hand twice a day for a few minutes within a tissue culture incubator (37°C/5\%C0 {\textbar} {\textbar} 2 {\textbar} ) further allowed optimal exchange of gases and nutrients to the embedded embryoid bodies. {\textbar} [00130] Differentiation Media 1 , a one-to-one mixture of {DMEM}/F12 and Neurobasal media supplemented with a 1 :200 dilution N2 supplement, a 1 : 100 dilution B27 - vitamin A, 2.5 pg/{mL} insulin, 55 {microM} beta-mercaptoethanol kept under nitrogen mask and frozen at -20°C, 100 units/{mL} penicillin, 100 pg/{mL} streptomycin, and 0.25 pg/{mL} Fungizone, was added to a 100 mm tissue culture dish. The film containing the embryoid bodies in Matrigel was inverted onto the 100 mm dish with differentiation media 1 and incubated at 37°C for 16 hours. After incubation, the embryoid body/Matrigel droplets were transferred from the film to the culture dishes containing media. Static culture at 37°C was continued for 4 days until stable neural organoids formed. {\textbar} {\textbar} [00131] Organoids were gently transferred to culture flasks containing differentiation media 2, a one-to-one mixture of {DMEM}/F12 and Neurobasal media supplemented with a 1 :200 dilution N2 supplement, a 1:100 dilution B27 + vitamin A, 2.5 pg/{mL} insulin, 55microM beta-mercaptoethanol kept under nitrogen mask and frozen at -20°C, 100 units/{mL} penicillin, 100 pg/{mL} streptomycin, and 0.25 pg/{mL} Fungizone. The flasks were placed on an orbital shaker rotating at 40 rpm within the 37°C/5\% {CO}2 incubator. {\textbar} {\textbar} [00132] The media was changed in the flasks every 3-4 days to provide sufficient time for morphogen and growth factor gradients to act on targets within the recipient cells forming relevant structures of the brains. Great care was taken when changing media so as to avoid unnecessary perturbations to the morphogen/secreted growth factor gradients developed in the outer most periphery of the organoids as the structures grew into larger organoids. {\textbar} {\textbar} [00133] {FIG}.16 illustrates neural organoid development in vitro. Based on transcriptomic analysis, {iPSC} cells form a body of cells after 3D culture, which become neural progenitor cells ({NPC}) after neural differentiation media treatment. Neurons were observed in the cell culture after about one week. After about four (4) weeks or before, neurons of multiple lineage appeared. At about twelve (12) weeks or before, the organoid developed to a stage having different types of cells, including microglia, oligodendrocyte, astrocyte, neural precursor, neurons, and interneurons. Example 2: Human induced pluripotent stem cell-derived neural organoids express characteristics of human brain development. {\textbar} {\textbar} [00134] After approximately 12 weeks of in vitro culture, transcriptomic and immunohistochemical analysis indicated that organoids were generated according to the methods delineated in Example 1. Specifically, the organoids contained cells expressing markers characteristic of neurons, astrocytes, oligodendrocytes, microglia, and vasculature ({FIGs}. 1-14) and all major brain structures of neuroectodermal derivation. Morphologically identified by bright field imaging, the organoids included readily identifiable neural structures including cerebral cortex, cephalic flexure, and optic stalk ( compare , Grey's Anatomy Textbook). The gene expression pattern in the neural organoid was {\textgreater}98 \% concordant with those of the adult human brain reference (Clontech, \#636530). The organoids also expressed genes in a developmentally organized manner described previously (e.g. for the midbrain mesencephalic dopaminergic neurons; Blaese et al., Genetic control of midbrain dopaminergic neuron development. Rev Dev Biol. 4(2): 113-34, 2015). The structures also stained positive for multiple neural specific markers (dendrites, axons, nuclei), cortical neurons (Doublecortin), midbrain dopamine neurons (Tyrosine Hydroxylase), and astrocytes ({GFAP}) as shown by immunohistology). {\textbar} {\textbar} [00135] All human neural organoids were derived from {iPSCs} of fibroblast origin (from System Biosciences, Inc). The development of a variety of brain structures was characterized in the organoids. Retinal markers are shown in {FIG}.15. Doublecortin ({DCX}), a microtubule associated protein expressed during cortical development, was observed in the human neural organoid ({FIG}. {\textbar} {\textbar} 1 A and {FIG}. 1 B, and {FIG}. 16). Midbrain development was characterized by the presence of tyrosine hydroxylase ({FIG}. 2). In addition, transcriptomics revealed expression of the midbrain markers {DLKI}, {KLHL} I, and {PTPRU} ({FIG}. 6A). {GFAP} staining was used to identify the presence of astrocytes in the organoids ({FIG}. 3). {NeuN} positive staining indicated the presence of mature neurons ({FIG}. 3). In addition, the presence of {NKCCI} and {KCC}2, neuron-specific membrane proteins, was observed in the organoid ({FIG}. 4). A schematic of the roles of {NKCCI} and {KCC}2 is provided in {FIG}. 5A. {FIG}. 5B indicates that a variety of markers expressed during human brain development are also expressed in the organoids described in Example 1. {\textbar} {\textbar} [00136] Markers expressed within the organoids were consistent with the presence of excitatory, inhibitory, cholinergic, dopaminergic, serotonergic, astrocytic, oligodendritic, microglial, vasculature cell types. Further, the markers were consistent with those identified by the Human Brain Reference ({HBR}) from Clontech ({FIG}. 5C) and were reproducible in independent experiments ({FIG}. 5D). Non-brain tissue markers were not observed in the neural organoid ({FIG}. 6B). {\textbar} {\textbar} [00137] Tyrosine hydroxylase, an enzyme used in the synthesis of dopamine, was observed in the organoids using immunocytochemistry ({FIG}. 5B) and transcriptomics ({FIG}. 6A). The expression of other dopaminergic markers, including vesicular monoamine transporter 2 ({VMAT}2), dopamine active transporter ({DAT}) and dopamine receptor D2 (D2R) were observed using transcriptomic analysis. {FIG}. 7 delineates the expression of markers characteristic of cerebellar development. {FIG}. 8 provides a list of markers identified using transcriptomics that are characteristic of neurons present in the hippocampus dentate gyrus. Markers characteristic of the spinal cord were observed after 12 weeks of in vitro culture. {FIG}. 9 provides a list of markers identified using transcriptomics that are characteristic of {GABAergic} interneuron development. {\textbar} {\textbar} {FIG}. 10 provides a list of markers identified using transcriptomics that are characteristic of the brain stem, in particular, markers associated with the serotonergic raphe nucleus of the pons. {FIG}. {\textbar} {\textbar} 11 lists the expression of various Hox genes that are expressed during the development of the cervical, thoracic and lumbar regions of the spinal cord. {\textbar} {\textbar} [00138] {FIG}. 12 shows that results are reproducible between experiments. The expression of markers detected using transcriptomics is summarized in {FIG}. 13. {\textbar} {\textbar} [00139] In sum, the results reported herein support the conclusion that the invention provides an in vitro cultured organoid that resembles an approximately 5 week old human fetal brain, based on size and specific morphological features with great likeness to the optical stock, the cerebral hemisphere, and cephalic flexure in a 2-3mm organoid that can be grown in culture. High resolution morphology analysis was carried out using immunohistological methods on sections and confocal imaging of the organoid to establish the presence of neurons, axons, dendrites, laminar development of cortex, and the presence of midbrain marker. {\textbar} {\textbar} [00140] This organoid includes an interactive milieu of brain circuits as represented by the laminar organization of the cortical structures in Fig. 13 and thus supports formation of native neural niches in which exchange of {miRNA} and proteins by exosomes can occur among different cell types. {\textbar} {\textbar} [00141] Neural organoids were evaluated at weeks 1, 4 and 12 by transcriptomics. The organoid was reproducible and replicable ({FIGs}. 5C, 5D, {FIG}. 12, and {FIG}. 18). Brain organoids generated in two independent experiments and subjected to transcriptomic analysis showed {\textgreater}99\% replicability of the expression pattern and comparable expression levels of most genes with {\textless}2-fold variance among some of the replicates. [00142] Gene expression patterns were analyzed using whole genome transcriptomics as a function of time in culture. Results reported herein indicate that within the neural organoid known developmental order of gene expression in vivo occurs, but on a somewhat slower timeline. For example, the in vitro temporal expression of the transcription factors {NURRI} and {PITX}3, genes uniquely expressed during midbrain development, replicated known in vivo gene expression patterns (Fig 6A). Similarly, the transition from {GABA} mediating excitation to inhibition, occurred following the switch of the expression of the Na( {\textbar} {\textbar} + {\textbar} )-K( {\textbar} + {\textbar} )-2CI(--)) cotransporter {NKCCI} ({SLC}12A2), which increases intracellular chloride ions, to the K( {\textbar} + {\textbar} )-{CI}( ) cotransporter {KCC}2 ({SLC}12A5) (Owens and Kriegstein, Is there more to {GABA} than synaptic inhibition?, Nat Rev Neurosci. 3(9):715-27 2002), which decreases intracellular chloride ion concentrations (Blaesse et al., Cation-chloride cotransporters and neuronal function. Neuron. 61 (6) 820-838, 2009). Data on the development of the brain organoids in culture showed that expression profiles of {NKCCI} and {KCC}2 changed in a manner consistent with an embryonic brain transitioning from {GABA} being excitatory to inhibitory (Fig. 4 \& 5), a change that can be monitored by developmental transcriptomics. {\textbar} Example 3: Tuberous sclerosis complex model {\textbar} {\textbar} [00143] Tuberous sclerosis complex ({TSC}) is a genetic disorder that causes non-malignant tumors to form in multiple organs, including the brain. {TSC} negatively impacts quality of life, with patients experiencing seizures, developmental delay, intellectual disability, gastrointestinal distress and autism. Two genes are associated with {TSC}: (1) the {TSC}1 gene, located on chromosome 9 and also referred to as the hamartin gene and (2) the {TSC}2 gene located on chromosome 16 and referred to as the tuberin gene. {\textbar} {\textbar} [00144] Using methods as set forth in Example 1 , a human neural organoid from {iPSCs} was derived from a patient with a gene variant of the {TSC}2 gene ({ARG} I743GLN) from {iPSCs} (Cat\# {GM}25318 Coriell Institute Repository, {NJ}). This organoid served as a genetic model of a {TSC}2 mutant. {\textbar} {\textbar} [00145] Both normal and {TSC}2 mutant models were subject to genome-wide transcriptomic analysis using the Ampliseq™ analysis ({ThermoFisher}) to assess changes in gene expression and how well changes correlated with the known {TSC} clinical pathology (Fig. 14). {\textbar} {\textbar} [00146] Whole genome transcriptomic data showed that of all the genes expressed (13,000), less than a dozen showed greater than two-fold variance in the replicates for both Normal N)) and {TSC}2. This data supported the robustness and replicability of the human neural organoids at week 1 in culture. [00147] Clinically {TSC} patients present with tumors in multiple organs including the brain, lungs, heart, kidneys and skin (Harmatomas). In comparison of {WT} and {TSC}2, the genes expressed at two-fold to 300-fold differences, included those correlated with 1) tumor formation and 2) autism mapped using whole genome and exome sequencing strategies ({SFARI} site data base) ({FIG}. 19 and {FIG}. 20). {\textbar} {\textbar} [00148] {FIG}. 19 shows Ampliseq™ gene expression data for genes in the Simon Foundation Autism Research Initiative ({SFARI}) database compared between replicates of organoids from {TSC}2 (Arg 1743Gln) (column 2 and 3) and {WT} (column 3 and 4). Highlighted are autism genes and genes associated with other clinical symptoms with fold change (column 5) and {SFARI} database status or known tumor forming status. {\textbar} {\textbar} [00149] Thus, the transcriptomic data disclosed herein correlated well with known clinical phenotypes of tumors, autism and other clinical symptoms in {TSC} patients and demonstrated the usefulness of the human neural organoid model. {\textbar} {\textbar} Example 4: Human Neural Organoid Model Gene Expression to Predict Autism {\textbar} {\textbar} [00150] Autism is a development disorder that negatively impacts social interactions and day-to- day activities. In some cases the disease can include repetitive and unusual behaviors and reduced tolerance for sensory stimulation. Many of the autism-predictive genes are associated with brain development, growth, and/or organization of neurons and synapses. {\textbar} {\textbar} [00151] Autism has a strong genetic link with {DNA} mutations comprising a common molecular characteristic of autism. Autism encompasses a wide range of genetic changes, most often genetic mutations. The genes commonly identified as playing a role in autism include novel markers provided in Table 1 and autism markers provided in Table 2. {\textbar} {\textbar} [00152] Expression changes and mutations in the noted genes disclosed herein from the neural organoid at about week 1 , about week 4 and about week 12 are used in one embodiment to predict future autism risk. In a further aspect mutations in the genes disclosed can be determined at hours, days or weeks after reprogramming. {\textbar} {\textbar} [00153] In a second embodiment, mutations in Table 1, in the human neural organoid at about week 1 , about week 4, and about week 12 are used to predict the future risk of autism using above described methods for calculating risk. One skilled in the art would recognize that additional biomarker combinations expressed in the human neural organoid can also be used to predict future autism onset. [00154] The model used herein is validated and novel in that data findings reconcile that the model expresses sixty seven markers of autism that reflect the genes mutated in the genome of humans with autism ({SFARI} database of biomarkers, Table 2), as shown in Table 9. The model is novel in that it uses, as starting material, an individual’s {iPSCs} originating from skin or blood cells as the starting material to develop a neural organoid that allows for identification of autism markers early in development including at birth. {\textbar} {\textbar} Table 9. Therapeutic Neural Organoid Authentication Genes {\textbar} {\textbar} Table 10. Diagnostic Neural Organoid Authentication Genes {\textbar} {\textbar} Example 5: Predicting Risk of Disease Onset from Neural Organoid Gene Expression {\textbar} {\textbar} [00155] Gene expression in the neural organoid can be used to predict disease onset. Briefly, gene expression is correlated with Gene Card and Pubmed database genes and expression compared for dysregulated expression in diseased vs non-disease neural organoid gene expression. {\textbar} {\textbar} Example 6: Prediction of Co-Morbidities Associated with Autism {\textbar} {\textbar} [00156] The human neural organoid model data findings can be used in the prediction of comorbiditity onset or risk associated with autism including at birth. (https://en.wikipedia.org/wiki/Conditions\_comorbid\_to\_autism\_spectrum\_disorders). In detecting comorbidities, genes associated with one or more of these diseases are detected from the patient’s grown neural organoid. Such genes include, comorbidities and related accession numbers include, those listed in Table 11: {\textbar} {\textbar} Table 11: Genes and Accession Numbers for Co-Morbidities Associated with Autism {\textbar} {\textbar} [00157] The skilled worker will recognize these markers as set forth exemplarily herein to be human-specific marker proteins as identified, inter alia, in genetic information repositories such as {GenBank}; Accession Number for these markers are set forth in exemplary fashion in Table 11. One having skill in the art will recognize that variants derive from the full length gene sequence. Thus, the data findings and sequences in Table 11 encode the respective polypeptide having at least 70\% homology to other variants, including full length sequences. {\textbar} {\textbar} Example 7: Neural Organoids for Testing Drug Efficacy. {\textbar} {\textbar} [00158] Neural organoids can be used for pharmaceutical testing, safety, efficacy, and toxicity profiling studies. Specifically, using pharmaceuticals and human neural organoids, beneficial and detrimental genes and pathways associated with autism disease can be elucidated. For instance, Rapamycin has been shown to be beneficial in autism (Caban et al., 2017, Genetics of tuberous sclerosis complex: implications for clinical practice, Appl Clin Genet. 10: 1-8). Consistent with this, a human neural organoid from a patient with tuberous sclerosis was used to determine changes in gene expression following rapamycin treatment. The changes in gene expression provided insights into gene expression alterations that are beneficial and those that are detrimental for autism risk and onset. Neural organoids as provided herein can be used for testing candidate pharmaceutical agents, as well as testing whether any particular pharmaceutical agent inter alia for autism should be administered to a particular individual based on responsiveness, alternation, mutation, or changes in gene expression in a neural organoid produced from cells from that individual or in response to administration of a candidate pharmaceutical to said individual’s neural organoid. {\textbar} {\textbar} Other Embodiments: {\textbar} {\textbar} [00159] From the foregoing description, it will be apparent that variations and modifications can be made to the invention described herein to adopt it to various usages and conditions. Such embodiments are also within the scope of the following claims. {\textbar} {\textbar} [00160] The recitation of a listing of elements in any definition of a variable herein includes definitions of that variable as any single element or combination (or sub-combination) of listed elements. The recitation of an embodiment herein includes that embodiment as any single embodiment or in combination with any other embodiments or portions thereof. {\textbar} {\textbar} [00161] All patents and publications mentioned in this specification are herein incorporated by reference to the same extent as if each independent patent and publication was specifically and individually indicated to be incorporated by reference. {\textbar} {\textbar} {TABLE} 12. {SEQUENCE} {IDs} for {SEQUENCE} {LISTINGS} {RELATED} {TO} {AUTISM} {\textbar} {\textbar} [00162] Having described the invention in detail and by reference to specific aspects and/or embodiments thereof, it will be apparent that modifications and variations are possible without departing from the scope of the invention defined in the appended claims. More specifically, although some aspects of the present invention may be identified herein as particularly advantageous, it is contemplated that the present invention is not limited to these particular aspects of the invention. Percentages disclosed herein can vary in amount by ±10, 20, or 30\% from values disclosed and remain within the scope of the contemplated invention. {\textbar} {\textbar} Appendix: Brain Structure Markers and Accession No.
Issue: {WO}2021076960A1},
}

@patent{liu_etal22u,
	location = {{US}},
	title = {System and method for identifying transdiagnostic features shared across mental health disorders},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {A system for evaluating mental health of patients includes a memory and a control system. The memory contains executable code storing instructions for performing a method. The control system is coupled to the memory and includes one or more processors. The control system is configured to execute the machine executable code to cause the control system to perform the method: A selection of answers associated with a patient is received. The selection of answers corresponds to each question in a series of questions from mental health questionnaires. Unprocessed {MRI} data are received. The unprocessed {MRI} data correspond to a set of {MRI} images of a biological structure associated with the patient. The unprocessed {MRI} data is processed to output a set of {MRI} features. Using a machine learning model, the selection of answers and the set of {MRI} features are processed to output a mental health indication of the patient. {\textbar}   {\textbar} L'invention concerne un système d'évaluation de la santé mentale de patients qui comprend une mémoire et un système de commande. La mémoire contient des instructions de stockage de code exécutable pour mettre en œuvre une méthode. Le système de commande est couplé à la mémoire et comprend au moins un processeur. Le système de commande est conçu pour exécuter le code exécutable par machine pour amener le système de commande à exécuter la méthode : une sélection de réponses associées à un patient est reçue. La sélection de réponses correspond à chaque question d'une série de questions provenant de questionnaires de santé mentale. Des données non traitées d'{IRM} sont reçues. Les données non traitées d'{IRM} correspondent à un ensemble d'images {IRM} d'une structure biologique associée au patient. Les données non traitées d'{IRM} sont traitées pour produire un ensemble de caractéristiques d'{IRM}. A l'aide d'un modèle d'apprentissage machine, la sélection de réponses et l'ensemble de caractéristiques d'{IRM} sont traités pour produire une indication de la santé mentale du patient.
L'invention concerne un système d'évaluation de la santé mentale de patients qui comprend une mémoire et un système de commande. La mémoire contient des instructions de stockage de code exécutable pour mettre en œuvre une méthode. Le système de commande est couplé à la mémoire et comprend au moins un processeur. Le système de commande est conçu pour exécuter le code exécutable par machine pour amener le système de commande à exécuter la méthode : une sélection de réponses associées à un patient est reçue. La sélection de réponses correspond à chaque question d'une série de questions provenant de questionnaires de santé mentale. Des données non traitées d'{IRM} sont reçues. Les données non traitées d'{IRM} correspondent à un ensemble d'images {IRM} d'une structure biologique associée au patient. Les données non traitées d'{IRM} sont traitées pour produire un ensemble de caractéristiques d'{IRM}. A l'aide d'un modèle d'apprentissage machine, la sélection de réponses et l'ensemble de caractéristiques d'{IRM} sont traités pour produire une indication de la santé mentale du patient.
A system for evaluating mental health of patients includes a memory and a control system. The memory contains executable code storing instructions for performing a method. The control system is coupled to the memory and includes one or more processors. The control system is configured to execute the machine executable code to cause the control system to perform the method: A selection of answers associated with a patient is received. The selection of answers corresponds to each question in a series of questions from mental health questionnaires. Unprocessed {MRI} data are received. The unprocessed {MRI} data correspond to a set of {MRI} images of a biological structure associated with the patient. The unprocessed {MRI} data is processed to output a set of {MRI} features. Using a machine learning model, the selection of answers and the set of {MRI} features are processed to output a mental health indication of the patient.},
	type = {patent},
	author = {Liu, Yuelu and Mellem, Monika Sharma and Ahammad, Parvez and Gonzalez, Cabezas Humberto Andres and Kollada, Matthew},
	urldate = {2021-02-23},
	date = {2022-02-08},
	note = {Edition: G16H005020 {\textbar} A61B000500 {\textbar} A61B0005055 {\textbar} A61B000516 {\textbar} G06K000962 {\textbar} G06N002000 {\textbar} G16H001020 {\textbar} G16H002070 {\textbar} G16H003020 {\textbar} G16H003040 {\textbar} G16H005030 {\textbar} G16H005070 {CPC} - G16H005020 {\textbar} A61B00050042 {\textbar} A61B0005055 {\textbar} A61B000516 {\textbar} A61B00057267 {\textbar} G06K00096257 {\textbar} G06K00096263 {\textbar} G06K00096265 {\textbar} G06N002000 {\textbar} G16H001020 {\textbar} G16H001060 {\textbar} G16H003020 {\textbar} G16H003040 {\textbar} G16H005070 {\textbar} A61B2576026 {\textbar} G06V2201031 {\textbar} G16H002070 {\textbar} G16H005030 {EP}; {US} {EP}; {US} {US} {US} What is claimed is: {\textbar} {\textbar} 1. A system for evaluating a patient for mental health issues, the system comprising: {\textbar} a display device; {\textbar} {\textbar} a user interface; {\textbar} {\textbar} a memory containing machine readable medium comprising machine executable code having stored thereon instructions for performing a method; and {\textbar} {\textbar} a control system coupled to the memory comprising one or more processors, the control system configured to execute the machine executable code to cause the control system to: {\textbar} {\textbar} display, on the display device, a series of questions from mental health questionnaires comprising text and answers for each question; {\textbar} {\textbar} receive, from the user interface, a selection of answers from a patient of each of the series of questions; {\textbar} {\textbar} receive, unprocessed {MRI} data corresponding to a set of {MRI} images of a biological structure associated with the patient; {\textbar} {\textbar} process, using a machine learning model, the selection of answers and the unprocessed {MRI} data to output a mental health indication of the patient, and {\textbar} {\textbar} display, on the display device, the output of the processing, wherein the output is the mental health indication of the patient {\textbar} {\textbar} wherein the machine learning model was generated by: {\textbar} {\textbar} receiving labeled training data for a plurality of individuals indicating whether each of the plurality of individuals has one or more mental health disorders, the labeled training data comprising: {\textbar} {\textbar} {MRI} data recorded for each of the plurality of individuals; and {\textbar} {\textbar} a selection of answers to the series of questions for each of the plurality of individuals; {\textbar} {\textbar} determining a plurality of features from the labeled training data; {\textbar} {\textbar} training an initial machine learning model in a supervised manner, based on the plurality of features; {\textbar} {\textbar} extracting importance measures for each of the plurality of features, based on the training of the initial machine learning model; {\textbar} {\textbar} generating a plurality of subset machine learning models based on the extracted importance measures for the plurality of features; {\textbar} {\textbar} evaluating a classification performance of the generated plurality of subset machine learning models; and {\textbar} {\textbar} selecting at least one of the subset machine learning models as the machine learning model. {\textbar} {\textbar} 2. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on clinical scales data corresponding to the plurality of individuals. {\textbar} 3. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on {fMRI} full connectivity data corresponding to the plurality of individuals. {\textbar} 4. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on {sMRI} data corresponding to the plurality of individuals, the {sMRI} data comprising cortical volume data, cortical thickness data, and cortical surface area data. {\textbar} 5. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on input data corresponding to the plurality of individuals, wherein, for each individual, the input data comprises clinical scales data and {fMRI} data. {\textbar} 6. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on input data corresponding to the plurality of individuals, wherein, for each individual, the input data comprises clinical scales data and {sMRI} data. {\textbar} 7. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on input data corresponding to the plurality of individuals, wherein, for each individual, the input data comprises {fMRI} data and {sMRI} data. {\textbar} 8. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on input data corresponding to the plurality of individuals, wherein, for each individual, the input data comprises {fMRI} data, clinical scales data, and {sMRI} data. {\textbar} 9. A system for evaluating mental health of patients, the system comprising: {\textbar} a memory containing machine readable medium comprising machine executable code having stored thereon instructions for performing a method; and {\textbar} {\textbar} a control system coupled to the memory comprising one or more processors, the control system configured to execute the machine executable code to cause the control system to: {\textbar} {\textbar} receive a selection of answers associated with a patient, the selection of answers corresponding to each question in a series of questions from mental health questionnaires; {\textbar} {\textbar} receive, unprocessed {MRI} data corresponding to a set of {MRI} images of a biological structure associated with the patient; {\textbar} {\textbar} process the unprocessed {MRI} data to output a set of {MRI} features; {\textbar} {\textbar} process, using a machine learning model, the selection of answers, and the set of {MRI} features, to output a mental health indication of the patient; and {\textbar} {\textbar} display, on a display device, the output of the processing, wherein the output is the mental health indication of the patient {\textbar} {\textbar} wherein the machine learning model was generated by: {\textbar} {\textbar} receiving labeled training data for a plurality of individuals indicating whether each of the plurality of individuals has one or more mental health disorders, the labeled training data comprising: {\textbar} {\textbar} {MRI} data recorded for each of the plurality of individuals; and {\textbar} {\textbar} a selection of answers to the series of questions for each of the plurality of individuals; {\textbar} {\textbar} determining a plurality of features from the labeled training data; {\textbar} {\textbar} training an initial machine learning model in a supervised manner, based on the plurality of features; {\textbar} {\textbar} extracting importance measures for each of the plurality of features, based on the training of the initial machine learning model; {\textbar} {\textbar} generating a plurality of subset machine learning models based on the extracted importance measures for the plurality of features; {\textbar} {\textbar} evaluating a classification performance of the generated plurality of subset machine learning models; and {\textbar} {\textbar} selecting at least one of the subset machine learning models as the machine learning model. What is claimed is: {\textbar} {\textbar} 1. A system for evaluating a patient for mental health issues, the system comprising: {\textbar} a display device; {\textbar} {\textbar} a user interface; {\textbar} {\textbar} a memory containing machine readable medium comprising machine executable code having stored thereon instructions for performing a method; and {\textbar} {\textbar} a control system coupled to the memory comprising one or more processors, the control system configured to execute the machine executable code to cause the control system to: {\textbar} {\textbar} display, on the display device, a series of questions from mental health questionnaires comprising text and answers for each question; {\textbar} {\textbar} receive, from the user interface, a selection of answers from a patient of each of the series of questions; {\textbar} {\textbar} receive, unprocessed {MRI} data corresponding to a set of {MRI} images of a biological structure associated with the patient; {\textbar} {\textbar} process, using a machine learning model, the selection of answers and the unprocessed {MRI} data to output a mental health indication of the patient, and {\textbar} {\textbar} display, on the display device, the output of the processing, wherein the output is the mental health indication of the patient {\textbar} {\textbar} wherein the machine learning model was generated by: {\textbar} {\textbar} receiving labeled training data for a plurality of individuals indicating whether each of the plurality of individuals has one or more mental health disorders, the labeled training data comprising: {\textbar} {\textbar} {MRI} data recorded for each of the plurality of individuals; and {\textbar} {\textbar} a selection of answers to the series of questions for each of the plurality of individuals; {\textbar} {\textbar} determining a plurality of features from the labeled training data; {\textbar} {\textbar} training an initial machine learning model in a supervised manner, based on the plurality of features; {\textbar} {\textbar} extracting importance measures for each of the plurality of features, based on the training of the initial machine learning model; {\textbar} {\textbar} generating a plurality of subset machine learning models based on the extracted importance measures for the plurality of features; {\textbar} {\textbar} evaluating a classification performance of the generated plurality of subset machine learning models; and {\textbar} {\textbar} selecting at least one of the subset machine learning models as the machine learning model. {\textbar} {\textbar} 2. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on clinical scales data corresponding to the plurality of individuals. {\textbar} 3. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on {fMRI} full connectivity data corresponding to the plurality of individuals. {\textbar} 4. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on {sMRI} data corresponding to the plurality of individuals, the {sMRI} data comprising cortical volume data, cortical thickness data, and cortical surface area data. {\textbar} 5. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on input data corresponding to the plurality of individuals, wherein, for each individual, the input data comprises clinical scales data and {fMRI} data. {\textbar} 6. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on input data corresponding to the plurality of individuals, wherein, for each individual, the input data comprises clinical scales data and {sMRI} data. {\textbar} 7. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on input data corresponding to the plurality of individuals, wherein, for each individual, the input data comprises {fMRI} data and {sMRI} data. {\textbar} 8. The system of {\textbar} claim 1 {\textbar} , wherein the machine learning model is trained on input data corresponding to the plurality of individuals, wherein, for each individual, the input data comprises {fMRI} data, clinical scales data, and {sMRI} data. {\textbar} 9. A system for evaluating mental health of patients, the system comprising: {\textbar} a memory containing machine readable medium comprising machine executable code having stored thereon instructions for performing a method; and {\textbar} {\textbar} a control system coupled to the memory comprising one or more processors, the control system configured to execute the machine executable code to cause the control system to: {\textbar} {\textbar} receive a selection of answers associated with a patient, the selection of answers corresponding to each question in a series of questions from mental health questionnaires; {\textbar} {\textbar} receive, unprocessed {MRI} data corresponding to a set of {MRI} images of a biological structure associated with the patient; {\textbar} {\textbar} process the unprocessed {MRI} data to output a set of {MRI} features; {\textbar} {\textbar} process, using a machine learning model, the selection of answers, and the set of {MRI} features, to output a mental health indication of the patient; and {\textbar} {\textbar} display, on a display device, the output of the processing, wherein the output is the mental health indication of the patient {\textbar} {\textbar} wherein the machine learning model was generated by: {\textbar} {\textbar} receiving labeled training data for a plurality of individuals indicating whether each of the plurality of individuals has one or more mental health disorders, the labeled training data comprising: {\textbar} {\textbar} {MRI} data recorded for each of the plurality of individuals; and {\textbar} {\textbar} a selection of answers to the series of questions for each of the plurality of individuals; {\textbar} {\textbar} determining a plurality of features from the labeled training data; {\textbar} {\textbar} training an initial machine learning model in a supervised manner, based on the plurality of features; {\textbar} {\textbar} extracting importance measures for each of the plurality of features, based on the training of the initial machine learning model; {\textbar} {\textbar} generating a plurality of subset machine learning models based on the extracted importance measures for the plurality of features; {\textbar} {\textbar} evaluating a classification performance of the generated plurality of subset machine learning models; and {\textbar} {\textbar} selecting at least one of the subset machine learning models as the machine learning model. 1. A system for evaluating a patient for mental health issues, the system comprising: {\textbar} a display device; {\textbar} {\textbar} a user interface; {\textbar} {\textbar} a memory containing machine readable medium comprising machine executable code having stored thereon instructions for performing a method; and {\textbar} {\textbar} a control system coupled to the memory comprising one or more processors, the control system configured to execute the machine executable code to cause the control system to: {\textbar} {\textbar} display, on the display device, a series of questions from mental health questionnaires comprising text and answers for each question; {\textbar} {\textbar} receive, from the user interface, a selection of answers from a patient of each of the series of questions; {\textbar} {\textbar} receive, unprocessed {MRI} data corresponding to a set of {MRI} images of a biological structure associated with the patient; {\textbar} {\textbar} process, using a machine learning model, the selection of answers and the unprocessed {MRI} data to output a mental health indication of the patient, and {\textbar} {\textbar} display, on the display device, the output of the processing, wherein the output is the mental health indication of the patient {\textbar} {\textbar} wherein the machine learning model was generated by: {\textbar} {\textbar} receiving labeled training data for a plurality of individuals indicating whether each of the plurality of individuals has one or more mental health disorders, the labeled training data comprising: {\textbar} {\textbar} {MRI} data recorded for each of the plurality of individuals; and {\textbar} {\textbar} a selection of answers to the series of questions for each of the plurality of individuals; {\textbar} {\textbar} determining a plurality of features from the labeled training data; {\textbar} {\textbar} training an initial machine learning model in a supervised manner, based on the plurality of features; {\textbar} {\textbar} extracting importance measures for each of the plurality of features, based on the training of the initial machine learning model; {\textbar} {\textbar} generating a plurality of subset machine learning models based on the extracted importance measures for the plurality of features; {\textbar} {\textbar} evaluating a classification performance of the generated plurality of subset machine learning models; and {\textbar} {\textbar} selecting at least one of the subset machine learning models as the machine learning model. 1. A system for evaluating a patient for mental health issues, the system comprising: {\textbar} a display device; {\textbar} {\textbar} a user interface; {\textbar} {\textbar} a memory containing machine readable medium comprising machine executable code having stored thereon instructions for performing a method; and {\textbar} {\textbar} a control system coupled to the memory comprising one or more processors, the control system configured to execute the machine executable code to cause the control system to: {\textbar} {\textbar} display, on the display device, a series of questions from mental health questionnaires comprising text and answers for each question; {\textbar} {\textbar} receive, from the user interface, a selection of answers from a patient of each of the series of questions; {\textbar} {\textbar} receive, unprocessed {MRI} data corresponding to a set of {MRI} images of a biological structure associated with the patient; {\textbar} {\textbar} process, using a machine learning model, the selection of answers and the unprocessed {MRI} data to output a mental health indication of the patient, and {\textbar} {\textbar} display, on the display device, the output of the processing, wherein the output is the mental health indication of the patient {\textbar} {\textbar} wherein the machine learning model was generated by: {\textbar} {\textbar} receiving labeled training data for a plurality of individuals indicating whether each of the plurality of individuals has one or more mental health disorders, the labeled training data comprising: {\textbar} {\textbar} {MRI} data recorded for each of the plurality of individuals; and {\textbar} {\textbar} a selection of answers to the series of questions for each of the plurality of individuals; {\textbar} {\textbar} determining a plurality of features from the labeled training data; {\textbar} {\textbar} training an initial machine learning model in a supervised manner, based on the plurality of features; {\textbar} {\textbar} extracting importance measures for each of the plurality of features, based on the training of the initial machine learning model; {\textbar} {\textbar} generating a plurality of subset machine learning models based on the extracted importance measures for the plurality of features; {\textbar} {\textbar} evaluating a classification performance of the generated plurality of subset machine learning models; and {\textbar} {\textbar} selecting at least one of the subset machine learning models as the machine learning model. {CROSS}-{REFERENCE} {TO} {RELATED} {APPLICATION} {\textbar} {\textbar} This application is the National Phase of International Application {PCT}/{US}2019/048762, filed Aug. 29, 2019, which designated the United States, which claims priority to and the benefit of U.S. Provisional Patent No. 62/725,994 filed Aug. 31, 2018, each of which is hereby incorporated by reference herein in its entirety. {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} The foregoing and other advantages of the present disclosure will become apparent upon reading the following detailed description and upon reference to the drawings. {\textbar} {\textbar} {FIGS}. 1A-1D {\textbar} {\textbar} illustrate boxplots of the maximum {AUC}'s during sequential model selection, according to some implementations of the present disclosure; {\textbar} {FIGS}. 2A-2B {\textbar} {\textbar} illustrate time complexity of the importance-guided forward model selection procedure, according to some implementations of the present disclosure; {\textbar} {FIGS}. 3A-3D {\textbar} {\textbar} illustrate {ROC} from the truncated models producing the best {AUC} using phenotype data as features, according to some implementations of the present disclosure; {\textbar} {FIG}. 4 {\textbar} {\textbar} illustrates percentage of questions from each of thirteen (13) questionnaires among the set of most predictive questions producing the highest {AUC}, according to some implementations of the present disclosure; {\textbar} {FIGS}. 5A-5D {\textbar} {\textbar} illustrate comparing the count of items from each questionnaire among the actual set of most predictive questions with those from randomly ordered lists of questions, according to some implementations of the present disclosure; {\textbar} {FIGS}. 6A-6D {\textbar} {\textbar} illustrate {AUC}'s as a function of the number of top features included during sequential model selection, according to some implementations of the present disclosure; {\textbar} {FIGS}. 7A-7D {\textbar} {\textbar} illustrates actual {AUC}'s versus the distribution of {AUC}'s from classifiers trained and tested on randomly permuted class labels, according to some implementations of the present disclosure; {\textbar} {FIG}. 8A {\textbar} {\textbar} illustrates X-Y plots of number of features versus predicted outcome scores, according to some implementations of the present disclosure; {\textbar} {FIG}. 8B {\textbar} {\textbar} illustrates a comparison of measured outcome scores and predicted outcome scores, according to some implementations of the present disclosure; {\textbar} {FIGS}. 9A-9F {\textbar} {\textbar} illustrate measured versus predicted values for best models for depression or depressed mood, according to some implementations of the present disclosure; {\textbar} {FIGS}. 10A-10E {\textbar} {\textbar} illustrate measured versus predicted values for best models for anhedonia, according to some implementations of the present disclosure; {\textbar} {FIG}. 11A-111B {\textbar} {\textbar} illustrate measured versus predicted values for best models for anxiety, according to some implementations of the present disclosure; {\textbar} {FIGS}. 12A-12H {\textbar} {\textbar} illustrate measured versus predicted values for best models for negative symptoms, according to some implementations of the present disclosure; {\textbar} {FIG}. 13 {\textbar} {\textbar} illustrates best median r {\textbar} 2 {\textbar} for the best models for each outcome variable, according to some implementations of the present disclosure; {\textbar} {FIGS}. 14A-14B {\textbar} {\textbar} illustrate proportions of feature types in best models, according to some implementations of the present disclosure; {\textbar} {FIGS}. 15A-15F {\textbar} {\textbar} illustrate proportions of features from each scale for best model predicting depression or depressed mood, according to some implementations of the present disclosure; {\textbar} {FIGS}. 16A-16E {\textbar} {\textbar} illustrate proportions of features from each scale for best model predicting anhedonia, according to some implementations of the present disclosure; {\textbar} {FIGS}. 17A-17B {\textbar} {\textbar} illustrate proportions of features from each scale for best model predicting anxiety, according to some implementations of the present disclosure; {\textbar} {FIGS}. 18A-18G {\textbar} {\textbar} illustrate proportion of features from each scale for best model predicting negative symptoms, according to some implementations of the present disclosure; {\textbar} {FIGS}. 19A-19F {\textbar} {\textbar} illustrate binary heat maps for {fMRI} connectivity features of best model predicting depression or depressed mood, according to some implementations of the present disclosure; {\textbar} {FIGS}. 20A-20E {\textbar} {\textbar} illustrate binary heat maps for {fMRI} connectivity features of best model predicting anhedonia, according to some implementations of the present disclosure; {\textbar} {FIGS}. 21A-21B {\textbar} {\textbar} illustrate binary heat maps for {fMRI} connectivity features of best model predicting anxiety, according to some implementations of the present disclosure; {\textbar} {FIGS}. 22A-22H {\textbar} {\textbar} illustrate binary heat maps for {fMRI} connectivity features of best model predicting negative symptoms, according to some implementations of the present disclosure; {\textbar} {FIGS}. 23A-23B {\textbar} {\textbar} illustrate median r {\textbar} 2 {\textbar} for models with specific number of features, according to some implementations of the present disclosure; {\textbar} {FIGS}. 24A-24F {\textbar} {\textbar} illustrate proportions of features from each scale for the scales-only model predicting depression or depressed mood according to some implementations of the present disclosure; {\textbar} {FIGS}. 25A-25E {\textbar} {\textbar} illustrate proportions of features from each scale for scales-only model predicting anhedonia, according to some implementations of the present disclosure; {\textbar} {FIGS}. 26A-26B {\textbar} {\textbar} illustrate proportions of features from each scale for scales-only model predicting anxiety, according to some implementations of the present disclosure; {\textbar} {FIGS}. 27A-27H {\textbar} {\textbar} illustrate proportions of features from each scale for scales-only model predicting negative symptoms, according to some implementations of the present disclosure; {\textbar} {FIG}. 28 {\textbar} {\textbar} illustrates an exemplary system for implementing various methodologies disclosed herein, according to some implementations of the present disclosure; {\textbar} {FIG}. 29 {\textbar} {\textbar} illustrates an exemplary methodology for determining a symptom severity indicator for a patient, according to some implementations of the present disclosure; {\textbar} {FIG}. 30 {\textbar} {\textbar} illustrates an exemplary methodology for selecting a machine learning model as a generalized linear model, according to some implementations of the present disclosure; {\textbar} {FIGS}. 31A-31B {\textbar} {\textbar} illustrates a block diagram of an {MRI} system used to acquire {NMR} data, according to some implementations of the present disclosure; {\textbar} {FIG}. 32 {\textbar} {\textbar} illustrates a block diagram of a transceiver which forms part of the {MRI} system of {\textbar} {FIG}. 31A {\textbar} , according to some implementations of the present disclosure; and {\textbar} {FIG}. 33 {\textbar} {\textbar} illustrates an exemplary methodology for selecting a machine learning model as a diagnostic classifier, according to some implementations of the present disclosure. {\textbar} {TECHNICAL} {FIELD} {\textbar} {\textbar} The present disclosure relates to transdiagnostic feature selection, and more specifically, to the use of machine learning to identify shared transdiagnostic features. {\textbar} {\textbar} {BACKGROUND} {\textbar} {\textbar} The field of psychiatry has long relied on making diagnoses and recommending treatment for disorders based solely on clinical phenomenology. For example, the Diagnostic and Statistical Manual of Mental Disorders ({DSM}) is a standard for diagnosing psychiatric disorders in the United States. It provides a symptom-based taxonomy which serves to help clinicians classify various clusters of symptoms and abnormal behaviors into distinct categories of disorders. {\textbar} {\textbar} However, categorizing mental disorders as discrete entities each having its own distinct cluster of symptoms has its inadequacies. This approach hampers prognostic assessment, treatment, and drug development. Therefore, one objective of the present disclosure is to use a data-driven method to find highly-predictive biomarkers for several measures of depressed mood, anxiety, anhedonia and related negative symptoms. {\textbar} {\textbar} {SUMMARY} {\textbar} {\textbar} Aspects of the present disclosure include a system for evaluating a patient for mental health issues. The system includes a display device, a user interface, a memory, and a control system. The memory contains machine readable medium. The machine readable medium includes machine executable code storing instructions for performing a method. The control system is coupled to the memory, and includes one or more processors. The control system is configured to execute the machine executable code to cause the control system to perform the method: On the display device, a series of questions from mental health questionnaires is displayed. The series of questions includes text and answers for each question. From the user interface, a selection of answers of each of the series of questions is received from a patient. Unprocessed {MRI} data are received. The unprocessed {MRI} data correspond to a set of {MRI} images of a biological structure associated with the patient. Using a machine learning model, the selection of answers and the unprocessed {MRI} data are processed to output a mental health indication of the patient. {\textbar} {\textbar} In some aspects, the unprocessed {MRI} data corresponds to {MRI} data for a brain of the patient. In some aspects, the unprocessed {MRI} data includes at least one of: functional {MRI} data, resting-state functional {MRI} data, structural {MRI} data, and any combination thereof. In some aspects, the control system is further configured to preprocess the unprocessed {MRI} data to identify a plurality of features. {\textbar} {\textbar} In some aspects, the mental health indication is categorical. For example, the mental health indication includes a determination that the processed selection of answers and the processed {MRI} data includes indications of at least one of: a neuropsychiatric disorder, schizophrenia, a bi-polar disorder, and any combination thereof. {\textbar} {\textbar} In some aspects, outputting the mental health indication further comprises determining that the processed selection of answers and the processed {MRI} data identifies features corresponding to a mental disorder. {\textbar} {\textbar} In some aspects, the machine learning model is at least one of a generalized linear model, a regression model, a logistical regression model, a supervised regression method, random forest, {LASSO}, a supervised machine-learning model, and an elastic net. {\textbar} {\textbar} In some aspects, the machine learning model was generated by receiving labeled training data for a plurality of individuals. The labeled training data indicates whether each of the plurality of individuals has one or more mental health disorders. The labeled training data includes {MRI} data recorded for each of the plurality of individuals. The labeled training data further includes a selection of answers to the series of questions for each of the plurality of individuals. A plurality of features is determined from the labeled training data. An initial machine learning model is trained in a supervised manner. The initial machine learning model is trained based on the plurality of features. Importance measures for each of the plurality of features extracted based on the training of the initial machine learning model. A plurality of subset machine learning models is generated based on the extracted importance measures for the plurality of features. A classification performance of the generated plurality of subset machine learning models is evaluated At least one of the subset machine learning models is selected as the machine learning model. {\textbar} {\textbar} In some aspects, the machine learning model is trained on clinical scales data corresponding to the plurality of individuals. In some aspects, the machine learning model is trained on {fMRI} full connectivity data corresponding to the plurality of individuals. In some aspects, the machine learning model is trained on {sMRI} data corresponding to the plurality of individuals. The {sMRI} data includes cortical volume data, cortical thickness data, and cortical surface area data. {\textbar} {\textbar} In some aspects, the machine learning model is trained on input data corresponding to the plurality of individuals. For each individual, the input data can include various types of data. As an example, the input data includes clinical scales data and {fMRI} data. As another example, the input data includes clinical scales data and {sMRI} data. As a further example, the input data includes {fMRI} data and {sMRI} data. As yet another example, the input data includes {fMRI} data, clinical scales data, and {sMRI} data. {\textbar} {\textbar} Additional aspects of the present disclosure include a system for evaluating mental health of patients. The system includes a memory, and a control system. The memory contains machine readable medium. The machine readable medium includes machine executable code storing instructions for performing a method. The control system is coupled to the memory, and includes one or more processors. The control system is configured to execute the machine executable code to cause the control system to perform the method: A selection of answers associated with a patient is received. The selection of answers corresponds to each question in a series of questions from mental health questionnaires. Unprocessed {MRI} data are received. The unprocessed {MRI} data correspond to a set of {MRI} images of a biological structure associated with the patient. The unprocessed {MRI} data is processed to output a set of {MRI} features. Using a machine learning model, the selection of answers and the set of {MRI} features are processed to output a mental health indication of the patient. {\textbar} {\textbar} Further aspects of the present disclosure include a machine learning training system. The machine learning training system includes at least one nontransitory processor-readable storage medium and at least one processor communicatively coupled to the at least one nontransitory processor-readable storage medium. The at least one nontransitory processor-readable storage medium stores at least one of processor-executable instructions or data. The at least one processor, in operation, is configured to receive labeled training data. The labeled training data includes data for a plurality of individuals, which indicate whether each of the individuals has one or more of a plurality of mental health disorders. The labeled training data further includes a selection of answers to mental health questionnaires for each of the individuals, and {MRI} data recorded for each of the plurality of individuals. The answers and {MRI} data are processed to output a plurality of features. An initial machine learning model is trained in a supervised manner based at least in part on the received labeled training data. An importance measure for each of the plurality of features is extracted from the trained initial machine learning model. A plurality of subset machine learning models is generated based at least in part on the extracted importance measures for the plurality of features. A classification performance of the generated plurality of subset machine learning models are evaluated. At least one of the subset machine learning models is selected as a diagnostic classifier. The features of the diagnostic classifier are stored in the at least one nontransitory processor-readable storage medium for subsequent use as a screening tool. {\textbar} {\textbar} In some aspects, the machine learning system further includes using the features of the diagnostic classifier as a screening tool to assess at least one of intermediate or end-point outcomes in at least one clinical trial testing for treatment responses. {\textbar} {\textbar} In some aspects, the selected subset machine learning model includes a portion of the plurality of features. The portion selected from features includes an importance measure above a threshold value. {\textbar} {\textbar} In some aspects, each of the subset machine learning models includes a different selection of the portion of the plurality of features. In some aspects, at least twenty features of the plurality of features have an importance measure above the threshold value. For example, the portion of the plurality of features includes at least ten features and less than twenty features. {\textbar} {\textbar} In some aspects, the diagnostic classifier is operative to determine whether an individual is healthy or has a general mental health issue. In some aspects, the diagnostic classifier is operative to determine whether an individual is healthy or has a specific mental health disorder. In some aspects, the diagnostic classifier is operative to determine whether an individual has a first specific mental health disorder or a second specific mental health disorder. In some aspects, the diagnostic classifier is operative to determine whether an individual is at risk of developing a mental health disorder. {\textbar} {\textbar} In some aspects, the labeled training data includes, for each individual, an indication of at least one of the following: whether the individual is healthy, whether the individual has a general mental health issue, whether the individual has one or more specific mental health disorders, whether the individual is at risk of developing a general mental health issue, whether the individual is at risk of developing one or more specific mental health disorders, and any combination thereof. In some aspects, the labeled training data further comprises at least one of: functional measurement data or physiological measurement data. {\textbar} {\textbar} In some aspects, the selected subset machine learning model includes at least a subset of the following features: “I have more fun doing activities with other people than by myself”; “I have trouble concentrating”; “I have frequent mood changes without understanding why”; “I try to do well at everything I do”; “I need to think for a long time before I make a decision”; “I need a lot of self-control to keep myself out of trouble”; “I am often restless and can't sit still”; “I am very affected when one of my friends seems upset”; “My mood changes more than I think I should”; and “I do not get enough emotional support from other people.” {\textbar} {\textbar} In some aspects, the selected subset machine learning model includes at least a subset of the following features: “I like to please other people as much as I can”; “There are often times when I am so restless that it is impossible for me to sit still”; “My mood often changes, from happiness to sadness, without my knowing why”; “Although there are things that I enjoy doing by myself, I usually seem to have more fun when I do things with other people”; “I am more sentimental than most people”; “I love to excel at everything I do”; “People consider me a rather freewheeling and spontaneous person”; “I feel that I never really get all that I need from people”; “In unfamiliar surroundings, I am often so assertive and sociable that I surprise myself”; “I like to think about things for a long time before I make a decision”; “Sometimes ideas and insights come to me so fast that I cannot express them all”; “I have many hobbies”; “I like to keep my problems to myself”; “It is difficult for me to keep the same interests for a long time because my attention often shifts to something else”; “How often do you have trouble wrapping up the final details of a project, once the challenging parts have been done”; “I like to go slow in starting work, even if it is easy to do”; and “Usually I am more worried than most people that something might go wrong in the future.” {\textbar} {\textbar} In some aspects, in operation, the at least one processor trains the initial machine learning model using k-fold cross validation with logistic regression. In some aspects, each of the subset machine learning models includes a different combination of the features of the initial machine learning model. In some aspects, each of the subset machine learning models includes a different number of the features of the initial machine learning model determined by the importance measures. {\textbar} {\textbar} Still further aspects of the present disclosure include a system for evaluating mental health of patients. The system includes a memory and a control system. The memory contains machine readable medium. The machine readable medium includes machine executable code storing instructions for performing a method. The control system is coupled to the memory, and includes one or more processors. The control system is configured to execute the machine executable code to cause the control system to perform the method: Unprocessed {MRI} data are received. The unprocessed {MRI} data correspond to a set of {MRI} images of a biological structure of a patient. Using a machine learning model, the unprocessed {MRI} data are processed to output a mental health indication of the patient. {\textbar} {\textbar} The above summary is not intended to represent each embodiment or every aspect of the present disclosure. Rather, the foregoing summary merely provides an example of some of the novel aspects and features set forth herein. The above features and advantages, and other features and advantages of the present disclosure, will be readily apparent from the following detailed description of representative embodiments and modes for carrying out the present disclosure, when taken in connection with the accompanying drawings and the appended claims. {\textbar} {\textbar} While the present disclosure is susceptible to various modifications and alternative forms, specific embodiments have been shown by way of example in the drawings and will be described in detail herein. It should be understood, however, that the present disclosure is not intended to be limited to the particular forms disclosed. Rather, the present disclosure is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the present disclosure as defined by the appended claims. {\textbar} {\textbar} {DETAILED} {DESCRIPTION} {\textbar} {\textbar} The present disclosure is described with reference to the attached figures, where like reference numerals are used throughout the figures to designate similar or equivalent elements. The figures are not drawn to scale, and are provided merely to illustrate the instant disclosure. Several aspects of the disclosure are described below with reference to example applications for illustration. It should be understood that numerous specific details, relationships, and methods are set forth to provide a full understanding of the disclosure. One having ordinary skill in the relevant art, however, will readily recognize that the disclosure can be practiced without one or more of the specific details, or with other methods. In other instances, well-known structures or operations are not shown in detail to avoid obscuring the disclosure. The present disclosure is not limited by the illustrated ordering of acts or events, as some acts may occur in different orders and/or concurrently with other acts or events. Furthermore, not all illustrated acts or events are required to implement a methodology in accordance with the present disclosure. {\textbar} {\textbar} Aspects of the present disclosure can be implemented using one or more suitable processing device, such as general-purpose computer systems, microprocessors, digital signal processors, micro-controllers, application-specific integrated circuits ({ASIC}), programmable logic devices ({PLD}), field-programmable logic devices ({FPLD}), field-programmable gate arrays ({FPGA}), mobile devices such as a mobile telephone or personal digital assistants ({PDA}), a local server, a remote server, wearable computers, tablet computers, or the like. {\textbar} {\textbar} Memory storage devices of the one or more processing devices can include a machine-readable medium on which is stored one or more sets of instructions (e.g., software) embodying any one or more of the methodologies or functions described herein. The instructions can further be transmitted or received over a network via a network transmitter receiver. While the machine-readable medium can be a single medium, the term “machine-readable medium” should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of instructions. The term “machine-readable medium” can also be taken to include any medium that is capable of storing, encoding, or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the various embodiments, or that is capable of storing, encoding, or carrying data structures utilized by or associated with such a set of instructions. The term “machine-readable medium” can accordingly be taken to include, but not be limited to, solid-state memories, optical media, and magnetic media. A variety of different types of memory storage devices, such as a random access memory ({RAM}) or a read-only memory ({ROM}) in the system or a floppy disk, hard disk, {CD} {ROM}, {DVD} {ROM}, flash, or other computer-readable medium that is read from and/or written to by a magnetic, optical, or other reading and/or writing system that is coupled to the processing device, can be used for the memory or memories. {\textbar} {\textbar} Overview {\textbar} {\textbar} The Diagnostic and Statistical Manual of Mental Disorders ({DSM}) is a standard for diagnosing psychiatric disorders in the United States. Yet, evidence has long suggested that symptoms in psychiatric disorders do not follow boundaries between {DSM} categories, implicating an underlying latent transdiagnostic dimensional structure. While abnormal feature dimensions associated with the latent symptom dimensions can be identified within a single {DSM} category, the transdiagnostic dimensional structure shared across psychiatric disorders largely remains unknown. {\textbar} {\textbar} Thus, the field of psychiatry can rely on making diagnoses and recommending treatment for disorders based solely on clinical phenomenology. However, this approach hampers prognostic assessment, treatment, and drug development. As with many other areas of medicine, defining mental illness based on a combination of symptoms and biological underpinnings could allow for a richer understanding and potentially better management of these disorders. {\textbar} {\textbar} Moreover, dimensionality and comorbidity are pervasive in terms of symptoms across different {DSM} categories. Such dimensionality is manifested as heterogeneity in symptom clusters within disease categories defined by the {DSM} as well as overlaps across {DSM} categories. For instance, in the area of anxiety and mood disorders, more than 50\% of individuals are diagnosed of having more than one category of disorders according to the {DSM} at a given time. Similarly, about 50\% of bipolar disorder patients exhibit schizophrenic-like psychotic symptoms during illness episodes. The presence of such psychotic symptoms can be mood-incongruent and can occur outside of illness episodes, hence creating challenges in correctly categorizing and treating such patients. Overall, a latent trans-diagnostic dimensional structure may exist spanning multiple disorders. The {DSM}'s symptom-based taxonomy may not provide an accurate account of such latent structure of psychopathology. {\textbar} {\textbar} Furthermore, clinical symptoms such as depressed mood, anxiety, and anhedonia span multiple diagnostic categories, so one approach to linking them with their biological bases would be examination of symptom severity trans-diagnostically at suitable physiological levels. This approach of stratifying mental disorders by symptom dimension across current diagnostic categories could sidestep the main issue that categorical boundaries present. Evidence suggests symptom dimensions that span multiple psychiatric disorders and can be tied to biological bases. {\textbar} {\textbar} This issue may be addressed by identifying the underlying structures of psychopathology on multiple levels including symptom, behavior, physiology, imaging, and genetics. Data-driven methods based on symptom and behavior have largely focused on classifying and subtyping patients within a single diagnostic category. While such a focus on re-partitioning a single diagnostic category is useful, it is likely to be limited given the observed symptom overlaps across {DSM} categories. On the other hand, genetic risk for psychiatric disorders is pleiotropic and shared across broad dimensions of disorders, such as {SCZ}, {BD}, and {ADHD}. Yet, the genetic risk identified for psychiatric disorder is generally characterized by polygenic inheritance, hence the effect size from a given risk allele is likely to be small. Based on neuroimaging (e.g., {sMRI}), shared abnormalities in certain brain regions underlying common psychiatric disorders were identified. Functional {MRI} ({fMRI}) found altered functional connectivity patterns shared across multiple categories of disorders such as {SCZ}, {BD}, and {MDD}. {\textbar} {\textbar} Though valuable, the search for psychiatric biomarkers has thus largely been limited to those that permit diagnostic classification and generally limited to one type, mode, or category of biomarker. Certain clinical phenotypes described at the symptom or neurobiological levels may span multiple diagnoses. Therefore, exploration of transdiagnostic biomarkers that probe these levels of expression could expand our understanding beyond categorical definitions of disorders and towards disorders that vary along symptom dimensions. {\textbar} {\textbar} Therefore, the present disclosure contemplates that there exist distinct subtypes within various mental health disorders (e.g., {MDD}, {PTSD}, and panic disorder) based on, for example, orthogonal symptom dimensions shared across the {DSM} diagnoses and their corresponding biomarkers. The corresponding biomarkers can include biomarkers identifiable in neuroimaging as discussed further herein and other modalities (including advantageously combining modalities). While these important shared abnormal features associated with the latent transdiagnostic symptom and behavior dimensions can be identified, the robustness of the identified features in terms of their ability to reliably classify patients according to the symptom and behavior dimensions are tested and discussed herein. {\textbar} {\textbar} According to some implementations of the present disclosure, using the Consortium for Neuropsychiatric Phenomics (“{CNP}”) dataset, a set of phenotypic features shared across schizophrenia (“{SCZ}”), bipolar disorder (“{BD}”), and attention deficit/hyperactivity disorder (“{ADHD}”) from self-reported clinical instruments is identified. For example, the set of phenotypic features are identified according to four (4) transdiagnostic classifiers: (1) Healthy vs. All Patients, (2) Healthy vs. {SCZ} \& {BD}, (3) Healthy vs. {SCZ} \& {ADHD}, and (4) Healthy vs. {BD} \& {ADHD}. {\textbar} {\textbar} These phenotypic features can robustly distinguish patient groups from healthy controls, and outperformed classifiers trained on morphological and connectivity measures based on structural and functional magnetic resonance imaging. In addition, these phenotypic features encompass a wide range of domains, including personality and traits, positive and negative effects, cognition, sensory processing, and social processing. As an example, a highest proportion of shared phenotypic features consists of personality traits and temperaments defined in the Temperament and Character Inventory pertaining to harm avoidance, novelty seeking, persistence, and reward dependence. Thus, the present disclosure provides a robust data-driven approach to identify transdiagnostic features shared across various patient populations. {\textbar} {\textbar} Cross-cutting symptom subtypes were identified in patients with major depressive disorder ({MDD}), panic disorder, posttraumatic stress disorder ({PTSD}) or in healthy controls ({HC}) and mapped onto measures of cognitive, physiological, and functional outcome measures. Reward responsivity, the lack of which is related to anhedonia, is tied to deficits in {fMRI} connectivity in a transdiagnostic sample of {SZ}, {MDD}, {BD}, and psychosis risk subjects. Derived symptom dimensions correlated with various network-based {fMRI} connectivity measures in a community sample including representation of multiple psychopathological categories. In some examples, ventral striatal connectivity can predict future depressive order. {\textbar} {\textbar} Genetic risk variants correlate highly across {MDD}, {SZ}, {BD}, and attention deficit and hyperactivity disorder ({ADHD}), suggesting that examining symptoms in this transdiagnostic group could be highly informative. Thus, the present disclosure capitalizes on the Consortium for Neuropsychiatric Phenomics ({CNP}) dataset which includes three of these patient groups ({SZ}, {BD}, {ADHD}, and additionally healthy controls) and a rich set of clinical symptom evaluations and neuroimaging data for investigating biomarkers of symptom severity. One objective of the present disclosure is predicting severity for a subset of symptoms assessed in the dataset. In some examples, those datasets related to mood and emotional dysregulation are selected, for example, depression/depressed mood, anhedonia, anxiety, and other negative symptoms. {\textbar} {\textbar} While performing correlations is the dominant approach to examine variation along a symptom dimension, the framework of machine learning overcomes some shortcomings of correlative approaches as it allows us to create models and test predictive value and generalizability of those models on held out or new samples. Additionally, multivariate modeling allows a concurrent examination of phenotypes across the multiple levels of expression of mental illness—levels of cognitive behaviors, symptoms, brain measures, etc.—which may improve predictive ability. According to some implementations of the present disclosure, an exemplary method is disclosed for sorting and evaluating features by importance in order to improve biomarker development. {\textbar} {\textbar} Further, the present disclosure provides for predictive models of depression, anxiety, anhedonia, and other negative symptoms. Different types of machine learning (“{ML}”) models are utilized. Using the {CNP} dataset, predictability of the models is analyzed. The analysis further includes a comparison of single v. multimodal features. This dataset includes data from clinical scales, resting-state functional-{MRI} scans, and structural-{MRI} scans for patients with schizophrenia, bipolar disorder, {ADHD}, and healthy controls. Thus, the present disclosure provides a custom, data-driven method of identifying subsets of the most predictive features. The present disclosure allows a comparison in an unbiased manner, via different permutations of input feature set and {ML} model choice. For example, the predictability is analyzed and compared using multi-modal biomarkers and single modality biomarkers. A subset of features that maximized predictability is identified from a set that is several orders of magnitude larger than the subset. As an example, such subset includes edge-level {fMRI} connectivity features, clinical scale features, and {sMRI} features. Thus, the present disclosure provides for predicting transdiagnostic symptoms related to depression, anxiety, anhedonia, and other negative symptoms. {\textbar} {\textbar} Nonetheless, selection of the optimal features for exploring predictive models/biomarkers can be difficult in the face of high-dimensional, multi-modal data. An importance-weighted, forward selection approach is taken as a data-driven way to identify the optimal feature subset to include in regression model-building. Finding an optimal subset helps in high-dimensional cases where the number of features (p) is greater than the number of samples (n) to minimize overfitting of the models. It also reduces noise from uninformative input variables without requiring the modeler to judge whether a variable is signal or noise. {\textbar} {\textbar} The importance-weighted, forward selection approach involves an initial rank-ordering step for ordering features by importance, a forward-selection search step for building a series of models utilizing subsets of ordered features selected from the first step, and an evaluation step for evaluating each of these models using these candidate subsets according to a pre-specified criterion to find the optimal model. Thus, this approach integrates feature selection into regression modeling. Additionally, different types of input features are evaluated (e.g., responses to clinical symptom and trait scales, structural {MRI} measures, functional {MRI} measures). {\textbar} {\textbar} Two different linear regression algorithms that incorporate feature selection through regularization (Lasso, Elastic Net) and one non-linear algorithm (Random Forest) are also evaluated, in order to identify the best parameters and biomarkers for our selected set of symptom types. Thus, another exemplary method is disclosed herein to find highly-predictive biomarkers for several measures of depressed mood, anxiety, anhedonia and related negative symptoms and to compare the contribution of single versus multimodality feature sets and different algorithms to biomarker-building. {\textbar} {\textbar} As such, another objective of the present disclosure is to better understand the features returned by the best biomarkers at a category level. In line with the objectives herein, the present disclosure is directed to, among others, that 1) multi-modal biomarkers that are more predictive than single modality biomarkers, 2) data-driven methods that identify a subset of features and maximize predictability from a much larger set, and 3) from among that subset, analyzing edge-level {fMRI} connectivity features, clinical scale features, and {sMRI} features. In addition, {fMRI} connectivity features can be broadly distributed across many resting-state networks for most symptom biomarkers (though in some instances, default-mode network connectivity can be more abnormal) and that a few clinical scales are more highly represented than others. {\textbar} {\textbar} Exemplary Systems and Methodologies {\textbar} {\textbar} The present disclosure contemplates that a variety of systems can be used to perform various embodiments of the present disclosure. Referring now to {\textbar} {\textbar} {FIG}. 28 {\textbar} , an exemplary system {\textbar} 2800 {\textbar} is shown, which can be configured to perform various methods of the present disclosure, including methods {\textbar} 2900 {\textbar} , {\textbar} 3000 {\textbar} , and {\textbar} 3300 {\textbar} of {\textbar} {FIGS}. 29, 30, and 33 {\textbar} , respectively. In particular, system {\textbar} 2800 {\textbar} includes a display {\textbar} 2802 {\textbar} , a user interface {\textbar} 2804 {\textbar} , a control system {\textbar} 2806 {\textbar} , and a memory {\textbar} 2808 {\textbar} . In some examples, the system {\textbar} 2800 {\textbar} further includes one or more servers {\textbar} 2810 {\textbar} . {\textbar} The user interface {\textbar} {\textbar} 2804 {\textbar} is configured to receive input from a user. For example, the user interface {\textbar} 2804 {\textbar} can be a keyboard, a touchscreen, a mobile device, or any other device for receiving input, as known in the art. The user enters data on the user interface {\textbar} 2804 {\textbar} in response to prompts on the display {\textbar} 2802 {\textbar} . For example, the display {\textbar} 2802 {\textbar} outputs a series of mental health questions, and the user inputs an answer to each question on the user interface {\textbar} 2804 {\textbar} . In some examples, the user interface {\textbar} 2804 {\textbar} directly displays the input on display {\textbar} 2802 {\textbar} and relays the data to the control system {\textbar} 2806 {\textbar} . In some examples, the data is then stored in the memory {\textbar} 2808 {\textbar} . {\textbar} The display {\textbar} {\textbar} 2802 {\textbar} is configured to receive data from the control system {\textbar} 2806 {\textbar} and the user interface {\textbar} 2804 {\textbar} . For example, the display {\textbar} 2802 {\textbar} displays input received from the user interface {\textbar} 2804 {\textbar} ; in some examples, the data is first sent to the control system {\textbar} 2806 {\textbar} , which then processes the data and instructs the display {\textbar} 2802 {\textbar} according to the processed data. In other examples, the display {\textbar} 2802 {\textbar} displays data received from the control system {\textbar} 2806 {\textbar} . Exemplary data from the control system {\textbar} 2806 {\textbar} includes questions from a mental health questionnaire, answer boxes, answer options, answer data, or a mental health indicator. In some examples, the display {\textbar} 2802 {\textbar} is on a smart phone. {\textbar} The present disclosure also contemplates that more than one display {\textbar} {\textbar} 2802 {\textbar} can be used in system {\textbar} 2800 {\textbar} , as would be readily contemplated by a person skilled in the art. For example, one display can be viewable by a patient, while additional displays are visible to researchers and not to the patient. The multiple displays can output identical or different information, according to instructions by the control system {\textbar} 2806 {\textbar} . {\textbar} The control system {\textbar} {\textbar} 2806 {\textbar} can be communicatively coupled to the display {\textbar} 2802 {\textbar} , the user interface {\textbar} 2804 {\textbar} , and the memory {\textbar} 2808 {\textbar} . Further, the control system {\textbar} 2806 {\textbar} can be communicatively coupled to the server {\textbar} 2810 {\textbar} . For example, the communication can be wired or wireless. The control system {\textbar} 2806 {\textbar} is configured to perform any methods as contemplated according to {\textbar} {FIGS}. 29-30 {\textbar} (discussed further below). The control system {\textbar} 2806 {\textbar} can process and/or store input from the display {\textbar} 2802 {\textbar} , the user interface {\textbar} 2804 {\textbar} , and the memory {\textbar} 2808 {\textbar} . In some examples, the methodologies disclosed herein can be implemented, via the control system {\textbar} 2806 {\textbar} , on the server {\textbar} 2810 {\textbar} . It is also contemplated that the server {\textbar} 2810 {\textbar} includes a plurality of servers, and can be remote or local. Optionally, the control system and/or the memory {\textbar} 2808 {\textbar} may be incorporated into the server {\textbar} 2810 {\textbar} . {\textbar} In some examples, system {\textbar} {\textbar} 2800 {\textbar} can be a unitary device, for example, a smart phone, which includes a display {\textbar} 2802 {\textbar} , a user interface {\textbar} 2804 {\textbar} , a control system {\textbar} 2806 {\textbar} , and a memory {\textbar} 2808 {\textbar} . {\textbar} Turning now to {\textbar} {\textbar} {FIG}. 29 {\textbar} , an exemplary methodology {\textbar} 2900 {\textbar} is discussed for evaluating a patient for mental health issues. Additional details and alternate steps for methodology {\textbar} 2900 {\textbar} are discussed further with regards to {\textbar} {FIGS}. 1A-33 {\textbar} and the corresponding description. {\textbar} Methodology {\textbar} {\textbar} 2900 {\textbar} begins at step {\textbar} 2910 {\textbar} which provides for displaying a series of questions. An exemplary series of questions includes questions from mental health questionnaires, and includes both text and answers for each question. In some examples, the series of questions are displayed on a display device (e.g., the display {\textbar} 2802 {\textbar} of {\textbar} {FIG}. 28 {\textbar} ). {\textbar} In some aspects, the series of questions includes questions determined by a machine learning system (e.g., a machine learning algorithm) to be effective at screening patients. The questions determined by the machine learning system may be more effective than an initial and/or larger set of questions. For example, the machine learning system may be able to pick a number of most effective questions out of an initial set of questions. An exemplary set of most effective questions includes whether the patient agrees with each of the following statements in the past two weeks: “I have more fun doing activities with other people than by myself”; “I have trouble concentrating”; “I have frequent mood changes without understanding why”; “I try to do well at everything I do”; “I need to think for a long time before I make a decision”; “I need a lot of self-control to keep myself out of trouble”; “I am often restless and can't sit still”; “I am very affected when one of my friends seems upset”; “My mood changes more than I think I should”; and “I do not get enough emotional support from other people.” An exemplary set of answers to each of those questions may include: “Strongly Disagree,” “Disagree,” “Neither agree nor disagree,” “Agree,” and “Strongly Agree.” {\textbar} {\textbar} Methodology {\textbar} {\textbar} 2900 {\textbar} then provides for, at step {\textbar} 2920 {\textbar} , receiving answers for each of the series of questions (the questions provided for in step {\textbar} 2910 {\textbar} ). In some examples, the answers are received at a user interface (e.g., user interface {\textbar} 2804 {\textbar} of {\textbar} {FIG}. 28 {\textbar} ). In some examples, the answers include selection of a multiple choice question, a textual response, or any other user input as contemplated by one skilled in the art. In some examples, the answers are retrieved from a record entry corresponding to one patient in a database of patient records. This database can be stored in the memory {\textbar} 2808 {\textbar} of {\textbar} {FIG}. 28 {\textbar} , for example. In some examples, the database can be stored in the sever {\textbar} 2810 {\textbar} of {\textbar} {FIG}. 28 {\textbar} . In some examples, methodology {\textbar} 2900 {\textbar} begins directly at step {\textbar} 2920 {\textbar} . {\textbar} Step {\textbar} {\textbar} 2930 {\textbar} provides for receiving unprocessed {MRI} data. The unprocessed {MRI} data corresponds to a set of {MRI} images of a biological structure. In some examples, the biological structure is associated with the patient. In some examples, the {MRI} data corresponds to {MRI} data for a patient's brain (e.g., the same patient who provided answers at step {\textbar} 2920 {\textbar} ). The {MRI} data can include task-based {fMRI} data, rs-{fMRI} data, and/or {sMRI} data. In some examples, step {\textbar} 2930 {\textbar} receives other types of neuroimaging data instead of, or in addition to, the unprocessed {MRI} data. In additional examples of step {\textbar} 2930 {\textbar} , methodology {\textbar} 2900 {\textbar} can provide for receiving clinical scales data. In some examples of step {\textbar} 2930 {\textbar} , methodology {\textbar} 2900 {\textbar} provides for receiving processed {MRI} data. {\textbar} Step {\textbar} {\textbar} 2940 {\textbar} then provides for processing, using a machine learning model, the selection of answers from step {\textbar} 2920 {\textbar} and the data received at step {\textbar} 2930 {\textbar} (e.g., the unprocessed {MRI} data). In some examples of methodology {\textbar} 2900 {\textbar} , the data received at step {\textbar} 2930 {\textbar} is preprocessed to identify a plurality of features. {\textbar} At step {\textbar} {\textbar} 2950 {\textbar} , methodology {\textbar} 2900 {\textbar} provides for outputting a mental health indication of the patient. In some examples of the present disclosure, step {\textbar} 2850 {\textbar} performs processing of the answers and the received data as discussed further below with respect to methodology {\textbar} 3000 {\textbar} of {\textbar} {FIG}. 30 {\textbar} and methodology {\textbar} 3300 {\textbar} of {\textbar} {FIG}. 33 {\textbar} . In some aspects, the mental health indication is categorical. For example, the mental health indication includes a determination that the processed selection of answers and the processed {MRI} data includes indications of at least one of: a neuropsychiatric disorder, schizophrenia, a bi-polar disorder, unhealthy generally (versus healthy control) and any combination thereof. {\textbar} In some aspects, methodology {\textbar} {\textbar} 2900 {\textbar} further comprises determining that the processed selection of answers and the processed {MRI} data identifies features corresponding to a mental disorder. {\textbar} Even though methodology {\textbar} {\textbar} 2900 {\textbar} is illustrated to include steps {\textbar} 2910 {\textbar} - {\textbar} 2950 {\textbar} , the present disclosure also contemplates more or fewer steps. For example, real-time user input is optional for some implementations of the present disclosure. As such, additional aspects of the present disclosure include a system configured to perform a method, similar to methodology {\textbar} 2900 {\textbar} but not including real-time user input. For example, instead of first displaying a series of questions, this method begins with receiving a selection of answers associated with a patient. {\textbar} As another example, questions and answers from a mental health questionnaire is optional for some implementations of the present disclosure. As such, additional aspects of the present disclosure include a system configured to perform a method, similar to methodology {\textbar} {\textbar} 2900 {\textbar} but not including a series of questions or a series of answers. For example, using a machine learning model, the unprocessed {MRI} data are processed to output a mental health indication of the patient, without reference to a selection of answers associated with a patient. {\textbar} Referring now to methodology {\textbar} {\textbar} 3000 {\textbar} of {\textbar} {FIG}. 30 {\textbar} , an exemplary methodology is shown for selecting a machine learning model as a generalized linear model, according to various embodiments of the present disclosure. In some examples, the machine learning model is any of: a generalized linear model, a logistical regression model, a regression model, a supervised regression method, random forest model, {LASSO} model, and an elastic net model. In some examples, the machine learning model is any of the models and algorithms discussed further below. In one embodiment of method {\textbar} 3000 {\textbar} , the present disclosure provides two regularized general linear model regression algorithms, {LASSO} and Elastic Net, and one non-linear regression model algorithm, Random Forest. Elastic Net in particular can be used when the number of predictor variables is much greater than the number of samples. {\textbar} In step {\textbar} {\textbar} 3010 {\textbar} , methodology {\textbar} 3000 {\textbar} provides for receiving labeled training data regarding mental health disorder status for a plurality of individuals. In some examples, the labeled training data identifies whether each of the individuals has one or more mental health disorders and the mental health indicator of their symptoms. The labeled training data includes, for each individual, a selection of answers to mental health questionnaires and includes {MRI} data. The {MRI} data can be task-based {fMRI} data, {sMRI} data, and/or rs-{fMRI} data. In some examples, the labeled training data includes other types of neuroimaging data for each individual. In some examples, the labeled training data includes, for each individual, an indication of any of: whether the individual is healthy, whether the individual has a general mental health issue, whether the individual has one or more specific mental health disorders, whether the individual is at risk of developing a general mental health issue, or whether the individual is at risk of developing one or more specific mental health disorders. In some examples, the labeled training data includes another functional and/or physiological measurement dataset, as known in the art. {\textbar} In step {\textbar} {\textbar} 3020 {\textbar} , methodology {\textbar} 3000 {\textbar} provides for determining features from the labeled training data of step {\textbar} 3010 {\textbar} . The features are determined according to any methods, as known in the art. {\textbar} In step {\textbar} {\textbar} 3030 {\textbar} , methodology {\textbar} 3000 {\textbar} provides for training an initial machine learning model in a supervised manner, based on the features determined in step {\textbar} 3020 {\textbar} . In some examples, training this initial machine learning model includes using k-fold cross-validation with {LASSO} and Elastic Net regression. {\textbar} In some examples, training this initial machine learning model in step {\textbar} {\textbar} 3030 {\textbar} includes training the model on clinical scales data corresponding to the plurality of individuals. In some examples, training this initial machine learning model in step {\textbar} 3030 {\textbar} includes training the model on {fMRI} full connectivity data corresponding to the plurality of individuals. In some examples, training this initial machine learning model in step {\textbar} 3030 {\textbar} includes training the model on {sMRI} data corresponding to a plurality of individuals, the {sMRI} data including cortical volume data, cortical thickness data, and cortical surface area data. {\textbar} In some examples, training this initial machine learning model in step {\textbar} {\textbar} 3030 {\textbar} includes training the model on input data corresponding to the plurality of individuals. For each individual, the input data includes a variety of combinations of data. As a first example, the input data includes clinical scales data and {fMRI} data. As a second example, the input data includes clinical scales data and {sMRI} data. As a third example, the input data comprises {fMRI} data and {sMRI} data. {\textbar} As a fourth example, the input data comprises {fMRI} data, clinical scales data, and {sMRI} data. This particular combination of input data provides a high r {\textbar} {\textbar} 2 {\textbar} metric (calculated on an untouched evaluation set data to avoid biasing and overfitting our models) when using Elastic Net across the different outcome variables. {\textbar} In step {\textbar} {\textbar} 3040 {\textbar} , methodology {\textbar} 3000 {\textbar} provides for extracting importance measures for each of the features. These importance measures are selected based on the trained initial machine learning model. {\textbar} In step {\textbar} {\textbar} 3050 {\textbar} , methodology {\textbar} 3000 {\textbar} provides for generating a plurality of subset machine learning models, based on the extracted importance measures of step {\textbar} 3040 {\textbar} . {\textbar} In step {\textbar} {\textbar} 3060 {\textbar} , methodology {\textbar} 3000 {\textbar} provides for evaluating a regression performance of the generated subset machine learning models from step {\textbar} 3050 {\textbar} . In some examples, each of the subset machine learning models includes a different selection of features. In some examples, the subset machine learning models include only features with an importance measure above a threshold value. In some examples, the features are ranked based on the importance measure. In some examples, each of the subset machine learning models includes a sequentially lower number of features than a following subset machine learning model, wherein the features are selected for each subset machine learning model based on a highest importance measure. {\textbar} In step {\textbar} {\textbar} 3070 {\textbar} , methodology {\textbar} 3000 {\textbar} provides for selecting one of the subset machine learning models as a generalized linear learning model. The selection is based on the regression performances as evaluated in step {\textbar} 3060 {\textbar} . The selected subset machine learning model includes a portion of the plurality of features determined from step {\textbar} 3020 {\textbar} . The portion of features is selected from features with an importance measure above a threshold value. In some examples, more than one subset machine learning model is selected. {\textbar} In some examples of step {\textbar} {\textbar} 3070 {\textbar} , the threshold value is set so that at least twenty features of the plurality of features determined in step {\textbar} 3020 {\textbar} have an importance measure above the threshold value. In some examples, the threshold value is set to select a portion of between ten and twenty features. {\textbar} In some examples of step {\textbar} {\textbar} 3070 {\textbar} , the features of the machine learning model are stored in a non-transitory processor-readable storage medium (e.g., memory {\textbar} 2808 {\textbar} of {\textbar} {FIG}. 28 {\textbar} ). The features can then be later used as a screening tool. In some examples, the screening tool can output a mental health indicator of a mental health condition. In some examples, the screening tool assesses intermediate and/or end-point outcomes in clinical trial testing for treatment responses. {\textbar} Therefore, the selected machine learning model can then be used to process any of the input data as provided for in the present disclosure. {\textbar} {\textbar} Referring now to methodology {\textbar} {\textbar} 3300 {\textbar} of {\textbar} {FIG}. 33 {\textbar} , an exemplary methodology is shown for selecting a machine learning model as a diagnostic classifier, according to various embodiments of the present disclosure. Methodology {\textbar} 3300 {\textbar} can be applied in place of, or in combination of, methodology {\textbar} 3000 {\textbar} of {\textbar} {FIG}. 30 {\textbar} . {\textbar} In step {\textbar} {\textbar} 3310 {\textbar} , methodology {\textbar} 3300 {\textbar} provides for receiving labeled training data regarding mental health disorder status for a plurality of individuals. The labeled training data includes data for a plurality of individuals, which indicate whether each of the individuals has one or more of a plurality of mental health disorders. The labeled training data further includes a selection of answers to mental health questionnaires for each of the individuals, and {MRI} data recorded for each of the plurality of individuals. {\textbar} In some aspects, the labeled training data of step {\textbar} {\textbar} 3310 {\textbar} includes, for each individual, an indication of whether the individual is healthy, whether the individual has a general mental health issue, whether the individual has one or more specific mental health disorders, whether the individual is at risk of developing a general mental health issue, whether the individual is at risk of developing one or more specific mental health disorders, or the like, or any combination thereof. In some aspects, the labeled training data of step {\textbar} 3310 {\textbar} further includes functional measurement data and/or physiological measurement data. {\textbar} In step {\textbar} {\textbar} 3320 {\textbar} , methodology {\textbar} 3300 {\textbar} provides for determining features from the labeled training data of step {\textbar} 3310 {\textbar} . In some examples, the answers and {MRI} data of the received labeled training data are processed to output a plurality of features. The features are determined according to any methods, as known in the art. {\textbar} In step {\textbar} {\textbar} 3330 {\textbar} , methodology {\textbar} 3300 {\textbar} provides for training an initial machine learning model in a supervised manner, based at least in part on the received labeled training data. In some examples, the initial machine learning model is trained based on the features determined in step {\textbar} 3320 {\textbar} . In some examples, training this initial machine learning model includes using k-fold cross validation with logistic regression (e.g., with {LASSO} and/or Elastic Net regression). {\textbar} In step {\textbar} {\textbar} 3340 {\textbar} , methodology {\textbar} 3300 {\textbar} provides for extracting importance measures for each of the plurality of features. These importance measures are selected based on the trained initial machine learning model. {\textbar} In step {\textbar} {\textbar} 3350 {\textbar} , methodology {\textbar} 3300 {\textbar} provides for generating a plurality of subset machine learning models, based on the extracted importance measures of step {\textbar} 3340 {\textbar} . In some aspects, each of the subset machine learning models includes a different combination of the features of the initial machine learning model. In some aspects, each of the subset machine learning models includes a different number of the features of the initial machine learning model determined by the importance measures. {\textbar} In step {\textbar} {\textbar} 3360 {\textbar} , methodology {\textbar} 3300 {\textbar} provides for evaluating a classification performance of the generated subset machine learning models from step {\textbar} 3350 {\textbar} . {\textbar} In step {\textbar} {\textbar} 3370 {\textbar} , methodology {\textbar} 3300 {\textbar} provides for selecting one of the subset machine learning models as a diagnostic classifier. The selection is based on the classification performances as evaluated in step {\textbar} 3360 {\textbar} . The selected subset machine learning model includes a portion of the plurality of features determined from step {\textbar} 3320 {\textbar} . The portion of features is selected from features with an importance measure above a threshold value. In some examples, more than one subset machine learning model is selected. It is also contemplated that the selected machine learning model can then be used to process any of the input data as provided for in the present disclosure. {\textbar} In some aspects, the selected subset machine learning model of step {\textbar} {\textbar} 3370 {\textbar} includes a portion of the plurality of features. The portion selected from features includes an importance measure above a threshold value. In some aspects, each of the subset machine learning models includes a different selection of the portion of the plurality of features. In some aspects, at least twenty (2) features of the plurality of features have an importance measure above the threshold value. As an example, the portion of the plurality of features includes at least ten (10) features and less than twenty (20) features. As another example, the selected subset machine learning model includes M of the most important N features as determined by the importance measures, wherein M is an integer between 10 and 20 and N is an integer greater than 20. {\textbar} In some aspects, the diagnostic classifier of step {\textbar} {\textbar} 3370 {\textbar} is operative to determine whether an individual is healthy or has a general mental health issue. In some aspects, the diagnostic classifier of step {\textbar} 3370 {\textbar} is operative to determine whether an individual is healthy or has a specific mental health disorder. In some aspects, the diagnostic classifier of step {\textbar} 3370 {\textbar} is operative to determine whether an individual has a first specific mental health disorder or a second specific mental health disorder. In some aspects, the diagnostic classifier of step {\textbar} 3370 {\textbar} is operative to determine whether an individual is at risk of developing a mental health disorder. {\textbar} In some aspects, the selected subset machine learning model of step {\textbar} {\textbar} 3370 {\textbar} includes at least a subset of the following features, or any similar features as known in the art. {\textbar} “I have more fun doing activities with other people than by myself”; {\textbar} “I have trouble concentrating”; {\textbar} “I have frequent mood changes without understanding why”; {\textbar} “I try to do well at everything I do”; {\textbar} “I need to think for a long time before I make a decision”; {\textbar} “I need a lot of self-control to keep myself out of trouble”; {\textbar} “I am often restless and can't sit still”; {\textbar} “I am very affected when one of my friends seems upset”; {\textbar} “My mood changes more than I think I should”; and {\textbar} “I do not get enough emotional support from other people.” {\textbar} In some aspects, the selected subset machine learning model of step {\textbar} {\textbar} 3370 {\textbar} includes at least a subset of the following features, or any similar features as known in the art. {\textbar} “I like to please other people as much as I can”; {\textbar} “There are often times when I am so restless that it is impossible for me to sit still”; {\textbar} “My mood often changes, from happiness to sadness, without my knowing why”; {\textbar} “Although there are things that I enjoy doing by myself, I usually seem to have more fun when I do things with other people”; {\textbar} “I am more sentimental than most people”; {\textbar} “I love to excel at everything I do”; {\textbar} “People consider me a rather freewheeling and spontaneous person”; {\textbar} “I feel that I never really get all that I need from people”; {\textbar} “In unfamiliar surroundings, I am often so assertive and sociable that I surprise myself”; {\textbar} “I like to think about things for a long time before I make a decision”; {\textbar} “Sometimes ideas and insights come to me so fast that I cannot express them all”; {\textbar} “I have many hobbies”; {\textbar} “I like to keep my problems to myself”; {\textbar} “It is difficult for me to keep the same interests for a long time because my attention often shifts to something else”; {\textbar} “How often do you have trouble wrapping up the final details of a project, once the challenging parts have been done”; {\textbar} “I like to go slow in starting work, even if it is easy to do”; and {\textbar} “Usually I am more worried than most people that something might go wrong in the future.” {\textbar} In step {\textbar} {\textbar} 3380 {\textbar} , the features of the diagnostic classifier are stored for subsequent use as a screening tool. In some examples, the features are stored in at least one nontransitory processor-readable storage medium, such as the memory {\textbar} 2808 {\textbar} of {\textbar} {FIG}. 28 {\textbar} . {\textbar} In some aspects, the methodology {\textbar} {\textbar} 3300 {\textbar} further provides for includes using the features of the diagnostic classifier as a screening tool to assess at least one of intermediate or end-point outcomes in at least one clinical trial testing for treatment responses. {\textbar} In some aspects, the methodology {\textbar} {\textbar} 3300 {\textbar} further provides for further includes using the features of the diagnostic classifier as a screening tool to assess at least one of intermediate or end-point outcomes in at least one clinical trial testing for treatment responses. {\textbar} In some examples, the machine learning model of methodology {\textbar} {\textbar} 3300 {\textbar} can be implemented in a machine learning training system. Similar to the system {\textbar} 2800 {\textbar} of {\textbar} {FIG}. 28 {\textbar} , the machine learning training system includes at least one nontransitory processor-readable storage medium and at least one processor communicatively coupled to the at least one nontransitory processor-readable storage medium. The at least one nontransitory processor-readable storage medium stores at least one of processor-executable instructions or data. The at least one processor, in operation, is configured to receive labeled training data of methodology {\textbar} 3300 {\textbar} of {\textbar} {FIG}. 33 {\textbar} . {\textbar} As discussed herein, conventional diagnostic biomarker approaches do not fully account for the heterogeneity of symptoms under the umbrella of a single diagnosis or the shared symptoms between multiple diagnoses. It must be noted that conventional clinical practice does not provide transdiagnostic, multimodal predictive models of mental health. Thus, based on the seven feature set input, such as the examples disclosed herein with regard to steps {\textbar} {\textbar} 3060 {\textbar} and {\textbar} 3070 {\textbar} , various combinations of feature types are evaluated as inputs. For example, instead of only analyzing one type of biomarkers, the various combinations of input data include single and multimodal feature sets. The experimental data herein provides that the multimodal models perform better than those of single feature sets. Therefore, the models disclosed herein can be highly predictive based at least in part on their transdiagnostic and/or multimodal data input. {\textbar} Experimental Application and Disclosed Models—Part I {\textbar} {\textbar} An experimental methodology is disclosed further herein which provides additional examples of methodologies {\textbar} {\textbar} 2900 {\textbar} - {\textbar} 3000 {\textbar} and {\textbar} 3300 {\textbar} , as would be readily apparent to one skilled in the art. The experimental methodology includes experimental results which verify additional aspects of the disclosed systems and methods; the experimental results further verify additional benefits of the present disclosure as compared against conventional systems and methods. {\textbar} The {CNP} Dataset {\textbar} {\textbar} The {CNP} dataset is utilized. The {CNP} dataset contains rich data sources from a variety of modalities. The disclosure herein is focused on identifying shared transdiagnostic features in the phenotype data in the form of clinical scales as well as neuroimaging data (including both structural {MRI} and resting-state functional {MRI}). The downloaded dataset in this disclosure included 272 subjects, of which 50 were diagnosed with schizophrenia ({SCZ}), 49 with bipolar disorder ({BD}), and 43 with attention deficit and hyperactivity disorder ({ADHD}). The remaining 130 subjects were age-matched healthy controls ({HC}) recruited from the community. The diagnoses were given by following the Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition ({DSM}-{IV}; cite {DSM}) and were based on the Structured Clinical Interview for {DSM}-{IV} (cite {SCID}). To better characterize {ADHD} related symptoms, the Adult {ADHD} Interview (cite) was further used as a supplement. Out of all subjects, 1 had incomplete phenotype data from the clinical scales used in this disclosure, 10 had missing structural {MRI} ({sMRI}) data, and 10 had missing resting-state functional {MRI} ({fMRI}) data. Fifty-five (55) subjects had an aliasing artifact in their {sMRI} data, whereas 22 subjects had errors in the structural-functional alignment step during {MRI} preprocessing. These subjects were excluded from the corresponding modeling analyses performed during the methods disclosed herein. The subject numbers and demographics information are given in Table 1. In Table 1, the demographic information is based on initial number of subjects. The number of subjects with {sMRI} data excludes subjects with aliasing artifacts. The number of subjects with {fMRI} data excludes subjects with misaligned structural-function imaging data. {\textbar} {\textbar} {TABLE} 1 {\textbar} {\textbar} Demographic Information {\textbar} {\textbar} {HC} {\textbar} {\textbar} {SCZ} {\textbar} {BD} {\textbar} {ADHD} {\textbar} Total {\textbar} No of subjects {\textbar} {\textbar} 130 {\textbar} 50 {\textbar} 49 {\textbar} 43 {\textbar} 262 {\textbar} With complete phenotype {\textbar} {\textbar} 130 {\textbar} 50 {\textbar} 48 {\textbar} 43 {\textbar} 271 {\textbar} data {\textbar} {\textbar} With {sMRI} data {\textbar} {\textbar} 98 {\textbar} 30 {\textbar} 44 {\textbar} 34 {\textbar} 206 {\textbar} With {fMRI} data {\textbar} {\textbar} 104 {\textbar} 47 {\textbar} 41 {\textbar} 37 {\textbar} 229 {\textbar} Age {\textbar} {\textbar} Mean age {\textbar} {\textbar} 31.26 {\textbar} 36.46 {\textbar} 35.15 {\textbar} 33.09 {\textbar} {SD} age {\textbar} {\textbar} 8.74 {\textbar} 8.88 {\textbar} 9.07 {\textbar} 10.76 {\textbar} Range age {\textbar} {\textbar} 21-50 {\textbar} 22-49 {\textbar} 21-50 {\textbar} 21-50 {\textbar} Gender {\textbar} {\textbar} No. of female subjects {\textbar} {\textbar} 62 {\textbar} 12 {\textbar} 21 {\textbar} 22 {\textbar} Percent female subjects {\textbar} {\textbar} 47.69\% {\textbar} 24.00\% {\textbar} 42.86\% {\textbar} 51.16\% {\textbar} Race {\textbar} {\textbar} American Indian or {\textbar} {\textbar} 19.23\% {\textbar} 22.00\% {\textbar}  6.25\% {\textbar}    0\% {\textbar} Alaskan Native {\textbar} {\textbar} Asian {\textbar} {\textbar} 15.38\% {\textbar}  2.00\% {\textbar}    0\% {\textbar}  2.33\% {\textbar} Black/African American {\textbar} {\textbar}  0.77\% {\textbar}  4.00\% {\textbar}  2.08\% {\textbar}  2.33\% {\textbar} White {\textbar} {\textbar} 78.46\% {\textbar} 66.00\% {\textbar} 77.08\% {\textbar} 88.37\% {\textbar} More than one race {\textbar} {\textbar}    0\% {\textbar}  2.00\% {\textbar} 14.58\% {\textbar}  6.98\% {\textbar} Education {\textbar} {\textbar} No high school {\textbar} {\textbar}  1.54\% {\textbar} 18.00\% {\textbar}  2.08\% {\textbar}    0\% {\textbar} High school {\textbar} {\textbar} 12.31\% {\textbar} 44.00\% {\textbar} 29.17\% {\textbar} 23.26\% {\textbar} Some college {\textbar} {\textbar} 20.77\% {\textbar} 18.00\% {\textbar} 25.00\% {\textbar} 30.23\% {\textbar} Associate's degree {\textbar} {\textbar}  7.69\% {\textbar}  4.00\% {\textbar}  6.25\% {\textbar}  6.98\% {\textbar} Bachelor's degree {\textbar} {\textbar} 50.00\% {\textbar} 10.00\% {\textbar} 29.17\% {\textbar} 32.56\% {\textbar} Graduate degree {\textbar} {\textbar}  6.92\% {\textbar}    0\% {\textbar}  4.17\% {\textbar}  2.33\% {\textbar} Other {\textbar} {\textbar}  0.77\% {\textbar}  4.00\% {\textbar}  4.17\% {\textbar}  4.65\% {\textbar} Phenotype Data {\textbar} {\textbar} Subjects were administered a total of 20 questionnaires and scales to capture a wide range of phenotypical data including specific behavioral traits and symptom dimensions. These questionnaires/scales are either clinician-rated or self-reported. While the clinician-rated questionnaires only covered relevant patient groups, 13 self-reported clinical scales were given to all three patient groups as well as the heathy controls. Therefore, subjects' answers to each of the individual questions coming from these 13 self-reported scales are used as input features to the models. Specifically, the 13 self-reported scales used in the methods are: Chapman social anhedonia scale, Chapman physical anhedonia scale, Chapman perceptual aberrations scale, hypomanic personality scale, Hopkins symptom checklist, temperament and character inventory, adult {ADHD} self-report scale v1.1 screener, Barratt impulsiveness scale, Dickman functional and dysfunctional impulsivity scale, multidimensional personality questionnaire—control subscale, Eysenck's impulsivity inventory, scale for traits that increase risk for bipolar {II} disorder, and Golden and Meehl's Seven {MMPI} items selected by taxonomic method. {\textbar} {\textbar} {MRI} Data Acquisition Parameters {\textbar} {\textbar} {MRI} data were acquired on one of two 3T Siemens Trio scanners both housed at the University of California, Los Angeles. The {sMRI} data used in this disclosure are T1-weighted and were acquired using a magnetization-prepared rapid gradient-echo ({MPRAGE}) sequence with the following acquisition parameters: {TR}=1.9 s, {TE}=2.26 ms, {FOV}=250 mm, matrix=256×256, 176 1-mm thick slices oriented along the sagittal plane. The resting-state {fMRI} data contain a single run lasting 304 s. The scan was acquired using a T2*-weighted echoplanar imaging ({EPI}) sequence using the following parameters: 34 oblique slices, slice thickness=4 mm, {TR}=2 s, {TE}=30 ms, flip angle=90°, matrix size 64×64, {FOV}=192 mm. During the resting-state scan, subjects remained still and relaxed inside the scanner, and kept their eyes open. No specific stimulus or task was presented to them. {\textbar} {\textbar} {MRI} Preprocessing—{sMRI} {\textbar} {\textbar} Structural {MRI} preprocessing was implemented using Freesurfer's recon-all processing pipeline. Briefly, the T1-weighted structural image from each subject was intensity normalized and skull-stripped. The subcortical structures, white matter, and ventricles were segmented and labeled according to the algorithm. The pial and white matter surfaces were then extracted and tessellated, and cortical parcellation was obtained on the surfaces according to a gyral-based anatomical atlas which partitions each hemisphere into 34 regions. {\textbar} {\textbar} {MRI} Preprocessing—Resting-State {fMRI} {\textbar} {\textbar} Resting-state {fMRI} preprocessing was implemented in {AFNI}. Specifically, the first 3 volumes in the data were discarded to remove any transient magnetization effects in the data. Spikes in the resting-state {fMRI} data were then removed and all volumes were spatially registered with the 4 {\textbar} {\textbar} th {\textbar} volume to correct for any head motion. The Tiw structural image was deobliqued and uniformized to remove shading artifacts before skull-stripping. The skull-stripped structural image was then spatially registered with motion corrected {fMRI} data. The {fMRI} data were further spatially smoothed using a 6-mm {FWHM} Gaussian kernel and converted to percent signal change. Separately, the Freesurfer-generated aparc+aseg image from {sMRI} preprocessing was also spatially registered with and resampled to have the same spatial resolution of the {BOLD} image. {\textbar} Based on this, eroded white matter and ventricle masks were created, from which nuisance tissue regressors were built based on non-spatially smoothed {fMRI} data to model and remove variances that are not part of the {BOLD} signal. Specifically, the {ANATICOR} procedure is used where a locally averaged signal from the eroded white matter mask within a 25-mm radius spherical region of interest ({ROI}) centered at each gray matter voxel was used to create a voxel-wise local estimate of the white matter nuisance signal. This local estimate of the white matter nuisance signal, along with the estimated head motions and average signal from the ventricles were detrended with a 4 {\textbar} {\textbar} th {\textbar} order polynomial and then regressed out from the {fMRI} data. Finally, the clean resting-state {fMRI} data was spatially normalized to the {MI} template and resampled to have 2 mm isocubic voxels. {\textbar} Feature Extraction {\textbar} {\textbar} Measures were extracted from 3 data modalities as features: phenotype data from clinical scales, measures derived from the {sMRI} data, and functional correlations based on resting-state {fMRI} data. For phenotype features from clinical scales, subjects' responses were directly used from a total of 578 questions from the above listed 13 self-reported clinical scales. Responses from non-True/False type questions were normalized to have a range of between 0 and 1 to match those from True/False type questions. {\textbar} {\textbar} For {sMRI} features, the following were specifically used 1) the volume of subcortical structures generated by Freesurfer's subcortical volumetric segmentation, and 2) the area, thickness, and volume of cortical brain regions estimated from Freesurfer's surface-based analysis pipeline. For resting-state {fMRI} features, the brain is first parceled into 264 regions. Specifically, a 5-mm radius spherical {ROI} was seeded according to the {MI} coordinates of each brain region specified in the atlas. Second, the clean resting-state {BOLD} time series from all voxels within a given 5-mm radius spherical {ROI} were averaged to create the representative time series for the brain region. Third, functional connectivity between {ROIs} was estimated via the Pearson's correlation coefficient between the average time series from all pairs of brain regions. This resulted in a 264-by-264 correlation matrix, from which 34,716 are unique correlations between two distinct {ROIs} and were used as input features to the models. {\textbar} {\textbar} Model Fitting and Feature Importance Weighting {\textbar} {\textbar} The primary goals of machine learning analyses in this disclosure are two-fold: 1) to establish robust transdiagnostic classifiers that can reliably separate patient groups from healthy controls, and more importantly 2) to identify important features commonly found across patient groups distinguishing them from healthy controls. To achieve the first goal, the logistic regression model as implemented in the scikit-learn toolbox is utilized. Specifically, 4 transdiagnostic problems based on the {DSM} diagnosis labels provided in the {CNP} dataset were addressed: {HC} vs. All Patients, {HC} vs. {SCZ} \& {BD}, {HC} vs. {SCZ} \& {ADHD}, {HC} vs. {BD} \& {ADHD}. Separate logistic regression models were independently trained using each of the above extracted feature modalities (e.g., phenotype data, {sMRI} measures, and resting-state {fMRI} correlations) as inputs and their performances were evaluated in each of the transdiagnostic scenarios. Combinations of 2 and 3 feature modalities were also used as classifiers' inputs and their performances were evaluated in the same fashion. {\textbar} {\textbar} Because the number of features extracted was relatively large compared to the sample size in {CNP} data, the elastic net regularization term is added in all of the logistic regression models to prevent overfitting. The elastic net regularization is a linear combination of the L1 and L2 regularization terms and has advantages over L1 and L2 regularization when dealing with high-dimensional data with small sample size and correlated features. The use of elastic net regularization in these models also enabled feature selection as the regularization induces sparse models via the grouping effect where all the important features will be retained and the unimportant ones set to zero. This allowed for the identification of predictive features that are shared across multiple patient categories. {\textbar} {\textbar} The elastic net regularized logistic regression implemented in the scikit-learn toolbox contains two hyperparameters: the overall regularization strength and the mixing ratio between the L1 and L2 terms. The following procedure is adopted to determine the best regularization parameters. First, the input data were randomly partitioned into a development set and an evaluation set. The development set contains 80\% of the data upon which a grid search with 3-fold cross validation procedure was implemented to determine the best hyperparameters. Then the model was trained on the entire development set using the best hyperparameters and was further tested on the remaining 20\% of evaluation set which the model had never seen before to obtain testing performance. {\textbar} {\textbar} All features were standardized to have zero mean and unit variance within the training data (the training folds in the 3-fold cross validation or the development set) and the mean and variance from the training data were used to standardize the corresponding test data (the testing fold or the evaluation set) to avoid information spill-over from test data to training data. The entire process was implemented 10 times on 10 different random partitions of the development and evaluation sets. The following metrics were used to quantify the model performances: area under the receiver operating characteristics curve ({AUC}), accuracy, sensitivity, and specificity. The mean and standard deviation of the above metrics over the 10 evaluation sets were reported. {\textbar} {\textbar} From the above trained models, one can assess how predictive each feature is since the weights of the logistic regression model in the transdiagnostic classifiers represent the relationship between a given feature and the logarithm of the odds ratio of an observation being a patient. For each feature, its corresponding mean model weight is calculated and divided by the standard deviation across the 10 model implementations as the proxy for feature importance. Such a feature importance measure is analogous to the Cohen's d effect size measure and thus favored features with large weights and small standard deviations across the 10 model implementations. Features with large importance values from the transdiagnostic classifiers are potentially symptoms, traits, and neuropathological mechanisms shared across patient groups but are distinct from healthy controls. {\textbar} {\textbar} Feature Importance-Guided Sequential Model Selection {\textbar} {\textbar} Because the feature dimension of the input data is high compared to the sample size in the {CNP} dataset, the transdiagnostic classifiers using the full feature sets are likely to be subjected to a substantial amount of noise as well as features that are not predictive. The presence of those noisy features, especially when the sample size is small, might impede the ability of the models to achieve their best performances. To investigate whether improved classification performances can be achieved from a reduced set of most predictive features, the following feature importance-guided sequential model selection procedure is utilized. {\textbar} {\textbar} Specifically, first the features in the transdiagnostic classifiers are rank ordered according to their feature importance measures. Next, a series of truncated models was built such that each model would only take the top k most predictive features as inputs to perform the same transdiagnostic classification problems. Let k range from the top 1 most predictive feature to all available features in steps of 1 for clinical phenotype features, {sMRI} features, and the combination of the two feature sets. For any feature or feature combinations involving {fMRI} correlations, because of the significantly increased feature dimension, the k's were chosen from a geometric sequence with a common ratio of 2 (e.g., 1, 2, 4, 8, 16, . . . ). {\textbar} {\textbar} Model performances were obtained for each truncated model and were evaluated as a function of the number of top features (k) included in each truncated model. To statistically test whether the models' performances are significantly above chance level, a random permutation test is performed where labels in the data (e.g., {HC} vs. Patients) were shuffled 100 times and models were trained on these label-shuffled data using exactly the same approach as described above. The performances from the 100 models were used to construct the empirical null distribution against which the model performance from the actual data was then compared. {\textbar} {\textbar} For example, {\textbar} {\textbar} {FIGS}. 1A-1D {\textbar} illustrate boxplots of the maximum {AUC}'s during sequential model selection (the models are discussed further with regard to {\textbar} {FIGS}. 28-30 {\textbar} and corresponding description). The box represents the 1st and 3rd quartiles of the {AUC}'s across 10 model runs. The line represents the median and the whiskers represent the range of data. {\textbar} Experimental Results {\textbar} {\textbar} In total, classifiers were trained and tested on seven (7) sets of features by either using each individual feature modality (clinical scales, {sMRI}, and {fMRI}) or combinations of 2 or 3 feature modalities. The classifiers' performances using each of the seven (7) feature sets on the 4 transdiagnostic cases are reported in Table 2. {\textbar} {\textbar} {TABLE} 2 {\textbar} {\textbar} Performance of models using the full sets of features {\textbar} {\textbar} Scales + {\textbar} {\textbar} Scales {\textbar} {\textbar} {sMRI} {\textbar} {fMRI} {\textbar} s + {fMRI} {\textbar} Scales + {sMRI} {\textbar} Scales + {fMRI} {\textbar} s + {MRI} {\textbar} {HC} vs. {\textbar} {\textbar} {AUC} {\textbar} 0.83 {\textbar} 0.56 {\textbar} 0.59 {\textbar} 0.57 {\textbar} 0.89 {\textbar} 0.86 {\textbar} 0.86 {\textbar} Patients {\textbar} {\textbar} (0.04) {\textbar} (0.05) {\textbar} (0.04) {\textbar} (0.05) {\textbar} (0.07) {\textbar} (0.06) {\textbar} (0.05) {\textbar} Accuracy {\textbar} {\textbar} 0.77 {\textbar} 0.58 {\textbar} 0.60 {\textbar} 0.61 {\textbar} 0.91 {\textbar} 0.87 {\textbar} 0.86 {\textbar} (0.05) {\textbar} {\textbar} (0.08) {\textbar} (0.06) {\textbar} (0.07) {\textbar} (0.04) {\textbar} (0.05) {\textbar} (0.05) {\textbar} {HC} vs. {\textbar} {\textbar} {AUC} {\textbar} 0.90 {\textbar} 0.68 {\textbar} 0.65 {\textbar} 0.69 {\textbar} 0.90 {\textbar} 0.87 {\textbar} 0.89 {\textbar} {SCZ} + {BD} {\textbar} {\textbar} (0.06) {\textbar} (0.09) {\textbar} (0.09) {\textbar} (0.08) {\textbar} (0.05) {\textbar} (0.06) {\textbar} (0.04) {\textbar} Accuracy {\textbar} {\textbar} 0.82 {\textbar} 0.68 {\textbar} 0.69 {\textbar} 0.74 {\textbar} 0.90 {\textbar} 0.88 {\textbar} 0.89 {\textbar} (0.05) {\textbar} {\textbar} (0.10) {\textbar} (0.08) {\textbar} (0.06) {\textbar} (0.05) {\textbar} (0.06) {\textbar} (0.04) {\textbar} {HC} vs. {\textbar} {\textbar} {AUC} {\textbar} 0.85 {\textbar} 0.61 {\textbar} 0.59 {\textbar} 0.60 {\textbar} 0.87 {\textbar} 0.79 {\textbar} 0.81 {\textbar} {SCZ} + {\textbar} {\textbar} (0.06) {\textbar} (0.07) {\textbar} (0.08) {\textbar} (0.08) {\textbar} (0.06) {\textbar} (0.07) {\textbar} (0.07) {\textbar} {ADHD} {\textbar} {\textbar} Accuracy {\textbar} 0.77 {\textbar} 0.62 {\textbar} 0.59 {\textbar} 0.65 {\textbar} 0.89 {\textbar} 0.79 {\textbar} 0.81 {\textbar} (0.05) {\textbar} {\textbar} (0.07) {\textbar} (0.08) {\textbar} (0.06) {\textbar} (0.05) {\textbar} (0.07) {\textbar} (0.07) {\textbar} {HC} vs. {\textbar} {\textbar} {AUC} {\textbar} 0.87 {\textbar} 0.60 {\textbar} 0.54 {\textbar} 0.58 {\textbar} 0.92 {\textbar} 0.91 {\textbar} 0.88 {\textbar} {BD} + {\textbar} {\textbar} (0.06) {\textbar} (0.06) {\textbar} (0.08) {\textbar} (0.09) {\textbar} (0.05) {\textbar} (0.05) {\textbar} (0.05) {\textbar} {ADHD} {\textbar} {\textbar} Accuracy {\textbar} 0.80 {\textbar} 0.60 {\textbar} 0.55 {\textbar} 0.58 {\textbar} 0.92 {\textbar} 0.91 {\textbar} 0.88 {\textbar} (0.07) {\textbar} {\textbar} (0.06) {\textbar} (0.08) {\textbar} (0.09) {\textbar} (0.05) {\textbar} (0.05) {\textbar} (0.05) {\textbar} Overall, classifiers trained on feature sets involving phenotypical data from clinical scales (e.g., scales and scales+{MRI} feature sets) outperformed those only trained on {MRI} features ({sMRI}, {fMRI}, and s+{fMRI}) for all 4 transdiagnostic cases. For classifiers using features involving clinical scales, the mean {AUC} ranged from 0.79 to 0.92 (mean accuracy: 0.77-0.92), whereas the mean {AUC} ranged from 0.54 to 0.69 (mean accuracy: 0.55-0.74) for {MRI} feature sets. {\textbar} {\textbar} The importance of each feature in terms of its predictability of distinguishing {HC} from patient populations was estimated by the mean over standard deviation of the weights from 10 implementations of the above transdiagnostic classifiers. Based on this importance ranking of each individual feature, a set of truncated models were built sequentially by including only the top k (k ranging from 1 to all features) most predictive features in the models to identify the best subset of features producing the highest classification performance. The performance measures from the best truncated classification models are shown in {\textbar} {\textbar} {FIGS}. 1A-1D {\textbar} and Table 3, with the {AUC} from all transdiagnostic models being significantly above chance level as assessed via the random permutation test (all p's{\textless}0.05; see {\textbar} {FIGS}. 7A-7D {\textbar} —illustrating actual {AUC}'s (shown as a small circle) versus the distribution of {AUC}'s from classifiers trained and tested on randomly permuted class labels). {\textbar} {TABLE} 3 {\textbar} {\textbar} Best model performance during sequential model selection {\textbar} {\textbar} Scales + {\textbar} {\textbar} Scales {\textbar} {\textbar} {sMRI} {\textbar} {fMRI} {\textbar} s + {fMRI} {\textbar} Scales + {sMRI} {\textbar} Scales + {fMRI} {\textbar} s + {fMRI} {\textbar} {HC} vs. {\textbar} {\textbar} Maximum {\textbar} 0.95 {\textbar} 0.78 {\textbar} 0.87 {\textbar} 0.77 {\textbar} 0.96 {\textbar} 0.98 {\textbar} 0.96 {\textbar} Patients {\textbar} {\textbar} {AUC} {\textbar} (0.02) {\textbar} (0.06) {\textbar} (0.08) {\textbar} (0.06) {\textbar} (0.03) {\textbar} (0.02) {\textbar} (0.03) {\textbar} Accuracy {\textbar} {\textbar} 0.88 {\textbar} 0.71 {\textbar} 0.85 {\textbar} 0.77 {\textbar} 0.87 {\textbar} 0.92 {\textbar} 0.90 {\textbar} (0.04) {\textbar} {\textbar} (0.06) {\textbar} (0.07) {\textbar} (0.06) {\textbar} (0.05) {\textbar} (0.04) {\textbar} (0.04) {\textbar} Sensitivity {\textbar} {\textbar} 0.87 {\textbar} 0.81 {\textbar} 0.86 {\textbar} 0.77 {\textbar} 0.93 {\textbar} 0.91 {\textbar} 0.94 {\textbar} (0.08) {\textbar} {\textbar} (0.09) {\textbar} (0.09) {\textbar} (0.08) {\textbar} (0.07) {\textbar} (0.06) {\textbar} (0.05) {\textbar} Specificity {\textbar} {\textbar} 0.88 {\textbar} 0.60 {\textbar} 0.84 {\textbar} 0.76 {\textbar} 0.80 {\textbar} 0.92 {\textbar} 0.85 {\textbar} (0.04) {\textbar} {\textbar} (0.16) {\textbar} (0.18) {\textbar} (0.07) {\textbar} (0.15) {\textbar} (0.04) {\textbar} (0.09) {\textbar} Median k ≠ 0 {\textbar} {\textbar} 78 {\textbar} 124 {\textbar} 7539 {\textbar} 15569 {\textbar} 147 {\textbar} 32 {\textbar} 57 {\textbar} (5.50) {\textbar} {\textbar} (5.00) {\textbar} (938.50) {\textbar} (883.25) {\textbar} (29.00) {\textbar} (0.00) {\textbar} (2.75) {\textbar} {HC} vs. {\textbar} {\textbar} Maximum {\textbar} 0.98 {\textbar} 0.82 {\textbar} 0.93 {\textbar} 0.88 {\textbar} 0.99 {\textbar} 0.98 {\textbar} 1.00 {\textbar} {SCZ} + {\textbar} {\textbar} {AUC} {\textbar} (0.02) {\textbar} (0.08) {\textbar} (0.05) {\textbar} (0.04) {\textbar} (0.01) {\textbar} (0.02) {\textbar} (0.00) {\textbar} {BD} {\textbar} {\textbar} Accuracy {\textbar} 0.92 {\textbar} 0.73 {\textbar} 0.87 {\textbar} 0.86 {\textbar} 0.94 {\textbar} 0.92 {\textbar} 0.87 {\textbar} (0.05) {\textbar} {\textbar} (0.04) {\textbar} (0.06) {\textbar} (0.04) {\textbar} (0.02) {\textbar} (0.07) {\textbar} (0.09) {\textbar} Sensitivity {\textbar} {\textbar} 0.94 {\textbar} 0.52 {\textbar} 0.82 {\textbar} 0.90 {\textbar} 0.95 {\textbar} 0.99 {\textbar} 0.72 {\textbar} (0.07) {\textbar} {\textbar} (0.15) {\textbar} (0.14) {\textbar} (0.07) {\textbar} (0.05) {\textbar} (0.02) {\textbar} (0.20) {\textbar} Specificity {\textbar} {\textbar} 0.90 {\textbar} 0.88 {\textbar} 0.91 {\textbar} 0.83 {\textbar} 0.93 {\textbar} 0.85 {\textbar} 1.00 {\textbar} (0.09) {\textbar} {\textbar} (0.06) {\textbar} (0.09) {\textbar} (0.07) {\textbar} (0.05) {\textbar} (0.13) {\textbar} (0.00) {\textbar} Median k ≠ 0 {\textbar} {\textbar} 126 {\textbar} 111 {\textbar} 7613 {\textbar} 15325 {\textbar} 54 {\textbar} 233 {\textbar} 230 {\textbar} (4.50) {\textbar} {\textbar} (4.25) {\textbar} (1028.75) {\textbar} (973.25) {\textbar} (4.50) {\textbar} (44.75) {\textbar} (9.50) {\textbar} {HC} vs. {\textbar} {\textbar} Maximum {\textbar} 0.99 {\textbar} 0.86 {\textbar} 0.73 {\textbar} 0.93 {\textbar} 0.99 {\textbar} 0.99 {\textbar} 0.99 {\textbar} {SCZ} + {\textbar} {\textbar} {AUC} {\textbar} (0.01) {\textbar} (0.05) {\textbar} (0.07) {\textbar} (0.05) {\textbar} (0.01) {\textbar} (0.01) {\textbar} (0.01) {\textbar} {ADHD} {\textbar} {\textbar} Accuracy {\textbar} 0.93 {\textbar} 0.75 {\textbar} 0.68 {\textbar} 0.87 {\textbar} 0.81 {\textbar} 0.85 {\textbar} 0.87 {\textbar} (0.03) {\textbar} {\textbar} (0.06) {\textbar} (0.07) {\textbar} (0.08) {\textbar} (0.06) {\textbar} (0.07) {\textbar} (0.06) {\textbar} Sensitivity {\textbar} {\textbar} 0.91 {\textbar} 0.47 {\textbar} 0.65 {\textbar} 0.78 {\textbar} 0.52 {\textbar} 0.68 {\textbar} 0.72 {\textbar} (0.08) {\textbar} {\textbar} (0.15) {\textbar} (0.13) {\textbar} (0.20) {\textbar} (0.16) {\textbar} (0.18) {\textbar} (0.16) {\textbar} Specificity {\textbar} {\textbar} 0.95 {\textbar} 0.93 {\textbar} 0.70 {\textbar} 0.94 {\textbar} 1.00 {\textbar} 0.99 {\textbar} 0.99 {\textbar} (0.03) {\textbar} {\textbar} (0.02) {\textbar} (0.15) {\textbar} (0.07) {\textbar} (0.00) {\textbar} (0.04) {\textbar} (0.02) {\textbar} Median k ≠ 0 {\textbar} {\textbar} 90 {\textbar} 125 {\textbar} 13637 {\textbar} 7216 {\textbar} 280 {\textbar} 422 {\textbar} 405 {\textbar} (0.75) {\textbar} {\textbar} (10.75) {\textbar} (1455.75) {\textbar} (967.00) {\textbar} (13.75) {\textbar} (89.75) {\textbar} (91.75) {\textbar} {HC} vs. {\textbar} {\textbar} Maximum {\textbar} 0.97 {\textbar} 0.73 {\textbar} 0.87 {\textbar} 0.75 {\textbar} 0.98 {\textbar} 0.99 {\textbar} 0.99 {\textbar} {BD} + {\textbar} {\textbar} {AUC} {\textbar} (0.03) {\textbar} (0.06) {\textbar} (0.05) {\textbar} (0.06) {\textbar} (0.02) {\textbar} (0.01) {\textbar} (0.01) {\textbar} {ADHD} {\textbar} {\textbar} Accuracy {\textbar} 0.93 {\textbar} 0.68 {\textbar} 0.80 {\textbar} 0.74 {\textbar} 0.87 {\textbar} 0.89 {\textbar} 0.90 {\textbar} (0.03) {\textbar} {\textbar} (0.06) {\textbar} (0.10) {\textbar} (0.06) {\textbar} (0.06) {\textbar} (0.07) {\textbar} (0.04) {\textbar} Sensitivity {\textbar} {\textbar} 0.89 {\textbar} 0.54 {\textbar} 0.65 {\textbar} 0.70 {\textbar} 0.74 {\textbar} 0.78 {\textbar} 0.89 {\textbar} (0.07) {\textbar} {\textbar} (0.17) {\textbar} (0.28) {\textbar} (0.11) {\textbar} (0.18) {\textbar} (0.18) {\textbar} (0.13) {\textbar} Specificity {\textbar} {\textbar} 0.96 {\textbar} 0.80 {\textbar} 0.91 {\textbar} 0.77 {\textbar} 0.96 {\textbar} 0.99 {\textbar} 0.90 {\textbar} (0.07) {\textbar} {\textbar} (0.09) {\textbar} (0.07) {\textbar} (0.08) {\textbar} (0.07) {\textbar} (0.03) {\textbar} (0.09) {\textbar} Median k ≠ 0 {\textbar} {\textbar} 94 {\textbar} 87 {\textbar} 7808 {\textbar} 15682 {\textbar} 95 {\textbar} 225 {\textbar} 206 {\textbar} (7.00) {\textbar} {\textbar} (8.75) {\textbar} (667.25) {\textbar} (576.75) {\textbar} (13.75) {\textbar} (19.75) {\textbar} (48.00) {\textbar} Referring now to {\textbar} {\textbar} {FIGS}. 2A and 2B {\textbar} , the time complexity of the importance-guided forward model selection procedure is illustrated. {\textbar} {FIG}. 2A {\textbar} shows that the computation time (median across three implementations) grew linearly as the number of features increases in importance-guided forward model selection procedure. The round dots represent the actual data points, whereas the solid line is the best fitted regression line (slope: 0.03; intercept: 0.80). {\textbar} {FIG}. 2B {\textbar} shows that reduced computation time was achieved via sequential model selection procedure (round dots with solid line) compared to the estimated time complexity of a brute force feature selection procedure where all combinations of features are evaluated (triangles with dashed line). {\textbar} Referring again to {\textbar} {\textbar} {FIG}. 2A {\textbar} , the median computation time across three (3) implementations of the feature importance-guided sequential model selection procedure grew linearly as the number of input features increased. As shown in {\textbar} {FIG}. 2B {\textbar} , complexity is much reduced compared to the estimated time complexity from a brute force feature selection approach where all possible combinations of features were evaluated. The computation time of the brute force approach increased exponentially as the number of input features increased and quickly became intractable even for very small number of features ( {\textbar} {FIG}. 2B {\textbar} ). {\textbar} More importantly, significantly improved performance was obtained from the best truncated classification models compared with the corresponding models using the full sets of features (all p's{\textless}0.05 as assessed by rank-sum tests; Table 4). The test results were obtained using Wilcoxon's rank-sum test. {\textbar} {\textbar} {TABLE} 4 {\textbar} {\textbar} Test results comparing performances of the best truncated models against the full {\textbar} {\textbar} Scales + {\textbar} {\textbar} Scales {\textbar} {\textbar} {sMRI} {\textbar} {fMRI} {\textbar} s + {fMRI} {\textbar} Scales + {sMRI} {\textbar} Scales + {fMRI} {\textbar} s + {fMRI} {\textbar} {HC} vs. {\textbar} {\textbar} Test {\textbar} 100 {\textbar} 100 {\textbar} 100 {\textbar} 99.5 {\textbar} 82.5 {\textbar} 100 {\textbar} 95 {\textbar} Patients {\textbar} {\textbar} statistic {\textbar} p-value {\textbar} {\textbar} 0.000182 {\textbar} 0.000181 {\textbar} 0.000183 {\textbar} 0.000211 {\textbar} 0.01537 {\textbar} 0.000182 {\textbar} 0.000769 {\textbar} {HC} vs. {\textbar} {\textbar} Test {\textbar} 94.5 {\textbar} 91 {\textbar} 100 {\textbar} 99 {\textbar} 100 {\textbar} 94 {\textbar} 100 {\textbar} {SCZ} + {\textbar} {\textbar} statistic {\textbar} {BD} {\textbar} {\textbar} p-value {\textbar} 0.000853 {\textbar} 0.002152 {\textbar} 0.000182 {\textbar} 0.000245 {\textbar} 0.000172 {\textbar} 0.000977 {\textbar} 8.74E−05 {\textbar} {HC} vs. {\textbar} {\textbar} Test {\textbar} 100 {\textbar} 100 {\textbar} 92 {\textbar} 100 {\textbar} 100 {\textbar} 100 {\textbar} 100 {\textbar} {SCZ} + {\textbar} {\textbar} statistic {\textbar} {ADHD} {\textbar} {\textbar} p-value {\textbar} 0.000179 {\textbar} 0.000183 {\textbar} 0.001699 {\textbar} 0.000182 {\textbar} 0.000179 {\textbar} 0.000162 {\textbar} 0.00018 {\textbar} {HC} vs. {\textbar} {\textbar} Test {\textbar} 96 {\textbar} 94 {\textbar} 100 {\textbar} 96 {\textbar} 88 {\textbar} 95.5 {\textbar} 100 {\textbar} {BD} + {\textbar} {\textbar} statistic {\textbar} {ADHD} {\textbar} {\textbar} p-value {\textbar} 0.00058 {\textbar} 0.001008 {\textbar} 0.000182 {\textbar} 0.000577 {\textbar} 0.00451 {\textbar} 0.00063 {\textbar} 0.000176 {\textbar} Referring now to {\textbar} {\textbar} {FIGS}. 3A-3D {\textbar} , illustrating the {ROC} from the truncated models producing the best {AUC} using phenotype data as features. For all four (4) transdiagnostic cases, the truncated classification models using feature sets involving clinical scales had high performance with the mean {AUC} ranging from 0.95 to 1.00 (mean accuracy: 0.81-0.94). These models performed better compared to those using feature sets based solely on {MRI}, which had mean {AUC} ranging from 0.73-0.93 and mean accuracy ranging from 0.68-0.87. Among the truncated models using feature sets involving clinical scales, those using data only from clinical scales can already achieve very high performance with {AUC} ranging from 0.95 to 0.99 (see {\textbar} {FIGS}. 3A-3D {\textbar} ). Combining {MRI} features with clinical scales do not seem to further improve the models' performance. {\textbar} Turning now to {\textbar} {\textbar} {FIGS}. 6A-6D {\textbar} , {AUC}'s are illustrated as a function of the number of top features included during sequential model selection. The dark trace represents the mean {AUC} across ten (10) iterations of the sequential model selection procedure and the shaded area represents the mean+/−1 standard deviation. As shown, the performances of all truncated models in terms of {AUC} increased initially as the number of top features k increased. Interestingly, after reaching the highest classification performance, adding more features caused the performance to deteriorate, suggesting that increasingly amount of noise are present in features deemed less predictive by the classification model. {\textbar} The number of top features needed to produce the best truncated classification models for all four (4) transdiagnostic cases are listed in Table 3. The number of top features needed was relatively small for models involving clinical scales: 85-130 out of 578 features for models using only clinical scales; 58-312 out of 839 features for scales plus {sMRI} feature set; 32-512 out of 35294 features for scales plus {fMRI}; 64-512 out of 35555 features for scales plus {sMRI} and {fMRI} feature set. On the other hand, the number of top features needed to reach best performance for models involving {fMRI} was relatively large: 8192-16384 out of 34716 features for {fMRI} alone; 8192-16384 out of 34977 features for {sMRI} plus {fMRI}. For models using {sMRI} features alone, the model complexity was relatively low (89-136 out of 261 features). {\textbar} {\textbar} Based on the above analyses, models using phenotype data from clinical instruments produced high classification performance while at the same time maintained a relatively low model complexity compared to models using {MRI}-only features. This suggests that the phenotypical data captured by the 13 self-reported instruments may contain a compact set of shared features that are common across the patient populations but are highly distinct from healthy controls. Examining these shared phenotypical features is further focused below. {\textbar} {\textbar} {FIG}. 4 {\textbar} {\textbar} illustrates the percentage of questions from each of the thirteen (13) questionnaires among the set of most predictive questions producing the highest {AUC}. “Barratt” represents Barratt impulsiveness scale; “bipolari” represents Scale for Traits that Increase Risk for Bipolar {II} Disorder; “chaphypo” represents Hypomanic Personality Scale; “chapper” represents Chapman Perceptual Aberration Scale; “chapphy” represents Chapman Physical Anhedonia Scale; “chapsoc” represents Chapman Social Anhedonia Scale; “dick” represents Dickman Functional \& Dysfunctional Impulsivity Scale; “Eysenck” represents Eysenck Impulsiveness, Venturesomeness \& Empathy Scale; “asrs” represents Adult {ADHD} Self-Report Scale v1.1 Screener; “golden” represents Golden and Meehl's {\textbar} 7 {\textbar} {MMPI} Items; “Hopkins” represents Hopkins Symptom Checklist; “mpq” represents Multidimensional Personality Questionnaire—Control Subscale; and “tci” represents Temperament and Character Inventory. {\textbar} To investigate these shared phenotypical features, the proportion of questionnaire items from each clinical scale selected to be among the top set of features by the best truncated model (having the highest {AUC}) are shown in {\textbar} {\textbar} {FIG}. 4 {\textbar} . For all four (4) transdiagnostic classifiers, items from all 13 instruments were selected to be among the top features by the classifiers, which suggests that patient populations share a wide range of phenotypes that are distinct from healthy controls. These instruments cover broad phenotypes and symptom domains encompassing personality and traits, positive and negative effects (reward, fear, and anxiety), cognition (attention, response inhibition/impulsivity), sensory processing (perceptual disturbances), and social processing. {\textbar} {FIGS}. 5A-5D {\textbar} {\textbar} illustrate comparing the count of items from each questionnaire among the actual set of most predictive questions with those from randomly ordered lists of questions. While all questions included among the top features are highly predictive of patients from healthy controls, the instruments having the largest proportions among the top questions from all 4 transdiagnostic classifiers are the temperament and character inventory, the hypomanic personality scale, and Eysenck's impulsivity inventory. To examine whether particular instruments have significantly higher number of items among top questions (reaching highest {AUC}) than chance, the list of questions 100 times is shuffled and compared the number of top questions from each instrument obtained from the shuffled lists with the actual counts (see {\textbar} {FIGS}. 5A-5D {\textbar} ). {\textbar} These items from such instruments may indicate traits and symptom dimensions strongly represented across specific patient populations. For Healthy vs. Patients classifier, the temperament and character inventory had significantly higher count than chance. The individual items overall covered aspects of temperament pertaining to harm avoidance, novelty seeking, persistence, and reward dependence. For Healthy vs. {SCZ} \& {BD} classifier, both the hypomanic personality scale and the Golden and Meehl's Seven {MMPI} items had significantly higher count than chance. For Healthy vs. {SCZ} \& {ADHD} classifier, again the hypomanic personality scale had significantly higher count than chance. For Healthy vs. {BD} \& {ADHD} classifier, the {ADHD} self-report scale v1.1 screener had significantly higher count than chance. {\textbar} {\textbar} Additional Information {\textbar} {\textbar} In this disclosure, robust transdiagnostic classifiers is built based on phenotype data obtained from clinical instruments and {MRI} data to distinguish {SCZ}, {BD}, and {ADHD} patients from healthy controls. The feature importance-guided forward model selection approach adopted in this disclosure was shown to 1) produce transdiagnostic classifiers having outstanding performance and 2) identify the set of most predictive features shared across the patient populations. The classifiers based on phenotype data from clinical instruments reliably predicted patients from healthy controls. Interestingly, combining the phenotype data with {MRI} data did not significantly improve the results, suggesting that a robust set of features shared across patient populations can be found in phenotype data alone. Further investigation of the shared phenotypical features revealed that patient populations share a broad range of abnormal psychopathological dimensions spanning personality and traits, positive and negative affect, cognition, sensory and social processing. Overall, a data-driven approach is presented, which does not rely on a-priori hypotheses to build robust transdiagnostic classifiers and to mine the shared psychopathological dimensions across patient populations. {\textbar} {\textbar} The use of machine learning tools in psychiatry to systematically search for consistent patterns in clinical data across disease categories defined in {DSM} is an emerging trend. A substantial body of prior studies have focused on patient subtyping within a given. The present disclosure includes machine learning methods to develop transdiagnostic perspectives on the symptom dimensions and psychopathology. The machine learning approaches can include classification, regression, dimensionality reduction, and clustering to mine the transdiagnostic symptom dimensions underlying various psychiatric disorders. {\textbar} {\textbar} Some machine learning approaches either adopted a hypothesis-driven approach wherein a subset of measures (e.g., phenotype data from a given instrument and/or neuroimaging measures from a set of brain regions) were preselected based on a priori knowledge, or used the full set of input features without considering their relative importance in terms of predictive ability. Such approaches may not be ideal since neither of them lets the algorithm to be trained on the optimal set of features. This disclosure uses feature importance to guide forward model selection while building transdiagnostic classifiers to identify shared psychopathological features across multiple disease categories. The superb performance of the truncated models selected via this model selection approach demonstrate the robustness of the identified features. {\textbar} {\textbar} A broad set of phenotypes from the self-report clinical instruments were identified by the transdiagnostic classifiers to be shared across the patient populations. The phenotypes are distributed across all 13 self-reported clinical instruments and covers symptom domains encompassing personality and traits, positive and negative effects, cognition, sensory and social processing. There are shared symptom domains across {SCZ}, {BD}, and {ADHD}. In addition, these three disorders are significantly correlated risk factors for heritability. For {SCZ} and {BD}, shared features are identified both in terms of symptoms and the underlying psychopathology and biology. Similarly, shared symptoms and biology are identified between {SCZ} and {ADHD}. In addition, shared features are identified between {BD} and {ADHD}, along with high levels of comorbidity between them. Thus, this disclosure provides a data-driven confirmation on the shared phenotypes and symptoms across the three disease categories. {\textbar} {\textbar} An interesting finding is that in all four transdiagnostic classifiers, the temperament and character inventory had the largest proportion of questions among the set of most predictive questions determined by the classifier. The personality traits and characters defined in the {TCI} are associated with various mood disorders. Specifically, for disorders in the {CNP} dataset, positive association can be found between personality dimensions characterized in {TCI} and overall {ADHD} symptom as well as subtypes of {ADHD}. For {SCZ}, links are identified between positive and negative symptom dimensions and {TCI} factors. Among {BD} patients, personality profiles are identified that are distinct from healthy controls, and these profiles were further found to be shared with {MDD}. {\textbar} {\textbar} Further, this disclosure establishes the usefulness of personality traits as a set of robust transdiagnostic features. The fact that the {TCI} had the highest number of questions among top features in all four transdiagnostic classifiers suggests a broad domain of shared personality traits across these three patient categories. {\textbar} {\textbar} While the transdiagnostic classifiers selected questions from all 13 self-reported questionnaires, statistical tests between the actual count of questions from each questionnaire and those from a randomly shuffled importance ordering revealed subtle differences between the classifiers for different combinations of patient populations. These differences may in particular reflect clustered personality traits and symptom dimensions across specific patient populations. For the {HC} vs. {SCZ} \& {BD} case, the elevated item count from the hypomanic personality scale is consistent with the results obtained in the original paper by Eckblad and Chapman where high scorers on the hypomanic personality scale reported more schizotypical features in addition to increased hypomanic and depressive episodes. A 13-year follow-up of these high scorers showed that they had more mood and psychotic-like symptoms compared to healthy controls. Therefore, the items from the hypomanic personality scale may capture these clustered symptom domains. {\textbar} {\textbar} Additionally, the elevated item count from the Golden and Meehl's {\textbar} {\textbar} 7 {\textbar} {MMPI} items may reflect clustered phenotypes from the so-called “schizotypy” dimension within {SCZ} and {BD} patients. For {HC} vs. {SCZ} \& {ADHD} case, the hypomanic personality scale again had elevated item count. Symptom overlaps are identified, as well as genetic links between {ADHD} and schizophrenia and other psychosis disorders. Specifically, off-springs of {SCZ} patients are found to be more likely to have higher ratings of hyperactivity, which encompasses symptoms including increased activity, impulsivity, distractibility, and low tolerance for frustration. Such externalizing and attention problems are shared between {ADHD} and psychosis among adolescents. Therefore, the selected items from the hypomanic personality scale may reflect the shared hyperactivity domains across {SCZ} and {ADHD} patients. Finally, for the {HC} vs. {BD} \& {ADHD} case, the elevated item count from {ADHD} self-report scale v1.1 screener may indicate the similar aspects between hyperactivity and manic symptoms as well as other shared symptoms such as inattention between {BD} and {ADHD} patients. {\textbar} Experimental Method and Additional Details—Part {II} {\textbar} {\textbar} An experimental methodology is disclosed further herein which provides additional examples of methodologies {\textbar} {\textbar} 2900 {\textbar} and {\textbar} 3000 {\textbar} , as would be readily apparent to one skilled in the art. The experimental methodology includes experimental results which verify additional aspects of the disclosed systems and methods; the experimental results further verify additional benefits of the present disclosure as compared against conventional systems and methods. {\textbar} Participants {\textbar} {\textbar} Four groups of subjects were included in the sample which was drawn from adults ages 21-50: healthy controls ({HC}, n=130), Schizophrenia patients ({SZ}, n=50), Bipolar Disorder patient ({BD}, n=49), and Attention Deficit and Hyperactivity Disorder ({ADHD}, n=43). Stable medications were permitted for participants. Diagnoses were based on the Structured Clinical Interview for {DSM}-{IV} ({SCID}) and supplemented with the Adult {ADHD} Interview. Out of all subjects, one had incomplete clinical phenotype data from the clinical scales used, 10 had missing structural {MRI} ({sMRI}) data, and 10 had missing resting-state functional {MRI} ({fMRI}) data. Fifty-five subjects had an aliasing artifact in their {sMRI} data, whereas 22 subjects had errors in the structural-functional alignment step during {MRI} preprocessing. These subjects were excluded from the corresponding modeling analyses performed. {\textbar} {\textbar} The participant numbers and demographics information are given in Table 5. In Table 5, the demographic information is based on initial number of subjects. The number of subjects with {sMRI} data excludes subjects with aliasing artifacts. The number of subjects with {fMIR} data excludes subjects with misaligned structural-function imaging data. {\textbar} {\textbar} {TABLE} 5 {\textbar} {\textbar} Participant Demographics {\textbar} {\textbar} {HC} {\textbar} {\textbar} {SCZ} {\textbar} {BD} {\textbar} {ADHD} {\textbar} No. of subjects {\textbar} {\textbar} 130 {\textbar} 50 {\textbar} 49 {\textbar} 43 {\textbar} With complete phenotype data {\textbar} {\textbar} 130 {\textbar} 50 {\textbar} 48 {\textbar} 43 {\textbar} With {sMRI} data {\textbar} {\textbar} 98 {\textbar} 30 {\textbar} 44 {\textbar} 34 {\textbar} With {fMRI} data {\textbar} {\textbar} 104 {\textbar} 47 {\textbar} 41 {\textbar} 37 {\textbar} Age {\textbar} {\textbar} Mean age {\textbar} {\textbar} 31.26 {\textbar} 36.46 {\textbar} 35.15 {\textbar} 33.09 {\textbar} {SD} age {\textbar} {\textbar} 8.74 {\textbar} 8.88 {\textbar} 9.07 {\textbar} 10.76 {\textbar} Range age {\textbar} {\textbar} 21-50 {\textbar} 22-49 {\textbar} 21-50 {\textbar} 21-50 {\textbar} Gender {\textbar} {\textbar} No. of female subjects {\textbar} {\textbar} 62 {\textbar} 12 {\textbar} 21 {\textbar} 22 {\textbar} Percent female subjects {\textbar} {\textbar} 47.69\% {\textbar} 24.00\% {\textbar} 42.86\% {\textbar} 51.16\% {\textbar} Race {\textbar} {\textbar} American Indian or Alaskan Native {\textbar} {\textbar} 19.23\% {\textbar} 22.00\% {\textbar}  6.25\% {\textbar}    0\% {\textbar} Asian {\textbar} {\textbar} 15.38\% {\textbar}  2.00\% {\textbar}    0\% {\textbar}  2.33\% {\textbar} Black/African American {\textbar} {\textbar}  0.77\% {\textbar}  4.00\% {\textbar}  2.08\% {\textbar}  2.33\% {\textbar} White {\textbar} {\textbar} 78.46\% {\textbar} 66.00\% {\textbar} 77.08\% {\textbar} 88.37\% {\textbar} More than one race {\textbar} {\textbar}    0\% {\textbar}  2.00\% {\textbar} 14.58\% {\textbar}  6.98\% {\textbar} Education {\textbar} {\textbar} No high school {\textbar} {\textbar}  1.54\% {\textbar} 18.00\% {\textbar}  2.08\% {\textbar}    0\% {\textbar} High school {\textbar} {\textbar} 12.31\% {\textbar} 44.00\% {\textbar} 29.17\% {\textbar} 23.26 {\textbar} Some college {\textbar} {\textbar} 20.77\% {\textbar} 18.00\% {\textbar} 25.00\% {\textbar} 30.23\% {\textbar} Associate's degree {\textbar} {\textbar}  7.69\% {\textbar}  4.00\% {\textbar}  6.25\% {\textbar}  6.98\% {\textbar} Bachelor's degree {\textbar} {\textbar} 50.00\% {\textbar} 10.00\% {\textbar} 29.17\% {\textbar} 32.56\% {\textbar} Graduate degree {\textbar} {\textbar}  6.92\% {\textbar}    0\% {\textbar}  4.17\% {\textbar}  2.33\% {\textbar} Other {\textbar} {\textbar}  0.77\% {\textbar}  4.00\% {\textbar}  4.17\% {\textbar}  4.65\% {\textbar} {CNP} Dataset {\textbar} {\textbar} Of the extensive behavioral testing that participants underwent, results were analyzed from tests of their symptoms and traits, either clinician-administered or self-reported. The self-reported tests used in our analysis include Chapman social anhedonia scale (chapsoc), Chapman physical anhedonia scale (chapphy), Chapman perceptual aberrations scale (chapper), Chapman hypomanic personality scale, Hopkins symptom checklist (hopkins), Temperament and character inventory (tci), Adult {ADHD} self-report scale v1.1 screener (asrs), Barratt impulsiveness scale (barratt), Dickman functional and dysfunctional impulsivity scale (dickman), Multidimensional personality questionnaire—control subscale (mpq), Eysenck's impulsivity inventory (eysenck), Scale for traits that increase risk for bipolar {II} disorder (bipolarii), and Golden and Meehl's Seven {MMPI} items selected by taxonomic method (Golden). The clinician-administered scales used in our analysis include Hamilton rating scale for depression (hamd), the Brief psychiatric rating scale (bprs), and Scale for the assessment of negative symptoms (sans). {\textbar} {\textbar} All participants used in this sample also underwent magnetic resonance imaging sessions with T1 scans (structural {MRI}) and T2* scans of blood-oxygen-level-dependent ({BOLD}) resting-state functional-{MRI} and several tasks. The {sMRI} and resting-state {fMRI} data (304 seconds in length) were utilized. Resting-state {fMRI} data were analyzed. The resting-state {fMRI} data provided a fine-grained, data-driven set of functional connectivity features that exhibit meaningful individual differences that relate to symptoms. {\textbar} {\textbar} Preprocessing Data into Features {\textbar} {\textbar} All responses to individual questions were used, from the 13 self-report scales as input features for a total of 578 questions. Subjects who had missing values for any scales used in a particular model were not included in that model. Outcome variables for modeling depression, anxiety, anhedonia, and related negative symptoms were also selected from clinical scales, either self-report or clinician-administered. {\textbar} {\textbar} {sMRI} {\textbar} {\textbar} Preprocessing of {sMRI} was performed using Freesurfer's recon-all processing pipeline. Briefly, the T1-weighted structural image from each subject was intensity normalized and skull-stripped. The subcortical structures, white matter, and ventricles were segmented and labeled according to the algorithm described in. The pial and white matter surfaces were then extracted and tessellated, and cortical parcellation was obtained on the surfaces according to a gyral-based anatomical atlas which partitions each hemisphere into 34 regions. {\textbar} {\textbar} Preprocessing of {fMRI} was performed using {AFNI}. Preprocessing of each subject's echo planar image ({EPI}) data included several steps: removal of the first 3 volumes (before the scanner reached equilibrium magnetization), de-spiking, registration of all volumes to the now first volume, spatial smoothing with a 6 mm full-width half-maximum Gaussian filter, and normalization of all {EPI} volumes by the mean signal to represent data as percent signal change. Anatomical data also underwent several steps: deobliquing of the T1 data, uniformization of the T1 to remove shading artifacts, skull-stripping of the T1, spatial alignment of the T1 and Freesurfer-segmented and -parceled anatomy to the first volume of the {EPI} data, and resampling of the Freesurfer anatomy to the resolution of the {EPI} data. Subsequently, the {ANATICOR} procedure was used for nuisance tissue regression. White matter and ventricle masks were created and used to extract the {BOLD} signals (before spatially-smoothing the {BOLD} signal). A 25 mm-radius sphere at each voxel of the white matter mask was used to get averaged local white matter signal estimates while the average ventricle signal was calculated from the whole ventricle mask. Time series for the motion estimates, and the {BOLD} signals in the ventricles and white matter were detrended with a 4 {\textbar} {\textbar} th {\textbar} order polynomial. To clean the {BOLD} signal, the nuisance tissue regressors and the six motion estimate parameters were regressed out. Cleaned data residuals were used for all subsequent analysis. {\textbar} Both the preprocessed T1 scan and the cleaned residuals of the {EPI} scan were warped to {MNI} space and resampled to 2 mm isotropic voxels. The time series of the cleaned residual data was extracted from each of 264 regions of interest ({ROIs}) as delineated by the Power atlas. At each {ROI}, the signals from the voxels within a 5 mm radius sphere were averaged. Pearson's correlations were then calculated between the averaged time series from all {ROIs} yielding 34716 unique edges in the functional connectivity graph (upper triangle of the full correlation matrix). Quality control ({QC}) for {MRI} preprocessing was performed individually on the whole dataset, and rejection decisions were made for each participant's {sMRI} and {fMRI} data, respectively. Discrepancies were resolved in order to create a final rejection list of participants. {\textbar} {\textbar} Input features for each subject came from the three preprocessed datasets: raw scores on the 578 individual items of 13 self-report clinical scales, Freesurfer-calculated structural measurements (including subcortical volume, cortical volume, cortical area, cortical thickness), and {AFNI}-calculated functional connectivity scores between individual {ROIs}. Subsets of these input features were used as predictor variables in subsequent modeling as explained below. Output variables that were modeled included those which indexed depression, anxiety, anhedonia, or other negative symptoms. A mix of total scores, sub-scale sum or average scores, and individual question scores as each has their advantages. {\textbar} {\textbar} These scores include the 28-question versions of the total {HAMD} score (‘hamd’), the {HAMD} subscore for questions 1, 7, and 8 (‘hamd178’, indexes a melancholic-type of symptom), the {HAMD} item score for question 7 (‘hamd7’, indexes lack of interest or anhedonia), the Chapman Social Anhedonia total score (‘chapsoc’), the Chapman Physical Anhedonia total score (‘chapphy’), {BPRS} negative subscore (‘bprs\_negative’, the average of negative symptom questions 13, 16, 17, and 18), {BPRS} depression-anxiety subscore (‘bprs\_depanx’, the average of depression and anxiety symptom questions 2, 3, 4, and 5), Hopkins anxiety score (‘hopkins\_anxiety’, the average of anxiety symptom questions 2, 17, 23, 33, 39, and 50), Hopkins depression score (‘hopkins\_depression’, the average of depression symptom questions 5, 15, 19, 20, 22, 26, 29, 30, 31, 32, and 54), Bipolar ii mood score (‘bipolarii\_mood’, the sum of mood questions 1-9), Bipolar ii anxiety score (‘bipolar anxiety’, the sum of anxiety questions 24-31), {SANS} anhedonia factor score (‘sans factor\_anhedonia’, the average of anhedonia questions 17, 18, 19, and 20), {SANS} anhedonia global score (‘sans\_global\_anhedonia’, questions 21 which is the clinician's overall anhedonia assessment score), {SANS} avolition factor score (‘sans factor\_avolition’, the average of avolition items 12, 13, 14, and 15), {SANS} avolition global score (‘sans\_globals\_avolition’, question 16 which is the clinician's overall avolition assessment score), {SANS} blunt affect factor score (‘sans\_factor\_bluntaffect’, the average of affective flattening items 1, 2, 3, 4, 5, and 6), {SANS} blunt affect global score (‘sans\_global\_bluntaffect’, question 7 which is the clinician's overall blunt affect assessment score), {SANS} alogia factor score (‘sans\_factor\_alogia’, the average of alogia items 8, 9, and 10), {SANS} alogia global score (‘sans\_global\_alogia’, question 11 which is the clinician's overall alogia assessment score), {SANS} attention factor score (‘sans\_factor\_attention’, the average of attention items 22 and 23), and {SANS} attention global score (‘sans\_global\_attention’, question 24 which is the clinician's overall attention assessment score). {\textbar} {\textbar} Sum scores are commonly accepted by the {FDA} regarding positive efficacy results, but using only sum scores may obfuscate brain-behavior relationships at more fine-grained levels of symptoms. Subjects with missing values (“n/a”) for any input or output variables or who did not pass {MRI} {QC} were removed from the input set. As different input feature sets were used, different models had different sample sizes. The availability of clinical scores for particular clinical scales taken only by certain subsets of patients also affected the final sample size for each model. The samples sizes resulting from these factors are listed in Table 6. {\textbar} {\textbar} {TABLE} 6 {\textbar} {\textbar} Sample size for each model {\textbar} {\textbar} Scales\_ {\textbar} {\textbar} Scales\_ {\textbar} {\textbar} {sMRI}\_ {\textbar} Predicted Scores {\textbar} {\textbar} Scales {\textbar} {sMRI} {\textbar} {sMRI} {\textbar} Scales\_sMRI {\textbar} {sMRI}\_fMRI {\textbar} {fMRI} {\textbar} {fMRI} {\textbar} Chapman Social Anhedonia {\textbar} {\textbar} 271 {\textbar} 206 {\textbar} 147 {\textbar} 205 {\textbar} 117 {\textbar} 146 {\textbar} 116 {\textbar} Chapman Physical {\textbar} {\textbar} 271 {\textbar} 206 {\textbar} 147 {\textbar} 205 {\textbar} 117 {\textbar} 146 {\textbar} 116 {\textbar} Anhedonia {\textbar} {\textbar} {HAMD}, total score {\textbar} {\textbar} 141 {\textbar} 108 {\textbar} 82 {\textbar} 107 {\textbar} 63 {\textbar} 81 {\textbar} 62 {\textbar} {HAMD}, q1, 7, 8 sum score {\textbar} {\textbar} 140 {\textbar} 108 {\textbar} 82 {\textbar} 107 {\textbar} 63 {\textbar} 81 {\textbar} 62 {\textbar} {HAMD}, q7 {\textbar} {\textbar} 140 {\textbar} 108 {\textbar} 82 {\textbar} 107 {\textbar} 63 {\textbar} 81 {\textbar} 62 {\textbar} {BPRS}, negative score {\textbar} {\textbar} 141 {\textbar} 108 {\textbar} 82 {\textbar} 107 {\textbar} 63 {\textbar} 81 {\textbar} 62 {\textbar} {BPRS}, depression-anxiety {\textbar} {\textbar} 141 {\textbar} 108 {\textbar} 82 {\textbar} 107 {\textbar} 63 {\textbar} 81 {\textbar} 62 {\textbar} score {\textbar} {\textbar} Hopkins, anxiety score {\textbar} {\textbar} 271 {\textbar} 206 {\textbar} 147 {\textbar} 205 {\textbar} 117 {\textbar} 146 {\textbar} 116 {\textbar} Hopkins, depression score {\textbar} {\textbar} 271 {\textbar} 206 {\textbar} 147 {\textbar} 205 {\textbar} 117 {\textbar} 146 {\textbar} 116 {\textbar} Bipolar {II}, depression score {\textbar} {\textbar} 271 {\textbar} 206 {\textbar} 147 {\textbar} 205 {\textbar} 117 {\textbar} 146 {\textbar} 116 {\textbar} Bipolar {II}, anxiety score {\textbar} {\textbar} 271 {\textbar} 206 {\textbar} 147 {\textbar} 205 {\textbar} 117 {\textbar} 146 {\textbar} 116 {\textbar} {SANS}, anhedonia factor {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} score {\textbar} {\textbar} {SANS}, avolition factor score {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} {SANS}, blunt affect factor {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} score {\textbar} {\textbar} {SANS}, alogia factor score {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} {SANS}, attention factor score {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} {SANS}, anhedonia global {\textbar} {\textbar} 98 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} score {\textbar} {\textbar} {SANS}, avolition global score {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} {SANS}, blunt affect global {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} score {\textbar} {\textbar} {SANS}, alogia global score {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} {SANS}, attention global score {\textbar} {\textbar} 99 {\textbar} 75 {\textbar} 54 {\textbar} 74 {\textbar} 40 {\textbar} 53 {\textbar} 39 {\textbar} Regression Modeling {\textbar} {\textbar} All regression modeling was performed with a combination of custom python code and the python toolbox scikit-leam. Twenty-one (21) different sum, sub-, or individual item scores were modeled across the clinical scales. For each of the 21 models, seven combinations of feature types were used as the inputs to be able to evaluate performance of single- and multi-modal feature sets. These included clinical scales only, {sMRI} only, {fMRI} only, scales+{sMRI}, scales+{fMRI}, {sMRI}+{fVIRI}, and scales+{sMRI}+{fMRI}. {\textbar} {\textbar} As input features varied in their mean values and regularized models require normally-distributed data, scaled each input feature was scaled separately to have zero mean and unit variance. For each scale output and feature set input, used two regularized general linear model regression algorithms were used—Lasso and Elastic Net—and one non-linear regression model algorithm—Random Forest—for the modeling. These methods improve prediction accuracy and interpretability over regular regression methods using ordinary least squares. {\textbar} {\textbar} The Lasso approach uses regularization by imposing an L {\textbar} {\textbar} 1 {\textbar} -penalty parameter to force some coefficients to zero; this step introduces model parsimony that benefits interpretability and predictive performance. If predictor variables are correlated, however, the Lasso approach will arbitrarily force only a subset of them to zero which makes interpretation of specific features more difficult. The Elastic Net algorithm uses both L {\textbar} 1 {\textbar} - and L2-penalty parameters to better be able to retain groups of correlated predictor variables; this improves interpretability as highly predictive features will not randomly be set to zero thereby diminishing their importance to the model. It is also better suited in cases when the number of predictor variables is much greater than the number of samples (p{\textgreater}{\textgreater}n). The non-linear regression algorithm Random Forest was also chosen for comparison purposes. {\textbar} Thus, 441 (21×7×3) sets of models were built. For each of these sets of models, hyperparameters were tuned using 5-fold cross-validated grid-search on a training set of data (80\% of data), and selected hyperparameters were used on a separate evaluation set of data (20\% held-out sample). The hyperparameter range for Lasso was alpha=[0.01 0.03 and 0.1] (three samples through the log space of [0.01:0.1]). Hyperparameter ranges for Elastic Net were alpha=[0.01 0.03 and 0.1] and l1\_ratio=[0.1 0.5 0.9]. And hyperparameter ranges for Random Forest included number of estimators=[10 100] and minimum samples at a leaf=[1 5 10]. The best hyperparameters were chosen from the model that maximized the r {\textbar} {\textbar} 2 {\textbar} score (coefficient of determination) across the 5-fold cross-validation procedure in the training set. All subsequent models were built using the best hyperparameters for that set. {\textbar} {FIG}. 8A {\textbar} {\textbar} illustrates X-Y plots of number of features versus predicted outcome scores. For example, predicting the total {HAMD} score using Elastic Net and scales+{sMRI}+{fMRI} as input illustrates how median {MSE} (left, top) and median r {\textbar} 2 {\textbar} (left, bottom) varies with each feature subset, each with standard deviation bars. {\textbar} {FIG}. 8B {\textbar} illustrates a comparison of measured outcome scores and predicted outcome scores. For example, measured versus predicted outcome scores (right) illustrate how closely the model predictions are to actual outcome scores for individuals in the held-out sample. {\textbar} Referring generally to {\textbar} {\textbar} {FIGS}. 8A-9B {\textbar} , for each of the 441 sets of models, an importance-weighted, forward selection approach was used to regression modeling, which involves the following steps: (1) an initial rank-ordering step for ordering features by importance, (2) a forward-selection search step for building a series of models utilizing subsets of ordered features selected from the first step, and (3) an evaluation step for evaluating each of these models using these candidate subsets according to a pre-specified criterion to find the optimal model. This approach thus integrates feature selection into modeling. {\textbar} Each step utilized the grid-search procedure to optimize hyperparameters as explained above. First, the feature rank-ordering step uses the full feature set (either scale only, {sMRI} only, etc.) as the input to the model algorithms which returns not only predicted values for the evaluation dataset but also the importance of each feature for the resulting model. Feature importance was assessed from the regression coefficients with ordering (most important to least important) based on the absolute value of the coefficient. Ordering by absolute value reflects that features with the largest magnitude influence the symptom severity scores the most. Feature ordering was performed separately for Lasso and Elastic Net models, but as feature importance is harder to assess for the Random Forest algorithm, the ordering from the Elastic Net models was used as input for the subsequent steps of Random Forest modeling instead. {\textbar} {\textbar} Second, the forward-selection search step systematically searches through subsets of the rank-ordered features for the subset that leads to the best model. Since having more features than samples increases the risk of overfitting and uninformative features add noise which decreases model performance, a data-driven method of searching the ordered feature space was selected for an optimal subset of features. A series of regressions was run on subsets of the ordered features with subsets chosen in powers of 2 (e.g., inputting the top feature only, the top 2 features only, the top 4 features only, etc.) up to 2 {\textbar} {\textbar} 15 {\textbar} features. In order to generate descriptive statistics for this step, twenty-five (25) iterations of modeling for each feature subset were used to get median and standard deviation metric scores. The metrics chosen for the final step of evaluation were mean squared error ({MSE}) and r {\textbar} 2 {\textbar} . The median r {\textbar} 2 {\textbar} and standard deviation of r {\textbar} 2 {\textbar} were found for each subset. {\textbar} The best model overall was selected by finding the maximum median r {\textbar} {\textbar} 2 {\textbar} value over all feature subsets and selecting the model that corresponded to that max median r {\textbar} 2 {\textbar} value ( {\textbar} {FIGS}. 9A-9B {\textbar} ). All subsequent follow up is on the 441 best models for each combination of input×model type×output. To find which input feature set (clinical scales only, {sMRI} only, {fMRI} only, scales+{sMRI}, scales+{fMRI}, {sMRI}+{fMRI}, and scales+{sMRI}+{fMR}) and which model type (Lasso, Elastic Net, Random Forest) lead to the best biomarkers, subsequent comparisons were also made based on the r {\textbar} 2 {\textbar} of the best models. The r {\textbar} 2 {\textbar} is a standardized measurement of explained variance while the {MSE} values are not standardized across the different models making it less appropriate to use {MSE} for comparison. {\textbar} Experimental Results {\textbar} {\textbar} Within a multi-modal dataset, the best biomarkers were found for symptom severity. Of the 441 sets of models created, the best median {MSE}, r {\textbar} {\textbar} 2 {\textbar} , and number of features chosen for the best model are listed by input type in Tables 7-15. {\textbar} {TABLE} 7 {\textbar} {\textbar} Models with scales as Input Feature Set {\textbar} {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Lasso {\textbar} {ElasticNet} {\textbar} {RandomForest} {\textbar} Chapman Social {\textbar} {\textbar} median {MSE} {\textbar} 11.1271192 {\textbar} 12.5102035 {\textbar} 18.52422909 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.79553146 {\textbar} 12.5102035 {\textbar} 0.663112391 {\textbar} p {\textbar} {\textbar} 60 {\textbar} 126 {\textbar} n/a {\textbar} Chapman {\textbar} {\textbar} median {MSE} {\textbar} 22.1445803 {\textbar} 19.66968 {\textbar} 29.07554113 {\textbar} Physical {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.62740091 {\textbar} 0.64236923 {\textbar} 0.390169303 {\textbar} Anhedonia {\textbar} {\textbar} p {\textbar} 30 {\textbar} 240 {\textbar} n/a {\textbar} {HAMD}, total {\textbar} {\textbar} median {MSE} {\textbar} 43.793948 {\textbar} 39.5487303 {\textbar} 55.91616365 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.64032781 {\textbar} 0.68561252 {\textbar} 0.52124878 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 30 {\textbar} n/a {\textbar} {HAMD}, q1, 7, 8 {\textbar} {\textbar} median {MSE} {\textbar} 2.01814843 {\textbar} 1.66515201 {\textbar} 2.259603571 {\textbar} sum score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.57873064 {\textbar} 0.62740408 {\textbar} 0.450071051 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 111 {\textbar} n/a {\textbar} {HAMD}, q7 {\textbar} {\textbar} median {MSE} {\textbar} 0.62723587 {\textbar} 0.64544389 {\textbar} 0.728892857 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.53344986 {\textbar} 0.50668328 {\textbar} 0.358667497 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 31 {\textbar} n/a {\textbar} {BPRS}, negative {\textbar} {\textbar} median {MSE} {\textbar} 0.26698062 {\textbar} 0.25566474 {\textbar} 0.265797419 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.31461782 {\textbar} 0.31801616 {\textbar} 0.322618632 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 16 {\textbar} n/a {\textbar} {BPRS}, {\textbar} {\textbar} median {MSE} {\textbar} 0.41526043 {\textbar} 0.49462448 {\textbar} 0.645597869 {\textbar} depression- {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.69385756 {\textbar} 0.63793659 {\textbar} 0.506121615 {\textbar} anxiety score {\textbar} {\textbar} p {\textbar} 29 {\textbar} 15 {\textbar} n/a {\textbar} Hopkins, anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.12342578 {\textbar} 0.13413996 {\textbar} 0.132160047 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.56143153 {\textbar} 0.5247619 {\textbar} 0.514104345 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 54 {\textbar} n/a {\textbar} Hopkins, {\textbar} {\textbar} median {MSE} {\textbar} 0.12009199 {\textbar} 0.14761639 {\textbar} 0.157354172 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.55009395 {\textbar} 0.52978675 {\textbar} 0.487804566 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 50 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 1.48573552 {\textbar} 1.48573552 {\textbar} 1.48573552 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.79140084 {\textbar} 0.79140084 {\textbar} 0.79140084 {\textbar} p {\textbar} {\textbar} 53 {\textbar} 53 {\textbar} 53 {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 1.14386984 {\textbar} 1.25201497 {\textbar} 1.432082609 {\textbar} anxiety score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.60840301 {\textbar} 0.61587207 {\textbar} 0.527387046 {\textbar} p {\textbar} {\textbar} 55 {\textbar} 62 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.83876628 {\textbar} 0.59576226 {\textbar} 0.956182813 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.47594879 {\textbar} 0.54907114 {\textbar} 0.35565793 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 31 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.75904172 {\textbar} 0.53277714 {\textbar} 0.842343438 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.37282752 {\textbar} 0.52685866 {\textbar} 0.277248843 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 95 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.35110694 {\textbar} 0.29422649 {\textbar} 0.467130979 {\textbar} affect factor {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.50744677 {\textbar} 0.63150632 {\textbar} 0.404207334 {\textbar} score {\textbar} {\textbar} p {\textbar} 27 {\textbar} 30 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.30051278 {\textbar} 0.28023609 {\textbar} 0.261009716 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.47299533 {\textbar} 0.45477607 {\textbar} 0.347271029 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 21 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.86509729 {\textbar} 0.51250215 {\textbar} 0.83855625 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.19195497 {\textbar} 0.55007444 {\textbar} 0.306327586 {\textbar} p {\textbar} {\textbar} 23 {\textbar} 31 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.97997004 {\textbar} 0.77234958 {\textbar} 1.3385 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.48838999 {\textbar} 0.51134602 {\textbar} 0.280770186 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 97 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} {SANS}, avolition {\textbar} {SANS}, avolition {\textbar} {SANS}, avolition {\textbar} global score {\textbar} {\textbar} global score {\textbar} global score {\textbar} global score {\textbar} median r {\textbar} {\textbar} 2 {\textbar} {SANS}, avolition {\textbar} {SANS}, avolition {\textbar} {SANS}, avolition {\textbar} global score {\textbar} {\textbar} global score {\textbar} global score {\textbar} p {\textbar} {\textbar} {SANS}, avolition {\textbar} {SANS}, avolition {\textbar} {SANS}, avolition {\textbar} global score {\textbar} {\textbar} global score {\textbar} global score {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.7771112 {\textbar} 0.73140944 {\textbar} 1.117416344 {\textbar} affect global {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.51491093 {\textbar} 0.51498925 {\textbar} 0.279459854 {\textbar} score {\textbar} {\textbar} p {\textbar} 28 {\textbar} 16 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.47215453 {\textbar} 0.38144655 {\textbar} 0.7015 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.52195716 {\textbar} 0.56271799 {\textbar} 0.175649402 {\textbar} p {\textbar} {\textbar} 48 {\textbar} 54 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 1.0888059 {\textbar} 1.14883735 {\textbar} 1.33584404 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.36828624 {\textbar} 0.37581968 {\textbar} 0.207184361 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 23 {\textbar} n/a {\textbar} {TABLE} 8 {\textbar} {\textbar} Models with {sMRI} as Input Feature Set {\textbar} {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Lasso {\textbar} {ElasticNet} {\textbar} {RandomForest} {\textbar} Chapman Social {\textbar} {\textbar} median {MSE} {\textbar} 46.6436876 {\textbar} 43.8925147 {\textbar} 56.19190933 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.13059127 {\textbar} 0.06492086 {\textbar} 0.018169833 {\textbar} p {\textbar} {\textbar} 32 {\textbar} 32 {\textbar} n/a {\textbar} Chapman {\textbar} {\textbar} median {MSE} {\textbar} 45.608347 {\textbar} 42.8346492 {\textbar} 51.84063311 {\textbar} Physical {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.08315395 {\textbar} 0.1578689 {\textbar} 0.051603031 {\textbar} Anhedonia {\textbar} {\textbar} p {\textbar} 29 {\textbar} 61 {\textbar} n/a {\textbar} {HAMD}, total {\textbar} {\textbar} median {MSE} {\textbar} 106.7787 {\textbar} 126.52325 {\textbar} 148.4359545 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.18545856 {\textbar} 0.13091374 {\textbar} −0.028624069 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 63 {\textbar} n/a {\textbar} {HAMD}, q1, 7, 8 {\textbar} {\textbar} median {MSE} {\textbar} 3.91992524 {\textbar} 3.6155941 {\textbar} 4.89586655 {\textbar} sum score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.24368153 {\textbar} 0.41216092 {\textbar} 0.029851586 {\textbar} p {\textbar} {\textbar} 12 {\textbar} 32 {\textbar} n/a {\textbar} {HAMD}, q7 {\textbar} {\textbar} median {MSE} {\textbar} 1.09102119 {\textbar} 1.03588134 {\textbar} 1.235452088 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.233324 {\textbar} 0.25076498 {\textbar} 0.094440028 {\textbar} p {\textbar} {\textbar} 12 {\textbar} 8 {\textbar} n/a {\textbar} {BPRS}, negative {\textbar} {\textbar} median {MSE} {\textbar} 0.39982436 {\textbar} 0.32335276 {\textbar} 0.402057778 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.00824425 {\textbar} -0.0155099 {\textbar} −0.007323061 {\textbar} p {\textbar} {\textbar} 4 {\textbar} 0 {\textbar} n/a {\textbar} {BPRS}, {\textbar} {\textbar} median {MSE} {\textbar} 1.15920977 {\textbar} 0.95818565 {\textbar} 1.451526015 {\textbar} depression- {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.17862626 {\textbar} 0.28621436 {\textbar} 0.054920555 {\textbar} anxiety score {\textbar} {\textbar} p {\textbar} 16 {\textbar} 16 {\textbar} n/a {\textbar} Hopkins, anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.26190654 {\textbar} 0.25999248 {\textbar} 0.305197627 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.0345918 {\textbar} 0.04196626 {\textbar} −0.024837299 {\textbar} p {\textbar} {\textbar} 3 {\textbar} 6 {\textbar} n/a {\textbar} Hopkins, {\textbar} {\textbar} median {MSE} {\textbar} 0.28184369 {\textbar} 0.29874141 {\textbar} 0.312998029 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.02605857 {\textbar} 0.01897287 {\textbar} 0.013456599 {\textbar} p {\textbar} {\textbar} 4 {\textbar} 3 {\textbar} n/a {\textbar} Bipolar {II}, mood {\textbar} {\textbar} median {MSE} {\textbar} 6.60397522 {\textbar} 6.40784263 {\textbar} 6.606565127 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.04096752 {\textbar} 0.12327275 {\textbar} 0.000331189 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 22 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 2.96567459 {\textbar} 2.86508927 {\textbar} 3.207035714 {\textbar} anxiety score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.0553218 {\textbar} 0.12103751 {\textbar} −0.038229814 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 16 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 1.2865302 {\textbar} 1.37559255 {\textbar} 1.500729847 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.07116012 {\textbar} 0.0838163 {\textbar} 0.049659227 {\textbar} p {\textbar} {\textbar} 1 {\textbar} 7 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.84434359 {\textbar} 0.68288494 {\textbar} 1.226599689 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.06990071 {\textbar} 0.25025035 {\textbar} −0.055433989 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 16 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 1.02091208 {\textbar} 0.73699746 {\textbar} 0.860400744 {\textbar} affect factor {\textbar} {\textbar} median r {\textbar} 2 {\textbar} −0.0397132 {\textbar} 0.17453646 {\textbar} −0.048103458 {\textbar} score {\textbar} {\textbar} p {\textbar} 6 {\textbar} 8 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.48120689 {\textbar} 0.42570429 {\textbar} 0.45733438 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.13644323 {\textbar} 0.14511349 {\textbar} 0.125931485 {\textbar} p {\textbar} {\textbar} 2 {\textbar} 4 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 1.1922749 {\textbar} 1.10667518 {\textbar} 1.225370598 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.05745299 {\textbar} 0.07908587 {\textbar} 0.022559648 {\textbar} p {\textbar} {\textbar} 2 {\textbar} 10 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 1.69045647 {\textbar} 1.31358016 {\textbar} 2.053971977 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.11891888 {\textbar} 0.26245368 {\textbar} 0.008426596 {\textbar} p {\textbar} {\textbar} 7 {\textbar} 16 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 1.33022003 {\textbar} 1.81957272 {\textbar} 1.972625302 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.24852834 {\textbar} 0.11766409 {\textbar} −0.052500711 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 8 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 1.70285398 {\textbar} 1.28177902 {\textbar} 1.779535383 {\textbar} affect global {\textbar} {\textbar} median r {\textbar} 2 {\textbar} −0.0107927 {\textbar} 0.21717229 {\textbar} −0.0705761 {\textbar} score {\textbar} {\textbar} p {\textbar} 20 {\textbar} 30 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 1.0508356 {\textbar} 0.69226706 {\textbar} 1.125291206 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} −0.0546058 {\textbar} 0.12641629 {\textbar} −0.046307774 {\textbar} p {\textbar} {\textbar} 2 {\textbar} 16 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 1.39313125 {\textbar} 1.23859557 {\textbar} 1.600134651 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.05351207 {\textbar} 0.18494907 {\textbar} 0.018476896 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 8 {\textbar} n/a {\textbar} {TABLE} 9 {\textbar} {\textbar} Models with {fMRI} as Input Feature Set {\textbar} {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Lasso {\textbar} {ElasticNet} {\textbar} {RandomForest} {\textbar} Chapman Social {\textbar} {\textbar} median {MSE} {\textbar} 24.1366711 {\textbar} 13.2464801 {\textbar} 35.74676667 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.5908661 {\textbar} 0.7319229 {\textbar} 0.258061818 {\textbar} p {\textbar} {\textbar} 75 {\textbar} 345 {\textbar} n/a {\textbar} Chapman {\textbar} {\textbar} median {MSE} {\textbar} 30.901329 {\textbar} 21.4057029 {\textbar} 39.74679883 {\textbar} Physical {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.61525222 {\textbar} 0.65566807 {\textbar} 0.247477881 {\textbar} Anhedonia {\textbar} {\textbar} p {\textbar} 76 {\textbar} 358 {\textbar} n/a {\textbar} {HAMD}, total {\textbar} {\textbar} median {MSE} {\textbar} 33.2005788 {\textbar} 38.9725415 {\textbar} 71.34669412 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.66777371 {\textbar} 0.59569346 {\textbar} 0.207388274 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 500 {\textbar} n/a {\textbar} {HAMD}, q1, 7, 8 {\textbar} {\textbar} median {MSE} {\textbar} 0.95578396 {\textbar} 0.91593487 {\textbar} 2.650023529 {\textbar} sum score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.79179955 {\textbar} 0.74061902 {\textbar} 0.332485876 {\textbar} p {\textbar} {\textbar} 28 {\textbar} 191 {\textbar} n/a {\textbar} {HAMD}, q7 {\textbar} {\textbar} median {MSE} {\textbar} 0.31201916 {\textbar} 0.37790437 {\textbar} 0.808070588 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.73200199 {\textbar} 0.69881084 {\textbar} 0.356340961 {\textbar} p {\textbar} {\textbar} 38 {\textbar} 54 {\textbar} n/a {\textbar} {BPRS}, negative {\textbar} {\textbar} median {MSE} {\textbar} 0.18757938 {\textbar} 0.1506109 {\textbar} 0.241262868 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.58051551 {\textbar} 0.57369558 {\textbar} 0.279867098 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 131 {\textbar} n/a {\textbar} {BPRS}, {\textbar} {\textbar} median {MSE} {\textbar} 0.48898993 {\textbar} 0.38228361 {\textbar} 0.69174958 {\textbar} depression- {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.51218225 {\textbar} 0.54291803 {\textbar} 0.343333691 {\textbar} anxiety score {\textbar} {\textbar} p {\textbar} 23 {\textbar} 36 {\textbar} n/a {\textbar} Hopkins, anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.16332994 {\textbar} 0.10991548 {\textbar} 0.250750368 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.4518252 {\textbar} 0.65341477 {\textbar} 0.307182751 {\textbar} p {\textbar} {\textbar} 24 {\textbar} 85 {\textbar} n/a {\textbar} Hopkins, {\textbar} {\textbar} median {MSE} {\textbar} 0.14661675 {\textbar} 0.1591489 {\textbar} 0.206618425 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.48845674 {\textbar} 0.45016098 {\textbar} 0.280274072 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 29 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 2.2093303 {\textbar} 2.53026198 {\textbar} 4.058693333 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.64341678 {\textbar} 0.62534857 {\textbar} 0.323775594 {\textbar} p {\textbar} {\textbar} 50 {\textbar} 255 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 1.74502231 {\textbar} 0.98772213 {\textbar} 2.523746667 {\textbar} anxiety score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.48106 {\textbar} 0.6442545 {\textbar} 0.304516018 {\textbar} p {\textbar} {\textbar} 43 {\textbar} 153 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.57249993 {\textbar} 0.44668826 {\textbar} 0.671989773 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.54341834 {\textbar} 0.72603119 {\textbar} 0.476297105 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 66 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.38427335 {\textbar} 0.41349887 {\textbar} 0.523188636 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.60922858 {\textbar} 0.68171714 {\textbar} 0.393902033 {\textbar} p {\textbar} {\textbar} 20 {\textbar} 63 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.35097663 {\textbar} 0.13853868 {\textbar} 0.319771716 {\textbar} affect factor {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.36340364 {\textbar} 0.81112876 {\textbar} 0.421756359 {\textbar} score {\textbar} {\textbar} p {\textbar} 22 {\textbar} 29 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.5114133 {\textbar} 0.5450171 {\textbar} 0.863740909 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.58044727 {\textbar} 0.55803846 {\textbar} 0.351176332 {\textbar} p {\textbar} {\textbar} 11 {\textbar} 16 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.6479366 {\textbar} 0.653431 {\textbar} 0.703936364 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.57849286 {\textbar} 0.5910022 {\textbar} 0.567246117 {\textbar} p {\textbar} {\textbar} 13 {\textbar} 22 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.65626457 {\textbar} 0.45879379 {\textbar} 1.112490909 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.65501818 {\textbar} 0.7356483 {\textbar} 0.41697963 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 126 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.76806032 {\textbar} 0.40498193 {\textbar} 0.725527273 {\textbar} affect global {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.5075324 {\textbar} 0.67717999 {\textbar} 0.438660494 {\textbar} score {\textbar} {\textbar} p {\textbar} 20 {\textbar} 18 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.18058636 {\textbar} 0.25612571 {\textbar} 0.360454545 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.71239653 {\textbar} 0.44974554 {\textbar} 0.20472973 {\textbar} p {\textbar} {\textbar} 12 {\textbar} 21 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.82370349 {\textbar} 0.84473842 {\textbar} 1.018854545 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.53408014 {\textbar} 0.55862342 {\textbar} 0.381446429 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 70 {\textbar} n/a {\textbar} {TABLE} 10 {\textbar} {\textbar} Models with {sMRI} + {fMRI} as Input Feature Set {\textbar} {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Lasso {\textbar} {ElasticNet} {\textbar} {RandomForest} {\textbar} Chapman Social {\textbar} {\textbar} median {MSE} {\textbar} 20.3800964 {\textbar} 14.682152 {\textbar} 34.56825833 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.61287335 {\textbar} 0.67729341 {\textbar} 0.271666677 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 559 {\textbar} n/a {\textbar} Chapman {\textbar} {\textbar} median {MSE} {\textbar} 29.5944321 {\textbar} 14.4191528 {\textbar} 39.64058054 {\textbar} Physical {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.47730737 {\textbar} 0.73988389 {\textbar} 0.270972364 {\textbar} Anhedonia {\textbar} {\textbar} p {\textbar} 72 {\textbar} 211 {\textbar} n/a {\textbar} {HAMD}, total {\textbar} {\textbar} median {MSE} {\textbar} 40.444502 {\textbar} 27.0655892 {\textbar} 65.45605995 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.46827069 {\textbar} 0.61111933 {\textbar} 0.317391988 {\textbar} p {\textbar} {\textbar} 13 {\textbar} 448 {\textbar} n/a {\textbar} {HAMD}, q1, 7, 8 {\textbar} {\textbar} median {MSE} {\textbar} 2.36930173 {\textbar} 1.3053619 {\textbar} 2.42418007 {\textbar} sum score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.57469992 {\textbar} 0.78027275 {\textbar} 0.415661799 {\textbar} p {\textbar} {\textbar} 21 {\textbar} 78 {\textbar} n/a {\textbar} {HAMD}, q7 {\textbar} {\textbar} median {MSE} {\textbar} 0.48427727 {\textbar} 0.44843705 {\textbar} 0.733507692 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.51760748 {\textbar} 0.62850068 {\textbar} 0.374694444 {\textbar} p {\textbar} {\textbar} 4 {\textbar} 95 {\textbar} n/a {\textbar} {BPRS}, negative {\textbar} {\textbar} median {MSE} {\textbar} 0.10894905 {\textbar} 0.20808541 {\textbar} 0.228798077 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.58309527 {\textbar} 0.48416688 {\textbar} 0.339701299 {\textbar} p {\textbar} {\textbar} 10 {\textbar} 12 {\textbar} n/a {\textbar} {BPRS}, {\textbar} {\textbar} median {MSE} {\textbar} 0.74672192 {\textbar} 0.4527803 {\textbar} 0.745567681 {\textbar} depression- {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.34811518 {\textbar} 0.59421236 {\textbar} 0.305609826 {\textbar} anxiety score {\textbar} {\textbar} p {\textbar} 15 {\textbar} 119 {\textbar} n/a {\textbar} Hopkins, anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.12090694 {\textbar} 0.09822079 {\textbar} 0.189571301 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.55139531 {\textbar} 0.65036656 {\textbar} 0.303938076 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 29 {\textbar} n/a {\textbar} Hopkins, {\textbar} {\textbar} median {MSE} {\textbar} 0.17540687 {\textbar} 0.1383836 {\textbar} 0.199493796 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.38018872 {\textbar} 0.4151432 {\textbar} 0.199243267 {\textbar} p {\textbar} {\textbar} 21 {\textbar} 16 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 3.58417568 {\textbar} 1.86722182 {\textbar} 4.104375843 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.45476109 {\textbar} 0.71921058 {\textbar} 0.297745091 {\textbar} p {\textbar} {\textbar} 48 {\textbar} 241 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 1.28026365 {\textbar} 0.70325067 {\textbar} 2.257191667 {\textbar} anxiety score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.60209066 {\textbar} 0.78935698 {\textbar} 0.32304625 {\textbar} p {\textbar} {\textbar} 25 {\textbar} 161 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.40512803 {\textbar} 0.35700521 {\textbar} 0.63381875 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.71570239 {\textbar} 0.77152059 {\textbar} 0.552279155 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 48 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.18738998 {\textbar} 0.11302804 {\textbar} 0.45203125 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.67281 {\textbar} 0.84257768 {\textbar} 0.519285076 {\textbar} p {\textbar} {\textbar} 7 {\textbar} 41 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.1055558 {\textbar} 0.16598636 {\textbar} 0.406562166 {\textbar} affect factor {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.7535557 {\textbar} 0.76532171 {\textbar} 0.476367098 {\textbar} score {\textbar} {\textbar} p {\textbar} 24 {\textbar} 65 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.40859079 {\textbar} 0.11637806 {\textbar} 0.236031927 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.29255013 {\textbar} 0.7725277 {\textbar} 0.559877681 {\textbar} p {\textbar} {\textbar} 7 {\textbar} 77 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.88823187 {\textbar} 0.57576394 {\textbar} 1.095494073 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.40161221 {\textbar} 0.63872035 {\textbar} 0.319304654 {\textbar} p {\textbar} {\textbar} 17 {\textbar} 107 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.55331606 {\textbar} 0.21081588 {\textbar} 0.7125 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.56105366 {\textbar} 0.82726123 {\textbar} 0.5096 {\textbar} p {\textbar} {\textbar} 6 {\textbar} 67 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.76193885 {\textbar} 0.26705401 {\textbar} 0.75875 {\textbar} affect global {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.5411395 {\textbar} 0.84012485 {\textbar} 0.526436782 {\textbar} score {\textbar} {\textbar} p {\textbar} 11 {\textbar} 41 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.52887025 {\textbar} 0.25762776 {\textbar} 0.3487375 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.31534639 {\textbar} 0.65101623 {\textbar} 0.320888889 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 26 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.35172813 {\textbar} 0.28886716 {\textbar} 0.5875 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.70380789 {\textbar} 0.75674345 {\textbar} 0.5975 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 13 {\textbar} n/a {\textbar} {TABLE} 11 {\textbar} {\textbar} Models with Scales + {sMRI} as Input Feature Set {\textbar} {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Lasso {\textbar} {ElasticNet} {\textbar} {RandomForest} {\textbar} Chapman Social {\textbar} {\textbar} median {MSE} {\textbar} 10.1872913 {\textbar} 10.8473571 {\textbar} 23.01353415 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.8189687 {\textbar} 0.79591289 {\textbar} 0.599748178 {\textbar} p {\textbar} {\textbar} 59 {\textbar} 63 {\textbar} n/a {\textbar} Chapman {\textbar} {\textbar} median {MSE} {\textbar} 15.1648738 {\textbar} 15.1775051 {\textbar} 31.00075366 {\textbar} Physical {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.6745091 {\textbar} 0.69034822 {\textbar} 0.429974564 {\textbar} Anhedonia {\textbar} {\textbar} p {\textbar} 92 {\textbar} 123 {\textbar} n/a {\textbar} {HAMD}, total {\textbar} {\textbar} median {MSE} {\textbar} 44.8743169 {\textbar} 21.4111889 {\textbar} 51.17416788 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.62386495 {\textbar} 0.80822534 {\textbar} 0.600713723 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 123 {\textbar} n/a {\textbar} {HAMD}, q1, 7, 8 {\textbar} {\textbar} median {MSE} {\textbar} 2.04269051 {\textbar} 1.25720156 {\textbar} 2.447818182 {\textbar} sum score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.59849127 {\textbar} 0.76841313 {\textbar} 0.474861019 {\textbar} p {\textbar} {\textbar} 38 {\textbar} 110 {\textbar} n/a {\textbar} {HAMD}, q7 {\textbar} {\textbar} median {MSE} {\textbar} 0.5660152 {\textbar} 0.37695234 {\textbar} 0.771495455 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.60961318 {\textbar} 0.73435387 {\textbar} 0.407349419 {\textbar} p {\textbar} {\textbar} 28 {\textbar} 58 {\textbar} n/a {\textbar} {BPRS}, negative {\textbar} {\textbar} median {MSE} {\textbar} 0.22947823 {\textbar} 0.11052677 {\textbar} 0.223487784 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.3567901 {\textbar} 0.68800207 {\textbar} 0.426280069 {\textbar} p {\textbar} {\textbar} 12 {\textbar} 54 {\textbar} n/a {\textbar} {BPRS}, {\textbar} {\textbar} median {MSE} {\textbar} 0.47774909 {\textbar} 0.37200915 {\textbar} 0.716768024 {\textbar} depression- {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.6784626 {\textbar} 0.76758706 {\textbar} 0.520999457 {\textbar} anxiety score {\textbar} {\textbar} p {\textbar} 39 {\textbar} 58 {\textbar} n/a {\textbar} Hopkins, anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.15278469 {\textbar} 0.14505891 {\textbar} 0.147720373 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.46629576 {\textbar} 0.47103414 {\textbar} 0.475010058 {\textbar} p {\textbar} {\textbar} 14 {\textbar} 49 {\textbar} n/a {\textbar} Hopkins, {\textbar} {\textbar} median {MSE} {\textbar} 0.13015768 {\textbar} 0.10560835 {\textbar} 0.148762648 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.58405287 {\textbar} 0.67747487 {\textbar} 0.516387069 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 102 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 1.11473489 {\textbar} 1.02057729 {\textbar} 1.722802026 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.84118256 {\textbar} 0.86421896 {\textbar} 0.745336441 {\textbar} p {\textbar} {\textbar} 32 {\textbar} 114 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 0.81608355 {\textbar} 0.79832926 {\textbar} 1.565412195 {\textbar} anxiety score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.7409768 {\textbar} 0.73479011 {\textbar} 0.523792469 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 58 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.80659301 {\textbar} 0.8876104 {\textbar} 1.02542 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.4847042 {\textbar} 0.43714204 {\textbar} 0.251376657 {\textbar} p {\textbar} {\textbar} 24 {\textbar} 13 {\textbar} n/a {\textbar} {SAMS} avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.35767455 {\textbar} 0.29545236 {\textbar} 0.76713875 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.64133778 {\textbar} 0.69348871 {\textbar} 0.252067852 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 54 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.29046712 {\textbar} 0.35398284 {\textbar} 0.555033335 {\textbar} affect global {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.65317772 {\textbar} 0.57650195 {\textbar} 0.346361453 {\textbar} score {\textbar} {\textbar} p {\textbar} 15 {\textbar} 29 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.27355305 {\textbar} 0.22486147 {\textbar} 0.370562213 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.43984006 {\textbar} 0.45944781 {\textbar} 0.260900092 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 22 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.61391724 {\textbar} 0.52919515 {\textbar} 0.840366667 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.42634181 {\textbar} 0.56616671 {\textbar} 0.26694625 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 90 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.82696728 {\textbar} 0.91638191 {\textbar} 1.31 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.52922904 {\textbar} 0.52124193 {\textbar} 0.349258197 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 57 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 1.0735851 {\textbar} 0.96201314 {\textbar} 1.69874 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.48944093 {\textbar} 0.4703767 {\textbar} 0.186773404 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 92 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.47919468 {\textbar} 0.64615998 {\textbar} 0.941919557 {\textbar} affect global {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.56575973 {\textbar} 0.5970739 {\textbar} 0.403780513 {\textbar} score {\textbar} {\textbar} p {\textbar} 16 {\textbar} 89 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.42319702 {\textbar} 0.51674167 {\textbar} 0.709333333 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.41947137 {\textbar} 0.43807514 {\textbar} 0.181628238 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 16 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.5766073 {\textbar} 0.87984786 {\textbar} 1.165269856 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.53935525 {\textbar} 0.37445084 {\textbar} 0.141182351 {\textbar} p {\textbar} {\textbar} 23 {\textbar} 56 {\textbar} n/a {\textbar} {TABLE} 12 {\textbar} {\textbar} Models with Scales + {fMRI} as Input Feature Set {\textbar} {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Lasso {\textbar} {ElasticNet} {\textbar} {RandomForest} {\textbar} Chapman Social {\textbar} {\textbar} median {MSE} {\textbar} 7.54857525 {\textbar} 8.62749906 {\textbar} 15.861 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.85696606 {\textbar} 0.82923337 {\textbar} 0.624779485 {\textbar} p {\textbar} {\textbar} 47 {\textbar} 31 {\textbar} n/a {\textbar} Chapman {\textbar} {\textbar} median {MSE} {\textbar} 11.4387261 {\textbar} 9.64819292 {\textbar} 30.3415 {\textbar} Physical {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.80523296 {\textbar} 0.84146325 {\textbar} 0.46116541 {\textbar} Anhedonia {\textbar} {\textbar} p {\textbar} 46 {\textbar} 211 {\textbar} n/a {\textbar} {HAMD}, total {\textbar} {\textbar} median {MSE} {\textbar} 30.0928229 {\textbar} 18.4018727 {\textbar} 56.24705882 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.68185562 {\textbar} 0.75611578 {\textbar} 0.409766837 {\textbar} p {\textbar} {\textbar} 64 {\textbar} 500 {\textbar} n/a {\textbar} {HAMD}, q1, 7, 8 {\textbar} {\textbar} median {MSE} {\textbar} 0.78599809 {\textbar} 1.39375053 {\textbar} 2.453211765 {\textbar} sum score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.8139221 {\textbar} 0.66728025 {\textbar} 0.351087925 {\textbar} p {\textbar} {\textbar} 26 {\textbar} 38 {\textbar} n/a {\textbar} {HAMD}, q7 {\textbar} {\textbar} median {MSE} {\textbar} 0.50886936 {\textbar} 0.2839172 {\textbar} 0.698394118 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.56050644 {\textbar} 0.74835288 {\textbar} 0.35008427 {\textbar} p {\textbar} {\textbar} 14 {\textbar} 71 {\textbar} n/a {\textbar} {BPRS}, negative {\textbar} {\textbar} median {MSE} {\textbar} 0.12890998 {\textbar} 0.10125789 {\textbar} 0.263854412 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.6985185 {\textbar} 0.72757156 {\textbar} 0.365523303 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 77 {\textbar} n/a {\textbar} {BPRS}, {\textbar} {\textbar} median {MSE} {\textbar} 0.38343051 {\textbar} 0.3666505 {\textbar} 0.614460907 {\textbar} depression- {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.60430968 {\textbar} 0.6324356 {\textbar} 0.400634204 {\textbar} anxiety score {\textbar} {\textbar} p {\textbar} 10 {\textbar} 126 {\textbar} n/a {\textbar} Hopkins, anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.15000759 {\textbar} 0.09454587 {\textbar} 0.182484719 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.59683759 {\textbar} 0.70395432 {\textbar} 0.494827971 {\textbar} p {\textbar} {\textbar} 27 {\textbar} 127 {\textbar} n/a {\textbar} Hopkins, {\textbar} {\textbar} median {MSE} {\textbar} 0.07745056 {\textbar} 0.109673 {\textbar} 0.166952453 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.70911272 {\textbar} 0.61049809 {\textbar} 0.487824855 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 26 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 0.8612683 {\textbar} 0.81444012 {\textbar} 1.874116667 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.86949418 {\textbar} 0.87448985 {\textbar} 0.716193323 {\textbar} p {\textbar} {\textbar} 50 {\textbar} 236 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 0.92825662 {\textbar} 0.5885091 {\textbar} 1.4777 {\textbar} anxiety score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.72875618 {\textbar} 0.82518059 {\textbar} 0.545020104 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 32 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.75319007 {\textbar} 0.40312956 {\textbar} 0.602954545 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.45645379 {\textbar} 0.69809318 {\textbar} 0.4687 {\textbar} p {\textbar} {\textbar} 20 {\textbar} 113 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.44983495 {\textbar} 0.23568128 {\textbar} 0.523295022 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.54295816 {\textbar} 0.75660524 {\textbar} 0.482050744 {\textbar} p {\textbar} {\textbar} 4 {\textbar} 104 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.59539547 {\textbar} 0.15419775 {\textbar} 0.651515161 {\textbar} affect factor {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.11155579 {\textbar} 0.74503811 {\textbar} 0.238753545 {\textbar} score {\textbar} {\textbar} p {\textbar} 18 {\textbar} 66 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.20516943 {\textbar} 0.18387234 {\textbar} 0.251717177 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.27467066 {\textbar} 0.25771316 {\textbar} 0.141923298 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 44 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.62059488 {\textbar} 0.67939691 {\textbar} 0.932954545 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.5322245 {\textbar} 0.55054858 {\textbar} 0.260303398 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 21 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 1.03514893 {\textbar} 0.51331319 {\textbar} 0.843345455 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.37662089 {\textbar} 0.71666415 {\textbar} 0.526349083 {\textbar} p {\textbar} {\textbar} 38 {\textbar} 94 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.69546127 {\textbar} 0.31666292 {\textbar} 0.8424 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.5712837 {\textbar} 0.7831869 {\textbar} 0.423196371 {\textbar} p {\textbar} {\textbar} 32 {\textbar} 76 {\textbar} n/a {\textbar} {SANS}, blunt {\textbar} {\textbar} median {MSE} {\textbar} 0.53970926 {\textbar} 0.24419898 {\textbar} 0.918772727 {\textbar} affect global {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.63412804 {\textbar} 0.8621164 {\textbar} 0.286820238 {\textbar} score {\textbar} {\textbar} p {\textbar} 7 {\textbar} 104 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.23416101 {\textbar} 0.1346341 {\textbar} 0.459032293 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.63027204 {\textbar} 0.76082807 {\textbar} 0.337482692 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 79 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.67038649 {\textbar} 0.3496769 {\textbar} 0.864181818 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.60670155 {\textbar} 0.72306165 {\textbar} 0.405159722 {\textbar} p {\textbar} {\textbar} 34 {\textbar} 49 {\textbar} n/a {\textbar} {TABLE} 13 {\textbar} {\textbar} Models with Scales + {sMRI} + {fMRI} as Input Feature Set {\textbar} {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Lasso {\textbar} {ElasticNet} {\textbar} {RandomForest} {\textbar} Chapman Social {\textbar} {\textbar} median {MSE} {\textbar} 7.02713487 {\textbar} 9.88649254 {\textbar} 19.15130417 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.82179475 {\textbar} 0.80395702 {\textbar} 0.574399043 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 106 {\textbar} n/a {\textbar} Chapman Physical {\textbar} {\textbar} median {MSE} {\textbar} 23.103581 {\textbar} 15.813689 {\textbar} 24.33652917 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.62015743 {\textbar} 0.65207517 {\textbar} 0.427901305 {\textbar} p {\textbar} {\textbar} 48 {\textbar} 32 {\textbar} n/a {\textbar} {HAMD}, total {\textbar} {\textbar} median {MSE} {\textbar} 53.9003365 {\textbar} 20.609113 {\textbar} 56.87493846 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.40119528 {\textbar} 0.74613682 {\textbar} 0.382350302 {\textbar} p {\textbar} {\textbar} 45 {\textbar} 287 {\textbar} n/a {\textbar} {HAMD}, q1, 7, 8 {\textbar} {\textbar} median {MSE} {\textbar} 0.83612067 {\textbar} 0.66395437 {\textbar} 1.736653846 {\textbar} sum score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.74556212 {\textbar} 0.84561512 {\textbar} 0.4934095 {\textbar} p {\textbar} {\textbar} 22 {\textbar} 15 {\textbar} n/a {\textbar} {HAMD}, q7 {\textbar} {\textbar} median {MSE} {\textbar} 0.37916308 {\textbar} 0.27904854 {\textbar} 0.592908763 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.68283541 {\textbar} 0.74596354 {\textbar} 0.456458962 {\textbar} p {\textbar} {\textbar} 24 {\textbar} 41 {\textbar} n/a {\textbar} {BPRS}, negative {\textbar} {\textbar} median {MSE} {\textbar} 0.12270201 {\textbar} 0.21086621 {\textbar} 0.238864423 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.67420458 {\textbar} 0.56848126 {\textbar} 0.393594454 {\textbar} p {\textbar} {\textbar} 20 {\textbar} 59 {\textbar} n/a {\textbar} {BPRS}, depression- {\textbar} {\textbar} median {MSE} {\textbar} 0.43485082 {\textbar} 0.23737832 {\textbar} 0.5453289 {\textbar} anxiety score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.62338118 {\textbar} 0.73608677 {\textbar} 0.465149531 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 101 {\textbar} n/a {\textbar} Hopkins, anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.08598748 {\textbar} 0.07735448 {\textbar} 0.155089002 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.68432645 {\textbar} 0.75087675 {\textbar} 0.472547865 {\textbar} p {\textbar} {\textbar} 27 {\textbar} 47 {\textbar} n/a {\textbar} Hopkins, {\textbar} {\textbar} median {MSE} {\textbar} 0.13237647 {\textbar} 0.07568423 {\textbar} 0.128395595 {\textbar} depression {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.51367615 {\textbar} 0.72075418 {\textbar} 0.551525829 {\textbar} score {\textbar} {\textbar} p {\textbar} 8 {\textbar} 28 {\textbar} n/a {\textbar} Bipolar {II}, {\textbar} {\textbar} median {MSE} {\textbar} 0.72420064 {\textbar} 0.61353445 {\textbar} 1.800416667 {\textbar} depression score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.87359605 {\textbar} 0.90430728 {\textbar} 0.707705862 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 93 {\textbar} n/a {\textbar} Bipolar {II}, anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.52050357 {\textbar} 0.53484936 {\textbar} 1.415204167 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.83781236 {\textbar} 0.84698368 {\textbar} 0.541076495 {\textbar} p {\textbar} {\textbar} 72 {\textbar} 31 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.3853509 {\textbar} 0.34019896 {\textbar} 0.741640625 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.66868235 {\textbar} 0.76398652 {\textbar} 0.479339276 {\textbar} p {\textbar} {\textbar} 25 {\textbar} 96 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.11339753 {\textbar} 0.24172352 {\textbar} 0.337739063 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.87833197 {\textbar} 0.75047895 {\textbar} 0.54596125 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 37 {\textbar} n/a {\textbar} {SANS}, blunt affect {\textbar} {\textbar} median {MSE} {\textbar} 0.28002122 {\textbar} 0.10988582 {\textbar} 0.373347216 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.62139163 {\textbar} 0.86521702 {\textbar} 0.504200316 {\textbar} p {\textbar} {\textbar} 12 {\textbar} 48 {\textbar} n/a {\textbar} {SANS}, alogia factor {\textbar} {\textbar} median {MSE} {\textbar} 0.18371445 {\textbar} 0.28849662 {\textbar} 0.245543402 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.56331434 {\textbar} 0.39736881 {\textbar} 0.370516386 {\textbar} p {\textbar} {\textbar} 4 {\textbar} 11 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.33208967 {\textbar} 0.38759467 {\textbar} 0.5703125 {\textbar} factor score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.76203213 {\textbar} 0.69803375 {\textbar} 0.388411538 {\textbar} p {\textbar} {\textbar} 14 {\textbar} 75 {\textbar} n/a {\textbar} {SANS}, anhedonia {\textbar} {\textbar} median {MSE} {\textbar} 0.31323163 {\textbar} 0.48323333 {\textbar} 0.9457375 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.77081433 {\textbar} 0.69441199 {\textbar} 0.416995804 {\textbar} p {\textbar} {\textbar} 10 {\textbar} 100 {\textbar} n/a {\textbar} {SANS}, avolition {\textbar} {\textbar} median {MSE} {\textbar} 0.40052226 {\textbar} 0.35670872 {\textbar} 0.61165 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.68969915 {\textbar} 0.65259748 {\textbar} 0.437284034 {\textbar} p {\textbar} {\textbar} 20 {\textbar} 8 {\textbar} n/a {\textbar} {SANS}, blunt affect {\textbar} {\textbar} median {MSE} {\textbar} 0.77088686 {\textbar} 0.24344448 {\textbar} 0.6033125 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.4716052 {\textbar} 0.81951831 {\textbar} 0.669752381 {\textbar} p {\textbar} {\textbar} 12 {\textbar} 60 {\textbar} n/a {\textbar} {SANS}, alogia {\textbar} {\textbar} median {MSE} {\textbar} 0.29111249 {\textbar} 0.30605891 {\textbar} 0.434708622 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.3509162 {\textbar} 0.54233936 {\textbar} 0.377058065 {\textbar} p {\textbar} {\textbar} 12 {\textbar} 13 {\textbar} n/a {\textbar} {SANS}, attention {\textbar} {\textbar} median {MSE} {\textbar} 0.62341815 {\textbar} 0.59315255 {\textbar} 0.7232875 {\textbar} global score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.39958268 {\textbar} 0.36730395 {\textbar} 0.333212632 {\textbar} p {\textbar} {\textbar} 8 {\textbar} 57 {\textbar} n/a {\textbar} {TABLE} 14 {\textbar} {\textbar} Sets Returned by Forward Selection Approach {\textbar} {\textbar} Comparison of all Elastic Net Models using Truncated Feature {\textbar} {\textbar} Scales\_ {\textbar} {\textbar} Scales\_ {\textbar} {\textbar} {sMRI}\_ {\textbar} Scales\_ {\textbar} {sMRI}\_ {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Scales {\textbar} {sMRI} {\textbar} {fMRI} {\textbar} {sMRI} {\textbar} {fMRI} {\textbar} {fMRI} {\textbar} {fMRI} {\textbar} Chapman Social {\textbar} {\textbar} median {MSE} {\textbar} 12.510 {\textbar} 43.893 {\textbar} 13.246 {\textbar} 10.847 {\textbar} 14.682 {\textbar} 8.627 {\textbar} 886 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.782 {\textbar} 0.065 {\textbar} 0.732 {\textbar} 0.796 {\textbar} 0.677 {\textbar} 0.829 {\textbar} 1.804 {\textbar} p {\textbar} {\textbar} 126 {\textbar} 32 {\textbar} 345 {\textbar} 63 {\textbar} 559 {\textbar} 31 {\textbar} 106 {\textbar} Chapman Physical {\textbar} {\textbar} median {MSE} {\textbar} 19.670 {\textbar} 42.835 {\textbar} 21.406 {\textbar} 15.178 {\textbar} 14.419 {\textbar} 9.648 {\textbar} 15.814 {\textbar} Anhedonia {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.642 {\textbar} 0.158 {\textbar} 0.656 {\textbar} 0.690 {\textbar} 0.740 {\textbar} 0.841 {\textbar} 0.652 {\textbar} p {\textbar} {\textbar} 240 {\textbar} 61 {\textbar} 358 {\textbar} 123 {\textbar} 211 {\textbar} 211 {\textbar} 32 {\textbar} {HAMD}, total score {\textbar} {\textbar} median {MSE} {\textbar} 39.549 {\textbar} 126.523 {\textbar} 38.973 {\textbar} 21.411 {\textbar} 27.066 {\textbar} 18.402 {\textbar} 20.609 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.686 {\textbar} 0.131 {\textbar} 0.596 {\textbar} 0.808 {\textbar} 0.611 {\textbar} 0.756 {\textbar} 0.746 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 63 {\textbar} 500 {\textbar} 123 {\textbar} 448 {\textbar} 500 {\textbar} 287 {\textbar} {HAMD}, q1, 7, 8 sum {\textbar} {\textbar} median {MSE} {\textbar} 1.665 {\textbar} 3.616 {\textbar} 0.916 {\textbar} 1.257 {\textbar} 1.305 {\textbar} 1.394 {\textbar} 0.664 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.627 {\textbar} 0.412 {\textbar} 0.741 {\textbar} 0.768 {\textbar} 0.780 {\textbar} 0.667 {\textbar} 0.846 {\textbar} p {\textbar} {\textbar} 111 {\textbar} 32 {\textbar} 191 {\textbar} 110 {\textbar} 78 {\textbar} 38 {\textbar} 15 {\textbar} {HAMD}, q7 {\textbar} {\textbar} median {MSE} {\textbar} 0.645 {\textbar} 1.036 {\textbar} 0.378 {\textbar} 0.377 {\textbar} 0.448 {\textbar} 0.284 {\textbar} 0.279 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.507 {\textbar} 0.251 {\textbar} 0.699 {\textbar} 0.734 {\textbar} 0.629 {\textbar} 0.748 {\textbar} 0.746 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 8 {\textbar} 54 {\textbar} 58 {\textbar} 95 {\textbar} 71 {\textbar} 41 {\textbar} {BPRS}, negative score {\textbar} {\textbar} median {MSE} {\textbar} 0.256 {\textbar} 0.323 {\textbar} 0.151 {\textbar} 0.111 {\textbar} 0.208 {\textbar} 0.101 {\textbar} 0.211 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.318 {\textbar} −0.016 {\textbar} 0.574 {\textbar} 0.688 {\textbar} 0.484 {\textbar} 0.728 {\textbar} 0.568 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 0 {\textbar} 131 {\textbar} 54 {\textbar} 12 {\textbar} 77 {\textbar} 59 {\textbar} {BPRS}, depression-anxiety {\textbar} {\textbar} median {MSE} {\textbar} 0.495 {\textbar} 0.958 {\textbar} 0.382 {\textbar} 0.372 {\textbar} 0.453 {\textbar} 0.367 {\textbar} 0.237 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.638 {\textbar} 0.286 {\textbar} 0.543 {\textbar} 0.768 {\textbar} 0.594 {\textbar} 0.632 {\textbar} 0.736 {\textbar} p {\textbar} {\textbar} 15 {\textbar} 16 {\textbar} 36 {\textbar} 58 {\textbar} 119 {\textbar} 126 {\textbar} 101 {\textbar} Hopkins, anxiety score {\textbar} {\textbar} median {MSE} {\textbar} 0.134 {\textbar} 0.260 {\textbar} 0.110 {\textbar} 0.145 {\textbar} 0.098 {\textbar} 0.095 {\textbar} 0.077 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.525 {\textbar} 0.042 {\textbar} 0.653 {\textbar} 0.471 {\textbar} 0.650 {\textbar} 0.704 {\textbar} 0.751 {\textbar} p {\textbar} {\textbar} 54 {\textbar} 6 {\textbar} 85 {\textbar} 49 {\textbar} 29 {\textbar} 127 {\textbar} 47 {\textbar} Hopkins, depression score {\textbar} {\textbar} median {MSE} {\textbar} 0.148 {\textbar} 0.299 {\textbar} 0.159 {\textbar} 0.106 {\textbar} 0.138 {\textbar} 0.110 {\textbar} 0.076 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.530 {\textbar} 0.019 {\textbar} 0.450 {\textbar} 0.677 {\textbar} 0.415 {\textbar} 0.610 {\textbar} 0.721 {\textbar} p {\textbar} {\textbar} 50 {\textbar} 3 {\textbar} 29 {\textbar} 102 {\textbar} 16 {\textbar} 26 {\textbar} 28 {\textbar} Bipolar {II}, mood score {\textbar} {\textbar} median {MSE} {\textbar} 1.183 {\textbar} 6.408 {\textbar} 2.530 {\textbar} 1.021 {\textbar} 1.867 {\textbar} 0.814 {\textbar} 0.614 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.836 {\textbar} 0.123 {\textbar} 0.625 {\textbar} 0.864 {\textbar} 0.719 {\textbar} 0.874 {\textbar} 0.904 {\textbar} p {\textbar} {\textbar} 112 {\textbar} 22 {\textbar} 255 {\textbar} 114 {\textbar} 241 {\textbar} 236 {\textbar} 93 {\textbar} Bipolar {II}, anxiety score {\textbar} {\textbar} median {MSE} {\textbar} 1.252 {\textbar} 2.865 {\textbar} 0.988 {\textbar} 0.798 {\textbar} 0.703 {\textbar} 0.589 {\textbar} 0.535 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.616 {\textbar} 0.121 {\textbar} 0.644 {\textbar} 0.735 {\textbar} 0.789 {\textbar} 0.825 {\textbar} 0.847 {\textbar} p {\textbar} {\textbar} 62 {\textbar} 16 {\textbar} 153 {\textbar} 58 {\textbar} 161 {\textbar} 32 {\textbar} 31 {\textbar} {SANS}, anhedonia factor {\textbar} {\textbar} median {MSE} {\textbar} 0.596 {\textbar} 1.376 {\textbar} 0.447 {\textbar} 0.888 {\textbar} 0.357 {\textbar} 0.403 {\textbar} 0.340 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.549 {\textbar} 0.084 {\textbar} 0.726 {\textbar} 0.437 {\textbar} 0.772 {\textbar} 0.698 {\textbar} 0.764 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 7 {\textbar} 66 {\textbar} 13 {\textbar} 48 {\textbar} 113 {\textbar} 96 {\textbar} {SANS}, avolition factor {\textbar} {\textbar} median {MSE} {\textbar} 0.533 {\textbar} 0.683 {\textbar} 0.413 {\textbar} 0.295 {\textbar} 0.113 {\textbar} 0.236 {\textbar} 0.242 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.527 {\textbar} 0.250 {\textbar} 0.682 {\textbar} 0.693 {\textbar} 0.843 {\textbar} 0.757 {\textbar} 0.750 {\textbar} p {\textbar} {\textbar} 95 {\textbar} 16 {\textbar} 63 {\textbar} 54 {\textbar} 41 {\textbar} 104 {\textbar} 37 {\textbar} {SANS} blunt affect factor {\textbar} {\textbar} median {MSE} {\textbar} 0.294 {\textbar} 0.737 {\textbar} 0.139 {\textbar} 0.354 {\textbar} 0.166 {\textbar} 0.154 {\textbar} 0.110 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.632 {\textbar} 0.175 {\textbar} 0.811 {\textbar} 0.577 {\textbar} 0.765 {\textbar} 0.745 {\textbar} 0.865 {\textbar} p {\textbar} {\textbar} 30 {\textbar} 8 {\textbar} 29 {\textbar} 29 {\textbar} 65 {\textbar} 66 {\textbar} 48 {\textbar} {SANS}, alogia factor score {\textbar} {\textbar} median {MSE} {\textbar} 0.280 {\textbar} 0.426 {\textbar} 0.092 {\textbar} 0.225 {\textbar} 0.116 {\textbar} 0.184 {\textbar} 0.288 {\textbar} median r {\textbar} {\textbar} 2 {\textbar} 0.455 {\textbar} 0.145 {\textbar} 0.783 {\textbar} 0.459 {\textbar} 0.773 {\textbar} 0.258 {\textbar} 0.397 {\textbar} p {\textbar} {\textbar} 21 {\textbar} 4 {\textbar} 37 {\textbar} 22 {\textbar} 77 {\textbar} 44 {\textbar} 11 {\textbar} {SANS}, attention factor {\textbar} {\textbar} median {MSE} {\textbar} 0.513 {\textbar} 1.107 {\textbar} 0.545 {\textbar} 0.529 {\textbar} 0.436 {\textbar} 0.679 {\textbar} 0.388 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.550 {\textbar} 0.079 {\textbar} 0.558 {\textbar} 0.566 {\textbar} 0.607 {\textbar} 0.551 {\textbar} 0.698 {\textbar} p {\textbar} {\textbar} 31 {\textbar} 10 {\textbar} 16 {\textbar} 90 {\textbar} 93 {\textbar} 21 {\textbar} 75 {\textbar} {SANS}, anhedonia global {\textbar} {\textbar} median {MSE} {\textbar} 0.772 {\textbar} 1.314 {\textbar} 0.653 {\textbar} 0.916 {\textbar} 0.576 {\textbar} 0.513 {\textbar} 0.483 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.511 {\textbar} 0.262 {\textbar} 0.591 {\textbar} 0.521 {\textbar} 0.639 {\textbar} 0.717 {\textbar} 0.694 {\textbar} p {\textbar} {\textbar} 97 {\textbar} 16 {\textbar} 22 {\textbar} 57 {\textbar} 107 {\textbar} 94 {\textbar} 100 {\textbar} {SANS}, avolition global {\textbar} {\textbar} median {MSE} {\textbar} 1.175 {\textbar} 1.820 {\textbar} 0.459 {\textbar} 0.962 {\textbar} 0.211 {\textbar} 0.317 {\textbar} 0.357 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.514 {\textbar} 0.118 {\textbar} 0.736 {\textbar} 0.470 {\textbar} 0.827 {\textbar} 0.783 {\textbar} 0.653 {\textbar} p {\textbar} {\textbar} 41 {\textbar} 8 {\textbar} 126 {\textbar} 92 {\textbar} 67 {\textbar} 76 {\textbar} 8 {\textbar} {SANS}, blunt affect global {\textbar} {\textbar} median {MSE} {\textbar} 0.731 {\textbar} 1.282 {\textbar} 0.405 {\textbar} 0.646 {\textbar} 0.267 {\textbar} 0.244 {\textbar} 0.243 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.515 {\textbar} 0.217 {\textbar} 0.677 {\textbar} 0.597 {\textbar} 0.840 {\textbar} 0.862 {\textbar} 0.820 {\textbar} p {\textbar} {\textbar} 16 {\textbar} 30 {\textbar} 18 {\textbar} 89 {\textbar} 41 {\textbar} 104 {\textbar} 60 {\textbar} {SANS}, alogia global {\textbar} {\textbar} median {MSE} {\textbar} 0.381 {\textbar} 0.692 {\textbar} 0.256 {\textbar} 0.517 {\textbar} 0.258 {\textbar} 0.135 {\textbar} 0.306 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.563 {\textbar} 0.126 {\textbar} 0.450 {\textbar} 0.438 {\textbar} 0.651 {\textbar} 0.761 {\textbar} 0.542 {\textbar} p {\textbar} {\textbar} 54 {\textbar} 16 {\textbar} 21 {\textbar} 16 {\textbar} 26 {\textbar} 79 {\textbar} 13 {\textbar} {SANS}, attention global {\textbar} {\textbar} median {MSE} {\textbar} 1.149 {\textbar} 1.239 {\textbar} 0.845 {\textbar} 0.880 {\textbar} 0.289 {\textbar} 0.350 {\textbar} 0.593 {\textbar} score {\textbar} {\textbar} median r {\textbar} 2 {\textbar} 0.376 {\textbar} 0.185 {\textbar} 0.559 {\textbar} 0.374 {\textbar} 0.757 {\textbar} 0.723 {\textbar} 0.367 {\textbar} p {\textbar} {\textbar} 23 {\textbar} 8 {\textbar} 70 {\textbar} 56 {\textbar} 13 {\textbar} 49 {\textbar} 57 {\textbar} {TABLE} 15 {\textbar} {\textbar} Comparison of all Elastic Net Models using Full Feature Sets {\textbar} {\textbar} Scales\_ {\textbar} {\textbar} Scales\_ {\textbar} {\textbar} {sMRI}\_ {\textbar} Scales\_ {\textbar} {sMRI}\_ {\textbar} Predicted Scores {\textbar} {\textbar} Metric {\textbar} Scales {\textbar} {sMRI} {\textbar} {fMRI} {\textbar} {sMRI} {\textbar} {fMRI} {\textbar} {fMRI} {\textbar} {fMRI} {\textbar} Chapman Social Anhedonia {\textbar} {\textbar} {MSE} {\textbar} 23.597 {\textbar} 118.983 {\textbar} 60.536 {\textbar} 21.494 {\textbar} 39.454 {\textbar} 25.938 {\textbar} 25.641 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.539 {\textbar} −0.941 {\textbar} −0.255 {\textbar} 0.597 {\textbar} −0.443 {\textbar} 0.565 {\textbar} 0.293 {\textbar} Chapman Physical Anhedonia {\textbar} {\textbar} {MSE} {\textbar} 48.835 {\textbar} 69.992 {\textbar} 64.141 {\textbar} 36.425 {\textbar} 65.951 {\textbar} 25.679 {\textbar} 59.355 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.249 {\textbar} −1.046 {\textbar} −0.156 {\textbar} 0.052 {\textbar} −0.537 {\textbar} 0.435 {\textbar} 0.247 {\textbar} {HAMD}, total score {\textbar} {\textbar} {MSE} {\textbar} 77.891 {\textbar} 282.184 {\textbar} 164.331 {\textbar} 46.766 {\textbar} 161.696 {\textbar} 69.011 {\textbar} 86.035 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.474 {\textbar} −0.369 {\textbar} −0.110 {\textbar} 0.640 {\textbar} −0.235 {\textbar} 0.143 {\textbar} 0.210 {\textbar} {HAMD}, q1, 7, 8 sum score {\textbar} {\textbar} {MSE} {\textbar} 4.178 {\textbar} 3.786 {\textbar} 4.760 {\textbar} 3.286 {\textbar} 3.250 {\textbar} 4.631 {\textbar} 2.246 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.320 {\textbar} 0.242 {\textbar} −0.448 {\textbar} 0.637 {\textbar} −0.140 {\textbar} 0.244 {\textbar} 0.350 {\textbar} {HAMD}, q7 {\textbar} {\textbar} {MSE} {\textbar} 1.198 {\textbar} 1.945 {\textbar} 1.179 {\textbar} 1.052 {\textbar} 2.082 {\textbar} 1.430 {\textbar} 1.439 {\textbar} r {\textbar} {\textbar} 2 {\textbar} −0.053 {\textbar} −0.409 {\textbar} −1.543 {\textbar} 0.224 {\textbar} −0.407 {\textbar} −0.023 {\textbar} 0.162 {\textbar} {BPRS}, negative score {\textbar} {\textbar} {MSE} {\textbar} 0.504 {\textbar} 0.764 {\textbar} 0.678 {\textbar} 0.207 {\textbar} 0.461 {\textbar} 0.345 {\textbar} 0.632 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.037 {\textbar} −0.361 {\textbar} −0.564 {\textbar} 0.024 {\textbar} −0.104 {\textbar} −1.803 {\textbar} 0.219 {\textbar} {BPRS}, depression-anxiety score {\textbar} {\textbar} {MSE} {\textbar} 0.992 {\textbar} 1.606 {\textbar} 1.301 {\textbar} 0.610 {\textbar} 1.091 {\textbar} 0.929 {\textbar} 0.850 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.146 {\textbar} 0.060 {\textbar} −0.283 {\textbar} 0.580 {\textbar} −1.005 {\textbar} −0.164 {\textbar} −0.347 {\textbar} Hopkins, anxiety score {\textbar} {\textbar} {MSE} {\textbar} 0.105 {\textbar} 0.328 {\textbar} 0.343 {\textbar} 0.130 {\textbar} 0.261 {\textbar} 0.253 {\textbar} 0.213 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.324 {\textbar} −0.028 {\textbar} −0.110 {\textbar} 0.322 {\textbar} 0.031 {\textbar} −0.097 {\textbar} −0.510 {\textbar} Hopkins, depression score {\textbar} {\textbar} {MSE} {\textbar} 0.196 {\textbar} 0.310 {\textbar} 0.276 {\textbar} 0.208 {\textbar} 0.348 {\textbar} 0.224 {\textbar} 0.103 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.373 {\textbar} 0.019 {\textbar} −0.595 {\textbar} 0.229 {\textbar} −0.157 {\textbar} 0.290 {\textbar} 0.238 {\textbar} Bipolar {II}, mood score {\textbar} {\textbar} {MSE} {\textbar} 2.172 {\textbar} 11.538 {\textbar} 7.683 {\textbar} 1.809 {\textbar} 6.379 {\textbar} 2.426 {\textbar} 2.099 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.670 {\textbar} −0.282 {\textbar} −0.140 {\textbar} 0.676 {\textbar} −0.255 {\textbar} 0.579 {\textbar} 0.658 {\textbar} Bipolar {II}, anxiety score {\textbar} {\textbar} {MSE} {\textbar} 1.831 {\textbar} 3.432 {\textbar} 3.634 {\textbar} 1.815 {\textbar} 2.762 {\textbar} 1.200 {\textbar} 1.108 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.183 {\textbar} −0.115 {\textbar} 0.003 {\textbar} 0.624 {\textbar} −0.072 {\textbar} 0.473 {\textbar} 0.387 {\textbar} {SANS}, anhedonia factor score {\textbar} {\textbar} {MSE} {\textbar} 2.195 {\textbar} 2.619 {\textbar} 1.974 {\textbar} 1.724 {\textbar} 0.975 {\textbar} 1.499 {\textbar} 1.464 {\textbar} r {\textbar} {\textbar} 2 {\textbar} −0.328 {\textbar} −1.457 {\textbar} −0.254 {\textbar} −0.092 {\textbar} 0.053 {\textbar} −0.039 {\textbar} 0.154 {\textbar} {SANS}, avolition factor score {\textbar} {\textbar} {MSE} {\textbar} 1.446 {\textbar} 1.203 {\textbar} 1.682 {\textbar} 1.023 {\textbar} 0.646 {\textbar} 0.935 {\textbar} 0.585 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.007 {\textbar} −0.326 {\textbar} −0.490 {\textbar} −0.097 {\textbar} −0.292 {\textbar} −0.238 {\textbar} 0.354 {\textbar} {SANS}, blunt affect factor score {\textbar} {\textbar} {MSE} {\textbar} 0.564 {\textbar} 1.736 {\textbar} 0.396 {\textbar} 0.809 {\textbar} 0.472 {\textbar} 0.997 {\textbar} 0.381 {\textbar} r {\textbar} {\textbar} 2 {\textbar} −0.666 {\textbar} −0.339 {\textbar} −0.896 {\textbar} 0.256 {\textbar} −0.249 {\textbar} −0.204 {\textbar} −2.057 {\textbar} {SANS}, alogia factor score {\textbar} {\textbar} {MSE} {\textbar} 0.552 {\textbar} 0.285 {\textbar} 0.365 {\textbar} 0.483 {\textbar} 0.242 {\textbar} 1.137 {\textbar} 0.505 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.009 {\textbar} −0.088 {\textbar} −0.591 {\textbar} −0.005 {\textbar} −1.901 {\textbar} −0.517 {\textbar} −0.014 {\textbar} {SANS}, attention factor score {\textbar} {\textbar} {MSE} {\textbar} 1.343 {\textbar} 1.985 {\textbar} 1.573 {\textbar} 1.282 {\textbar} 2.240 {\textbar} 2.140 {\textbar} 1.794 {\textbar} r {\textbar} {\textbar} 2 {\textbar} −0.094 {\textbar} −0.502 {\textbar} −0.244 {\textbar} −0.431 {\textbar} −0.327 {\textbar} −0.850 {\textbar} −0.305 {\textbar} {SANS}, anhedonia global score {\textbar} {\textbar} {MSE} {\textbar} 2.081 {\textbar} 2.232 {\textbar} 2.138 {\textbar} 2.234 {\textbar} 2.147 {\textbar} 2.496 {\textbar} 1.920 {\textbar} r {\textbar} {\textbar} 2 {\textbar} 0.022 {\textbar} −0.395 {\textbar} −0.244 {\textbar} −0.018 {\textbar} −0.227 {\textbar} −0.697 {\textbar} 0.122 {\textbar} {SANS}, avolition global score {\textbar} {\textbar} {MSE} {\textbar} 2.720 {\textbar} 2.947 {\textbar} 1.774 {\textbar} 2.670 {\textbar} 0.923 {\textbar} 1.217 {\textbar} 1.698 {\textbar} r {\textbar} {\textbar} 2 {\textbar} −0.441 {\textbar} −0.326 {\textbar} 0.050 {\textbar} −0.318 {\textbar} 0.222 {\textbar} −0.753 {\textbar} −0.132 {\textbar} {SANS}, blunt affect global score {\textbar} {\textbar} {MSE} {\textbar} 1.611 {\textbar} 2.108 {\textbar} 1.737 {\textbar} 1.064 {\textbar} 0.810 {\textbar} 1.251 {\textbar} 0.629 {\textbar} r {\textbar} {\textbar} 2 {\textbar} −0.184 {\textbar} −1.010 {\textbar} −0.083 {\textbar} 0.288 {\textbar} −0.672 {\textbar} 0.243 {\textbar} 0.085 {\textbar} {SANS}, alogia global score {\textbar} {\textbar} {MSE} {\textbar} 0.790 {\textbar} 1.879 {\textbar} 1.408 {\textbar} 1.154 {\textbar} 0.746 {\textbar} 0.789 {\textbar} 0.901 {\textbar} r {\textbar} {\textbar} 2 {\textbar} −0.926 {\textbar} −0.566 {\textbar} −0.469 {\textbar} −0.273 {\textbar} −0.541 {\textbar} −0.325 {\textbar} −0.802 {\textbar} {SANS}, attention global score {\textbar} {\textbar} {MSE} {\textbar} 3.080 {\textbar} 1.995 {\textbar} 2.191 {\textbar} 1.911 {\textbar} 1.207 {\textbar} 1.045 {\textbar} 2.996 {\textbar} r {\textbar} {\textbar} 2 {\textbar} −0.721 {\textbar} −0.163 {\textbar} −0.287 {\textbar} −0.250 {\textbar} −0.016 {\textbar} −0.129 {\textbar} −1.084 {\textbar} Weaker models were filtered out by first examining which model algorithm gave the best r {\textbar} {\textbar} 2 {\textbar} metric across the outcome variables for each predictor variable. Not only did Elastic Net perform the best according to this criteria (73\% won), but it also returns the most interpretable features (for methodological reasons as discussed herein). Then for each outcome variable the r {\textbar} 2 {\textbar} across different predictor variable sets were compared (e.g., Table 14). Overall, both scales+{fMRI} and scales+{sMRI}+{fMRI} input sets had the majority of, but an equal number of, winning models based on r {\textbar} 2 {\textbar} (seven winning models each). All other models performed relatively well except {sMRI}-only models. For comparison with the modeling results using the full feature sets (not the truncated sets returned by the forward modeling approach), as shown in Table 15. These were suboptimal to the forward modeling approach. The features returned for one of the winning sets were further examined. Those models used all three features types as input. {\textbar} Referring to {\textbar} {\textbar} {FIGS}. 9A-12H {\textbar} , for the 21 models with Scales+{sMRI}+{fMRI} input feature set, model performance was evaluated on the held-out test set with measured versus predicted plots. {\textbar} {FIGS}. 9A-9F {\textbar} illustrate measured versus predicted values for best models for depression or depressed mood, according to some implementations of the present disclosure. The measured versus predicted outcome scores (right) illustrate how closely the model predictions are to actual outcome scores for individuals in the held-out sample for this set of models. Held-out sample sizes differ between models since some scales were not given to all participants (e.g., the {SANS} scale was only given to {BD} and {SZ} patients). Similar to {\textbar} {FIG}. 9A-9F {\textbar} , {\textbar} {FIGS}. 10A-10E {\textbar} illustrate measured versus predicted values for best models for anhedonia; {\textbar} {FIG}. 11A-11B {\textbar} illustrate measured versus predicted values for best models for anxiety; and {\textbar} {FIGS}. 12A-12H {\textbar} illustrate measured versus predicted values for best models for negative symptoms. {\textbar} Referring to {\textbar} {\textbar} {FIG}. 13 {\textbar} , for the 21 models with Scales+{sMRI}+{fMRI} input feature set, model performance was evaluated on the held-out test set with r {\textbar} 2 {\textbar} values across models for different outcome variables (see Table 14—last column). {\textbar} {FIG}. 13 {\textbar} illustrates best median r {\textbar} 2 {\textbar} for the best models for each outcome variable. Models selected were using Scales+{sMRI}+{fMRI} as the input feature set and Elastic Net. Next to each outcome variable, the corresponding number of non-zero features (p) returned by the model appears. {\textbar} Next, turning to {\textbar} {\textbar} {FIGS}. 14A-14B {\textbar} , proportions of features derived from scale, {fMRI}, and {sMRI} feature sets were compared, for the best model for each outcome variable, both among the whole feature set and the top 25\% of features. {\textbar} {FIGS}. 14A-14B {\textbar} illustrate proportions of feature types in best models. More specifically, {\textbar} {FIG}. 14A {\textbar} illustrates proportion of all features returned by the model. The densest hatching plots proportion of features from scales; the hatching with medium density plots proportion from {fMRI} connectivity measures; and the least dense hatching plots proportion from {sMRI} measures. {\textbar} {FIG}. 14B {\textbar} illustrates proportion of feature types in the top 25\% of features returned by the model. Thus, {\textbar} {FIG}. 14B {\textbar} demonstrates that for many outcome variables there is a disproportionate number of scale features in the top features though there are more {fMRI} features overall in the models (see {\textbar} {FIG}. 14A {\textbar} ). {\textbar} There is a paucity of {sMRI} features in both the whole feature set and the top quarter of features. Groupings of the scale-based features were further examined. The groups were sorted by proportion of the scales from which they are derived. For each model, grouped by symptom type of the outcome variable, the scale features for the best model are proportionately selected from the scales shown in {\textbar} {\textbar} {FIGS}. 15A-18G {\textbar} . The {TCI} scale in particular is often represented among the top scales by proportion. {\textbar} Referring now to {\textbar} {\textbar} {FIGS}. 15A-15F {\textbar} , proportions of features from each scale are illustrated, for best model predicting depression or depressed mood. Of the features returned by the best model that were scale items, each pie chart illustrates the proportion of those items that were from the corresponding scales for the model for each outcome variable. For example, for the {SANS}, global blunt affect model, 20\% of the scale items were from the {TCI} scale, 20\% from the chapper scale, 20\% from the chapsoc scale, and 40\% from the Eysenck scale. Similar to {\textbar} {FIGS}. 15A-15F {\textbar} , {\textbar} {FIGS}. 16A-16E {\textbar} illustrate proportions of features from each scale for best model predicting anhedonia; {\textbar} {FIGS}. 17A-17B {\textbar} illustrate proportions of features from each scale for best model predicting anxiety; and {\textbar} {FIGS}. 18A-18G {\textbar} illustrate proportion of features from each scale for best model predicting negative symptoms. {\textbar} Turning generally to {\textbar} {\textbar} {FIGS}. 19A-22H {\textbar} , the {fMRI} features can also be grouped by suggested canonical resting-state networks from the Power atlas and are shown in the connectivity matrices, according to some implementations of the present disclosure. More specifically, {\textbar} {FIGS}. 19A-19F {\textbar} illustrate binary heat maps for {fMRI} connectivity features of best model predicting depression or depressed mood. For all non-zero {fMRI} connectivity features returned by the respective model, the regression coefficients for each individual edge between two nodes is plotted in the connectivity matrix for that model. Each row and column represents a single {ROI} from the Power atlas, ordered consistently in both directions. Coefficients have been binarized (positive plotted as stars, negative as circles) for easier viewing of sparse matrices. Upper and lower triangles illustrate redundant information, so only upper triangles are plotted. Lines delineate canonical resting state networks for easier visualization of network category for each feature. Similar to {\textbar} {FIGS}. 19A-22H {\textbar} , {\textbar} {FIGS}. 20A-20E {\textbar} illustrate binary heat maps for {fMRI} connectivity features of best model predicting anhedonia; {\textbar} {FIGS}. 21A-21B {\textbar} illustrate binary heat maps for {fMRI} connectivity features of best model predicting anxiety; and {\textbar} {FIGS}. 22A-22H {\textbar} illustrate binary heat maps for {fMRI} connectivity features of best model predicting negative symptoms. {\textbar} Binarized versions of the regression coefficients (pos→1, neg→−1) are plotted for better visualization of the location of features across the networks. Connectivity matrices have the same {ROIs} and networks listed on both axes, and the lower left triangle is redundant to the upper right triangle. Thus data is only plotted in the upper triangle. The predictive {fMRI} connectivity features appear mostly distributed across multiple networks rather than selective to a few particular networks. The exception for a few outcome variables (‘hamd,’ ‘sans\_global\_bluntaffect,’ ‘chapsoc,’ ‘sans\_global\_anhedonia,’ and ‘sans\_factor\_avolition’) is in connectivity between the {DMN} and other networks. In particular, the predictive edges between the {DMN} and other networks mostly originate from the anterior cingulate and/or the medial orbitofrontal lobe. {\textbar} {\textbar} Since the number of samples used in each model varied based on the number of subjects who completed a particular scale and the number of dropped subjects due to poor quality (did not pass {QC}), some models were built with as few as n=38 subjects (the {SANS} models with all three input types). To examine if the results could be due to overfitting, r {\textbar} {\textbar} 2 {\textbar} was further compared for just p=32 and 64 features to look at cases where overfitting is less likely (p0.5 suggesting that overfitting is not the major contributor to the high predictability of these models. Thus, predictive value was still largely high with r {\textbar} 2 {\textbar} values mostly {\textgreater}0.5 for these models, suggesting that performance in the best models is likely not solely due to overfitting. {\textbar} In addition, according to some implementations of the present disclosure, the models with the least complexity are scales-only models. Results for this set of models is shown in {\textbar} {\textbar} {FIGS}. 24A-27H {\textbar} . (See Table 14 for metrics of scales-only models). More specifically, {\textbar} {FIGS}. 24A-24F {\textbar} illustrate proportions of features from each scale for the scales-only model predicting depression or depressed mood The model using Elastic Net with the median r {\textbar} 2 {\textbar} value was chosen for this further examination. {\textbar} {FIGS}. 25A-25E {\textbar} {\textbar} illustrate proportions of features from each scale for scales-only model predicting anhedonia, according to some implementations of the present disclosure; {\textbar} {FIGS}. 26A-26B {\textbar} {\textbar} illustrate proportions of features from each scale for scales-only model predicting anxiety, according to some implementations of the present disclosure; {\textbar} {FIGS}. 27A-27H {\textbar} {\textbar} illustrate proportions of features from each scale for scales-only model predicting negative symptoms, according to some implementations of the present disclosure; {\textbar} Additional Information {\textbar} {\textbar} According to some implementations of the present disclosure, biomarkers were explored for severity of various psychiatric symptoms including depression, anxiety, anhedonia, and other negative symptoms in a transdiagnostic sample. An importance-ranked, forward selection modeling approach was applied to search for the most predictive input features from a set of clinical scale measures, structural {MRI} measures, and functional {MRI} measures and to evaluate several different modeling algorithms. Notably, this data-driven methods of selecting feature subsets additionally improved model predictability over models using the whole feature set. Overall, Elastic Net regression with multi-modal inputs, either all three input feature types or a combination of scale scores and {fMRI} connectivity measures, preformed the best. These models explained the most variance in the outcome measures which were a range of total scores of a scale, scores from a subset of questions from a scale, or individual question scores from a scale for the symptoms evaluated. {\textbar} {\textbar} Elastic Net regression returns regression coefficients which can be examined for further interpretation of biomarkers. The magnitude of the non-zero coefficients included in the best models were evaluated to parse out the features. Overall, the individual, edge-level {fMRI} connectivity measures between specific network nodes dominated in nearly all of the regression models for different symptom measures, but responses to individual questions in self-report clinical scales were also highly predictive. {sMRI} measures were not well-represented among the essential features in our models. Scale features also tended to be more highly represented in the top 25\% of features than in the whole set of features returned by the models, though this was not the case for every outcome variable. Thus, their relative importance may be higher than {fMRI} features, though clearly the multi-modal models performed better than scales-only models suggesting an additive effect to the multi-modal models. Therefore, a comparison of different feature types in transdiagnostic was disclosed, along with identifying a community-based symptom severity biomarker. {\textbar} {\textbar} The categorical origins of the clinical scale features and {fMRI} features for these models were further investigated. Within each symptom grouping (depression/mood, anxiety, anhedonia, negative symptoms) of the outcome variables, there was also some similarity in the scales from which they were drawn as many included items from the {TCI} scale, Hopkins Symptom Checklist, and several Chapman scales. The {TCI} scale in particular was consistently among the top three scales in predicting all but one outcome variable for depression, anxiety, and anhedonia. This scale measures temperaments such as harm avoidance and novelty seeking which are associated with depression and anxiety. {\textbar} {\textbar} The number of scales from which predictor variables were drawn also seemed to correspond to how broad the outcome variable was. For example, ‘hamd,’ ‘chapphy,’ and ‘chapsoc’ outcome variables were all total scores from their respective scales, and their models drew features from more scales than models predicting sub-scores or individual item scores (such as ‘sans\_factor\_bluntaffect’ or ‘hamd7’). This may suggest that predicting more narrowly-defined outcome scores utilizes less scales and may require administration of few scales to patients for optimal modeling at least within multi-modal datasets. {\textbar} {\textbar} Assessing the categorical groupings of importance-ranked {fMRI} connectivity features for each model was done according to canonical resting-state networks of the Power atlas. This analysis demonstrated that these highly-predictive features are distributed across many networks in many of our models. This may have the implication that it is useful for examining connections between individual nodes when creating models instead of relying solely upon summary metrics of networks such as graph theory metrics. {\textbar} {\textbar} In several models (‘hamd,’ ‘sans\_global\_bluntaffect,’ ‘chapsoc,’ ‘sans\_global\_anhedonia,’ and ‘sans\_factor\_avolition’), some pattern of connectivity between the default mode network ({DMN}) and other networks did emerge as an important set of predictor variables. In particular, the predictive edges between the {DMN} and other networks mostly originate from the anterior cingulate and/or the medial orbitofrontal lobe, regions that have previously been implicated in anhedonia. In addition, {DMN} connectivity is associated with depressive and negative symptoms. {DMN} variability increases in {SZ} patients with depression and correlates with this symptom score. Additionally, hypoconnectivity in the {DMN} is found in patients with {SZ} and psychotic bipolar disorder where connectivity was negatively correlated with negative. {DMN} within- and between-network connectivity is also altered in mood and psychotic disorders and tied to reduced reward responsiveness (a proxy for anhedonia). {\textbar} {\textbar} The present disclosure includes a data-driven method to search for improved biomarkers and to show the representation of the most predictive features at a high level. Other high-dimensional datasets, such as genetic expression data, may also benefit from an importance-weighted forward modeling approach to find which genes are most predictive of which symptoms. Clustering methods can provide one way to reduce the dimensionality by grouping genes by similarity. Feature selection may also benefit from grouping or selecting variables by predictability rather than similarity. While cross-validation on held-out test sets is meant to minimize overfitting, some models returned p{\textgreater}n and thus may still be susceptible to overfitting. But models which perform feature selection such as Elastic Net are designed to work on problems where p{\textgreater}{\textgreater}n and may help to reduce overfitting. {\textbar} {\textbar} Additional Embodiments {\textbar} {\textbar} Further aspects of the present disclosure include the following method: Clinical scale data, resting-state functional-{MRI} data, and structural-{MRI} scans are received for multiple patients with schizophrenia, bipolar disorder, attention deficit and hyperactivity disorder (“{ADHD}”), or healthy controls. The received data are preprocessed. At least one logistic regression model of features in the received data is generated. A set of predictive phenotypic features in the received data is generated based on weights generated from the at least one logistic regression model. {\textbar} {\textbar} Additional aspects of the present disclosure include the following computing system: A computer system includes at least one database, a memory, and a processor. The at least one database stores clinical scale data, resting-state functional-{MRI} data, and structural-{MRI} scans for multiple patients with schizophrenia, bipolar disorder, {ADHD}, or healthy controls. The memory stores computer instructions. The processor is configured to execute the computer instructions to preprocess the data stored in the at least one database. At least one logistic regression model of features in the received data is generated. A set of predictive phenotypic features in the received data is generated based on weights generated from the at least one logistic regression model. {\textbar} {\textbar} Still further aspects of the present disclosure include a system for evaluating a patient for mental health issues. The system includes a display, a user interface, a memory, and a control system. The memory contains machine readable medium. The machine readable medium includes machine executable code storing instructions for performing a method. The control system is coupled to the memory, and includes one or more processors. The control system is configured to execute the machine executable code to cause the control system to perform the method: On the display, a series of questions is displayed. The series of questions is from mental health questionnaires. The series of questions includes text and answers for each question. From the user interface, a selection of answers is received from a patient of each of the series of questions. A set of {MRI} data output is received after scanning the patient's brain using magnetic resonance imaging. Using a machine learning model, the selection of answers and the set of {MRI} data are processed to output an indication of the mental health of the patient. In some aspects, the mental health includes neuropsychiatric disorders, schizophrenia, and bi-polar disorder. {\textbar} {\textbar} Still additional aspects of the present disclosure include a machine learning based approach to build robust data-driven transdiagnostic classifiers to distinguish {SCZ}, {BD}, and {ADHD} patients from healthy controls ({HCs}) based on the openly available {CNP} dataset is described. Multiple data modalities are utilized, including clinical behavioral/symptom phenotypes and neuroimaging data ({sMRI} and {fMRI}) to obtain the optimal transdiagnostic models. Specifically, feature-importance guided sequential model selection approach is adopted in which classifiers were first built based on full sets of features to extract the feature importance and then from which a series of truncated models were built and evaluated to obtain the model producing the best performance. All transdiagnostic classifiers achieved very high performance in classifying various patient cohorts from healthy controls. More importantly, this feature and model selection approach not only allowed for the finding of the most robust transdiagnostic classifier but also identify the corresponding subset of most predictive features shared commonly across {SCZ}, {BD}, and {ADHD} patients. These shared features are reported and the identified latent abnormal psychopathological structure across these psychiatric disorders is discussed. {\textbar} {\textbar} Although the present disclosure provides for models trained on the {CNP} database, the present disclosure contemplates that any database comprising clinical scales data and {MRI} data can be used to produce models, as would be readily contemplated by one skilled in the art. {\textbar} {\textbar} The disclosed models selected as informative the features which trend in the same direction for all participants. The present disclosure contemplates that brain activity can be examined which diverges between patient groups; such an approach can yield other features. {\textbar} {\textbar} Although the present disclosure discusses input primarily in terms of {fMRI} data and {sMRI} data, other embodiments can provide for receiving rs-{fMRI}. {\textbar} {\textbar} Altogether, the present disclosure provides a data-driven way to improve biomarker development for predicting symptom severity transdiagnostically and can be used in a personalized medicine approach in diagnosing and treating behavioral disorders. {\textbar} {\textbar} Machine Learning Implementation {\textbar} {\textbar} Various aspects of the present disclosure can be performed by a machine-learning algorithm, as readily understood by a person skilled in the art. In some examples, step {\textbar} {\textbar} 2940 {\textbar} of {\textbar} {FIG}. 29 {\textbar} and methodology {\textbar} 3000 {\textbar} of {\textbar} {FIG}. 30 {\textbar} can be performed by a supervised or unsupervised algorithm. For instance, the system may utilize more basic machine learning tools including 1) decision trees (“{DT}”), (2) Bayesian networks (“{BN}”), (3) artificial neural network (“{ANN}”), or (4) support vector machines (“{SVM}”). In other examples, deep learning algorithms or other more sophisticated machine learning algorithms, e.g., convolutional neural networks (“{CNN}”), or capsule networks (“{CapsNet}”) may be used. {\textbar} {DT} are classification graphs that match input data to questions asked at each consecutive step in a decision tree. The {DT} program moves down the “branches” of the tree based on the answers to the questions (e.g., First branch: Did the clinical scales data include certain input? yes or no. Branch two: Did the {MRI} data include certain features? yes or no, etc.). {\textbar} {\textbar} Bayesian networks (“{BN}”) are based on likelihood something is true based on given independent variables and are modeled based on probabilistic relationships. {BN} are based purely on probabilistic relationships that determine the likelihood of one variable based on another or others. For example, {BN} can model the relationships between {MRI} data, clinical scales data, and any other information as contemplated by the present disclosure. Particularly, if a question type and particular features of the patient's {MRI} data are known, a {BN} can be used to compute a symptom severity indicator. Thus, using an efficient {BN} algorithm, an inference can be made based on the input data. {\textbar} {\textbar} Artificial neural networks (“{ANN}”) are computational models inspired by an animal's central nervous system. They map inputs to outputs through a network of nodes. However, unlike {BN}, in {ANN} the nodes do not necessarily represent any actual variable. Accordingly, {ANN} may have a hidden layer of nodes that are not represented by a known variable to an observer. {ANNs} are capable of pattern recognition. Their computing methods make it easier to understand a complex and unclear process that might go on during determining a symptom severity indicator based on a variety of input data. {\textbar} {\textbar} Support vector machines (“{SVM}”) came about from a framework utilizing of machine learning statistics and vector spaces (linear algebra concept that signifies the number of dimensions in linear space) equipped with some kind of limit-related structure. In some cases, they may determine a new coordinate system that easily separates inputs into two classifications. For example, a {SVM} could identify a line that separates two sets of points originating from different classifications of events. {\textbar} {\textbar} Deep neural networks ({DNN}) have developed recently and are capable of modeling very complex relationships that have a lot of variation. Various architectures of {DNN} have been proposed to tackle the problems associated with algorithms such as {ANN} by many researchers during the last few decades. These types of {DNN} are {CNN} (Convolutional Neural Network), {RBM} (Restricted Boltzmann Machine), {LSTM} (Long Short Term Memory) etc. They are all based on the theory of {ANN}. They demonstrate a better performance by overcoming the back-propagation error diminishing problem associated with {ANN}. {\textbar} {\textbar} Machine learning models require training data to identify the features of interest that they are designed to detect. For instance, various methods may be utilized to form the machine learning models, including applying randomly assigned initial weights for the network and applying gradient descent using back propagation for deep learning algorithms. In other examples, a neural network with one or two hidden layers can be used without training using this technique. {\textbar} {\textbar} In some examples, the machine learning model can be trained using labeled data, or data that represents certain user input. In other examples, the data will only be labeled with the outcome and the various relevant data may be input to train the machine learning algorithm. {\textbar} {\textbar} For instance, to determine whether particular mental health disorder fits the input data, various machine learning models may be utilized that input various data disclosed herein. In some examples, the input data will be labeled by having an expert in the field label the relevant regulations according to the particular situation. Accordingly, the input to the machine learning algorithm for training data identifies various data as from a healthy control or from a patient. {\textbar} {\textbar} Exemplary {NMR} System {\textbar} {\textbar} Referring now to {\textbar} {\textbar} {FIGS}. 31A-32 {\textbar} , the methods and embodiments of the present disclosure can be performed on an exemplary nuclear magnetic resonance (“{NMR} system”). As a person of ordinary skill in the art understands, {NMR} commonly refers to the hardware used to generate different types of scans, including {MRI} scans. Referring now to {\textbar} {FIGS}. 31A-32 {\textbar} , there is shown the major components of an {NMR} system which can be used to carry out the methods of the various embodiments. {\textbar} {FIG}. 32 {\textbar} shows the components of an exemplary transceiver for the {NMR} system of {\textbar} {FIGS}. 31A-31B {\textbar} . It should be noted that the methods of the various embodiments can also be carried out using other {NMR} systems. {\textbar} The operation of the system of {\textbar} {\textbar} {FIGS}. 31A-32 {\textbar} is controlled from an operator console {\textbar} 100 {\textbar} which includes a console processor {\textbar} 101 {\textbar} that scans a keyboard {\textbar} 102 {\textbar} and receives inputs from a human operator through a control panel {\textbar} 103 {\textbar} and a plasma display/touch screen {\textbar} 104 {\textbar} . The console processor {\textbar} 101 {\textbar} communicates through a communications link {\textbar} 116 {\textbar} with an applications interface module {\textbar} 117 {\textbar} in a separate computer system {\textbar} 107 {\textbar} . Through the keyboard {\textbar} 102 {\textbar} and controls {\textbar} 103 {\textbar} , an operator controls the production and display of images by an image processor {\textbar} 106 {\textbar} in the computer system {\textbar} 107 {\textbar} , which connects directly to a video display {\textbar} 118 {\textbar} on the console {\textbar} 100 {\textbar} through a video cable {\textbar} 105 {\textbar} . {\textbar} The computer system {\textbar} {\textbar} 107 {\textbar} is formed about a backplane bus which conforms with the {VME} standards, and it includes a number of modules which communicate with each other through this backplane. In addition to the application interface {\textbar} 117 {\textbar} and the image processor {\textbar} 106 {\textbar} , these include a {CPU} module {\textbar} 108 {\textbar} that controls the {VME} backplane, and an {SCSI} interface module {\textbar} 109 {\textbar} that connects the computer system {\textbar} 107 {\textbar} through a bus {\textbar} 110 {\textbar} to a set of peripheral devices, including disk storage {\textbar} 111 {\textbar} and tape drive {\textbar} 112 {\textbar} . The computer system {\textbar} 107 {\textbar} also includes a memory module {\textbar} 113 {\textbar} , known in the art as a frame buffer for storing image data arrays, and a serial interface module {\textbar} 114 {\textbar} that links the computer system {\textbar} 107 {\textbar} through a high speed serial link {\textbar} 115 {\textbar} to a system interface module {\textbar} 120 {\textbar} located in a separate system control cabinet {\textbar} 122 {\textbar} . {\textbar} The system control {\textbar} {\textbar} 122 {\textbar} includes a series of modules which are connected together by a common backplane {\textbar} 118 {\textbar} . The backplane {\textbar} 118 {\textbar} is comprised of a number of bus structures, including a bus structure which is controlled by a {CPU} module {\textbar} 119 {\textbar} . The serial interface module {\textbar} 120 {\textbar} connects this backplane {\textbar} 118 {\textbar} to the high speed serial link {\textbar} 115 {\textbar} , and pulse generator module {\textbar} 121 {\textbar} connects the backplane {\textbar} 118 {\textbar} to the operator console {\textbar} 100 {\textbar} through a serial link {\textbar} 125 {\textbar} . It is through this link {\textbar} 125 {\textbar} that the system control {\textbar} 122 {\textbar} receives commands from the operator which indicate the scan sequence that is to be performed. {\textbar} The pulse generator module {\textbar} {\textbar} 121 {\textbar} operates the system components to carry out the desired scan sequence. It produces data which indicates the timing, strength and shape of the {RF} pulses which are to be produced, and the timing of and length of the data acquisition window. The pulse generator module {\textbar} 121 {\textbar} also connects through serial link {\textbar} 126 {\textbar} to a set of gradient amplifiers {\textbar} 127 {\textbar} , and it conveys data thereto which indicates the timing and shape of the gradient pulses that are to be produced during the scan. The pulse generator module {\textbar} 121 {\textbar} also receives patient data through a serial link {\textbar} 128 {\textbar} from a physiological acquisition controller {\textbar} 129 {\textbar} . The physiological acquisition control {\textbar} 129 {\textbar} can receive a signal from a number of different sensors connected to the patient. For example, it may receive {ECG} signals from electrodes or respiratory signals from a bellows and produce pulses for the pulse generator module {\textbar} 121 {\textbar} that synchronizes the scan with the patient's cardiac cycle or respiratory cycle. And finally, the pulse generator module {\textbar} 121 {\textbar} connects through a serial link {\textbar} 132 {\textbar} to scan room interface circuit {\textbar} 133 {\textbar} which receives signals at inputs {\textbar} 135 {\textbar} from various sensors associated with the position and condition of the patient and the magnet system. It is also through the scan room interface circuit {\textbar} 133 {\textbar} that a patient positioning system {\textbar} 134 {\textbar} receives commands which move the patient cradle and transport the patient to the desired position for the scan. {\textbar} The gradient waveforms produced by the pulse generator module {\textbar} {\textbar} 121 {\textbar} are applied to a gradient amplifier system {\textbar} 127 {\textbar} comprised of Gx, Gy, and Gz amplifiers {\textbar} 136 {\textbar} , {\textbar} 137 {\textbar} and {\textbar} 138 {\textbar} , respectively. Each amplifier {\textbar} 136 {\textbar} , {\textbar} 137 {\textbar} , and {\textbar} 138 {\textbar} is utilized to excite a corresponding gradient coil in an assembly generally designated {\textbar} 139 {\textbar} . The gradient coil assembly {\textbar} 139 {\textbar} forms part of a magnet assembly {\textbar} 155 {\textbar} which includes a polarizing magnet {\textbar} 140 {\textbar} that produces a 1.5 Tesla polarizing field that extends horizontally through a bore. The gradient coils {\textbar} 139 {\textbar} encircle the bore, and when energized, they generate magnetic fields in the same direction as the main polarizing magnetic field, but with gradients Gx, Gy and Gz directed in the orthogonal x-, y- and z-axis directions of a Cartesian coordinate system. That is, if the magnetic field generated by the main magnet {\textbar} 140 {\textbar} is directed in the z direction and is termed {BO}, and the total magnetic field in the z direction is referred to as Bz, then Gx∂Bz/∂x, Gy=∂Bz/∂y and Gz=∂Bz/∂z, and the magnetic field at any point (x,y,z) in the bore of the magnet assembly {\textbar} 155 {\textbar} is given by B(x,y,z)=Bo+Gxx+{GyyGzz}. The gradient magnetic fields are utilized to encode spatial information into the {NMR} signals emanating from the patient being scanned. Because the gradient fields are switched at a very high speed when an {EPI} sequence is used to practice the preferred embodiment of the invention, local gradient coils are employed in place of the whole-body gradient coils {\textbar} 139 {\textbar} . These local gradient coils are designed for the head and are in close proximity thereto. This enables the inductance of the local gradient coils to be reduced and the gradient switching rates increased as required for the {EPI} pulse sequence. For a description of these local gradient coils which is incorporated herein by reference, see U.S. Pat. No. 5,372,137 issued on Dec. 13, 1994, and entitled “{NMR} Local Coil for Brain Imaging”. {\textbar} Located within the bore {\textbar} {\textbar} 142 {\textbar} is a circular cylindrical whole-body {RF} coil {\textbar} 152 {\textbar} . This coil {\textbar} 152 {\textbar} produces a circularly polarized {RF} field in response to {RF} pulses provided by a transceiver module {\textbar} 150 {\textbar} in the system control cabinet {\textbar} 122 {\textbar} . These pulses are amplified by an {RF} amplifier {\textbar} 151 {\textbar} and coupled to the {RF} coil {\textbar} 152 {\textbar} by a transmit/receive switch {\textbar} 154 {\textbar} which forms an integral part of the {RF} coil assembly. Waveforms and control signals are provided by the pulse generator module {\textbar} 121 {\textbar} and utilized by the transceiver module {\textbar} 150 {\textbar} for {RF} carrier modulation and mode control. The resulting {NMR} signals radiated by the excited nuclei in the patient may be sensed by the same {RF} coil {\textbar} 152 {\textbar} and coupled through the transmit/receive switch {\textbar} 154 {\textbar} to a preamplifier {\textbar} 153 {\textbar} . The amplified {NMR} signals are demodulated, filtered, and digitized in the receiver section of the transceiver {\textbar} 150 {\textbar} . {\textbar} The transmit/receive switch {\textbar} {\textbar} 154 {\textbar} is controlled by a signal from the pulse generator module {\textbar} 121 {\textbar} to electrically connect the {RF} amplifier {\textbar} 151 {\textbar} to the coil {\textbar} 152 {\textbar} during the transmit mode and to connect the preamplifier {\textbar} 153 {\textbar} during the receive mode. The transmit/receive switch {\textbar} 154 {\textbar} also enables a separate local {RF} head coil to be used in the transmit and receive mode to improve the signal-to-noise ratio of the received {NMR} signals. With currently available {NMR} systems such a local {RF} coil is preferred in order to detect small variations in {NMR} signal. Reference is made to the above cited U.S. Pat. No. 5,372,137 for a description of the preferred local {RF} coil. {\textbar} In addition to supporting the polarizing magnet {\textbar} {\textbar} 140 {\textbar} and the gradient coils {\textbar} 139 {\textbar} and {RF} coil {\textbar} 152 {\textbar} , the main magnet assembly {\textbar} 155 {\textbar} also supports a set of shim coils {\textbar} 156 {\textbar} associated with the main magnet {\textbar} 140 {\textbar} and used to correct inhomogeneities in the polarizing magnet field. The main power supply {\textbar} 157 {\textbar} is utilized to bring the polarizing field produced by the superconductive main magnet {\textbar} 140 {\textbar} to the proper operating strength and is then removed. {\textbar} The {NMR} signals picked up by the {RF} coil are digitized by the transceiver module {\textbar} {\textbar} 150 {\textbar} and transferred to a memory module {\textbar} 160 {\textbar} which is also part of the system control {\textbar} 122 {\textbar} . When the scan is completed and an entire array of data has been acquired in the memory modules {\textbar} 160 {\textbar} , an array processor {\textbar} 161 {\textbar} operates to Fourier transform the data into an array of image data. This image data is conveyed through the serial link {\textbar} 115 {\textbar} to the computer system {\textbar} 107 {\textbar} where it is stored in the disk memory {\textbar} 111 {\textbar} . In response to commands received from the operator console {\textbar} 100 {\textbar} , this image data may be archived on the tape drive {\textbar} 112 {\textbar} , or it may be further processed by the image processor {\textbar} 106 {\textbar} and conveyed to the operator console {\textbar} 100 {\textbar} and presented on the video display {\textbar} 118 {\textbar} as will be described in more detail hereinafter. {\textbar} Referring particularly to {\textbar} {\textbar} {FIG}. 32 {\textbar} , the transceiver {\textbar} 150 {\textbar} includes components which produce the {RF} excitation field B {\textbar} 1 {\textbar} through power amplifier {\textbar} 151 {\textbar} at a coil {\textbar} 152 {\textbar} A and components which receive the resulting {NMR} signal induced in a coil {\textbar} 152 {\textbar} B. As indicated above, the coils {\textbar} 152 {\textbar} A and B may be a single whole-body coil, but the best results are achieved with a single local {RF} coil specially designed for the head. The base or carrier frequency of the {RF} excitation field is produced under control of a frequency synthesizer {\textbar} 200 {\textbar} which receives a set of digital signals ({CF}) through the backplane {\textbar} 118 {\textbar} from the {CPU} module {\textbar} 119 {\textbar} and pulse generator module {\textbar} 121 {\textbar} . These digital signals indicate the frequency and phase of the {RF} carrier signal, which is produced at an output {\textbar} 201 {\textbar} . The commanded {RF} carrier is applied to a modulator and up converter {\textbar} 202 {\textbar} where its amplitude is modulated in response to a signal R(t) also received through the backplane {\textbar} 118 {\textbar} from the pulse generator module {\textbar} 121 {\textbar} . The signal R(t) defines the envelope, and therefore the bandwidth, of the {RF} excitation pulse to be produced. It is produced in the module {\textbar} 121 {\textbar} by sequentially reading out a series of stored digital values that represent the; desired envelope. These stored digital values may, in turn, be changed from the operator console {\textbar} 100 {\textbar} to enable any desired {RF} pulse envelope to be produced. The modulator and up converter {\textbar} 202 {\textbar} produces an {RF} pulse at the desired Larmor frequency at an output {\textbar} 205 {\textbar} . The magnitude of the {RF} excitation pulse output through line {\textbar} 205 {\textbar} is attenuated by an exciter attenuator circuit {\textbar} 206 {\textbar} which receives a digital command, {TA}, from the backplane {\textbar} 118 {\textbar} . The attenuated {RF} excitation pulses are applied to the power amplifier {\textbar} 151 {\textbar} that drives the {RF} coil {\textbar} 152 {\textbar} A. For a more detailed description of this portion of the transceiver {\textbar} 122 {\textbar} , reference is made to U.S. Pat. No. 4,952,877, which is incorporated herein by reference. {\textbar} Referring still to {\textbar} {\textbar} {FIGS}. 31A-32 {\textbar} , the {NMR} signal produced by the subject is picked up by the receiver coil {\textbar} 152 {\textbar} B and applied through the preamplifier {\textbar} 153 {\textbar} to the input of a receiver attenuator {\textbar} 207 {\textbar} . The receiver attenuator {\textbar} 207 {\textbar} further amplifies the {NMR} signal, and this is attenuated by an amount determined by a digital attenuation signal ({RA}) received from the backplane {\textbar} 118 {\textbar} . The receive attenuator {\textbar} 207 {\textbar} is also turned on and off by a signal from the pulse generator module {\textbar} 121 {\textbar} such that it is not overloaded during {RF} excitation. The received {NMR} signal is at or around the Larmor frequency, which in the preferred embodiment is around 63.86 {MHz} for 1.5 Tesla. This high-frequency signal is down-converted in a two-step process by a down converter {\textbar} 208 {\textbar} which first mixes the {NMR} signal with the carrier signal on line {\textbar} 201 {\textbar} and then mixes the resulting difference signal with the 2.5 {MHz} reference signal on line {\textbar} 204 {\textbar} . The resulting down-converted {NMR} signal on line {\textbar} 212 {\textbar} has a maximum bandwidth of 125 {kHz}, and it is centered at a frequency of 187.5 {kHz}. The down-converted {NMR} signal is applied to the input of an analog-to-digital (A/D) converter {\textbar} 209 {\textbar} , which samples and digitizes the analog signal at a rate of 250 {kHz}. The output of the A/D converter {\textbar} 209 {\textbar} is applied to a digital detector, and signal processor {\textbar} 210 {\textbar} which produce 16-bit in-phase (I) values and 16-bit quadrature (Q) values corresponding to the received digital signal. The resulting stream of digitized I and Q values of the received {NMR} signal is output through backplane {\textbar} 118 {\textbar} to the memory module {\textbar} 160 {\textbar} where they are employed to reconstruct an image. {\textbar} To preserve the phase information contained in the received {NMR} signal, both the modulator and up converter {\textbar} {\textbar} 202 {\textbar} in the exciter section and the down converter {\textbar} 208 {\textbar} in the receiver section are operated with common signals. More particularly, the carrier signal at the output {\textbar} 201 {\textbar} of the frequency synthesizer {\textbar} 200 {\textbar} and the 2.5 {MHz} reference signal at the output {\textbar} 204 {\textbar} of the reference frequency generator {\textbar} 203 {\textbar} are employed in both frequency conversion processes. Phase consistency is thus maintained, and phase changes in the detected {NMR} signal accurately indicate phase changes produced by the excited spins. The 2.5 {MHz} reference signal as well as 5, 10 and 60 {MHz} reference signals are produced by the reference frequency generator {\textbar} 203 {\textbar} from a common 20 {MHz} master clock signal. The latter three reference signals are employed by the frequency synthesizer {\textbar} 200 {\textbar} to produce the carrier signal on output {\textbar} 201 {\textbar} . For a more detailed description of the receiver, reference is made to U.S. Pat. No. 4,992,736, which is incorporated herein by reference. {\textbar} Computer \& Hardware Implementation of Disclosure {\textbar} {\textbar} It should initially be understood that the disclosure herein may be implemented with any type of hardware and/or software, and may be a pre-programmed general purpose computing device. For example, the system may be implemented using a server, a personal computer, a portable computer, a thin client, or any suitable device or devices. The disclosure and/or components thereof may be a single device at a single location, or multiple devices at a single, or multiple, locations that are connected together using any appropriate communication protocols over any communication medium such as electric cable, fiber optic cable, or in a wireless manner. {\textbar} {\textbar} It should also be noted that the disclosure is illustrated and discussed herein as having a plurality of modules which perform particular functions. It should be understood that these modules are merely schematically illustrated based on their function for clarity purposes only, and do not necessary represent specific hardware or software. In this regard, these modules may be hardware and/or software implemented to substantially perform the particular functions discussed. Moreover, the modules may be combined together within the disclosure, or divided into additional modules based on the particular function desired. Thus, the disclosure should not be construed to limit the present invention, but merely be understood to illustrate one example implementation thereof. {\textbar} {\textbar} The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some implementations, a server transmits data (e.g., an {HTML} page) to a client device (e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device). Data generated at the client device (e.g., a result of the user interaction) can be received from the client device at the server. {\textbar} {\textbar} Implementations of the subject matter described in this specification can be implemented in a computing system that includes a back-end component (e.g., as a data server) or a middleware component (e.g., an application server) or a front-end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification) or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“{LAN}”) and a wide area network (“{WAN}”), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks). {\textbar} {\textbar} Implementations of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Implementations of the subject matter described in this specification can be implemented as one or more computer programs (e.g., one or more modules of computer program instructions) encoded on computer storage medium for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions can be encoded on an artificially-generated propagated signal (e.g., a machine-generated electrical, optical, or electromagnetic signal) that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. A computer storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Moreover, while a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially-generated propagated signal. The computer storage medium can also be, or be included in, one or more separate physical components or media (e.g., multiple {CDs}, disks, or other storage devices). {\textbar} {\textbar} The operations described in this specification can be implemented as operations performed by a “data processing apparatus” on data stored on one or more computer-readable storage devices or received from other sources. {\textbar} {\textbar} The term “data processing apparatus” encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple ones, or combinations, of the foregoing The apparatus can include special purpose logic circuitry (e.g., an {FPGA} (field-programmable gate array) or an {ASIC} (application-specific integrated circuit)). The apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question (e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them). The apparatus and execution environment can realize various different computing model infrastructures, such as web services, distributed computing, and grid computing infrastructures. {\textbar} {\textbar} A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network. {\textbar} {\textbar} The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry (e.g., an {FPGA} (field-programmable gate array) or an {ASIC} (application-specific integrated circuit)). {\textbar} {\textbar} Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data (e.g., magnetic, magneto-optical disks, or optical disks). However, a computer need not have such devices. Moreover, a computer can be embedded in another device (e.g., a mobile telephone, a personal digital assistant ({PDA}), a mobile audio or video player, a game console, a Global Positioning System ({GPS}) receiver, or a portable storage device (e.g., a universal serial bus ({USB}) flash drive), to name just a few). Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices (e.g., {EPROM}, {EEPROM}, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and {CD}-{ROM} and {DVD}-{ROM} disks). The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. {\textbar} {\textbar} {CONCLUSION} {\textbar} {\textbar} The various methods and techniques described above provide a number of ways to carry out the invention. Of course, it is to be understood that not necessarily all objectives or advantages described can be achieved in accordance with any particular embodiment described herein. Thus, for example, those skilled in the art will recognize that the methods can be performed in a manner that achieves or optimizes one advantage or group of advantages as taught herein without necessarily achieving other objectives or advantages as taught or suggested herein. A variety of alternatives are mentioned herein. It is to be understood that some embodiments specifically include one, another, or several features, while others specifically exclude one, another, or several features, while still others mitigate a particular feature by inclusion of one, another, or several advantageous features. {\textbar} {\textbar} Furthermore, the skilled artisan will recognize the applicability of various features from different embodiments. Similarly, the various elements, features, and steps discussed above, as well as other known equivalents for each such element, feature or step, can be employed in various combinations by one of ordinary skill in this art to perform methods in accordance with the principles described herein. Among the various elements, features, and steps, some will be specifically included and others specifically excluded in diverse embodiments. {\textbar} {\textbar} Although the application has been disclosed in the context of certain embodiments and examples, it will be understood by those skilled in the art that the embodiments of the application extend beyond the specifically disclosed embodiments to other alternative embodiments and/or uses and modifications and equivalents thereof. {\textbar} {\textbar} In some embodiments, the terms “a” and “an” and “the” and similar references used in the context of describing a particular embodiment of the application (especially in the context of certain of the following claims) can be construed to cover both the singular and the plural. The recitation of ranges of values herein is merely intended to serve as a shorthand method of referring individually to each separate value falling within the range. Unless otherwise indicated herein, each individual value is incorporated into the specification as if it were individually recited herein. All methods described herein can be performed in any suitable order unless otherwise indicated herein or otherwise clearly contradicted by context. The use of any and all examples, or exemplary language (for example, “such as”) provided with respect to certain embodiments herein is intended merely to better illuminate the application and does not pose a limitation on the scope of the application otherwise claimed. No language in the specification should be construed as indicating any non-claimed element essential to the practice of the application. {\textbar} {\textbar} Certain embodiments of this application are described herein. Variations on those embodiments will become apparent to those of ordinary skill in the art upon reading the foregoing description. It is contemplated that skilled artisans can employ such variations as appropriate, and the application can be practiced otherwise than specifically described herein. Accordingly, many embodiments of this application include all modifications and equivalents of the subject matter recited in the claims appended hereto as permitted by applicable law. Moreover, any combination of the above-described elements in all possible variations thereof is encompassed by the application unless otherwise indicated herein or otherwise clearly contradicted by context. {\textbar} {\textbar} Particular implementations of the subject matter have been described. Other implementations are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. {\textbar} {\textbar} All patents, patent applications, publications of patent applications, and other material, such as articles, books, specifications, publications, documents, things, and/or the like, referenced herein are hereby incorporated herein by this reference in their entirety for all purposes, excepting any prosecution file history associated with same, any of same that is inconsistent with or in conflict with the present document, or any of same that may have a limiting affect as to the broadest scope of the claims now or later associated with the present document. By way of example, should there be any inconsistency or conflict between the description, definition, and/or the use of a term associated with any of the incorporated material and that associated with the present document, the description, definition, and/or the use of the term in the present document shall prevail. {\textbar} {\textbar} In closing, it is to be understood that the embodiments of the application disclosed herein are illustrative of the principles of the embodiments of the application. Other modifications that can be employed can be within the scope of the application. Thus, by way of example, but not of limitation, alternative configurations of the embodiments of the application can be utilized in accordance with the teachings herein. Accordingly, embodiments of the present application are not limited to that precisely as shown and described. {\textbar} {\textbar} While various examples of the present disclosure have been described above, it should be understood that they have been presented by way of example only, and not limitation. Numerous changes to the disclosed examples can be made in accordance with the disclosure herein without departing from the spirit or scope of the disclosure. Thus, the breadth and scope of the present disclosure should not be limited by any of the above described examples. Rather, the scope of the disclosure should be defined in accordance with the following claims and their equivalents. {\textbar} {\textbar} Although the disclosure has been illustrated and described with respect to one or more implementations, equivalent alterations and modifications will occur to others skilled in the art upon the reading and understanding of this specification and the annexed drawings. In addition, while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations, such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. {\textbar} {\textbar} The terminology used herein is for the purpose of describing particular examples only and is not intended to be limiting of the disclosure. As used herein, the singular forms “a,” “an,” and “the” are intended to include the plural forms as well, unless the context clearly indicates otherwise. Furthermore, to the extent that the terms “including,” “includes,” “having,” “has,” “with,” or variants thereof, are used in either the detailed description and/or the claims, such terms are intended to be inclusive in a manner similar to the term “comprising.” {\textbar} {\textbar} Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this disclosure belongs. Furthermore, terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art, and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein. {\textbar} {\textbar} {REFERENCES} {\textbar} {\textbar} 1. Anckarsater H, Stahlberg O, Larson T, Hakansson C, Jutblad S-B, Niklasson L, Nyden A, Wentz E, Westergren S, Cloninger C R, Gillberg C, Rastam M (2006) The Impact of {ADHD} and Autism Spectrum Disorders on Temperament, Character, and Personality Development. Am J Psychiat 163:1239-1244. {\textbar} {\textbar} 2. Anttila V et al. (2017) Analysis of shared heritability in common disorders of the brain. Biorxiv 360:048991. {\textbar} 3. Biswal, B. B., Mennes, M., Zuo, X.-N., Gohel, S., Kelly, C., Smith, S. M., . . . Milham, M. P. (2010). Toward discovery science of human brain function. {\textbar} Proceedings of the National Academy of Sciences {\textbar} , 107(10), 4734-4739. https://doi.org/10.1073/pnas.0911855107 (Original work published) {\textbar} 4. Breiman, L. (2001). Random Forests. {\textbar} Machine Learning {\textbar} , 45(1), 5-32. https://doi.org/10.1023/a:1010933404324 (Original work published) {\textbar} 5. Brodersen K H, Deserno L, Schlagenhauf F, Lin Z, Penny W D, Buhmann J M, Stephan K E (2014) Dissecting psychiatric spectrum disorders by generative embedding. Neuroimage Clin 4:98-111. {\textbar} 6. Bzdok D, Meyer-Lindenberg A (2017) Machine Learning for Precision Psychiatry: Opportunities and Challenges. Biological Psychiatry Cognitive Neurosci Neuroimaging. {\textbar} 7. Celikel, F., Kose, S., Cumurcu, B., Erkorkmaz, U., Sayar, K., Borckardt, J. J., \& Cloninger, R. C. (2009). Cloninger's temperament and character dimensions of personality in patients with major depressive disorder. {\textbar} Comprehensive Psychiatry {\textbar} , 50(6), 556-561. https://doi.org/10.1016/j.comppsych.2008.11.012 (Original work published) {\textbar} 8. Cenik, B., Cenik, C., Snyder, M. P., \& Brown, S. E. (2017). Plasma sterols and depressive symptom severity in a population-based cohort. {\textbar} {PLOS} {ONE} {\textbar} , 12(9), e0184382. https://doi.org/10.1371/journal.pone.0184382 (Original work published) {\textbar} 9. Clementz B A, Sweeney J A, Hamm J P, Ivleva E I, Ethridge L E, Pearlson G D, Keshavan M S, Tamminga C A (2016) Identification of Distinct Psychosis Biotypes Using Brain-Based Biomarkers. Am J Psychiat 173:373-384. {\textbar} 10. Cloninger C R, Bayon C, rakic D (1998) Measurement of temperament and character in mood disorders: a model of fundamental states as personality types. J Affect Disorders 51:21-32. {\textbar} 11. Cloninger, R. C., Svrakic, D. M., \& Przybeck, T. R. (1993). A Psychobiological Model of Temperament and Character. {\textbar} Archives of General Psychiatry {\textbar} , 50(12), 975-990. https://doi.org/10.1001/archpsyc.1993.01820240059008 (Original work published) {\textbar} 12. Consortium B et al. (2018) Genomic Dissection of Bipolar Disorder and Schizophrenia, Including 28 Subphenotypes. Cell 173:1705-1715.e16. {\textbar} 13. Consortium C-D (2013) Identification of risk loci with shared effects on five major psychiatric disorders: a genome-wide analysis. Lancet 381:1371-1379. {\textbar} 14. Consortium, T., Anttila, V., Bulik-Sullivan, B., Finucane, H. K., Walters, R. K., Bras, J., . . . Neale, B. M. (2018). Analysis of shared heritability in common disorders of the brain. {\textbar} Science {\textbar} , 360(6395), eaap8757. https://doi.org/10.1126/science.aap8757 (Original work published) {\textbar} 15. Cox, R. W. (1996). {AFNI}: Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages. {\textbar} Computers and Biomedical Research {\textbar} , 29(3), 162-173. https://doi.org/i0.1006/cbmr.1996.0014 (Original work published) {\textbar} 16. Desikan R S, Segonne F, Fischl B, Quinn B T, Dickerson B C, Blacker D, Buckner R L, Dale A M, Maguire P R, Hyman B T, Albert M S, Killiany R J (2006) An automated labeling system for subdividing the human cerebral cortex on {MRI} scans into gyral based regions of interest. Neuroimage 31:968-980. https://doi.org/10.1016/j.neuroimage.2006.01.021 (Original work published) {\textbar} 17. Dias T G, Iyer S P, Carpenter S D, Cary R P, Wilson V B, Mitchell S H, Nigg J T, Fair D A (2015) Characterizing heterogeneity in children with and without {ADHD} based on reward system connectivity. Dev Cogn Neurosci 11:155-174. {\textbar} 18. Doshi-Velez F, Ge Y, Kohane I (2014) Comorbidity Clusters in Autism Spectrum Disorders: An Electronic Health Record Time-Series Analysis. Pediatrics 133:e54-e63. {\textbar} 19. Drevets, W. C., Price, J. L., \& Furey, M. L. (2008). Brain structural and functional abnormalities in mood disorders: implications for neurocircuitry models of depression. {\textbar} Brain Structure and Function {\textbar} , 213(1-2), 93-118. https://doi.org/10.1007/s00429-008-0189-x (Original work published) {\textbar} 20. Drysdale A T et al. (2016) Resting-state connectivity biomarkers define neurophysiological subtypes of depression. Nat Med. {\textbar} 21. Dubois, J., \& Adolphs, R. (2016). Building a Science of Individual Differences from {fMRI}. {\textbar} Trends in Cognitive Sciences {\textbar} , 20(6), 425-443. https://doi.org/10.1016/j.tics.2016.03.014 (Original work published) {\textbar} 22. Eckblad M, Chapman L J (1986) Development and validation of a scale for hypomanic personality. J Abnorm Psychol 95:214. {\textbar} 23. Elliott M L, Romer A L, Knodt A R, Hariri A R (2018) A Connectome Wide Functional Signature of Transdiagnostic Risk for Mental Illness. Biorxiv:196220. {\textbar} 24. {ETTINGER} U, {JOOBER} R, {GUZMAN} R D, O'{DRISCOLL} G A (2006) Schizotypy, attention deficit hyperactivity disorder, and dopamine genes. Psychiat Clin Neuros 60:764-767. {\textbar} 25. Fischl B, Liu A, Dale A M (2001) Automated Manifold Surgery: Constructing Geometrically Accurate and Topologically Correct Models of the Human Cerebral Cortex. Ieee T Med Imaging 20:70. {\textbar} 26. Fischl B, Salat D H, Busa E, Albert M, Dieterich M, Haselgrove C, van der Kouwe A, Killiany R, Kennedy D, Klaveness S, Montillo A, Makris N, Rosen B, Dale A M (2002) Whole Brain Segmentation Automated Labeling of Neuroanatomical Structures in the Human Brain. Neuron 33:341-355. https://doi.org/10.1016/s0896-6273(02)00569-x (Original work published) {\textbar} 27. Fried, E. I., \& Nesse, R. M. (2015). Depression sum-scores don't add up: why analyzing specific depression symptoms is essential. {\textbar} {BMC} Medicine {\textbar} , 13(1). https://doi.org/i0.1186/si2916-015-0325-4 (Original work published) {\textbar} 28. Gandal M J, Haney J R, Parikshak N N, Leppa V, Ramaswami G, Hartl C, Schork A J, Appadurai V, Buil A, Werge T M, Liu C, White K P, Consortium C, Consortium P, Group {iPSYCH}-B, Horvath S, Geschwind D H (2018) Shared molecular neuropathology across major psychiatric disorders parallels polygenic overlap. Science 359:693-697. {\textbar} 29. Geisler D, Walton E, Naylor M, Roessner V, Lim K O, Schulz C S, Gollub R L, Calhoun V D, Sponheim S R, Ehrlich S (2015) Brain structure and function correlates of cognitive subtypes in schizophrenia. Psychiatry Res Neuroimaging 234:74-83. {\textbar} 30. Georgiades S, Szatmari P, Boyle M, Hanna S, Duku E, Zwaigenbaum L, Bryson S, Fombonne E, Volden J, Mirenda P, Smith I, Roberts W, Vaillancourt T, Waddell C, Bennett T, Thompson A, in Team P (2013) Investigating phenotypic heterogeneity in children with autism spectrum disorder: a factor mixture modeling approach. J Child Psychol Psyc 54:206-215. {\textbar} 31. Getz, G., Levine, E., \& Domany, E. (2000). Coupled two-way clustering analysis of gene microarray data. {\textbar} Proceedings of the National Academy of Sciences {\textbar} , 97(22), 12079-12084. https://doi.org/10.1073/pnas.210134797 (Original work published) {\textbar} 32. Gheiratmand M, Rish I, Cecchi G A, Brown M R, Greiner R, Polosecki P I, Bashivan P, Greenshaw A J, Ramasubbu R, Dursun S M (2017) Learning stable and predictive network-based patterns of schizophrenia and its clinical symptoms. Npj Schizophrenia 3:22. https://doi.org/10.1038/s41537-017-0022-8 (Original work published) {\textbar} 33. Golden R R, Meehl P E (1979) Detection of the schizoid taxon with {MMPI} indicators. J Abnorm Psychol 88:217. {\textbar} 34. Gotts, S. J., Simmons, K. W., Milbury, L. A., Wallace, G. L., Cox, R. W., \& Martin, A. (2012). Fractionation of social brain circuits in autism spectrum disorders. {\textbar} Brain {\textbar} , 135(9), 2711-2725. https://doi.org/10.1093/brain/aws160 (Original work published) {\textbar} 35. Grisanzio K A, Goldstein-Piekarski A N, Wang M, Ahmed A P, Samara Z, Williams L M (2017) Transdiagnostic Symptom Clusters and Associations With Brain, Behavior, and Daily Function in Mood, Anxiety, and Trauma Disorders. Jama Psychiatry. https://doi.org/10.1001/jamapsychiatry.2017.3951 (Original work published) {\textbar} 36. Grucza R A, Przybeck T R, Spitznagel E L, Cloninger C R (2003) Personality and depressive symptoms: a multi-dimensional analysis. J Affect Disorders 74:123-130. {\textbar} 37. Guillem F, Bicu M, Semkovska M, Debruille J B (2002) The dimensional symptom structure of schizophrenia and its association with temperament and character. Schizophr Res 56:137-147. {\textbar} 38. Hajirezaei S, Mohammadi A, Soleimani M, Rahiminezhad F, Mohammadi M, Cloninger R C (2017) Comparing the Profile of Temperament and Character Dimensions in Patients with Major Depressive Disorder and Bipolar Mood Disorder with a Control Group. Iranian J Psychiatry 12:147-153. {\textbar} 39. Hamshere M L, Stergiakouli E, Langley K, Martin J, Holmans P, Kent L, Owen M J, Gill M, Thapar A, O' Donovan M, Craddock N (2013) Shared polygenic contribution between childhood attention-deficit hyperactivity disorder and adult schizophrenia. Br J Psychiatry 203:107-111. {\textbar} 40. Harvey, P.-O., Pruessner, J., Czechowska, Y., \& Lepage, M. (2007). Individual differences in trait anhedonia: a structural and functional magnetic resonance imaging study in non-clinical subjects. {\textbar} Molecular Psychiatry {\textbar} , 12(8), 4002021. https://doi.org/10.1038/sj.mp.4002021 (Original work published) {\textbar} 41. Hastie, T., Tibshirani, R., \& Friedman, J. (2009). {\textbar} The elements ofstatistical learning: data mining, inference, and prediction {\textbar} (2nd ed.). New York: Springer. (Original work published) {\textbar} 42. Hori H, Noguchi H, Hashimoto R, Nakabayashi T, Saitoh O, Murray R M, Okabe S, Kunugi H (2008) Personality in schizophrenia assessed with the Temperament and Character Inventory ({TCI}). Psychiat Res 160:175-183. {\textbar} 43. Insel, T. R., \& Cuthbert, B. N. (2015). Brain disorders? Precisely. {\textbar} Science {\textbar} , 348(6234), 499-500. https://doi.org/10.1126/science.aab2358 (Original work published) {\textbar} 44. Jo H, Saad Z S, Simmons K W, Milbury L A, Cox R W (2010) Mapping sources of correlation in resting state {FMRI}, with artifact detection and removal. Neuroimage 52:571-582. https://doi.org/10.1016/j.neuroimage.2010.04.246 (Original work published) {\textbar} 45. Joyce, D. W., Kehagia, A. A., Tracy, D. K., Proctor, J., \& Shergill, S. S. (2017). Realising stratified psychiatry using multidimensional signatures and trajectories. {\textbar} Journal of Translational Medicine {\textbar} , 15(1), 15. https://doi.org/10.1186/si2967-016-1116-1 (Original work published) {\textbar} 46. Kanth Ryali, Chen T, Supekar K, Menon V (2012) Estimation of functional connectivity in {fMRI} data using stability selection-based sparse partial correlation with elastic net penalty. Neuroimage 59:3852-3861. {\textbar} 47. Kapur, S., Phillips, A., \& Insel, T. (2012). Why has it taken so long for biological psychiatry to develop clinical tests and what to do about it? {\textbar} Molecular Psychiatry {\textbar} , 17(12), 1174. https://doi.org/10.1038/mp.2012.105 (Original work published) {\textbar} 48. Keedwell, P. A., Andrew, C., Williams, S., Brammer, M. J., \& Phillips, M. L. (2005). The Neural Correlates of Anhedonia in Major Depressive Disorder. {\textbar} Biological Psychiatry {\textbar} , 58(11), 843-853. https://doi.org/10.1016/j.biopsych.2005.05.019 (Original work published) {\textbar} 49. Keshavan M S, Sujata M, Mehra A, Montrose D M, Sweeney J A (2003) Psychosis proneness and {ADHD} in young relatives of schizophrenia patients. Schizophr Res 59:85-92. {\textbar} 50. Kessler R, Gruber M, Hettema J, Hwang I, Sampson N, Yonkers K (2007) Co-morbid major depression and generalized anxiety disorders in the National Comorbidity Survey follow-up. Psychol Med 38:365-374. {\textbar} 51. Klassen L J, Katzman M A, Chokka P (2010) Adult {ADHD} and its comorbidities, with a focus on bipolar disorder. J Affect Disorders 124:1-8. {\textbar} 52. Kwapil T R, Miller M B, Zinser M C, Chapman L J, Chapman J, Eckblad M (2000) A longitudinal study of high scorers on the Hypomanic Personality Scale. J Abnorm Psychol 109:222. {\textbar} 53. Lamers F, Burstein M, He J, Avenevoli S, Angst J, Merikangas K R (2012) Structure of major depressive disorder in adolescents and adults in the U S general population. Br J Psychiatry 201:143-150. {\textbar} 54. Larsson H, Ryden E, Boman M, Längström N, Lichtenstein P, Landen M (2013) Risk of bipolar disorder and schizophrenia in relatives of people with attention-deficit hyperactivity disorder. Br J Psychiatry 203:103-106. {\textbar} 55. Lewandowski K, Sperry S, Cohen B, Öngür D (2014) Cognitive variability in psychotic disorders: a cross-diagnostic cluster analysis. Psychol Med 44:3239-3248. {\textbar} 56. Lo, A., Chernoff, H., Zheng, T., \& Lo, S.-H. (2015). Why significant variables aren't automatically good predictors. {\textbar} Proceedings of the National Academy of Sciences {\textbar} , 112(45), 13892-13897. https://doi.org/10.1073/pnas.1518285112 (Original work published) {\textbar} 57. Loo H M et al. (2014) {MAJOR} {DEPRESSIVE} {DISORDER} {SUBTYPES} {TO} {PREDICT} {LONG}-{TERM} {COURSE}. Depress Anxiety 31:765-777. {\textbar} 58. Lotan, A., Fenckova, M., Bralten, J., Alttoa, A., Dixson, L., Williams, R. W., \& van der Voet, M. (2014). Neuroinformatic analyses of common and distinct genetic components associated with major neuropsychiatric disorders. {\textbar} Frontiers in Neuroscience {\textbar} , 8, 331. https://doi.org/10.3389/fnins.2014.00331 (Original work published) {\textbar} 59. Lynn D E, Lubke G, Yang M, {McCracken} J T, {McGough} J J, Ishii J, Loo S K, Nelson S F, Smalley S L (2005) Temperament and Character Profiles and the Dopamine D4 Receptor Gene in {ADHD}. Am J Psychiat 162:906-913. {\textbar} 60. Martino, M., Magioncalda, P., Huang, Z., Conio, B., Piaggio, N., Duncan, N. W., . . . Northoff, G. (2016). Contrasting variability patterns in the default mode and sensorimotor networks balance in bipolar depression and mania. {\textbar} Proceedings of the National Academy of Sciences {\textbar} , 113(17), 4824-4829. https://doi.org/i0.1073/pnas.1517558113 (Original work published) {\textbar} 61. Mayberg, H. S., Liotti, M., Brannan, S. K., {McGinnis}, S., Mahurin, R. K., Jerabek, P. A., . . . Fox, P. T. (1999). Reciprocal Limbic-Cortical Function and Negative Mood: Converging {PET} Findings in Depression and Normal Sadness. {\textbar} American Journal of Psychiatry {\textbar} , 156(5), 675-682. https://doi.org/10.1176/ajp.156.5.675 (Original work published) {\textbar} 62. Meda, S. A., Ruaño, G., Windemuth, A., O'Neil, K., Berwise, C., Dunn, S. M., . . . Pearlson, G. D. (2014). Multivariate analysis reveals genetic associations of the resting default mode network in psychotic bipolar disorder and schizophrenia. {\textbar} Proceedings of the National Academy of Sciences {\textbar} , 111(19), E2066-E2075. https://doi.org/10.1073/pnas.1313093111 (Original work published) {\textbar} 63. Mostert J C, Hoogman M, Onnink M A, van Rooij D, von Rhein D, van Hulzen K J, Dammers J, Kan C C, Buitelaar J K, Norris D G, Franke B (2018) Similar Subgroups Based on Cognitive Performance Parse Heterogeneity in Adults With {ADHD} and Healthy Controls. J Atten Disord 22:281-292. {\textbar} 64. Nagel, M., Jansen, P. R., Stringer, S., Watanabe, K., de Leeuw, C. A., Bryois, J., . . . Posthuma, D. (2018). Meta-analysis of genome-wide association studies for neuroticism in 449,484 individuals identifies novel genetic loci and pathways. {\textbar} Nature Genetics {\textbar} , 50(7), 920-927. https://doi.org/10.1038/s41588-018-0151-7 (Original work published) {\textbar} 65. Nierenberg A A, Miyahara S, Spencer T, Wisniewski S R, Otto M W, Simon N, Pollack M H, Ostacher M J, Yan L, Siegel R, Sachs G S, Investigators S-B (2005) Clinical and Diagnostic Implications of Lifetime Attention-Deficit/Hyperactivity Disorder Comorbidity in Adults with Bipolar Disorder: Data from the First 1000 {STEP}-{BD} Participants. Biol Psychiat 57:1467-1473. {\textbar} 66. Öngür, D., Farabaugh, A., Iosifescu, D. V., Perlis, R., \& Fava, M. (2005). Tridimensional Personality Questionnaire Factors in Major Depressive Disorder: Relationship to Anxiety Disorder Comorbidity and Age of Onset. {\textbar} Psychotherapy and Psychosomatics {\textbar} , 74(3), 173-178. https://doi.org/10.1159/000084002 (Original work published) {\textbar} 67. Pallanti S, Salerno L (2015) Raising attention to attention deficit hyperactivity disorder in schizophrenia. World J Psychiatry 5:47-55. {\textbar} 68. Pan, P., Sato, J. R., Salum, G. A., Rohde, L. A., Gadelha, A., Zugman, A., . . . Stringaris, A. (2017). Ventral Striatum Functional Connectivity as a Predictor of Adolescent Depressive Disorder in a Longitudinal Community-Based Sample. {\textbar} American Journal of Psychiatry {\textbar} , 174(11), 1112-1119. https://doi.org/10.1176/appi.ajp.2017. Ser. No. 17/040,430 (Original work published) {\textbar} 69. Park M M, Raznahan A, Shaw P, Gogtay N, Lerch J P, Chakravarty M M (2018) Neuroanatomical phenotypes in mental illness: identifying convergent and divergent cortical phenotypes across autism, {ADHD} and schizophrenia. J Psychiatry Neurosci Jpn 43:201-212. {\textbar} 70. Pearlson G D (2015) Etiologic, Phenomenologic, and Endophenotypic Overlap of Schizophrenia and Bipolar Disorder. Annu Rev Clin Psycho 11:1-31. {\textbar} 71. Peralta V, de Jalón E, Campos M S, Zandio M, Sanchez-Torres A, Cuesta M J (2011) The meaning of childhood attention-deficit hyperactivity symptoms in patients with a first-episode of schizophrenia-spectrum psychosis. Schizophr Res 126:28-35. {\textbar} 72. Philippi, C. L., Motzkin, J. C., Pujara, M. S., \& Koenigs, M. (2015). Subclinical depression severity is associated with distinct patterns of functional connectivity for subregions of anterior cingulate cortex. {\textbar} Journal of Psychiatric Research {\textbar} , 71, 103-111. https://doi.org/10.1016/j.jpsychires.2015.10.005 (Original work published) {\textbar} 73. Poldrack R A, Congdon E, Triplett W, Gorgolewski K J, Karlsgodt K H, Mumford J A, Sabb F W, Freimer N B, London E D, Cannon T D, Bilder R M (2016) A phenome-wide examination of neural and cognitive function. {\textbar} Scientific Data {\textbar} , 3, 160110. https://doi.org/10.1038/sdata.2016.110 (Original work published) {\textbar} 74. Power J D, Cohen A L, Nelson S M, Wig G S, Barnes K, Church J A, Vogel A C, Laumann T O, Miezin F M, Schlaggar B L, Petersen S E (2011) Functional Network Organization of the Human Brain. Neuron 72:665-678. {\textbar} 75. Power, J. D., Cohen, A. L., Nelson, S. M., Wig, G. S., Barnes, K., Church, J. A., . . . Petersen, S. E. (2011). Functional Network Organization of the Human Brain. {\textbar} Neuron {\textbar} , 72(4), 665-678. https://doi.org/10.1016/j.neuron.2011.09.006 (Original work published) {\textbar} 76. Purcell S M et al. (2009) Common polygenic variation contributes to risk of schizophrenia and bipolar disorder. Nature 460:748. {\textbar} 77. Rhebergen D, Lamers F, Spijker J, de Graaf R, Beekman A, Penninx B (2011) Course trajectories of unipolar depressive disorders identified by latent class growth analysis. Psychol Med 42:1383-1396. {\textbar} 78. Rieder R O, Nichols P L (1979) Offspring of Schizophrenics {III}: Hyperactivity and Neurological Soft Signs. Arch Gen Psychiat 36:665-674. {\textbar} 79. Salgado C A I, Bau C H D, Grevet E H, Fischer A G, Victor M M, Kalil K L S, Sousa N O, Garcia C R, Belmonte-de-Abreu P (2009) Inattention and Hyperactivity Dimensions of {ADHD} Are Associated with Different Personality Profiles. Psychopathology 42:108-112. {\textbar} 80. Sharma, A., Wolf, D. H., Ciric, R., Kable, J. W., Moore, T. M., Vandekar, S. N., . . . Satterthwaite, T. D. (2017). Common Dimensional Reward Deficits Across Mood and Psychotic Disorders: A Connectome-Wide Association Study. {\textbar} American Journal of Psychiatry {\textbar} , 174(7), 657-666. https://doi.org/10.1176/appi.ajp.2016. Ser. No. 16/070,774 (Original work published) {\textbar} 81. Shen, X., Finn, E. S., Scheinost, D., Rosenberg, M. D., Chun, M. M., Papademetris, X., \& Constable, T. R. (2017). Using connectome-based predictive modeling to predict individual behavior from brain connectivity. {\textbar} Nature Protocols {\textbar} , 12(3), 506-518. https://doi.org/10.1038/nprot.2016.178 (Original work published) {\textbar} 82. Sun H, Lui S, Yao L, Deng W, Xiao Y, Zhang W, Huang X, Hu J, Bi F, Li T, Sweeney J A, Gong Q (2015) Two Patterns of White Matter Abnormalities in Medication-Naive Patients With First-Episode Schizophrenia Revealed by Diffusion Tensor Imaging and Cluster Analysis. Jama Psychiatry 72:678-686. {\textbar} 83. Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. {\textbar} Journal of the Royal Statistical Society, Series B {\textbar} , 58(1), 267-288. (Original work published) {\textbar} 84. van Hulst B, de Zeeuw P, Durston S (2014) Distinct neuropsychological profiles within {ADHD}: a latent class analysis of cognitive control, reward sensitivity and timing. Psychol Med 45:735-745. {\textbar} 85. van Hulzen K, Scholz C J, Franke B, Ripke S, Klein M, {McQuillin} A, Sonuga-Barke E J, Group P, Kelsoe J R, Landen M, Andreassen O A, Group P, Lesch K-P, Weber H, Faraone S V, Arias-Vasquez A, Reif A (2017) Genetic Overlap Between Attention-Deficit/Hyperactivity Disorder and Bipolar Disorder: Evidence From Genome-wide Association Study Meta-analysis. Biol Psychiat 82:634-641. {\textbar} 86. van Loo H M, de Jonge P, Romeijn J-W, Kessler R C, Schoevers R A (2012) Data-driven subtypes of major depressive disorder: a systematic review. Bmc Med 10:1-12. {\textbar} 87. Veatch O, Veenstra-{VanderWeele} J, Potter M, Pericak-Vance M, Haines J (2014) Genetically meaninngful phenotypic subgroups in autism spectrum disorders. {\textbar} Genes Brain Behav {\textbar} 13:276-285. {\textbar} 88. Wacker, J., Dillon, D. G., \& Pizzagalli, D. A. (2009). The role of the nucleus accumbens and rostral anterior cingulate cortex in anhedonia: Integration of resting {EEG}, {fMRI}, and volumetric techniques. {\textbar} {NeuroImage} {\textbar} , 46(1), 327-337. https://doi.org/10.1016/j.neuroimage.2009.01.058 (Original work published) {\textbar} 89. Wang H, Jung Y-E, Chung S-K, Hong J, Kang N, Kim M-D, Bahk W-M (2017) Prevalence and correlates of bipolar spectrum disorder comorbid with {ADHD} features in nonclinical young adults. J Affect Disorders 207:175-180. {\textbar} 90. {WILLIAM} B (2001) Schizophrenia and Attention Deficit Disorder. Ann Ny Acad Sci 931:239-250. {\textbar} 91. Woo, C.-W., Chang, L. J., Lindquist, M. A., \& Wager, T. D. (2017). Building better biomarkers: brain models in translational neuroimaging. {\textbar} Nature Neuroscience {\textbar} , 20(3), 365-377. https://doi.org/10.1038/nn.4478 (Original work published) {\textbar} 92. Xia, C., Ma, Z., Ciric, R., Gu, S., Betzel, R. F., Kaczkurkin, A. N., . . . Satterthwaite, T. D. (2018). Linked dimensions of psychopathology and connectivity in functional brain networks. {\textbar} Nature Communications {\textbar} , 9(1), 3003. https://doi.org/10.1038/s41467-018-05317-y (Original work published) {\textbar} 93. Yarkoni, T., \& Westfall, J. (2017). Choosing Prediction Over Explanation in Psychology: Lessons From Machine Learning. {\textbar} Perspectives on Psychological Science {\textbar} , 12(6), 1100-1122. https://doi.org/10.1177/1745691617693393 (Original work published) {\textbar} 94. Zou H, Hastie T (2005) Regularization and variable selection via the elastic net. {\textbar} Journal of the Royal Statistical Society {\textbar} : Series B (Statistical Methodology), 67(2), 301-320. https://doi.org/10.1111/j.1467-9868.2005.00503.x (Original work published)
Issue: {US}11244762B2},
}

@patent{muller-myhsok_etal15a,
	location = {{US}},
	title = {Genetic predictors of response to treatment with {CRHR}1 antagonists},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {The invention relates inter alia to methods for predicting the response of patients with depressive symptoms and/or anxiety symptoms to treatment with a {CRHR}1 antagonist, and algorithms, kits, microarrays, probes and or/primers for use in such methods.
The invention relates inter alia to methods for predicting the response of patients with depressive symptoms and/or anxiety symptoms to treatment with a {CRHR}1 antagonist, and algorithms, kits, microarrays, probes and or/primers for use in such methods.
The invention relates inter alia to methods for predicting the response of patients with depressive symptoms and/or anxiety symptoms to treatment with a {CRHR}1 antagonist, and algorithms, kits, microarrays, probes and or/primers for use in such methods.},
	type = {patent},
	author = {Müller-Myhsok, Bertram and Binder, Elisabeth and Holsboer, Florian},
	urldate = {2014-10-23},
	date = {2015-10-01},
	note = {Edition: G06F001922 {\textbar} A61K0031426 {\textbar} A61K003144 {\textbar} A61K003153 {\textbar} C12Q000168 {\textbar} G06F001900 {CPC}  - G16H005020 {\textbar} A61K0031426 {\textbar} A61K003144 {\textbar} A61K003153 {\textbar} C12Q00016883 {\textbar} G16B003000 {\textbar} C12Q2600106 {\textbar} C12Q2600118 {\textbar} C12Q2600156 {\textbar} C12Q260016 {EP}; {US} {EP}; {US} {US} {US}
Issue: {US}20150278438A1
Number Of Volumes: 514245 {\textbar} 43500611 {\textbar} 506002 {\textbar} 506009 {\textbar} 506016 {\textbar} 514348 {\textbar} 514370 {\textbar} 5360231 {\textbar} 702019 1 {\textbar} . A method for providing an algorithm for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method comprises the following steps: {\textbar} (a) performing a single nucleotide polymorphism ({SNP}) genotyping analysis in a group of patients with depressive symptoms and/or anxiety symptoms; {\textbar} {\textbar} (b) determining a value indicative for {CRH} activity in each patient of the group, wherein a value indicative for {CRH} overactivity is indicative for a patient responding to a treatment with a {CRHR}1 antagonist; {\textbar} {\textbar} (c) identifying at least one {SNP} associated with a value indicative for {CRH} overactivity as determined in step (b); and {\textbar} {\textbar} (d) determining the algorithm by machine-learning from the association of the at least one {SNP} identified in step (c) with the value indicative for {CRH} overactivity. {\textbar} {\textbar} 2 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the {SNP} genotyping analysis is performed in a group of at least 10 patients. {\textbar} 3 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the {SNP} genotyping analysis comprises the use of {SNP}-specific primers, {SNP}-specific probes, a primer extension reaction, the use of {SNP} microarrays and/or the use of sequencing methods. {\textbar} 4 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the value indicative for {CRH} activity in each patient is determined by measuring {ACTH} response to a combined dexamethasone suppression/{CRH} stimulation test in each patient. {\textbar} 5 {\textbar} . (canceled) {\textbar} 6 {\textbar} . (canceled) {\textbar} 7 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein in step (d) a number N of {SNPs} identified in step (c) is associated with a value indicative for {CRH} overactivity, wherein N is sufficient to provide an algorithm having an accuracy of prediction of at least 80\% and/or a sensitivity of prediction of at least 70\% and/or a specificity of prediction of at least 70\% and/or a positive predictive value of prediction of at least 70\% and/or a negative predictive value of prediction of at least 70\%. {\textbar} 8 {\textbar} . The method according to {\textbar} claim 7 {\textbar} , wherein N is at least 20. {\textbar} 9 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein step (c) further comprises identifying at least one {SNP} associated with a value indicative for normal {CRH} activity as determined in step (b), and step (d) further comprises machine-learning from the association of the at least one {SNP} associated with the value indicative for normal {CRH} activity identified in step (c) with the value indicative for normal {CRH} activity. {\textbar} 10 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the algorithm determined in step (d) associates at least one {SNP} selected from the group consisting of {SNPs} described in table 1 and an {SNP} in strong linkage disequilibrium with an {SNP} described in table 1 with a value indicative for {CRH} overactivity or with a value indicative for normal {CRH} activity. {\textbar} 11 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the algorithm determined in step (d) associates the {SNPs} described in table 1 with a value indicative for {CRH} overactivity and with a value indicative for normal {CRH} activity, respectively. {\textbar} 12 {\textbar} . A method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method comprises the following steps: {\textbar} (a) determining in a nucleic acid sample obtained from a patient the presence or absence of at least one single nucleotide polymorphism ({SNP}) associated with a value indicative for {CRH} overactivity; {\textbar} {\textbar} (b) predicting the treatment response to {CRHR}1 antagonists by linking an algorithm provided by the method of {\textbar} {\textbar} claim 1 {\textbar} with the presence or absence of the at least one {SNP} determined in step (a). {\textbar} 13 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein step (a) comprises determining at least one of the {SNPs}, which were associated with a value indicative for {CRH} overactivity when determining the algorithm by machine-learning from this association. {\textbar} 14 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein step (a) is preceded by a step of obtaining a nucleic acid sample from a patient. {\textbar} 15 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein in step (a) the presence or absence of a number N of {SNPs} is determined. {\textbar} 16 {\textbar} . The method according to {\textbar} claim 15 {\textbar} , wherein N is at least 20. {\textbar} 17 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein determining in step (a) further comprises determining at least one {SNP} associated with a value indicative for normal {CRH} activity. {\textbar} 18 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein the at least one {SNP}, determined in step (a) is selected from the group consisting of {SNPs} described in table 1 and an {SNP} in strong linkage disequilibrium with an {SNP} described in table 1. {\textbar} 19 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein determining in step (a) comprises determining the {SNPs} described in table 1. {\textbar} 20 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein the at least one {SNP} associated with a value indicative for {CRH} overactivity or with a value indicative for normal {CRH} activity is determined in step (a) by using {SNP}-specific primers, {SNP}-specific probes, a primer extension reaction, {SNP} microarrays and/or sequencing methods. {\textbar} 21 {\textbar} . A group of biomarkers, comprising: {\textbar} {SNP} rs6437726, {\textbar} {\textbar} {SNP} rs1986684, {\textbar} {\textbar} {SNP} rs7380830, {\textbar} {\textbar} {SNP} rs3903768, {\textbar} {\textbar} {SNP} rs7325978, {\textbar} {\textbar} {SNP} rs13585, {\textbar} {\textbar} {SNP} rs9368373, {\textbar} {\textbar} {SNP} rs10935354, {\textbar} {\textbar} {SNP} rs8095703, {\textbar} {\textbar} {SNP} rs10206851, {\textbar} {\textbar} {SNP} rs9542977, {\textbar} {\textbar} {SNP} rs4942879, {\textbar} {\textbar} {SNP} rs9542954, {\textbar} {\textbar} {SNP} rs1593478, {\textbar} {\textbar} {SNP} rs9542951, {\textbar} {\textbar} {SNP} rs2188534, {\textbar} {\textbar} {SNP} rs12524124, {\textbar} {\textbar} {SNP} rs4352629, {\textbar} {\textbar} {SNP} rs7448716, {\textbar} {\textbar} {SNP} rs11873533, {\textbar} {\textbar} {SNP} rs10062658, {\textbar} {\textbar} {SNP} rs12547917, {\textbar} {\textbar} {SNP} rs1038268, {\textbar} {\textbar} {SNP} rs2375811, {\textbar} {\textbar} {SNP} rs1352671, {\textbar} {\textbar} {SNP} rs364331, {\textbar} {\textbar} {SNP} rs1924949, {\textbar} {\textbar} {SNP} rs11025990, {\textbar} {\textbar} {SNP} rs3758562, and {\textbar} {\textbar} {SNP} rs10156056. {\textbar} {\textbar} 22 {\textbar} . (canceled) {\textbar} 23 {\textbar} . (canceled) {\textbar} 24 {\textbar} . (canceled) {\textbar} 25 {\textbar} . A method for detecting {CRH} overactivity in a patient with depressive symptoms and/or anxiety symptoms, comprising determining the status of a biomarker as defined in {\textbar} claim 21 {\textbar} in a nucleic acid sample isolated from a patient's sample, wherein the presence of indicator nucleotides is indicative for {CRH} overactivity. {\textbar} 26 {\textbar} . A method for monitoring depression and/or anxiety therapy of a patient with a {CRHR}1 antagonist comprising the step of determining the status of a biomarker as defined in {\textbar} claim 21 {\textbar} before and during the therapy. {\textbar} 27 {\textbar} . A method of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, comprising: {\textbar} (a) determining in a nucleic acid sample isolated from a patient's sample the status of a biomarker selected from the group consisting of {SNP} rs6437726, {SNP} rs1986684, {SNP} rs7380830, {SNP} rs3903768, {SNP} rs7325978, {SNP} rs13585, {SNP} rs9368373, {SNP} rs10935354, {SNP} rs8095703, {SNP} rs10206851, {SNP} rs9542977, {SNP} rs4942879, {SNP} rs9542954, {SNP} rs1593478, {SNP} rs9542951, {SNP} rs2188534, {SNP} rs12524124, {SNP} rs4352629, {SNP} rs7448716, {SNP} rs11873533, {SNP} rs10062658, {SNP} rs12547917, {SNP} rs1038268, {SNP} rs2375811, {SNP} rs1352671, {SNP} rs364331, {SNP} rs1924949, {SNP} rs11025990, {SNP} rs3758562, and {SNP} rs10156056; and {\textbar} {\textbar} (b) identifying the patient as eligible for a therapy with a {CRHR}1 antagonist, where the algorithm provided by the method of {\textbar} {\textbar} claim 1 {\textbar} predicts that the patient responds to the treatment with {CRHR}1 antagonists. {\textbar} 28 {\textbar} . (canceled) {\textbar} 29 {\textbar} . The method of {\textbar} claim 27 {\textbar} , further comprising a step of administering a {CRHR}1 antagonist. {\textbar} 30 {\textbar} . The method of {\textbar} claim 27 {\textbar} , wherein the {CRHR}1 antagonist is selected from the group consisting of {CP}154,526, Antalarmin, {CRA} 5626, Emicerfont, {DMP}-696, {DMP}-904, {DMP}-695, {SC}-241, {BMS}-561388, Pexacerfont, R121919, {NBI}30545, {PD}-171729, Verucerfont, {NBI}34041, {NBI}35965, {SN}003, {CRA}0450, {SSR}125543A, {CP}-316,311, {CP}-376,395, {NBI}-27914, {ONO}-2333Ms, {NBI}-34101, {PF}-572778, {GSK}561579 and {GSK}586529. {\textbar} 31 {\textbar} . (canceled) {\textbar} 32 {\textbar} . (canceled) {\textbar} 33 {\textbar} . (canceled) {\textbar} 34 {\textbar} . A composition for the analysis of at least one single nucleotide polymorphism ({SNP}) indicative for the treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, comprising a nucleic acid affinity ligand for a biomarker as defined in {\textbar} claim 21 {\textbar} . {\textbar} 35 {\textbar} . A kit, diagnostic composition or device for the analysis of at least one single nucleotide polymorphism ({SNP}) indicative for the treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, comprising at least one primer and/or probe selective for determining the presence or absence of at least one {SNP} associated with a value indicative for {CRH} overactivity. {\textbar} 36 {\textbar} . (canceled) {\textbar} 37 {\textbar} . (canceled) {\textbar} 38 {\textbar} . (canceled) {\textbar} 39 {\textbar} . (canceled) {\textbar} 40 {\textbar} . (canceled) {\textbar} 41 {\textbar} . (canceled) 1 {\textbar} . A method for providing an algorithm for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method comprises the following steps: {\textbar} (a) performing a single nucleotide polymorphism ({SNP}) genotyping analysis in a group of patients with depressive symptoms and/or anxiety symptoms; {\textbar} {\textbar} (b) determining a value indicative for {CRH} activity in each patient of the group, wherein a value indicative for {CRH} overactivity is indicative for a patient responding to a treatment with a {CRHR}1 antagonist; {\textbar} {\textbar} (c) identifying at least one {SNP} associated with a value indicative for {CRH} overactivity as determined in step (b); and {\textbar} {\textbar} (d) determining the algorithm by machine-learning from the association of the at least one {SNP} identified in step (c) with the value indicative for {CRH} overactivity. {\textbar} {\textbar} 2 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the {SNP} genotyping analysis is performed in a group of at least 10 patients. {\textbar} 3 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the {SNP} genotyping analysis comprises the use of {SNP}-specific primers, {SNP}-specific probes, a primer extension reaction, the use of {SNP} microarrays and/or the use of sequencing methods. {\textbar} 4 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the value indicative for {CRH} activity in each patient is determined by measuring {ACTH} response to a combined dexamethasone suppression/{CRH} stimulation test in each patient. {\textbar} 5 {\textbar} . (canceled) {\textbar} 6 {\textbar} . (canceled) {\textbar} 7 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein in step (d) a number N of {SNPs} identified in step (c) is associated with a value indicative for {CRH} overactivity, wherein N is sufficient to provide an algorithm having an accuracy of prediction of at least 80\% and/or a sensitivity of prediction of at least 70\% and/or a specificity of prediction of at least 70\% and/or a positive predictive value of prediction of at least 70\% and/or a negative predictive value of prediction of at least 70\%. {\textbar} 8 {\textbar} . The method according to {\textbar} claim 7 {\textbar} , wherein N is at least 20. {\textbar} 9 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein step (c) further comprises identifying at least one {SNP} associated with a value indicative for normal {CRH} activity as determined in step (b), and step (d) further comprises machine-learning from the association of the at least one {SNP} associated with the value indicative for normal {CRH} activity identified in step (c) with the value indicative for normal {CRH} activity. {\textbar} 10 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the algorithm determined in step (d) associates at least one {SNP} selected from the group consisting of {SNPs} described in table 1 and an {SNP} in strong linkage disequilibrium with an {SNP} described in table 1 with a value indicative for {CRH} overactivity or with a value indicative for normal {CRH} activity. {\textbar} 11 {\textbar} . The method according to {\textbar} claim 1 {\textbar} , wherein the algorithm determined in step (d) associates the {SNPs} described in table 1 with a value indicative for {CRH} overactivity and with a value indicative for normal {CRH} activity, respectively. {\textbar} 12 {\textbar} . A method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method comprises the following steps: {\textbar} (a) determining in a nucleic acid sample obtained from a patient the presence or absence of at least one single nucleotide polymorphism ({SNP}) associated with a value indicative for {CRH} overactivity; {\textbar} {\textbar} (b) predicting the treatment response to {CRHR}1 antagonists by linking an algorithm provided by the method of {\textbar} {\textbar} claim 1 {\textbar} with the presence or absence of the at least one {SNP} determined in step (a). {\textbar} 13 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein step (a) comprises determining at least one of the {SNPs}, which were associated with a value indicative for {CRH} overactivity when determining the algorithm by machine-learning from this association. {\textbar} 14 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein step (a) is preceded by a step of obtaining a nucleic acid sample from a patient. {\textbar} 15 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein in step (a) the presence or absence of a number N of {SNPs} is determined. {\textbar} 16 {\textbar} . The method according to {\textbar} claim 15 {\textbar} , wherein N is at least 20. {\textbar} 17 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein determining in step (a) further comprises determining at least one {SNP} associated with a value indicative for normal {CRH} activity. {\textbar} 18 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein the at least one {SNP}, determined in step (a) is selected from the group consisting of {SNPs} described in table 1 and an {SNP} in strong linkage disequilibrium with an {SNP} described in table 1. {\textbar} 19 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein determining in step (a) comprises determining the {SNPs} described in table 1. {\textbar} 20 {\textbar} . The method according to {\textbar} claim 12 {\textbar} , wherein the at least one {SNP} associated with a value indicative for {CRH} overactivity or with a value indicative for normal {CRH} activity is determined in step (a) by using {SNP}-specific primers, {SNP}-specific probes, a primer extension reaction, {SNP} microarrays and/or sequencing methods. {\textbar} 21 {\textbar} . A group of biomarkers, comprising: {\textbar} {SNP} rs6437726, {\textbar} {\textbar} {SNP} rs1986684, {\textbar} {\textbar} {SNP} rs7380830, {\textbar} {\textbar} {SNP} rs3903768, {\textbar} {\textbar} {SNP} rs7325978, {\textbar} {\textbar} {SNP} rs13585, {\textbar} {\textbar} {SNP} rs9368373, {\textbar} {\textbar} {SNP} rs10935354, {\textbar} {\textbar} {SNP} rs8095703, {\textbar} {\textbar} {SNP} rs10206851, {\textbar} {\textbar} {SNP} rs9542977, {\textbar} {\textbar} {SNP} rs4942879, {\textbar} {\textbar} {SNP} rs9542954, {\textbar} {\textbar} {SNP} rs1593478, {\textbar} {\textbar} {SNP} rs9542951, {\textbar} {\textbar} {SNP} rs2188534, {\textbar} {\textbar} {SNP} rs12524124, {\textbar} {\textbar} {SNP} rs4352629, {\textbar} {\textbar} {SNP} rs7448716, {\textbar} {\textbar} {SNP} rs11873533, {\textbar} {\textbar} {SNP} rs10062658, {\textbar} {\textbar} {SNP} rs12547917, {\textbar} {\textbar} {SNP} rs1038268, {\textbar} {\textbar} {SNP} rs2375811, {\textbar} {\textbar} {SNP} rs1352671, {\textbar} {\textbar} {SNP} rs364331, {\textbar} {\textbar} {SNP} rs1924949, {\textbar} {\textbar} {SNP} rs11025990, {\textbar} {\textbar} {SNP} rs3758562, and {\textbar} {\textbar} {SNP} rs10156056. {\textbar} {\textbar} 22 {\textbar} . (canceled) {\textbar} 23 {\textbar} . (canceled) {\textbar} 24 {\textbar} . (canceled) {\textbar} 25 {\textbar} . A method for detecting {CRH} overactivity in a patient with depressive symptoms and/or anxiety symptoms, comprising determining the status of a biomarker as defined in {\textbar} claim 21 {\textbar} in a nucleic acid sample isolated from a patient's sample, wherein the presence of indicator nucleotides is indicative for {CRH} overactivity. {\textbar} 26 {\textbar} . A method for monitoring depression and/or anxiety therapy of a patient with a {CRHR}1 antagonist comprising the step of determining the status of a biomarker as defined in {\textbar} claim 21 {\textbar} before and during the therapy. {\textbar} 27 {\textbar} . A method of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, comprising: {\textbar} (a) determining in a nucleic acid sample isolated from a patient's sample the status of a biomarker selected from the group consisting of {SNP} rs6437726, {SNP} rs1986684, {SNP} rs7380830, {SNP} rs3903768, {SNP} rs7325978, {SNP} rs13585, {SNP} rs9368373, {SNP} rs10935354, {SNP} rs8095703, {SNP} rs10206851, {SNP} rs9542977, {SNP} rs4942879, {SNP} rs9542954, {SNP} rs1593478, {SNP} rs9542951, {SNP} rs2188534, {SNP} rs12524124, {SNP} rs4352629, {SNP} rs7448716, {SNP} rs11873533, {SNP} rs10062658, {SNP} rs12547917, {SNP} rs1038268, {SNP} rs2375811, {SNP} rs1352671, {SNP} rs364331, {SNP} rs1924949, {SNP} rs11025990, {SNP} rs3758562, and {SNP} rs10156056; and {\textbar} {\textbar} (b) identifying the patient as eligible for a therapy with a {CRHR}1 antagonist, where the algorithm provided by the method of {\textbar} {\textbar} claim 1 {\textbar} predicts that the patient responds to the treatment with {CRHR}1 antagonists. {\textbar} 28 {\textbar} . (canceled) {\textbar} 29 {\textbar} . The method of {\textbar} claim 27 {\textbar} , further comprising a step of administering a {CRHR}1 antagonist. {\textbar} 30 {\textbar} . The method of {\textbar} claim 27 {\textbar} , wherein the {CRHR}1 antagonist is selected from the group consisting of {CP}154,526, Antalarmin, {CRA} 5626, Emicerfont, {DMP}-696, {DMP}-904, {DMP}-695, {SC}-241, {BMS}-561388, Pexacerfont, R121919, {NBI}30545, {PD}-171729, Verucerfont, {NBI}34041, {NBI}35965, {SN}003, {CRA}0450, {SSR}125543A, {CP}-316,311, {CP}-376,395, {NBI}-27914, {ONO}-2333Ms, {NBI}-34101, {PF}-572778, {GSK}561579 and {GSK}586529. {\textbar} 31 {\textbar} . (canceled) {\textbar} 32 {\textbar} . (canceled) {\textbar} 33 {\textbar} . (canceled) {\textbar} 34 {\textbar} . A composition for the analysis of at least one single nucleotide polymorphism ({SNP}) indicative for the treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, comprising a nucleic acid affinity ligand for a biomarker as defined in {\textbar} claim 21 {\textbar} . {\textbar} 35 {\textbar} . A kit, diagnostic composition or device for the analysis of at least one single nucleotide polymorphism ({SNP}) indicative for the treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, comprising at least one primer and/or probe selective for determining the presence or absence of at least one {SNP} associated with a value indicative for {CRH} overactivity. {\textbar} 36 {\textbar} . (canceled) {\textbar} 37 {\textbar} . (canceled) {\textbar} 38 {\textbar} . (canceled) {\textbar} 39 {\textbar} . (canceled) {\textbar} 40 {\textbar} . (canceled) {\textbar} 41 {\textbar} . (canceled) 1 {\textbar} . A method for providing an algorithm for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method comprises the following steps: {\textbar} (a) performing a single nucleotide polymorphism ({SNP}) genotyping analysis in a group of patients with depressive symptoms and/or anxiety symptoms; {\textbar} {\textbar} (b) determining a value indicative for {CRH} activity in each patient of the group, wherein a value indicative for {CRH} overactivity is indicative for a patient responding to a treatment with a {CRHR}1 antagonist; {\textbar} {\textbar} (c) identifying at least one {SNP} associated with a value indicative for {CRH} overactivity as determined in step (b); and {\textbar} {\textbar} (d) determining the algorithm by machine-learning from the association of the at least one {SNP} identified in step (c) with the value indicative for {CRH} overactivity. 1 {\textbar} . A method for providing an algorithm for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method comprises the following steps: {\textbar} (a) performing a single nucleotide polymorphism ({SNP}) genotyping analysis in a group of patients with depressive symptoms and/or anxiety symptoms; {\textbar} {\textbar} (b) determining a value indicative for {CRH} activity in each patient of the group, wherein a value indicative for {CRH} overactivity is indicative for a patient responding to a treatment with a {CRHR}1 antagonist; {\textbar} {\textbar} (c) identifying at least one {SNP} associated with a value indicative for {CRH} overactivity as determined in step (b); and {\textbar} {\textbar} (d) determining the algorithm by machine-learning from the association of the at least one {SNP} identified in step (c) with the value indicative for {CRH} overactivity. {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} : Graph of the phenotypic distribution of ln({AAUC}) at in-patient admission. The X-axis shows the ln of the {AUC} of the {ACTH} response and the Y-axis the frequency in total N/bin. The dashed vertical indicates the cut-off for being classified as a low vs. high responder. {AAUC} is the area under the curve of the {ACTH} response. {\textbar} {FIG}. 2 {\textbar} {\textbar} : Increased {REMS} activity in {CRH}-{COE} {\textbar} {CNS} {\textbar} mice is suppressed by {DMP}696 (50 mg/kg/d) application via drinking water. Treatment day one, light grey; treatment day 2, dark grey; treatment day three, black. Symbols indicate significant differences between baseline and treatment day one (+), two (\#) or three (*). Light and dark bar on the x-axis indicate light and dark period, respectively. {\textbar} {FIG}. 3 {\textbar} {\textbar} : Increased activity of {REMS} in {CRH}-{COE} {\textbar} {CNS} {\textbar} is suppressed by application of the {CRH}-R1 antagonist {SSR}125543 (50 mg/kg/d) via drinking water. Baseline day, white; treatment day two, dark grey; treatment day three, black. Symbols indicate significant differences between baseline and treatment day two (\#) or three (*). Light and dark bar on the x-axis indicate light and dark period, respectively. {\textbar} {FIG}. 4 {\textbar} {\textbar} : {REMS} activity in Cor26 {CRH} mice is suppressed by application of the {CRH}-R1 antagonist {CP}-316311 (50 mg/kg/d) via drinking water. Baseline day, white; treatment day two, dark grey; treatment day three, black. {\textbar} {FIELD} {OF} {THE} {INVENTION} {\textbar} {\textbar} The invention relates inter alia to methods for predicting the response of patients with depressive symptoms and/or anxiety symptoms to treatment with a {CRHR}1 antagonist, and algorithms, kits, microarrays, probes and or/primers for use in such methods. {\textbar} {\textbar} {BACKGROUND} {OF} {THE} {INVENTION} {\textbar} {\textbar} While current antidepressant drugs can provide effective treatments of patients with depression and/or anxiety symptoms in a number of psychiatric disorders, some of the patients may only show partial remission of symptoms or do not respond at all (Trivedi et al., Am J Psychiatry, 2006). This may be due to the fact that these drugs do not target the inherent pathophysiologic disturbances leading to the clinical condition in these patients. A number of antidepressant strategies, derived from both animal studies and human studies have been tested, but so far with little success. One of these approaches is the use of corticotropin releasing hormone receptor type 1 ({CRHR}1) antagonists. Increased activity or concentrations of its ligand corticotropin releasing hormone ({CRH}) in the brain or the cerebrospinal fluid have been shown to be associated with depression and anxiety in humans (Nemeroff et al., Arch Gen Psychiatry, 1988; Nemeroff et al. Science, 1984; Purba et al. Arch Gen Psychiatry, 1996; Carpenter, et al. Neuropsychopharmacology, 2004), primates (Coplan et al., Proc Natl Acad Sci {USA}, 1996; Sanchez et al., {\textbar} {\textbar} Dev Psychopathol {\textbar} , 2001) and rodents (Muller et al. Nat Neurosci., 2003; Timpl et al., Nat Genet. 1998). In addition, molecular studies in experimental animals and open label studies in human patients indicate that {CRHR}1 may be suitable in the treatment of depression and anxiety (Ising et al., Exp Clin Psychopharmacol., 2007; Holsboer et al., {CNS} Spectr., 2001; Paez-Pereda et al., Expert Opin Investig Drugs, 2011). However, so far all randomized clinical trials have failed to demonstrate the superiority of this drug to placebo (Coric et al., Depress Anxiety, 2010; Binneman et al., Am J Psychiatry, 2008). {\textbar} Hence, there is still uncertainty whether {CRHR}1 antagonists are indeed suitable to treat depressive symptoms and/or anxiety symptoms in patients in need thereof. In order to establish the chances of such a therapy it would be desirable to provide reliable methods for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms. {\textbar} {\textbar} {SUMMARY} {OF} {THE} {INVENTION} {\textbar} {\textbar} One aspect of the present inventions relates to a method for providing an algorithm for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms. The method may comprise the following steps: {\textbar} {\textbar} (a) performing a single nucleotide polymorphism ({SNP}) genotyping analysis in a group of patients with depressive symptoms and/or anxiety symptoms; {\textbar} {\textbar} (b) determining a value indicative for {CRH} activity in each patient of the group, wherein a value indicative for {CRH} overactivity is indicative for a patient responding to a treatment with a {CRH}1 antagonist; {\textbar} {\textbar} (c) identifying at least one {SNP} associated with a value indicative for {CRH} overactivity as determined in step (b); and {\textbar} {\textbar} (d) determining the algorithm by machine-learning from the association of the at least one {SNP} identified in step (c) with the value indicative for {CRH} overactivity. {\textbar} {\textbar} In one embodiment of the invention, the {SNP} genotyping analysis is performed in a group of at least 10 patients. {\textbar} {\textbar} In another embodiment, the {SNP} genotyping analysis comprises the use of {SNP}-specific primers, {SNP}-specific probes, a primer extension reaction, the use of {SNP} microarrays and/or the use of sequencing methods. {\textbar} {\textbar} Typically, the value indicative for {CRH} overactivity in each patient is determined by measuring {ACTH} response and/or cortisol response to a combined dexamethasone suppression/{CRH} stimulation test in each patient. {\textbar} {\textbar} Usually, at least 20, optionally at least 25 or at least 30 {SNPs} associated with the value indicative for {CRH} overactivity are identified in step (c). {\textbar} {\textbar} In one embodiment machine-learning is selected from the group consisting of artificial neural network learning, decision tree learning, support vector machine learning, Bayesian network learning, clustering and regression analysis. {\textbar} {\textbar} In a specific embodiment, artificial neural network learning is used as the machine-learning method. {\textbar} {\textbar} In one embodiment, in step (d), a number N of {SNPs} identified in step (c) is associated with a value indicative for {CRH} overactivity, wherein N is sufficient to provide an algorithm having an accuracy of prediction of at least 80\% and/or a sensitivity of prediction of at least 70\% and/or a specificity of prediction of at least 70\% and/or a positive predictive value of prediction of at least 70\% and/or a negative predictive value of prediction of at least 70\%. N may be at least 20 or at least 25, such as 30. {\textbar} {\textbar} In one embodiment, step (c) further comprises identifying at least one {SNP} associated with a value indicative for normal {CRH} activity as determined in step (b) of the above described method. Further, in this embodiment, step (d) may further comprise machine-learning from the association of the at least one {SNP} identified in step (c) with the value indicative for normal {CRH} overactivity. {\textbar} {\textbar} In another embodiment, the algorithm determined in step (d) associates at least one {SNP} selected from the group consisting of {SNPs} described in table 1 below and an {SNP} in strong linkage disequilibrium with any of the foregoing {SNPs} with a value indicative for {CRH} overactivity or normal {CRH} activity. {\textbar} {\textbar} In a further embodiment, the algorithm determined in step (d) associates at least 20, optionally at least 25 or at least 30 {SNPs} selected from the group consisting of {SNPs} described in table 1 and an {SNP} in strong linkage disequilibrium with any of the foregoing {SNPs} with a value indicative for {CRH} overactivity or normal {CRH} activity. {\textbar} {\textbar} In a specific embodiment, the algorithm determined in step (d) associates all of the {SNPs} described in table 1 with {CRH} overactivity or normal {CRH} activity. {\textbar} {\textbar} Another aspect of the invention is a method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method comprises the following steps: {\textbar} {\textbar} (a) determining in a nucleic acid sample obtained from a patient the presence or absence of at least one single nucleotide polymorphism ({SNP}) associated with a value indicative for {CRH} overactivity; {\textbar} {\textbar} (b) predicting the treatment response to {CRHR}1 antagonists by linking an algorithm provided by the method for providing an algorithm as described above with the presence or absence of the at least one {SNP} determined in step (a). {\textbar} {\textbar} Step (a) may comprise determining at least one of the {SNPs}, optionally all of the {SNPs} which were associated with a value indicative for {CRH} overactivity when determining the algorithm by machine-learning from this association. {\textbar} {\textbar} In one embodiment of the method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, the method comprises a further step of determining a value indicative for the rapid-eye-movement ({REM}) density, e.g. during a first {REM} night sleep episode of a patient. {\textbar} {\textbar} In one embodiment, the method for predicting a treatment response is preceded by a step of obtaining a nucleic acid sample from a patient. {\textbar} {\textbar} The method for predicting a treatment response as described above may further comprise in step (a) determining at least one {SNP} associated with a value indicative for normal {CRH} activity. {\textbar} {\textbar} In another embodiment, in step (a) the presence or absence of a number of {SNPs} is determined, wherein the {SNPs} optionally correspond to the {SNPs} which were sufficient to provide an algorithm having an accuracy of prediction of at least 80\% and/or a sensitivity of prediction of at least 70\% and/or a specificity of prediction of at least 70\% and/or a positive predictive value of prediction of at least 70\% and/or a negative predictive value of prediction of at least 70\%. N may be at least 20 or at least 25, such as 30. {\textbar} {\textbar} In a further embodiment at least 20, optionally at least 25 or at least 30 {SNPs} selected from the group of {SNPs} consisting of {SNPs} as described in table 1 below and an {SNP} in strong linkage disequilibrium with any of the foregoing {SNPs} are determined. {\textbar} {\textbar} In a specific embodiment all of the {SNPs} described in table 1 are determined. {\textbar} {\textbar} Typically, in the method for predicting a treatment response to {CRHR}1 antagonists the at least one {SNP} associated with a value indicative for {CRH} overactivity or for normal {CRH} activity is determined by using {SNP}-specific primers, {SNP}-specific probes, a primer extension reaction, {SNP} microarrays and/or sequencing methods. Another aspect of the invention concerns a group of biomarkers, comprising: {\textbar} {\textbar} {SNP} rs6437726, {\textbar} {SNP} rs1986684, {\textbar} {SNP} rs7380830, {\textbar} {SNP} rs3903768, {\textbar} {SNP} rs7325978, {\textbar} {SNP} rs13585, {\textbar} {SNP} rs9368373, {\textbar} {SNP} rs10935354, {\textbar} {SNP} rs8095703, {\textbar} {SNP} rs10206851, {\textbar} {SNP} rs9542977, {\textbar} {SNP} rs4942879, {\textbar} {SNP} rs9542954, {\textbar} {SNP} rs1593478, {\textbar} {SNP} rs9542951, {\textbar} {SNP} rs2188534, {\textbar} {SNP} rs12524124, {\textbar} {SNP} rs4352629, {\textbar} {SNP} rs7448716, {\textbar} {SNP} rs11873533, {\textbar} {SNP} rs10062658, {\textbar} {SNP} rs12547917, {\textbar} {SNP} rs1038268, {\textbar} {SNP} rs2375811, {\textbar} {SNP} rs1352671, {\textbar} {SNP} rs364331, {\textbar} {SNP} rs1924949, {\textbar} {SNP} rs11025990, {\textbar} {SNP} rs3758562, and {\textbar} {SNP} rs10156056. {\textbar} In one embodiment, the group of biomarkers is a group of biomarkers, wherein {\textbar} {\textbar} {SNP} rs6437726 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 1, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1986684 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 2, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7380830 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 3, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs3903768 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 4, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7325978 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 5, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs13585 is represented by a single polymorphic change at position 185 of {SEQ} {ID} {NO}: 6, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9368373 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 7, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs10935354 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 8, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs8095703 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 9, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs10206851 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 10, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542977 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 11, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs4942879 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 12, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs9542954 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 13, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1593478 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 14, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542951 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 15, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs2188534 is represented by a single polymorphic change at position 200 of {SEQ} {ID} {NO}: 16, wherein in one or two alleles the wild-type nucleotide G is replaced by indicator nucleotide T, {\textbar} {SNP} rs12524124 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 17, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs4352629 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 18, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs7448716 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 19, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11873533 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 20, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs10062658 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 21, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs12547917 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 22, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs1038268 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 23, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs2375811 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 24, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1352671 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 25, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs364331 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 26, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1924949 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 27, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11025990 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 28, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs3758562 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 29, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, and {\textbar} {SNP} rs10156056 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 30, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide G. {\textbar} The group of biomarkers as described above may constitute a marker for a treatment response to {CRHR}1 antagonists in patients with depressive and/or anxiety symptoms. {\textbar} {\textbar} Further, the group of biomarkers may additionally comprise {REM} density. {\textbar} {\textbar} Another aspect of the invention concerns a method for detecting {CRH} overactivity in a patient with depressive symptoms and/or anxiety symptoms, comprising determining the status of a biomarker or a group of biomarkers as defined above in a nucleic acid isolated from a patient's sample, wherein the presence of indicator nucleotides as defined above is indicative for {CRH} overactivity. {\textbar} {\textbar} Another aspect of the invention concerns a method for monitoring depression and/or anxiety therapy of a patient with a {CRHR}1 antagonist comprising the step of determining the status of a biomarker or a group of biomarkers as defined above before and during the therapy, optionally also after the therapy. {\textbar} {\textbar} Another aspect of the invention concerns a method of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, comprising: {\textbar} {\textbar} (a) determining in a nucleic acid sample isolated from a patient's sample the status of a biomarker or a group of biomarkers as defined above; {\textbar} {\textbar} (b) identifying the patient as eligible for a therapy with a {CRHR}1 antagonist, where the algorithm provided by the method of claim {\textbar} {\textbar} 1 {\textbar} predicts that patient responds to the treatment with {CRHR}1 antagonists. {\textbar} Another aspect of the invention concerns a method of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, comprising: {\textbar} {\textbar} (a) determining in a nucleic acid sample isolated from a patient's sample the status of a biomarker or a group of biomarkers as defined above; {\textbar} {\textbar} (b) identifying the patient as eligible for a therapy with a {CRHR}1 antagonist, where the patient's sample is classified as showing the presence of indicator nucleotides as defined above. {\textbar} {\textbar} In some embodiments of the above methods of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, the method may further comprise a step of administering a {CRHR}1 antagonist. {\textbar} {\textbar} In some embodiments of the above methods of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, the {CRHR}1 antagonist may be selected from the group consisting of {CP}154,526, Antalarmin, {CRA} 5626, Emicerfont, {DMP}-696, {DMP}-904, {DMP}-695, {SC}-241, {BMS}-561388, Pexacerfont, R121919, {NBI}30545, {PD}-171729, Verucerfont, {NBI}34041, {NBI}35965, {SN}003, {CRA}0450, {SSR}125543A, {CP}-316,311, {CP}-376,395, {NBI}-27914, {ONO}-2333Ms, {NBI}-34101, {PF}-572778, {GSK}561579 and {GSK}586529. {\textbar} {\textbar} A further aspect of the invention is a composition for the analysis of at least one single nucleotide polymorphism ({SNP}) indicative for the treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, comprising a nucleic acid affinity ligand for a biomarker as defined above. {\textbar} {\textbar} A further aspect of the invention is a kit, diagnostic composition or device for the analysis of at least one single nucleotide polymorphism ({SNP}) indicative for the treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, comprising at least one primer and/or probe selective for determining the presence or absence of at least one {SNP} associated with a value indicative for {CRH} overactivity. {\textbar} {\textbar} Usually the kit, diagnostic composition or device further comprises an enzyme for primer elongation, nucleotides and/or labeling agents. {\textbar} {\textbar} Another aspect of the invention concerns an microarray for the analysis of at least one single nucleotide polymorphism ({SNP}) indicative for the treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, comprising at least one probe selective for determining the presence or absence of at least one {SNP} associated with the value indicative for {CRH} overactivity. {\textbar} {\textbar} Another aspect of the invention concerns a primer or probe for the analysis of at least one single nucleotide polymorphism ({SNP}) associated with a value indicative for {CRH} overactivity. {\textbar} {\textbar} A further aspect of the invention is the use of a microarray as described above for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms. {\textbar} {\textbar} A further aspect of the invention is the use of a group of biomarkers as defined in above for detecting {CRH} overactivity in patients with depressive symptoms and/or anxiety symptoms, or for screening a population of patients with depressive symptoms and/or anxiety symptoms for eligibility for a therapy with a {CRHR}1 antagonist. {\textbar} {\textbar} Another aspect of the inventions deals with a computer program product designed such that a method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms is performed when the computer program product is used on a computer, wherein the method comprises linking the algorithm provided by the method for providing an algorithm as described above with the presence or absence of at least one single nucleotide polymorphism ({SNP}) associated with a value indicative for {CRH} overactivity in a nucleic acid sample of a patient. {\textbar} {\textbar} A further aspect of the invention relates to a machine-readable medium with instructions which can be performed on a computer for the performance of a method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method comprises linking the algorithm provided by the method for providing an algorithm as described above with the presence or absence of at least one single nucleotide polymorphism ({SNP}) associated with a value indicative for {CRH} overactivity in a nucleic acid sample of a patient. {\textbar} {\textbar} Further, an aspect of the invention refers to a method for providing an algorithm for predicting a treatment response to a compound for treating depressive symptoms and/or anxiety symptoms in patients who have {CRH} overactivity, wherein the method comprises the following steps: {\textbar} {\textbar} (a) performing a single nucleotide polymorphism ({SNP}) genotyping analysis in a group of patients with depressive symptoms and/or anxiety symptoms; {\textbar} {\textbar} (b) determining a value indicative for {CRH} activity in each patient of the group; {\textbar} {\textbar} (c) identifying at least one {SNP} associated with a value indicative for {CRH} overactivity as determined in step (b); {\textbar} {\textbar} (d) determining the algorithm by machine-learning from the association of the at least one {SNP} identified in step (c) with the value indicative for {CRH} overactivity. {\textbar} {\textbar} An additional aspect of the invention refers to a method for predicting a treatment response to a compound for treating depressive symptoms and/or anxiety symptoms in patients who have {CRH} overactivity, wherein the method may comprise the following steps: {\textbar} {\textbar} (a) determining in a nucleic acid sample obtained from a patient the presence or absence of at least one single nucleotide polymorphism ({SNP}) associated with a value indicative for {CRH} overactivity; {\textbar} {\textbar} (b) predicting the treatment response to {CRHR}1 antagonists by linking the algorithm provided by the method for providing an algorithm as described above with the presence or absence of the at least one {SNP} determined in step (b). {\textbar} {\textbar} {DETAILED} {DESCRIPTION} {OF} {THE} {INVENTION} {\textbar} {\textbar} Where the term “comprise” or “comprising” is used in the present description and claims, it does not exclude other elements or steps. For the purposes of the present invention, the term “consisting of” is considered to be an optional embodiment of the term “comprising of”. If hereinafter a group is defined to comprise at least a certain number of embodiments, this is also to be understood to disclose a group which optionally consists only of these embodiments. {\textbar} {\textbar} Where an indefinite or a definite article is used when referring to a singular noun such as “a” or “an”, or “the”, this includes a plural form of that noun unless specifically stated. {\textbar} {\textbar} Vice versa, when the plural form of a noun is used it refers also the singular form. For example, when {SNPs} are mentioned, this is also to be understood as a single {SNP}. {\textbar} {\textbar} Furthermore, the terms first, second, third or (a), (b), (c) and the like in the description and in the claims are used for distinguishing between similar elements and not necessarily for describing a sequential or chronological order. It is to be understood that the terms so used are interchangeable under appropriate circumstances and that the embodiments of the invention described herein are capable of operation in other sequences than described or illustrated herein. {\textbar} {\textbar} Further definitions of the terms will be given in the following in the context of which the terms are used. {\textbar} {\textbar} It has been found that a treatment response to {CRH} antagonists in patients with depressive symptoms and/or anxiety symptoms can be reliably predicted by using a machine-learning based prediction algorithm derived from the association of {SNPs} with values indicative for {CRH} overactivity. {\textbar} {\textbar} Further, a patient group responsive to the treatment with {CRHR}1 antagonists has been identified. In particular, patients with depressive and/or anxiety symptoms having {CRH} overactivity can be successfully treated with {CRHR}1 antagonists. {\textbar} {\textbar} The term “treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms” in the sense of the invention refers to a response in a patient with depressive symptoms and/or anxiety symptoms during and/or after the treatment with one or more {CRHR}1 antagonists compared to before the treatment. The response may range from a partial alleviation of the symptoms to a complete remission of the symptoms, indicated by the change of symptoms strength and/or frequency of relapse of individual symptoms and/or the mean change on a depression scale, e.g. as described herein. The response can occur shortly after treatment or after a certain time period. A decrease in symptom severity from pretreatment of 25\% or more is usually considered a partial alleviation of symptoms. Remission may be defined as achieving a value of 8 or less on the Hamilton Depression Rating Scale ({HAM}-D) or equivalent values on other rating scales named below. {\textbar} {\textbar} The term “{CRHR}1 antagonist” refers to a compound capable of binding directly or indirectly to a {CRH} receptor 1 so as to modulate the receptor mediated activity. {CRHR}1 antagonists are well known in the literature and are e.g. described in {WO} 94/13676, {EP} 0 773 023, {WO} 2004/047866, {WO} 2004/094420, {WO} 98/03510, {WO} 97/029109, {WO} 2006/044958, {WO} 2001/005776 and {WO} 95/033750. Exemplary {CRHR}1 antagonists comprise {NBI}30775/R121919 (Neurocrine), {CP}316.311 (Pfizer), {CP}154,526 (Pfizer), Emicerfont (Glaxo), {ONO}-2333Ms (Ono Pharmaceutical), Pexacerfont (Bristol-Myers-Squibb), {SSR}125543 (Sanofi-Aventis), {NBI}-34101 (Neurocrine) and {TAI}041 (Taisho). Further exemplary {CRHR}1 antagonists comprise Antalarmin, {CRA} 5626, {DMP}-696, {DMP}-904, {DMP}-695, {SC}-241, {BMS}-561388, {NBI}30545, {PD}-171729, Verucerfont, {NBI}34041, {NBI}35965, {SN}003, {CRA}0450, {CP}-376,395, {NBI}-27914, {PF}-572778, {GSK}561579 and {GSK}586529. {\textbar} {\textbar} One aspect concerns the provision of an algorithm for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms. The method may comprise the following steps: {\textbar} {\textbar} (a) performing a single nucleotide polymorphism ({SNP}) genotyping analysis in a group of patients with depressive symptoms and/or anxiety symptoms; {\textbar} {\textbar} (b) determining a value indicative for {CRH} activity in each patient of the group, wherein a value indicative for {CRH} overactivity is indicative or predictive for a patient responding to a treatment with a {CRH}1 antagonist; {\textbar} {\textbar} (c) identifying at least one {SNP} associated with a value indicative for {CRH} overactivity as determined in step (b); {\textbar} {\textbar} (d) determining the algorithm by machine-learning from the association of the at least one {SNP} identified in step (c) with the value indicative for {CRH} overactivity. {\textbar} {\textbar} In a step (a), a single nucleotide polymorphism ({SNP}) genotyping analysis in a group of patients with depressive symptoms and/or anxiety symptoms is performed. {\textbar} {\textbar} Depressive symptoms comprise inter alia low mood, low self-esteem, loss of interest or pleasure, psychosis, poor concentration and memory, social isolation, psychomotor agitation/retardation, thoughts of death or suicide, significant weight change (loss/gain), fatigue, and feeling of worthless. The depressive disorders can last for weeks to lifelong disorder with periodic reoccurring depressive episodes. For the diagnosis of the depression mode (e.g. moderate or severe depression) the Hamilton Depression Rating Scale ({HAM}-D) (Hamilton, J Neurol Neurosurg Psychiatry, 1960) may be used. The depression mode may be also rated by alternative scales as the Beck Depression Inventory ({BDI}), the Montgomery-Åsberg Depression Scale ({MADRS}), the Geriatric Depression Scale ({GDS}), the Zung Self-Rating Depression Scale ({ZSRDS}). {\textbar} {\textbar} Anxiety symptoms comprise inter alia panic disorders, generalized anxiety disorder, phobias and posttraumatic stress disorder. Typical symptoms of anxiety are avoidance behavior which may lead to social isolation, physical ailments like tachycardia, dizziness and sweating, mental apprehension, stress and tensions. The strength of these symptoms ranges from nervousness and discomfort to panic and terror in humans or animals. Most anxiety disorders may last for weeks or even months, some of them even for years and worsen if not suitably treated. For measuring the severity of anxiety symptoms, the Hamilton Anxiety Rating Scale ({HAM}-A) or the State-Trait Anxiety Rating Scale ({STAI}) can be used. {\textbar} {\textbar} A “group of patients” as used herein comprises at least two patients, such as at least 10 patients, or at least 100 patients, or at least 150 patients. Patients included in the analysis of step (a) may exhibit at least a moderate to severe depressive mode. The group of patients may comprise patients with {CRH} overactivity and/or patients with normal {CRH} activity. {\textbar} {\textbar} The term “polymorphism” as used herein refers to a variation in the genome of individuals, including, insertions, deletions, point mutations and translocations. {\textbar} {\textbar} The term “single nucleotide polymorphism” is well understood by the skilled person and refers to a point mutation at a certain position in the nucleotide sequence. In other words, only one nucleotide differs in a certain region. {\textbar} {\textbar} The nucleotide, that is present in the majority of the population, is also referred to as wild-type allele or major allele. As used herein, this state is defined as “absence of a {SNP}”. {\textbar} {\textbar} The specific nucleotide that is present in the minority of the population is also referred as the point mutation, mutated nucleotide or minor allele. As used herein this state is defined as “presence of a {SNP}”. {\textbar} {\textbar} The term “biomarker”, as used herein, relates to any nucleic acid sequence of any length, or a derivative thereof, which comprises a polymorphic variant as defined in: {\textbar} {\textbar} {SNP} rs6437726, {\textbar} {SNP} rs1986684, {\textbar} {SNP} rs7380830, {\textbar} {SNP} rs3903768, {\textbar} {SNP} rs7325978, {\textbar} {SNP} rs13585, {\textbar} {SNP} rs9368373, {\textbar} {SNP} rs10935354, {\textbar} {SNP} rs8095703, {\textbar} {SNP} rs10206851, {\textbar} {SNP} rs9542977, {\textbar} {SNP} rs4942879, {\textbar} {SNP} rs9542954, {\textbar} {SNP} rs1593478, {\textbar} {SNP} rs9542951, {\textbar} {SNP} rs2188534, {\textbar} {SNP} rs12524124, {\textbar} {SNP} rs4352629, {\textbar} {SNP} rs7448716, {\textbar} {SNP} rs11873533, {\textbar} {SNP} rs10062658, {\textbar} {SNP} rs12547917, {\textbar} {SNP} rs1038268, {\textbar} {SNP} rs2375811, {\textbar} {SNP} rs1352671, {\textbar} {SNP} rs364331, {\textbar} {SNP} rs1924949, {\textbar} {SNP} rs11025990, {\textbar} {SNP} rs3758562, and/or {\textbar} {SNP} rs10156056. {\textbar} A biomarker may, for instance, be represented by a nucleic acid molecule of a length of e.g. 1 nt, 2 nt, 3 nt, 4 nt, 5 nt, 10 nt, 15 nt, 20 nt, 25 nt, 30 nt, 35 nt, 40 nt, 45 nt, 50 nt, 60 nt, 70 nt, 80 nt, 90 nt, 100 nt, 200 nt, 300 nt, 400 nt, 500 nt, 1000 nt, 2000 nt, or more or any length in between these lengths. The representing nucleic acid may be any suitable nucleic acid molecule, e.g. a {DNA} molecule, e.g. a genomic {DNA} molecule or a {cDNA} molecule, or a {RNA} molecule, or a derivative thereof. The biomarker may further be represented by translated forms of the nucleic acid, e.g. a peptide or protein as long as the polymorphic modification leads to a corresponding modification of the peptide or protein. Corresponding information may be readily available to the skilled person from databases such as the {NCBI} {SNP} repository and {NCBI} Genbank. {\textbar} {\textbar} The {SNPs} as described herein may be present on the Watson or the Crick strand, with presence of the corresponding base. I.e. if, for example, a polymorphism is present on the Watson strand as A, it is present on the Crick strand as T, if the polymorphism is present on the Watson strand as T, it is present on the Crick strand as A, if the polymorphism is present on the Watson strand as G, it is present on the Crick strand as C, and if the polymorphism is present on the Watson strand as C, it is present on the Crick strand as G, and vice versa. Also the insertion or deletion of bases may be detected on the Watson and/or the Crick strand, with correspondence as defined above. For analytic purposes the strand identity may be defined, or fixed, or may be choose at will, e.g. in dependence on factors such the availability of binding elements, {GC}-content etc. Furthermore, for the sake of accuracy, the {SNP} may be defined on both strands (Crick and Watson) at the same time, and accordingly be analyzed. {\textbar} {\textbar} A “polymorphic site” or “polymorphic variant” as used herein relates to the position of a polymorphism or {SNP} as described herein within the genome or portion of a genome of a subject, or within a genetic element derived from the genome or portion of a genome of a subject. {\textbar} {\textbar} In theory, the wild-type allele could be mutated to three different nucleotides. However, the event of a mutation to a first nucleotide in the reproductive cells of an individual that gets established in a population occurs very rarely. The event that the same position is mutated to a second nucleotide and established in the population virtually never occurs and can be therefore neglected. Therefore, as used herein, a certain nucleotide position in the genome of an individual can have two states, the wild-type state (absence of a {SNP}) and the mutated state (presence of a {SNP}). {\textbar} {\textbar} The term “wildtype sequence” as used herein refers to the sequence of an allele, which does not show the {CRH} overactivity phenotype according to the present invention. The term may further refer to the sequence of the non phenotype-associated allele with the highest prevalence within a population, e.g. within a Caucasian population. {\textbar} {\textbar} The term “indicator sequence” as used herein refers to the sequence of an allele, which shows an association with a {CRH} overactivity phenotype according to the present invention. The term “indicator nucleotide” as used herein refers to the identity of the nucleotide at the position of a {SNP} or polymorphic site as defined herein, associated with a {CRH} overactivity phenotype according to the present invention. The term may refer to a non-wildtype nucleotide at positions of {SEQ} {ID} {NO}: 1 to 30 as described below: {\textbar} {\textbar} {SNP} rs6437726 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 1, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1986684 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 2, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7380830 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 3, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs3903768 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 4, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7325978 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 5, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs13585 which is represented by a single polymorphic change at position 185 of {SEQ} {ID} {NO}: 6, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9368373 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 7, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs10935354 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 8, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs8095703 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 9, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs10206851 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 10, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542977 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 11, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs4942879 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 12, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs9542954 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 13, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1593478 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 14, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542951 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 15, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs2188534 which is represented by a single polymorphic change at position 200 of {SEQ} {ID} {NO}: 16, wherein in one or two alleles the wild-type nucleotide G is replaced by indicator nucleotide T, {\textbar} {SNP} rs12524124 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 17, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs4352629 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 18, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs7448716 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 19, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11873533 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 20, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs10062658 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 21, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs12547917 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 22, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs1038268 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 23, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs2375811 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 24, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1352671 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 25, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs364331 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 26, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1924949 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 27, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11025990 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 28, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs3758562 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 29, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs10156056 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 30, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide G. {\textbar} The term “allele” or “allelic sequence” as used herein refers to a particular form of a gene or a particular nucleotide, e.g. a {DNA} sequence at a specific chromosomal location or locus. In certain embodiments of the present invention a {SNP} as defined herein may be found at or on one of two alleles in the human genome of a single subject. In further, specific embodiments, a {SNP} as defined herein may also be found at or on both alleles in the human genome of a single subject. The presence of an indicator nucleotide or an indicator triplet as defined herein on both alleles may have a higher predictive value than the presence of an indicator nucleotide or an indicator triplet on one allele only, the other allele comprising a wildtype genotype. The presence or absence of indicator nucleotides or indicator triplets on one or two alleles may be connected or linked with an algorithm for predicting the a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms as described herein. {\textbar} {\textbar} A person skilled in the art would be able to derive the exact position, nucleotide sequence, and indicator sequence from the above identified rs-nomenclature, e.g. from suitable database entries and associated information systems, e.g. the Single Nucleotide Polymorphism database ({dbSNP}) which is incorporated herein by reference. The information may also be retrievable in case of changes to the nomenclature, or to the surrounding sequence elements, e.g. based on history functions of a suitable database. {\textbar} {\textbar} The term “isolated nucleic acid molecule” a used herein refers to a nucleic acid entity, e.g. {DNA}, {RNA} etc, wherein the entity is substantially free of other biological molecules, such as, proteins, lipids, carbohydrates, other nucleic acids or other material, such as cellular debris and growth media. Generally, the term “isolated” is not intended to refer to the complete absence of such material, or to the absence of water, buffers, or salts, unless they are present in amounts which substantially interfere with the methods of the present invention. {\textbar} {\textbar} The term “single nucleotide polymorphism ({SNP}) genotyping analysis” as used herein refers to a test of determining in one or several patients the presence or absence of at least one {SNP}, typically several {SNPs}, and in some embodiments all (known) {SNPs} the human genome, including endogenous and exogenous regions. In particular, a {SNP} genotyping analysis as used herein may not be limited to the {CRHR}1 gene or to genes of the {CRH} pathway. In other words, an {SNP} genotyping analysis as used herein can be a genome-wide screening for {SNPs}. {\textbar} {\textbar} {SNP} genotyping analysis can be performed by methods known in the art such as microarray analysis or sequencing analysis or {PCR} related methods or mass spectrometry or 5′-nuclease assays or allele specific hybridization or high-throughput variants of these techniques or combinations thereof. These and other methods are known in the art. See for example Rampal, {DNA} Arrays: Methods and Protocols (Methods in Molecular Biology) 2010; Graham \& Hill, {DNA} Sequencing Protocols (Methods in Molecular Biology) 2001; Schuster, Nat. Methods, 2008 and Brenner, Nat. Biotech., 2000; Mardis, Annu Rev Genomics Hum Genet., 2008. Genomewide arrays can be purchased from different suppliers such as Illumia and Affymetix. {\textbar} {\textbar} For example, the determination of the nucleotide sequence and/or molecular structure may be carried out through allele-specific oligonucleotide ({ASO})-dot blot analysis, primer extension assays, {iPLEX} {SNP} genotyping, Dynamic allele-specific hybridization ({DASH}) genotyping, the use of molecular beacons, tetra primer {ARMS} {PCR}, a flap endonuclease invader assay, an oligonucleotide ligase assay, {PCR}-single strand conformation polymorphism ({SSCP}) analysis, quantitative real-time {PCR} assay, {SNP} microarray based analysis, restriction enzyme fragment length polymorphism ({RFLP}) analysis, targeted resequencing analysis and/or whole genome sequencing analysis. {\textbar} {\textbar} In some embodiments, any of the methods described herein comprises the determination of the haplotype for two copies of the chromosome comprising the {SNPs} identified herein. {\textbar} {\textbar} The term “determining the status of a biomarker” as used herein refers to any suitable method or technique of detecting the identity of an {SNP}, e.g. at the positions of the biomarkers described herein. The determination method may be a sequencing technique or a technique based on complementary nucleic acid binding. The context of the indicated positions, as well as the strand may differ, e.g. from patient to patient, or from sample to sample etc. {\textbar} {\textbar} A “subject's sample” as used herein may be any sample derived from any suitable part or portion of a subject's body. In some embodiments, blood or saliva samples are used. The sample used in the context of the present invention should be collected in a clinically acceptable manner, in particular in a way that nucleic acids and/or proteins are preserved. {\textbar} {\textbar} The term “primer” may denote an oligonucleotide that acts as an initiation point of nucleotide synthesis under conditions in which synthesis of a primer extension product complementary to a nucleic acid strand is induced. {\textbar} {\textbar} The term “probe” may denote an oligonucleotide that selectively hybridizes to a target nucleic acid under suitable conditions. {\textbar} {\textbar} The primers and probes may be generated such that they are able to discriminate between wild-type allele or mutated allele of the position of a {SNP} to be analyzed. Methods for the design of sequence specific primers and probes are known in the art (see e.g. William B. Coleman, Gregory J. Tsongalis, Molecular Diagnostics: For the Clinical Laboratorian, 2007; Weiner et al. Genetic Variation: A Laboratory Manual, 2010). {\textbar} {\textbar} Typically, a {SNP} is considered in the genotyping analysis if it occurs in a certain percentage in the population, for example in at least 5\% or at least 10\% of the population. In other words, the minor allele frequency ({MAF}) is larger than 0.05 or 0.10 ({MAF}{\textgreater}0.05 or {MAF}{\textgreater}0.10). {\textbar} {\textbar} For the {SNP} genotyping analysis a nucleic acid or {DNA} sample from a patient may be used. The nucleic acid or {DNA} sample can be a blood sample, a hair sample, a skin sample or a salvia sample of the patient. Any other sample obtainable from the patient and containing patient nucleic acid or {DNA} can also be used. The sample can be collected from the patient by any method known in the art. For example, a blood sample can be taken from a patient by use of a sterile needle. The collection of salvia out of the mouth and throat of the patient can be performed by use of a sterile cotton bud or by flushing said area and collecting the flushing solution. {\textbar} {\textbar} Usually, the nucleic acid or {DNA} is extracted or isolated or purified from the sample prior to {SNP} genotyping analysis. Any method known in the art may be used for nucleic acid or {DNA} extraction or isolation or purification. Suitable methods comprise inter alia steps such as centrifugation steps, precipitation steps, chromatography steps, dialyzing steps, heating steps, cooling steps and/or denaturation steps. For some embodiments, a certain nucleic acid or {DNA} content in the sample may be reached. Nucleic acid or {DNA} content can be measured for example via {UV} spectrometry as described in the literature. However, in alternative embodiments {SNP} genotyping analysis may also be performed by using a non-extracted or non-purified sample. {\textbar} {\textbar} Nucleic acid or {DNA} amplification may also be useful prior to the {SNP} analysis step. Any method known in the art can be used for nucleic acid or {DNA} amplification. {\textbar} {\textbar} The sample can thus be provided in a concentration and solution appropriate for the {SNP} analysis. {\textbar} {\textbar} The analyzed {SNPs} may be represented by values 0, 1 or 2. The value “0” may indicate that the {SNP} is present on none of the two homologous chromosomes. The value “1” may indicate that the {SNP} is present on one of the two homologous chromosomes. The value “2” may indicate that the {SNP} is present on both homologous chromosomes. Homologous chromosomes correspond to each other in terms of chromosome length, gene loci and staining pattern. One is inherited from the mother, the other is inherited from the father. {\textbar} {\textbar} In a step (b) of the method for providing a prediction algorithm, a value indicative for {CRH} activity in each patient is determined. {\textbar} {\textbar} The term “normal {CRH} activity” refers to a range of {CRH} activity which can be found in human beings who are not affected by a condition which is associated with an increase of {CRH} activity (such as depression). A value indicative for normal {CRH} activity is usually considered to be indicative or predictive for a patient not responding to a treatment with a {CRH}1 antagonist. {\textbar} {\textbar} The terms “{CRH} overactivity”, “{CRH} system overactivity”, “{CRH} hyperactivity”, “{CRH} hyperdrive” or “central {CRH} hyperdrive” are used herein interchangeable. An indication for {CRH} overactivity may be an increase in activity or concentration of {CRH} or of one or several molecules downstream of the {CRHR}1 receptor, that are activated or whose concentration is increased based on the activation of {CRHR}1 receptor upon {CRH} binding. A further indication for {CRH} overactivity may be a decrease in activity or concentration of one or several molecules downstream of the {CRHR}1 receptor, that are inactivated or whose concentration is decreased based on the activation of {CRHR}1 receptor upon {CRH} binding. A value indicative for {CRH} overactivity is usually considered to be indicative or predictive for a patient responding to a treatment with a {CRHR}1 antagonist. {CRH} activity vs. {CRH} overactivity may be defined relatively to the whole group, e.g. by using a median split of the area under the curve of the {ACTH} response in the dex/{CRH} test. Responses in the upper median may be categorized as being predictive of {CRH} overactivity, while responses in the lower median are indicative of normal {CRH} activity. {\textbar} {\textbar} A “value indicative for {CRH} activity”, a “value indicative for {CRH} overactivity” and/or a “value indicative for normal {CRH} activity” can be obtained by determining the concentration or activity of {CRH} and/or of a downstream target of the {CRHR}1 receptor. The analysis is usually set up in a way that it can be excluded that the modulation of activity or concentration of a downstream target of the {CRHR}1 receptor is due to another disturbance than {CRH} activity. For instance, the concentrations or activities of adrenocorticotrophin ({ACTH}) and/or cortisol are useful biomarkers for determining a value indicative for {CRH} overactivity. {\textbar} {\textbar} Typically, the {CRH} overactivity in each patient may be determined by measuring the {ACTH} and/or cortisol level response to a combined dexamethasone suppression/{CRH} stimulation test as described in Heuser et al. (J Psychiatr Res., 1994). In one embodiment of a combined dexamethasone suppression {CRH} stimulation test, subjects are pre-treated with dexamethasone and blood is drawn in certain intervals. Further, human {CRH} is administered after the first pretreatment with dexamethasone. Plasma {ACTH} and/or cortisol concentrations are then determined. The neuroendocrine response to the dex/{CRH} test may be analyzed using the total area under the curve ({AUC}) of the {ACTH} response. Details of an exemplary dex/{CRH} test are also described in Example 1 below. {\textbar} {\textbar} The neuroendocrine response to the dex/{CRH} test may be analyzed using the total area under the curve ({AUC}) of the {ACTH} response. Patients suffering from depression normally show an increased release of cortisol and of adrenocorticotropic hormone ({ACTH}) in response to the combined treatment with dexamethasone and {CRH} as performed during the test, thus indicating a dysregulation of the hypothalamic-pituitary-adrenal ({HPA}) axis. Patients with a high {HPA} axis dysregulation show {AUC} values of cortisol of between 3000 and 18000 {AUC} units (ng/ml×75 min) and/or {AUC} values of {ACTH} of between 1000 and 6500 {AUC} units (pg/ml×75 min). Patients having a low {HPA} axis dysregulation show {AUC} values of cortisol of between 300 and 2500 {AUC} units (ng/ml×75 min) and/or {AUC} values of {ACTH} of between 250 and 1000 {AUC} units (pg/ml×75 min) Various antidepressants lead to a reduction of these increased cortisol and {ACTH} levels in a combined dex/{CRH} test performed after the treatment with the antidepressants. Treatment response to antidepressants can thus be determined by performing a second dex/{CRH} test after treatment with the antidepressant and comparing the neuroendocrine response to the one shown in a combined dex/{CRH} test performed prior to treatment with the antidepressant. {\textbar} {\textbar} The term “normal {CRH} activity” refers to a range of {CRH} activity which can be found in human beings who are not affected by a condition which is associated with an increase of {CRH} activity (such as depression). A value indicative for normal {CRH} activity is usually considered to be indicative or predictive for a patient not responding to a treatment with a {CRHR}1 antagonist. {\textbar} {\textbar} “Downstream target” or “molecule which is downstream of the {CRHR}1 receptor” as used herein may denote a molecule such as an endogenous molecule (e.g. peptide, protein, lipid, nucleic acid or oligonucleotide) that is regulated by {CRHR}1 directly or indirectly. The direct or indirect regulation may comprise direct or indirect modulation of the activity and/or expression level and/or localization, degradation, stability of the downstream target. {\textbar} {\textbar} Steps (c) and (d) of the method for providing a prediction algorithm may analyze the association of the analyzed {SNPs} with the value indicative for {CRH} overactivity and/or normal {CRH} activity and generate an algorithm for predicting the treatment response to {CRHR}1 antagonists. {\textbar} {\textbar} In an exemplary embodiment, the group of patients may be split into two sets of similar size and similar values for descriptors such as demographic descriptors or clinical descriptors. These two sets are hereinafter also referred to as “training set” and “test set”. {\textbar} {\textbar} In step (c) of the method of this exemplary embodiment, at least one {SNP} associated with the value indicative for {CRH} overactivity as determined in step (b) is identified in the training set. {\textbar} {\textbar} Further, there can be at least two alternatives for the result provided by the prediction algorithm. First, the result may be a categorical answer whether the patient responds to {CRHR}1 antagonist treatment or not. Second, the prediction algorithm may provide the answer to which degree the patient responds or does not respond to the treatment. Depending on the desired result provided by the prediction algorithm the way of determining the algorithm may differ. {\textbar} {\textbar} In the alternative that the prediction algorithm will analyze whether a patient responds or does not respond to {CRHR}1 antagonist treatment, the values indicative for {CRH} activity may be provided as logic data variable (Boolean type; 0 vs. 1; true vs. false, high vs. low responder). Therefore, if the test performed to determine values indicative for {CRH} overactivity provides a data range, the patients may be dichotomized by a threshold into high vs. low responders. {\textbar} {\textbar} In the alternative that the test will analyze to which degree the patient responds or does not respond to the {CRHR}1 antagonist treatment, the values indicative for {CRH} activity may be provided as numerical values. {\textbar} {\textbar} Typically, {SNPs} that are modified in a significant percentage of the population are used in the method for providing a prediction algorithm. For example, only {SNPs} with a minor allele frequency ({MAF}) greater than 0.05 or 0.10 may be selected for further analysis. This means that only {SNPs} that are modified in at least 5\% or 10\% of the population are selected for further analysis. {\textbar} {\textbar} Association for all {SNPs} with the value indicative for {CRH} activity is tested by an association analysis testing the likelihood for a patient to be {CRH} overactive vs. {CRH} non-overactive in dependence of the genotype of said patient. Said association analysis may be conducted for example by an additive genetic model and/or by a logistic regression. A {SNP} is e.g. identified to be associated with a value indicative for {CRH} overactivity if the corresponding p-value is at least 1×10 {\textbar} {\textbar} −3 {\textbar} or at least 1×10 {\textbar} −4 {\textbar} or at least 1×10 {\textbar} −5 {\textbar} . The lower the p-value the more the {SNP} is associated with a value indicative for {CRH} overactivity. Accordingly, a {SNP} is e.g. identified to be associated with a value indicative for normal {CRH} activity if the corresponding p-value is at least 1×10 {\textbar} −3 {\textbar} or at least 1×10 {\textbar} −4 {\textbar} or at least 1×10 {\textbar} −5 {\textbar} . {\textbar} In the step (d) of this exemplary embodiment, the algorithm for predicting a treatment response to {CRHR}1 antagonists may be determined by the use of {SNPs} in the test set by a machine learning method. {\textbar} {\textbar} The term “algorithm for predicting” as used herein may refer to a classification function (also known as binary classification test). {\textbar} {\textbar} The term “machine-learning” as used herein may refer to a method known to the person skilled in the art of machine learning. In particular, machine learning is concerned with the design and development of algorithms that allow computers to evolve behaviors based on empirical data, such as from sensor data or databases. It may be selected from the group consisting of artificial neural network learning, decision tree learning, support vector machine learning, Bayesian network learning, clustering, and regression analysis. {\textbar} {\textbar} The term “reliable prediction of the treatment response to {CRHR}1 antagonists” as used herein may refer to a high performance of the prediction algorithm. The evaluation of the performance of the prediction algorithm may depend on the problem the algorithm is applied for. If the algorithm is used to identify patients that are likely to response to the treatment with {CRHR}1 antagonists the performance is usually expressed by a high accuracy and/or sensitivity and/or precision. If patients should be identified which are likely not to respond to the treatment with {CRHR}1 antagonists, specificity and/or negative predictive value are typical statistical measures to describe the performance of the prediction algorithm. {\textbar} {\textbar} For optimizing the prediction performance of the algorithm, the step of determining the algorithm by a machine-learning method in a first subset of the test set and testing the prediction performance in an second independent subset of the test set may be repeated based on different numbers and groups of {SNPs}, until the desired prediction performance is reached. {\textbar} {\textbar} Accuracy, sensitivity, precision, specificity and negative predictive value are exemplary statistical measure of the performance of the prediction algorithm. In the following, examples are given for determining the performance of the prediction algorithm. {\textbar} {\textbar} As used herein, accuracy may be calculated as (number of true positives+number of true negatives)/(number of true positives+number of false positives+number of true negatives+number of false negatives), e.g. (number of patients correctly diagnosed as responding to {CRHR}1 antagonist+number of patients correctly diagnosed as not responding to {CRHR}1 antagonist)/(number of patients correctly diagnosed as responding to {CRHR}1 antagonist+number of patients wrongly diagnosed as responding to {CRHR}1 antagonist+number of patients correctly diagnosed as not responding to {CRHR}1 antagonist+number of patients wrongly diagnosed as not responding to {CRHR}1 antagonist). The accuracy of prediction may e.g. be at least 60\%, at least 70\%, at least 80\% or at least 90\%. {\textbar} {\textbar} A used herein, sensitivity may be calculated as (true positives)/(true positives+false negatives), e.g.: (number of patients correctly diagnosed as responding to {CRHR}1 antagonist)/(number of patients correctly diagnosed as responding to {CRHR}1 antagonist+number of patients wrongly diagnosed as not responding to {CRHR}1 antagonist). The sensitivity of prediction may be at least 60\%, at least 70\%, at least 80\% or at least 90\%. {\textbar} {\textbar} As used herein, precision (also referred to as positive predictive value) may be calculated as (true positives)/(true positives+false positives), e.g.: (number of patients correctly diagnosed as responding to {CRHR}1 antagonist)/(number of patients correctly diagnosed as responding to {CRHR}1 antagonist+number of patients wrongly diagnosed as responding to {CRHR}1 antagonist). The precision of prediction may be at least 60\%, at least 70\%, at least 80\% or at least 90\%. {\textbar} {\textbar} As used herein, specificity is calculated as (true negatives)/(true negatives+false positives), e.g.: (number of patients correctly diagnosed as not responding to {CRHR}1 antagonist)/(number of patients correctly diagnosed as not responding to {CRHR}1 antagonist+number of patients wrongly diagnosed as responding to {CRHR}1 antagonist). The specificity of prediction may be at least 60\%, at least 70\%, at least 80\% or at least 90\%. {\textbar} {\textbar} As used herein, negative predictive value is calculated as (true negatives)/(true negatives+false negatives), e.g.: (number of patients correctly diagnosed as not responding to {CRHR}1 antagonist)/(number of patients correctly diagnosed as not responding to {CRHR}1 antagonist+number of patients wrongly diagnosed as not responding to {CRHR}1 antagonist). The negative predictive value may be at least 60\%, at least 70\%, at least 80\% or at least 90\%. {\textbar} {\textbar} Other statistical measures useful for describing the performance of the prediction algorithm are geometric mean of sensitivity and specificity, geometric mean of positive predictive value and negative predictive value, F-measure and area under {ROC} curve, and the positive and negative likelihood ratios, the false discovery rate and Matthews correlation coefficient. These measures and method for their determination are well known in the art. {\textbar} {\textbar} In general, a prediction algorithm with high sensitivity may have low specificity and vice versa. The decision to select an algorithm having certain statistical characteristics such as accuracy, sensitivity or specificity may also depend on the costs associated with a treatment with a {CRHR}1 antagonist should the prediction be positive and/or whether such a treatment is detrimental in cases where the result is a false positive. {\textbar} {\textbar} For a prediction whether a patient likely responds to the treatment with {CRHR}1 antagonists the prediction algorithm may be based on a number of {SNPs} sufficient to achieve a prediction sensitivity and/or precision of at least 55\%, optionally at least 80\%. {\textbar} {\textbar} For the prediction whether it is unlikely that a patient responds to the treatment with {CRHR}1 antagonists the prediction algorithm may be based on a number of {SNPs} sufficient to achieve a prediction specificity and/or negative predictive value of at least 55\%, optionally at least 80\%. {\textbar} {\textbar} For a prediction whether a patient responds to a treatment with {CRHR}1 antagonists or not the prediction algorithm may be based on a number of {SNPs} sufficient to achieve sensitivity and/or precision and/or specificity and/or negative predictive value of at least 55\%, optionally at least 80\%. {\textbar} {\textbar} In one embodiment, a number N of {SNPs} is associated with a value indicative for {CRH} overactivity or normal {CRH} activity in step (d) of the method for providing an algorithm and/or the presence or absence of a number N of {SNPs} is determined in step (a) of the method for predicting a treatment response, wherein N is sufficient to provide an accuracy of at least 80\% and a sensitivity of at least 70\% and a specificity of at least 70\%. In another embodiment, a number N of {SNPs} is associated with a value indicative for {CRH} overactivity in step (d) of the method for providing an algorithm and/or the presence or absence of a number N of {SNPs} is determined in step (a) of the method for predicting a treatment response, wherein N is sufficient to provide an accuracy of at least 85\% and a sensitivity of at least 80\% and a specificity of at least 80\%. {\textbar} {\textbar} Typically, at least 10, at least 20, at least 25 or at least 30 {SNPs} are used for determination of the algorithm in step (d) of the method for providing a prediction algorithm. {\textbar} {\textbar} The skilled person in the art knows that the use of different machine-learning methods and adapting parameters used therein can be also used for improvement of the prediction reliability. The whole statistical work-flow can be automated by a computer. {\textbar} {\textbar} Another aspect of the invention is a method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, wherein the method may comprise the following steps: {\textbar} {\textbar} (a) determining in a nucleic acid sample obtained from a patient the presence or absence of at least one single nucleotide polymorphism ({SNP}) associated with a value indicative for {CRH} overactivity; {\textbar} {\textbar} (b) predicting the treatment response to {CRHR}1 antagonists by linking the algorithm provided by the method of claim {\textbar} {\textbar} 1 {\textbar} with the presence or absence of the at least one {SNP} determined in step (a). {\textbar} “Linking an algorithm for predicting a treatment response to {CRHR}1 antagonists in patients having depressive symptoms and/or anxiety symptoms with the presence or absence of the at least one {SNP}” as used herein may refer to using such an algorithm to predict the treatment response based on the determined presence or absence of the at least one {SNP}, e.g. by integrating the at least one {SNP} determined in step (a) of the above method by the algorithm. {\textbar} {\textbar} In one embodiment of the method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, step (a) comprises determining at least one of the {SNPs}, optionally all of the {SNPs} which were associated with a value indicative for {CRH} overactivity when determining the algorithm by machine-learning from this association. {\textbar} {\textbar} In another embodiment of the method for predicting a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, the method may be accompanied by analyzing the rapid-eye-movement ({REM}) during night sleep of a patient in a sleep {EEG}. {\textbar} {\textbar} {REM} sleep typically comprises a characteristic coincidence of nearly complete muscle atonia, a waking-like pattern of brain oscillations and rapid eye movements ({REMs}). The amount of {REMs} during consecutive {REM} sleep episodes is usually increasing throughout the night. Single and short {REMs} with low amplitude can be characteristic for initial parts of {REM} sleep. The amount of {REMs} in particular within the first {REM} sleep episode can be of clinical relevance. Recent clinical and animal data supports the correlation of {REM} density with an increased {CRH} activity. For example, Kimura et al. (Mol. Psychiatry, 2010) showed that mice overexpressing {CRH} in the forebrain exhibit constantly increased rapid eye movement ({REM}) sleep compared to wildtype mice. In addition, it could be shown that treatment with the {CRHR}1 antagonist {DMP}696 could reverse the {REM} enhancement. Thus, the {SNP} analysis and {REM} density analysis as described herein may be combined for predicting the response of patients with depressive symptoms and/or anxiety symptoms to treatment with a {CRHR}1 antagonist. The {REM} analysis may be carried out before, concomitant or after the {SNP} analysis. For example, the {REM} density analysis may be carried out on persons that where identified by the {SNP} analysis as {CRH} hyperdrive patients. {\textbar} {\textbar} The recording of a “sleep-{EEG}” (also referred to “polysomatic recordings”) may comprise electroencephalography ({EEG}), vertical and horizontal electrooculography ({EOG}), electromyography ({EMG}) and/or electrocardiography ({ECG}). In {EOG}, muscle activities of right and left eye may be recorded by electrooculograms (one or typically two channels) in order to visualize the phasic components of {REM} sleep. {\textbar} {\textbar} “{REM} analysis” or “analyzing the rapid-eye-movement ({REM})” may refer to a method comprising recoding of muscle activities of right and left eye by {EOG} and then analyzing the electrooculogram. The recognition of {REM} in the electrooculogram may be done manually (for example by standard guidelines Rechtschaffen and Kales, 1968, Bethesda, Md.: National Institute of Neurological Diseases and Blindness). {\textbar} {\textbar} In one embodiment the method comprises a further step of obtaining a nucleic acid sample from a patient preceding the step of {SNP} determination. {\textbar} {\textbar} Typically, a {SNP} is considered in the genotyping analysis of step (a) of the method of prediction if it occurs in a certain percentage in the population, for example in at least 5\% or at least 10\% of the population. In other words, the minor allele frequency ({MAF}) is larger than 0.05 ({MAF}{\textgreater}0.05) or 0.10 ({MAF}{\textgreater}0.10). {\textbar} {\textbar} For the {SNP} genotyping analysis of step (a) of the method of prediction a nucleic acid or {DNA} sample from a patient may be used. The nucleic acid or {DNA} sample can be a blood sample, a hair sample, a skin sample or a salvia sample of the patient. Any other sample of the patient containing nucleic acid or {DNA} can also be used. The sample can be collected from the patient by any method known in the art. For example, a blood sample can be taken from a patient by use of a sterile needle. The collection of salvia out of the mouth and throat of the patient can be performed by use of a sterile cotton bud or by flushing said area and collecting the flushing solution. {\textbar} {\textbar} Usually, the nucleic acid or {DNA} is extracted or isolated or purified from the sample prior to {SNP} genotyping analysis. Any method known in the art may be used for nucleic acid or {DNA} extraction or isolation or purification. Suitable methods comprise inter alia steps such as centrifugation steps, precipitation steps, chromatography steps, dialyzing steps, heating steps, cooling steps and/or denaturation steps. For some embodiments, a certain nucleic acid or {DNA} content in the sample may be reached. Nucleic acid or {DNA} content can be measured for example via {UV} spectrometry as known in art. However, the {SNP} genotyping analysis may also be performed by using a non-extracted or non-purified sample. {\textbar} {\textbar} Nucleic acid or {DNA} amplification may also be useful prior to the {SNP} analysis step. Any method known in the art can be used for nucleic acid or {DNA} amplification. The sampled can thus be provided in a concentration and solution appropriate for the {SNP} analysis. {\textbar} {\textbar} The analyzed {SNPs} may be represented by values 0, 1 or 2. The value “0” may indicate that the {SNP} is present on none of the two homologous chromosomes. The value “1” may indicate that the {SNP} is present on one of the two homologous chromosomes. The value “2” may indicate that the {SNP} is present on both homologous chromosomes. Homologous chromosomes correspond to each other in terms of chromosome length, gene loci and staining pattern. One is inherited from the mother, the other is inherited from the father. {\textbar} {\textbar} In order to determine {SNPs}, {SNP}-specific primers and/or probes, a primer extension reaction, {SNP} microarrays, {DNA}-sequencing may be used. These reagents and methods are routinely used in the art (see for example Chen, {PCR} Cloning Protocols (Methods in Molecular Biology) 2002; Schuster, Nat. Methods, 2008, Rampal, {DNA} Arrays: Methods and Protocols (Methods in Molecular Biology) 2010; Brenner, Nat. Biotech., 2000; Mardis, Annu Rev Genomics Hum Genet., 2008). For example, {MALDI}-{TOF} (matrix-assisted laser desorption ionization time of flight) mass spectrometry on the Sequenom platform (San Diego, {USA}) may be used to genotype the selected variants. For primer selection, multiplexing and assay design, and the mass-extension for producing primer extension products the {MassARRAY} Assay Designer software may be used using the sequences presented in table 1 as input. The {MassARRAY} Typer 3.4 software may be used for genotype calling. Any other reagent or method known to the person skilled in the art may be used in order to detect the {SNPs} in an individual. {\textbar} {\textbar} In one embodiment, at least one {SNP} determined in step (a) and used for the prediction algorithm of step (b) is a {SNP} selected from the group consisting of {SNPs} as shown in table 1 and an {SNP} in strong linkage disequilibrium with any of the {SNPs} shown in table 1. {\textbar} {\textbar} {TABLE} 1 {\textbar} {\textbar} {SNPs} (together with flanking sequences) which may be used {\textbar} {\textbar} to predict the response to {CRHR}1 antagonists in patients {\textbar} {\textbar} with depressive symptoms and/or anxiety symptoms. The {\textbar} {\textbar} position of the {SNP} is indicated in bold as [wild-type {\textbar} {\textbar} allele/mutated allele]. {\textbar} {\textbar} {SNP}\_ID {\textbar} {\textbar} {SEQUENCE} {\textbar} {RS}6437726 {\textbar} {\textbar} {CAAGAAAGAGAGTAATAAAAATAACCACAATGAGGGCTCTCATTAATACT} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {GGATCTTATGGAAACCAATTGTTCAGTCCCTCAACAAAAGACCAGATGG} {\textbar} {NO}: 1 {\textbar} {\textbar} {GCAGGAAGCTAAATATACACCATGCACTAAACATTATGAGTATCATAGTT} {\textbar} {TACAAGTCAAAGGGGGCTCTATTGAAGATAGTTCTATTTTCCCTCTATAT} {\textbar} {\textbar} T {\textbar} {\textbar} [A/G] {\textbar} {TCTGCTAGACAATACCTGATAACATTATCCAAGTAAATGACAACTT} {\textbar} {GATAAATAGTAATTTCCAATGGTGAACAGAGGTGACATTTCCTCATTACA} {\textbar} {\textbar} {AAAATATTTTCTTTGGCAGATGAGATTAACTGAATAAGAAATCCACTGAC} {\textbar} {\textbar} {ACTGAAATCACAGAGCCAAATTCCCTATCACAGCACTTATCACATTGCGT} {\textbar} {\textbar} {TAGG} {\textbar} {\textbar} {RS}1986684 {\textbar} {\textbar} {TTCCTTGTAGCGGGGAGAGAGACTCAGGGAAGGCAGGGTGATACCTGA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {GTTGGGGCTTAAAGCAAGGTAGGGTGTGTGTGGTGATGGCAAAATAGG} {\textbar} {NO}: 2 {\textbar} {\textbar} {TAGGAAGACAGCACGGGCAAAGTCCTGGAGGCAAGGACAGAAAGAGGA} {\textbar} {AGTGGCAGGAAGTGAGGCTGGGGAAATGAGTAGGGGTCAATCATGATG} {\textbar} {\textbar} {TTTCTGGT} {\textbar} {\textbar} [A/G] {\textbar} {TAGGGAAGAGTTTGGAATGCATCCTCTAGGCCATACGC} {\textbar} {CATTGGGGGCTTTTAAGAAAGACAGTGATGTTGGTTTGATTTGCATTTTA} {\textbar} {\textbar} {TATAGACTTTTCTGGCAGCTGAGAGGAAGGTGGTTTTGAGAATCACAAA} {\textbar} {\textbar} {GCTGCGGGAAGATCAGTCAGGAGGGTTCTAGAATAATCCAGGCAAGAG} {\textbar} {\textbar} {CTGATGGGGACTGAG} {\textbar} {\textbar} {RS}7380830 {\textbar} {\textbar} {ACAGGGGTGGCTACTCTTTCTCCAGAAATAGGTGTCCTGTGGGGCATTT} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {TGAAGTAGAATGTTGATAGTTGCTTTCAATTTTAGACTGGTAAATAAGAAT} {\textbar} {NO}: 3 {\textbar} {\textbar} {TGGGCATTTGAATTTCAATATACTCACTGTGTAACTGTTATTGAGTATGCT} {\textbar} {TTAAGTGACCTATAATACTGCTTCATTTAACTTTATTGTCCTAATAACT} {\textbar} {\textbar} [C/ {\textbar} T] {\textbar} {\textbar} {TCTTAGAGTGACAATAACTTAGGTTAGCCACTTGCCTAGGGTTCTGAA} {\textbar} {ACCAAGTAAATGGTGGAGCTGGAATTGCTGTTCTTGTCAGTCATTAGACT} {\textbar} {\textbar} {AGATCGGTTTTCTTCTTCCTACAAATTTTATATACTAAAAAATTTTGAAAAA} {\textbar} {\textbar} {AGACATTTTTCTTTGGGAAAAATAGGGAATGTCAGATCCCTTTGGAGATG} {\textbar} {\textbar} {RS}3903768 {\textbar} {\textbar} {CTCGCAGCAACCAAGCCTGCCCAAGCCGGGGAAACCTGGGGAGCAAAC} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CTTCACCTGCACTGTACATCAGAGACCAGTTGGCCCTATTTTGGCTCCT} {\textbar} {NO}: 4 {\textbar} {\textbar} {GTGGACAGGTAAGTATCCCTTTTGACTCATCCCCCAAATATCAGGTGAG} {\textbar} {CCAGGAAAATAAGGCCTTTGGCTTAGACAGTCAATTCAAAGTCTGCCAT} {\textbar} {\textbar} {AGCAT} {\textbar} {\textbar} [A/C] {\textbar} {CCTAATTACATCCCTATTGCCCCTTTTCTAGGTCGTTTCTCC} {\textbar} {TCTAACACGATTTTATTTTTCTGTCAGCCATTTTATTTTATTTCTCACCTTG} {\textbar} {\textbar} {AAATATATGTTTTCTTTGCAGTTTTTGCTTTGGCTTCCTGCTAACTCTATT} {\textbar} {\textbar} {TGGGCAATTGTTTAAGGCTGAACACTTGGTTATGAGAGGTACCCTGTTG} {\textbar} {\textbar} {TGTTGA} {\textbar} {\textbar} {RS}7325978 {\textbar} {\textbar} {TCATCAAGTCTCCTTTTTCTCTAGGAAAAATAACATTGTCAAGGTTATTAA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CAGTCAATAAGCTGTCATAGGCTCAGCATGGATGGGGATATTGGGTTTC} {\textbar} {NO}: 5 {\textbar} {\textbar} {CTTGTGCTTATATGAAAGATGGGAAAATCCGAAGTTCTTTTCACCCTGAT} {\textbar} {ATGGAAAATACCCAACATGAGGAGAAGCAGCAGCTATATGATTCTGAGC} {\textbar} {\textbar} A {\textbar} {\textbar} [C/T] {\textbar} {AGAATGGGAGTAAGAATAGGGTCATGCTGTACTGATTATCTGCTA} {\textbar} {ATAAAATGCAAAAGTGTTAGGTAATTTCATCAATATCCAGTTAATACTAAT} {\textbar} {\textbar} {ATAGTTAATATTTCATGACTGGGTAATATTTTATAATGATAAATATTTTTAT} {\textbar} {\textbar} {AGATCTTAGCTCTTTTTATTCTCATATCAACTGTATGAAATCAGTGATTGG} {\textbar} {\textbar} T {\textbar} {\textbar} {RS}13585 {\textbar} {\textbar} {CTGGGGACCTCAGGGAGAGGTACGCAGGTTGCCATGGCTGCGTCTGCA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {GTCCACCTGCCTTTCCACGCCAGGGAGTCAGTGATGTGGAGCCCCCTG} {\textbar} {NO}: 6 {\textbar} {\textbar} {GGCCCCAGTGGAAGCAGCGATCAGACTATGTGTCCTTGAAATAATGTTT} {\textbar} {ATTCCACGCTGTCCCGACAGCCCCCTCTGCAGGTCCCCT} {\textbar} {\textbar} [C/T] {\textbar} {GGTGTA} {\textbar} {CTCTGAGGTGGGAAACCCTCCCTGGGGGCGGTGAAGGGGAACTCGGG} {\textbar} {\textbar} {CCACCCCACCAGCCAGCAGATGCTCCAGCAGCCAGAGCCCCAGCCTGG} {\textbar} {\textbar} {AGCTGAGGCTCTTCCTGGGGCTCGCCGGGCCCCTGCAGGCTTTTCGGA} {\textbar} {\textbar} {CCCTCAGCCAGCCCGGCTTCCTCTGCTTTGGGCAGCAGCAAGCTGGCC} {\textbar} {\textbar} {CTT} {\textbar} {\textbar} {RS}9368373 {\textbar} {\textbar} {TTCCTGTGCCTCAGCTCCTCTGTAGAATGGTGCTGGCAATACAGTTTGC} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CTCATTGGGCTCTTGTAAGCTTTAAATAGGTTATTATACATAAAGAGCTA} {\textbar} {NO}: 7 {\textbar} {\textbar} {ATAGTGATGCCTGTAGCCGTTGTCTAAGTGCTAGCTCTGATGATGGTGA} {\textbar} {CAAAGAAGTAATAGCAATCAGTGGTTTAGATTAAACCATTTTAGGCATAA} {\textbar} {\textbar} {AC} {\textbar} {\textbar} [C/T] {\textbar} {GTTCTGCTAGAATCCAAGGGGAGATTTTTTCCCATCAAGGAGAC} {\textbar} {ATAGCTTGTTGGGAAGATAAGACATACCCAATTGCAGAAGTAATTAATTA} {\textbar} {\textbar} {ATTCTTTTTTTTTTTTTTTTTTTTTTTTTTGCGATGGAGTTTCGCTCTTGTT} {\textbar} {\textbar} {GCCCAGGCTGGAGTGCAATAGCATGATCTCGGCTCACCACAACCTCTG} {\textbar} {\textbar} {CCTCCT} {\textbar} {\textbar} {RS}10935354 {\textbar} {\textbar} {ATAGGCCCTATACAGCTCTCAATTTCTTTAATCAATCTTCCTAGCAGCCC} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {GTGAGAAATATTACTGTCTTCAGCTTCCTAAAGGAGAAAACAGAGGCCT} {\textbar} {NO}: 8 {\textbar} {\textbar} {GGAGGGATTAAAAGACTTTTCTAAGATTTTAGAGGGCATGTTAGGGTTCA} {\textbar} {GGCCCAGGGCTGTCTAACCCAAGGCCTAATTCCTTCTATTACATCCATC} {\textbar} {\textbar} {AT} {\textbar} {\textbar} [A/G] {\textbar} {CATGAGTGAGCACTGGGCATGAGGATACGTCAGTGAAAGGGGC} {\textbar} {CCTGTAACATGGACCTTACATTTTGGCTGGGGGAGACAGGCAATGAATA} {\textbar} {\textbar} {CATAGGACCATGTTGGGAAGTGCTAAGTACTCTGATGATAACACAGCAG} {\textbar} {\textbar} {GGTGAGGTGACAGAGGTCTAGGGAGAGTGGTGTTCAGCAAAAACTTCT} {\textbar} {\textbar} {CTGGGGAGAGA} {\textbar} {\textbar} {RS}8095703 {\textbar} {\textbar} {AAAATTTACCAGGTTTAAAAAAAAAAAAACTCAAATGATATTTCAGAAACC} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {TACCCCTTTCAAAACAAGGAGGAGAAAAATCTTCTCCACAAAAGCACATA} {\textbar} {NO}: 9 {\textbar} {\textbar} {TTGAAAAAATATTTTGGGGGCAAGGCCTGAAAGGGTTGGCAGTGTGCAG} {\textbar} {TTCTGTTATTATTCCCGTGGCCATTTTATGGGCCTCAGCAAAACACTGGG} {\textbar} {\textbar} [A/G] {\textbar} {\textbar} {TCATTATCTGTCTTCTGGTTACTCCAGGAGAGCTAGCCATCACAAC} {\textbar} {CCAATGGAAGAGACTTCAGAGAAACCCACACAGGCACCAGAAGTCCTTC} {\textbar} {\textbar} {CCTTTCATCTGCCACTGTGGGGTTTTGTCCTCATCTATTACAATGTTGTC} {\textbar} {\textbar} {CAATCTCAGACTGCATTCAGAACAAAGGCTCTCAGACTGAGGATGAGTT} {\textbar} {\textbar} {CTTGGA} {\textbar} {\textbar} {RS}10206851 {\textbar} {\textbar} {CCAAATAATTGTTATTGTTGTTTTAACATGGCAATCACGTTATTTGCCATA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {TGTGAAAAAGAATATTTAAAATGCTTTTTAAAACTATGTATGTAAAAGAAT} {\textbar} {NO}: 10 {\textbar} {\textbar} {GTTTAAATTGTTTTAAAAATATGTTATATCTACCTTGGCACCATCCTTGCT} {\textbar} {GTTGAGAAATGACTTTTACCTGCTTACTTAGAAGGAAATGTCAGAAG} {\textbar} {\textbar} [C/T] {\textbar} {AGAAGTACATTTGAATACGATTATTTGAAAGCTTCATCCATTTTTCAAAG} {\textbar} {\textbar} {AATGTATACAGTAACACTAAATAGAAAGCATAGTTTATCAACTCTTCACTA} {\textbar} {\textbar} {AGAACAGTCTAGCAAGTATATCAGAGTGGCTGTGGTTCCAGTTGGACTA} {\textbar} {\textbar} {ACCTAATCATTTATGAAAAGGTGATAATAAGCTTGGACCAAGAGCACCCA} {\textbar} {\textbar} {RS}9542977 {\textbar} {\textbar} {CAGATGTTATGTGAAACTCTGGAGAAATAGTAGCAAGCAAGACTCACAT} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {GCCTCCTGCCCTCACAGAGCTCCATGATCTGGTGAAAGTGCCAGATATT} {\textbar} {NO}: 11 {\textbar} {\textbar} {TAAACCCATGGATGTGTGCACACAAAATAACAATTCTCTCAAGCGTTGTG} {\textbar} {AAGAAAAGTCACAGAGCACTACAAAAGCATGTAAGAGTGAGGCAAAACC} {\textbar} {\textbar} {TAT} {\textbar} {\textbar} [C/T] {\textbar} {GTGTTAGGACAGGGAAGGCTTCTGTGAGCTAACCTGAAGGAT} {\textbar} {GAGTAGGGGTGAGCCAGATGAAAAGGCGAGAGAAAAACATTCTGAGCA} {\textbar} {\textbar} {GAGACTGCCACTGAGTGCATCCCAGTTTTCCCAACATCTTAACACTGTAT} {\textbar} {\textbar} {AATGACTACACTGGATTTTCTTCATCCTGGATCCATGGTTAGACATGTTA} {\textbar} {\textbar} {ATATGCCTTC} {\textbar} {\textbar} {RS}4942879 {\textbar} {\textbar} {CCCAGTCTGTGGTATTTTTTTATAGCAGCACAAACAGACTAACACAAGAG} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {GTGGATAGGATTTGCGAGCATGGACCTTGGAGGTTTGTGGCCTCAATTT} {\textbar} {NO}: 12 {\textbar} {\textbar} {AAAGTGAGTACATTCACCCAGCTGGTGTTTTTCTCTTGCTGCTTGGGCA} {\textbar} {CAGAGATGGAGTAAATGGGTCTAATCAAGGATAAAGGGAGAGCCAAAGA} {\textbar} {\textbar} {GAT} {\textbar} {\textbar} [A/G] {\textbar} {GTAATATTTGAAAGGAAGTGTTTTTAATGATGTGCCATGTAATC} {\textbar} {TGAGCTGGGTCAGGAATGAAGTGAAAAACTAAGAGATGATGGATGATGA} {\textbar} {\textbar} {TAGGGGCTGTGAAAGGAAAACAAATCTTGGGGCCCCCAAATCACTAAGC} {\textbar} {\textbar} {TAAAGGAGAAAGTCAAGCTGGGAACTGTTTAGGGCAATCCTGCCTCCCA} {\textbar} {\textbar} {TTTTATTCA} {\textbar} {\textbar} {RS}9542954 {\textbar} {\textbar} {TATTACTGCTGAGAAAACTGGGTTTGATAAACTAAAGATGCCCATGTATA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {TCAGTCATGCTCCTGGTGAGAACAGGTGGCTCACTGCATAATGAGAGGA} {\textbar} {NO}: 13 {\textbar} {\textbar} {ATATTCAATTAACTATTTACAAAGCTATGGATGACATGTAGGGAAGCCAC} {\textbar} {AGAGAGAGTACAGTATCTAGAGCTAGTAAGAGTAGAAGGCCATCACTGT} {\textbar} {\textbar} {CC} {\textbar} {\textbar} [A/C] {\textbar} {CAGGCCTAAAGGAGGTAGAGCAGTCAAAGGAAACAAGAGACAA} {\textbar} {GGGAGGCTGCGAGGACAGGGCCACCTGGCAGAGCCATAACCTTAAACT} {\textbar} {\textbar} {AGGTAGTCACTTCTTGGCAACTCTGCAGGTAGGGAGCCAACCTCACTTT} {\textbar} {\textbar} {TAACCCTCCCTCTGATGCCCAGCTGGTTTACCCCATTGGTGAAAATCAG} {\textbar} {\textbar} {TGGGTGAGGGA} {\textbar} {\textbar} {RS}1593478 {\textbar} {\textbar} {CATGAAAAGATACTTAACATTGTAACATCTTTGCATTAGGGAACTGCAAA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {TCAAAATCATAACAAAATAGTACTGCATGCTCATTAGGATGACTATAATC} {\textbar} {NO}: 14 {\textbar} {\textbar} {CAAAAGAATAAAAAAGAAAATAACAGGTGTTGGTAGGGATACAGATATAG} {\textbar} {AGAAACTGGAGCTCTCATGCCTTGCTGGGGGGCATGTAAAATGATTCTG} {\textbar} {\textbar} C {\textbar} {\textbar} [C/T] {\textbar} {GCTTTGGAAAACAGTTTGGTGGTTCCTCAAAAAGTTAAACATATAA} {\textbar} {TCCAACAATTCCACCCAAAAGAATTGAAAGCAGGGTCTAGTACACCAAC} {\textbar} {\textbar} {GTTCATAGCAGCTTTATTCACATCAAGCCAAAGGTGGAAGCAGCCCAAA} {\textbar} {\textbar} {TGTCTACTGATGGATGAGTTGATACACAAAATGTGGTATATATATGCAAT} {\textbar} {\textbar} {GGAATA} {\textbar} {\textbar} {RS}9542951 {\textbar} {\textbar} {GCCACTTGAATGCCCCAAAATGGAGAGATGGGCGTGGGAAGAGAAAGA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CACCTCAGCAACACAGAGCTGAGAAAACACTGTGAGTTTTATTTAATTCC} {\textbar} {NO}: 15 {\textbar} {\textbar} {TACTTACCGTTATTTTGCATAGTAAACAAAAGGGATATTTTTGAAAATCCC} {\textbar} {TTTGGATAATTTCTGCCACCTAAAATTCTGAGCATTTTGACTCACTGCCTT} {\textbar} {\textbar} [A/G] {\textbar} {\textbar} {TAAAAAGAATCAATTAATTGAATAAGAGAAGGGATTCTCCCCTGAT} {\textbar} {CTTTTCAAGAATCCTTAAAAGGCACATTTCTCACTAAGGATCTTGAAAGT} {\textbar} {\textbar} {GTATTTCTAGCCAATCCCAGGAGTCACTGCTCAGAGATTTACATTTCACA} {\textbar} {\textbar} {AATGTAATCAACAGCCTAAGCAGAATATTGACGTTTGGACTGCAGAGCT} {\textbar} {\textbar} {CTGCT} {\textbar} {\textbar} {RS}2188534 {\textbar} {\textbar} {AGGGTCCCCAAATATTTCCATTTGAGATGACAAAGTGCTCTTCAGTCATT} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {TAGCTTACTCTTCAGTTCAGATGACTTATCATCTTGATTTCAGAGAGTTCA} {\textbar} {NO}: 16 {\textbar} {\textbar} {TATATGTCTGTTTTAAAAAACTGGTTCAAAAAGTCTGAAGTTACGAAACTA} {\textbar} {AACCAAATATGCATTACTCTCATGTCAAATTACAAGCTCTTAGCTGC} {\textbar} {\textbar} [G/T] {\textbar} {GGGATTTTTTCACATGCAGCCTGGAGCCCTTGAAAACCTCTGTTTTCTGT} {\textbar} {\textbar} {TAGACTCTCCAGGGTACACAGAAGTTGCCTCATTATTTTAGTTAATGGTG} {\textbar} {\textbar} {ACTGCAAATAAGCCCCCCAAGTCATTTAACTATGTGCTTACCACTGCTTT} {\textbar} {\textbar} {AAAAGAACCCCAAGTTAGGTCCTCATGTAGGTAAAGGAGCTCCCTTCAC} {\textbar} {\textbar} A {\textbar} {\textbar} {RS}12524124 {\textbar} {\textbar} {ACTTGGGCCCAAAGGCATTCAACTAGAAAGCTGGTAATAATAACAGCGA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CAGTTTATTGAGTCTTAGTGTTTCTGAGAACTTTTCTAAGTACTTTACACA} {\textbar} {NO}: 17 {\textbar} {\textbar} {TATTAAATTTTTAAATCTTCACATTAGTCCTGTGAGGAAGGTACTATTGTT} {\textbar} {ATGTCTGTATTACCCATGGGGATACTGACGCACAAAGAAGTCAAGTAAT} {\textbar} {\textbar} [A/G] {\textbar} {\textbar} {TATTTAAGATTCTAGTAAGTGCAGAGCCCAGGTGCATGCAGTGCCT} {\textbar} {GGGCTCTGCCACCCATGCAGTGCTGACTAGGGCTTCCACCCATGGATTT} {\textbar} {\textbar} {TTTTTTTTTTTTTTTTTTTTTGAGACAGAGTTTCGCTCTTGTTGCCCAGGC} {\textbar} {\textbar} {TGGAGTGCAATGGCATGATCTCGGCTCACCACAACCTCCGCCTCTCGG} {\textbar} {\textbar} {GTTCAA} {\textbar} {\textbar} {RS}4352629 {\textbar} {\textbar} {CCCATAATAATGAAGGATTGGACCTGATAATCTATCAGGTACATTTTAGC} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CTGAAATTTATTTGTACACACGCACAAACACAGACATGTGCACACACACA} {\textbar} {NO}: 18 {\textbar} {\textbar} {TACACATATATATATAACATTTATAAATTTTAAAACATAAAGCTATACTAGA} {\textbar} {AATGAAAGCTTATATATTGAACTGCCCCACCTTTCTATTTGCAGCCAG} {\textbar} {\textbar} [C/ {\textbar} T] {\textbar} {\textbar} {TACCACCCCAGTCTAATGTTTCACTTTATATAAATTCATTTATTCTTTTA} {\textbar} {CTCATTTCAAATATATGATGATGTAACTATAAAATCAACATTTAGTCACTC} {\textbar} {\textbar} {TGAATAACCCAAAATAGCAAATAATTTAAAAATCACTTCCACTTGACTTTA} {\textbar} {\textbar} {GAATCTATTACATGCATTGTTTTTCCAGAAAATTTACCTCATAATTAT} {\textbar} {\textbar} {RS}7448716 {\textbar} {\textbar} {CTACTTATATGATTAGAGAACAAGAATACTAGGGGGAAAATCAGCATGCA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {TATAATCTAAGAAATTGTCATTATAATTTTAAAATCCTTTGCAAAATCAGTA} {\textbar} {NO}: 19 {\textbar} {\textbar} {AATATGAGTTTAACTTATATAATGATACACACACACACTGATATGATGCTT} {\textbar} {TATTGTCTAAACACTGGCTGCTTGTGGAGACGTATTCTGGTAACAAA} {\textbar} {\textbar} [A/G] {\textbar} {AATATAGCATCTTAAAATTGATGCTAGCATTGTATATCCAAATAGAGAGT} {\textbar} {\textbar} {AAATGCAACCAGAATATTTTTTATATGTTTAACATTGTAGTGTTGCTGACA} {\textbar} {\textbar} {TCATTATATATTTGGTTATGTTAATCTCAAAATGCACAATATAGCTGTATG} {\textbar} {\textbar} {ATCTGTATAATGCAAAAAAATGTAGAGCTTCATTTTGATATTTATTAT} {\textbar} {\textbar} {RS}11873533 {\textbar} {\textbar} {CTGGAAGGGAACAATGGAAGAGGTGCATTAGTCACATTCCAAAATGCAG} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {GAAGCAATAACATGTGGCACTATTGTCATTTATGTAGCACCCTAAATACT} {\textbar} {NO}: 20 {\textbar} {\textbar} {GGGACAAATGACATAGATGCCCTTCTGTGATTACTAAACTCCCCCACAG} {\textbar} {TGTCTCAGAAGGAAGAGCTTTTGACAGGAAATCATCAAGATCTGATGAC} {\textbar} {\textbar} {ATT} {\textbar} {\textbar} [A/C] {\textbar} {GAGAGCAATTAACATTCTCTTCAACCATGAACTAATTGCCTCAT} {\textbar} {TCACATTTTTCTAGCCATCCTAGGAAGCAGATAATAAGCAGCAATTGTCC} {\textbar} {\textbar} {TGCCCAGGAATTCTGACTTGTGTAATTTGTAAAGCTTTTCTTTGTATCTAT} {\textbar} {\textbar} {TTCTTTCCTGTGGCCATCTTTTTGTTTTTGGACTGTTTGGTAACAGTAAGT} {\textbar} {\textbar} {GGGT} {\textbar} {\textbar} {RS}10062658 {\textbar} {\textbar} {ATCATTCAGTATTAAGAGAGAAATGAATACATTTTCAGATATACAAGAATT} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CAGTTTACCTCCCACAGAATCTCTGAAAAAAATATTAGATTACTATAGTTA} {\textbar} {NO}: 21 {\textbar} {\textbar} {AAAAGGAAAATAAAATAAGTCCTGTTAGAAATAATTGGTAAAAAAGCAAA} {\textbar} {GGTGATGAAAACTTATTGAAATATATTATTAAAGTAATTGTTAAAAAT} {\textbar} {\textbar} [A/G] {\textbar} {TACACTAAATCTAGAATATATAAATGTAGCAGTTGTTAAGGGGAAGGGGA} {\textbar} {\textbar} {AATAGAAGTGGAAGAAAATGAACATTAGAACAAATGTTTAGCAGTGGGAT} {\textbar} {\textbar} {TATTTTATTGGAAGTCTAATGTAAGAAGTATATTCTCCAGGGAGGTATTT} {\textbar} {\textbar} {CAAGGACATATGAATAGTAAAGGGATAATAAAACAACTCTATAAGGTAGT} {\textbar} {\textbar} {RS}12547917 {\textbar} {\textbar} {CACACACAACGCTGGGCCCAGTAAATAAGTTTTGTTTTTTCCCAGGGAA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {AAGTTGAACAACAATGGTGAGACCAGGAAGGCTCTCCGTTCACAGGAAA} {\textbar} {NO}: 22 {\textbar} {\textbar} {TACTGTGTCACCGCTCGGCCGCAGGCTGTGTGAGGTCACGGGCGACGC} {\textbar} {TCGGGTCACGTGTGGCGGCTCCTGTTCACAGTGCCGTGTGTGATAAACT} {\textbar} {\textbar} {GGGAC} {\textbar} {\textbar} [C/T] {\textbar} {TTCTGGTGAGGGGAGACTGGCGGGGGGTGGGGAGGGCA} {\textbar} {AGGAGTGGGAAAGTCGCCTATAAATGTTTAACAAAAGATCCGCAATGGG} {\textbar} {\textbar} {AACAGGAACTTGCATTCTTTCTTTCAATGGACAAAGCTTCCACATCAAGA} {\textbar} {\textbar} {TACGCTTGTGTGCTGGGACCAAATGCCACAGTGCGGCGAAACTCGTGA} {\textbar} {\textbar} {GCACAAGTCCTGCGT} {\textbar} {\textbar} {RS}1038268 {\textbar} {\textbar} {ACAACAGGGTATCCTAGCCCAGCAAAATTGACTCATAAATTTAATGATCA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CGCAATTGGTAATTCTAAATCCAGTCAGAAGTCTACATTCTGTGTCCACA} {\textbar} {NO}: 23 {\textbar} {\textbar} {GTGTCATGTCTAGATGTTGGTCCAGTCTCCCATGGACTGTGCCTTGTTAT} {\textbar} {TTGTTTTCTCTTTGCTAAGCCACATCCCCTGAGGGCTCTGTTTATGCTCA} {\textbar} {\textbar} [C/T] {\textbar} {\textbar} {TGCAAAATCTTTGACTTTTTAACTTACTGGGCATATTGTCTTCCTACT} {\textbar} {TTTGTTCTCTTCTGTTATTTTATTTACTTGACTCTGACATGTCTCATTCCC} {\textbar} {\textbar} {RS}2375811 {\textbar} {\textbar} {TTTCAATGGGACTGGTTGGACAGTGGGTGCAGCCCATGAAGGGCAAGC} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CAAAGCAGGCCGGGGCATCACCTCACCCGGGAAGCACAAGGGGTCAG} {\textbar} {NO}: 24 {\textbar} {\textbar} {GCGATTTCTCTTTCCTAGTCAAGGGAAGCCATGGCAGACTGCACCTGGA} {\textbar} {AAAACGAGACACTTCCACCCAAATACTGCGTTTTTCGCAAGGTCTTAGCA} {\textbar} {\textbar} {ACTAAC} {\textbar} {\textbar} [A/G] {\textbar} {GACAAGGAGATTCTCTCCCGTGCCTGGCTCGGCTGGTCC} {\textbar} {CACACCCACGGTGACTTGTTCACTGCTAGCACAGCAGTTTGAGATCGAA} {\textbar} {\textbar} {CTACGAGGCAACAACCTGGCTAAGGGAGGGGCATCTGCCATTGCTGAG} {\textbar} {\textbar} {GCTTGAGTAGGTAAACAAAGTGGCCAGGAAGCTCGAACTGGGTGGAGC} {\textbar} {\textbar} {CCACTGCAGCTTAGCA} {\textbar} {\textbar} {RS}1352671 {\textbar} {\textbar} {ACTTTAGGGACTTTGAGTGATGGACAACCCCCTATCAGATATCATCAGC} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CTGAAACATCCTTATCTTGGCATTAAATTAGAAGGAACCCCAGACCCTGC} {\textbar} {NO}: 25 {\textbar} {\textbar} {GTACCAGAATTGTTAGAATCACAGTCTCAGTAAAGAACCAACTCCTGATC} {\textbar} {ACTTCTCTAAAGGAAAGTTCTAGAAGTCTGCACACTCTGCAGTCACTTTC} {\textbar} {\textbar} A {\textbar} {\textbar} [A/C] {\textbar} {TTCTATCCAAGTGTACACTTAGAACTCTAGAAAACACTACGGAGA} {\textbar} {GTCTTCAGCCAGGTAAAGCCTAAAACCAGCAAAGAACAGGGAGAGTGA} {\textbar} {\textbar} {GGGA} {\textbar} {\textbar} {RS}364331 {\textbar} {\textbar} {CGGATTATCACAGTTCTCAAAAGAGGAGTATGCATTTGCTTGCTCCAATT} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {CCTCTTCTTCTACACTCTCTTAAGCATTCCTCAACCAGTCTAATATCTCAT} {\textbar} {NO}: 26 {\textbar} {\textbar} {AGTTCCCCAAAACTGCTCTGTTCAAGACCATTAGTAAGATCTTTGATGTT} {\textbar} {AATCTGTGGACCGTATCTCTGTCCTTATTTTACTTGAAGCCCAACAGCA} {\textbar} {\textbar} [A/C] {\textbar} {\textbar} {ATAAAAAAGTTGTTCTCCTCTCCTCCCTGCTACACTTTCCTTATGTG} {\textbar} {GCTTGCTGGGCTCCTCAGTCCCCTGTGAAAAACTCTGACATGGAGATAC} {\textbar} {\textbar} {TGCAGACCAGTAGAAGGGCTGGGCAGACACTATACAGAAACAGTATGC} {\textbar} {\textbar} {CCTACATGCTCCTTGGCTAAATCTCTAGAATTTTTTTCAGAACTCATCCA} {\textbar} {\textbar} {CAAATT} {\textbar} {\textbar} {RS}1924949 {\textbar} {\textbar} {ATTTTATCTCATTTACTTATTAAATCAAACCAATATTTTATGAAGTGATTCC} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {AGTATTGGAATAAAAATGTAATTCTTTAATCATTAAAAAATCTTTATGAATA} {\textbar} {NO}: 27 {\textbar} {\textbar} {CCTTACATCAACTGTAGGGGACCAACCAGGGAAAAGCAGGGAGACTTG} {\textbar} {TAGAATCTACACCTCCAGAACAACCGACCTCCATCTTCTGGACAACTC} {\textbar} {\textbar} [A/ {\textbar} G] {\textbar} {\textbar} {TCTTCTAAAGTGCAGGACAGACTAGTTGGGGGAGAAAGGAGGAAATG} {\textbar} {AAAGAGATAGACTAAAAGGGAGGGAGAGAACAGATATTTTTTAAGTACC} {\textbar} {\textbar} {TGTTATGTTCTGGATACAGCACAGAGTACATTGTATCTATTATTATAAGG} {\textbar} {\textbar} {CATAAAGAAAGATTTCTCAGGTTTTTGGAGTCAGATTGCAATATAAAATA} {\textbar} {\textbar} {ATAG} {\textbar} {\textbar} {RS}11025990 {\textbar} {\textbar} {TAACTTCAAATTGTTTTGCAAAATCTCTGTCATAAAAATGCTTACCAACAA} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {ATACTGATACTAAATTTAGATGTGGGGGTATTAGTTATAATCCTGAAGTG} {\textbar} {NO}: 28 {\textbar} {\textbar} {GGAGGGGGAACTTCTTAATTCCAATTTAGTTCTAAGAGAAGGAAGAGTA} {\textbar} {TTTAGGCCCAGAGAAGGTTACGCTTAAAGGTCTGATAGTGTTTTCTTTGA} {\textbar} {\textbar} [A/G] {\textbar} {\textbar} {AAATATGTCTCAAACTAGAGAATAAAACTAATTATCTCATCTAAGTT} {\textbar} {ACCTAGAGACATTTATGCTCATCAGTTTGATAAAGGACTGCAAGTAGACA} {\textbar} {\textbar} {CAGAAGCTGTATTTTCAGTCTTGAACCCAGCAATAGTACATTAACAAGAT} {\textbar} {\textbar} {TGGGGCAAGGCAAAGGGACTTTTGTGGCACAAGATACAATATATGGATT} {\textbar} {\textbar} {GCGT} {\textbar} {\textbar} {RS}3758562 {\textbar} {\textbar} {CTCTTCAAAGGCCTTTGCCCTTGGGTACCACAGGTTCTGAGACAAGAGG} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {GCTATGGAGAGCCCCCATTATAGCTGGAGCCTCCTGCCCTGCCCAAAG} {\textbar} {NO}: 29 {\textbar} {\textbar} {GTGTGACTTGAAGGGTGGAATTTCAGGCAGCGTGGCTCGCCCCAGGGA} {\textbar} {GGCAAAGAGGCCAGGGGAATCTTCAAAGGCCCTGGGCTCATCCCAGCT} {\textbar} {\textbar} {AGGAGGC} {\textbar} {\textbar} [A/G] {\textbar} {GGCACAGTCATAACCCTAATCCAGTGAACTCAGCCCTC} {\textbar} {ATCCTGACTCTCATGGTATTCTGTCCCAGGGAGCCTCTTTCCAGCTTTCT} {\textbar} {\textbar} {TAGAAGCTTTAATGTCAGCACTTGCAGGGCCTTAGAAACTGCACGCTAC} {\textbar} {\textbar} {CTCTTCATTTCATACATGAGGAAACTGAGGCCCAGGGTGGACACAGGGC} {\textbar} {\textbar} {TGCCCAGCGAGTTA} {\textbar} {\textbar} {RS}10156056 {\textbar} {\textbar} {ATTATAAAGCAAAGCACTAACCTCATAGAATACCTGAGTCAAGTTCCCTG} {\textbar} {SEQ} {ID} {\textbar} {\textbar} {TGTTCTCATTTTCTAGCCTCTTCTACCAGACACTATGAAAAATAACAGCC} {\textbar} {NO}: 30 {\textbar} {\textbar} {CCATCTCTCCAGAAAATCTTAGGAGATATAGGCGTGCTGAATTTAAGGT} {\textbar} {GTCTGTGGCACATGCAAGTGGATCAGCCACTGGGCTGTCCAGAATGCA} {\textbar} {\textbar} {AGA} {\textbar} {\textbar} [C/G] {\textbar} {AGAACTCAGAGTTGGGGACATAAACTTGGCAGTCATCTGTGTA} {\textbar} {AAAGAGAAAAGGTAGGTAAAGTCCCACAAGGATGGGTTGGCCTACAGAA} {\textbar} {\textbar} {GGCACAGAGAGAAGAGAGCCTGGTTTAGCATGGGCTACGATCAGAGTC} {\textbar} {\textbar} {CCTGGGTTCAAATCTTGGCTCCACCCATTTCTATCTGGTTGCTCTAGGG} {\textbar} {\textbar} {CATGTTACCTA} {\textbar} {\textbar} Polymorphisms in linkage disequilibrium with a {SNP} of table 1 can be identified by by methods known in the art. For example, Develin and Risch (Genomics, 1995) provide guidance for determining the parameter delta (also referred to as the “r”) as a standard measure of the disequilibrium. Gabriel et al. (Science, 2002) provides instructions for finding the maximal r {\textbar} {\textbar} 2 {\textbar} value in populations for disease gene mapping. Further, Carlson et al. (Am. J. Hum. Genet. (2003) disclose methods for selecting and analyzing polymorphisms based on linkage disequilibrium for disease gene association mapping. Stoyanovich and Pe'er (Bioinformatics, 2008) show that polymorphisms in linkage disequilibrium with indentified {SNPs} have virtually identical response profiles. Currently, several databases provide datasets that can be searched for polymorphisms in strong linkage disequilibrium, which can be accessed by the following addresses: http://1000.genomes.org, http://www.hapmap.org, http://www.broadinsitute.org/mpg/snap. An example workflow for determining {SNPs} linkage disequilibrium to a specific {SNP} is outlined in Uhr et al. (Neuron, 2008). {\textbar} {SNP} in strong linkage disequilibrium as used herein means that the {SNP} is in linkage disequilibrium with an r {\textbar} {\textbar} 2 {\textbar} higher than 0.7 or higher than 0.8 in the tested population or an ethnically close reference population with the identified {SNP}. {\textbar} In another embodiment, at least 20, optionally at least 25 or at least 30 {SNPs} selected from the group of table 1 are determined in step (a) and integrated by the prediction algorithm in step (b). For example, all intergenic {SNPs} of table 1 are determined in step (a) and integrated by the prediction algorithm in step (b). In another exemplary embodiment, all {SNPs} selected from the group of table 1 are determined in step (a) and integrated by the prediction algorithm of step (b). {\textbar} {\textbar} Typically, in step (a) of the method of predicting a treatment response to {CRHR}1 antagonists, the presence or absence of those {SNPs} is determined which were identified to be associated with values indicative for normal {CRH} activity or {CRH} overactivity and were thus considered when determining the prediction algorithm by machine-learning as described above. {\textbar} {\textbar} Another aspect of the invention concerns biomarkers. The biomarker or the set of biomarkers may be selected from one or more biomarkers of the group comprising comprising: {\textbar} {\textbar} {SNP} rs6437726, {\textbar} {SNP} rs1986684, {\textbar} {SNP} rs7380830, {\textbar} {SNP} rs3903768, {\textbar} {SNP} rs7325978, {\textbar} {SNP} rs13585, {\textbar} {SNP} rs9368373, {\textbar} {SNP} rs10935354, {\textbar} {SNP} rs8095703, {\textbar} {SNP} rs10206851, {\textbar} {SNP} rs9542977, {\textbar} {SNP} rs4942879, {\textbar} {SNP} rs9542954, {\textbar} {SNP} rs1593478, {\textbar} {SNP} rs9542951, {\textbar} {SNP} rs2188534, {\textbar} {SNP} rs12524124, {\textbar} {SNP} rs4352629, {\textbar} {SNP} rs7448716, {\textbar} {SNP} rs11873533, {\textbar} {SNP} rs10062658, {\textbar} {SNP} rs12547917, {\textbar} {SNP} rs1038268, {\textbar} {SNP} rs2375811, {\textbar} {SNP} rs1352671, {\textbar} {SNP} rs364331, {\textbar} {SNP} rs1924949, {\textbar} {SNP} rs11025990, {\textbar} {SNP} rs3758562, and/or {\textbar} {SNP} rs10156056. {\textbar} In one embodiment, the biomarker or the set of biomarkers is selected from one or more biomarkers as described above, wherein {\textbar} {\textbar} {SNP} rs6437726 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 1, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1986684 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 2, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7380830 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 3, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs3903768 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 4, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7325978 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 5, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs13585 is represented by a single polymorphic change at position 185 of {SEQ} {ID} {NO}: 6, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9368373 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 7, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs10935354 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 8, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs8095703 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 9, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs10206851 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 10, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542977 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 11, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs4942879 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 12, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs9542954 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 13, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1593478 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 14, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542951 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 15, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs2188534 is represented by a single polymorphic change at position 200 of {SEQ} {ID} {NO}: 16, wherein in one or two alleles the wild-type nucleotide G is replaced by indicator nucleotide T, {\textbar} {SNP} rs12524124 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 17, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs4352629 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 18, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs7448716 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 19, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11873533 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 20, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs10062658 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 21, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs12547917 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 22, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs1038268 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 23, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs2375811 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 24, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1352671 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 25, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs364331 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 26, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1924949 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 27, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11025990 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 28, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs3758562 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 29, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, and/or {\textbar} {SNP} rs10156056 is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 30, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide G. {\textbar} In a specific embodiment, a set of biomarkers or a group of biomarkers comprises at least 15, at least 20, at least 25 or all of the following biomarkers: {\textbar} {\textbar} {SNP} rs6437726, {\textbar} {SNP} rs1986684, {\textbar} {SNP} rs7380830, {\textbar} {SNP} rs3903768, {\textbar} {SNP} rs7325978, {\textbar} {SNP} rs13585, {\textbar} {SNP} rs9368373, {\textbar} {SNP} rs10935354, {\textbar} {SNP} rs8095703, {\textbar} {SNP} rs10206851, {\textbar} {SNP} rs9542977, {\textbar} {SNP} rs4942879, {\textbar} {SNP} rs9542954, {\textbar} {SNP} rs1593478, {\textbar} {SNP} rs9542951, {\textbar} {SNP} rs2188534, {\textbar} {SNP} rs12524124, {\textbar} {SNP} rs4352629, {\textbar} {SNP} rs7448716, {\textbar} {SNP} rs11873533, {\textbar} {SNP} rs10062658, {\textbar} {SNP} rs12547917, {\textbar} {SNP} rs1038268, {\textbar} {SNP} rs2375811, {\textbar} {SNP} rs1352671, {\textbar} {SNP} rs364331, {\textbar} {SNP} rs1924949, {\textbar} {SNP} rs11025990, {\textbar} {SNP} rs3758562, {\textbar} {SNP} rs10156056. {\textbar} In another specific embodiment, a set of biomarkers or a group of biomarkers comprises at least 15, at least 20, at least 25 or all of the following biomarkers: {\textbar} {\textbar} {SNP} rs6437726 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 1, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1986684 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 2, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7380830 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 3, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs3903768 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 4, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7325978 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 5, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs13585 which is represented by a single polymorphic change at position 185 of {SEQ} {ID} {NO}: 6, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9368373 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 7, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs10935354 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 8, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs8095703 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 9, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs10206851 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 10, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542977 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 11, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs4942879 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 12, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs9542954 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 13, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1593478 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 14, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542951 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 15, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs2188534 which is represented by a single polymorphic change at position 200 of {SEQ} {ID} {NO}: 16, wherein in one or two alleles the wild-type nucleotide G is replaced by indicator nucleotide T, {\textbar} {SNP} rs12524124 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 17, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs4352629 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 18, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs7448716 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 19, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11873533 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 20, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs10062658 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 21, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs12547917 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 22, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs1038268 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 23, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs2375811 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 24, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1352671 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 25, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs364331 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 26, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1924949 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 27, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11025990 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 28, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs3758562 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 29, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs10156056 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 30, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide G. {\textbar} For example, the set of biomarkers or the group of biomarkers consists of the following biomarkers: {\textbar} {\textbar} {SNP} rs6437726, {\textbar} {SNP} rs1986684, {\textbar} {SNP} rs7380830, {\textbar} {SNP} rs3903768, {\textbar} {SNP} rs7325978, {\textbar} {SNP} rs13585, {\textbar} {SNP} rs9368373, {\textbar} {SNP} rs10935354, {\textbar} {SNP} rs8095703, {\textbar} {SNP} rs10206851, {\textbar} {SNP} rs9542977, {\textbar} {SNP} rs4942879, {\textbar} {SNP} rs9542954, {\textbar} {SNP} rs1593478, {\textbar} {SNP} rs9542951, {\textbar} {SNP} rs2188534, {\textbar} {SNP} rs12524124, {\textbar} {SNP} rs4352629, {\textbar} {SNP} rs7448716, {\textbar} {SNP} rs11873533, {\textbar} {SNP} rs10062658, {\textbar} {SNP} rs12547917, {\textbar} {SNP} rs1038268, {\textbar} {SNP} rs2375811, {\textbar} {SNP} rs1352671, {\textbar} {SNP} rs364331, {\textbar} {SNP} rs1924949, {\textbar} {SNP} rs11025990, {\textbar} {SNP} rs3758562, {\textbar} {SNP} rs10156056. {\textbar} In another example, the set of biomarkers or the group of biomarkers consists of the following biomarkers: {\textbar} {\textbar} {SNP} rs6437726 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 1, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1986684 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 2, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7380830 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 3, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs3903768 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 4, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs7325978 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 5, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs13585 which is represented by a single polymorphic change at position 185 of {SEQ} {ID} {NO}: 6, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9368373 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 7, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs10935354 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 8, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs8095703 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 9, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs10206851 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 10, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542977 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 11, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs4942879 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 12, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs9542954 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 13, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1593478 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 14, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs9542951 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 15, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs2188534 which is represented by a single polymorphic change at position 200 of {SEQ} {ID} {NO}: 16, wherein in one or two alleles the wild-type nucleotide G is replaced by indicator nucleotide T, {\textbar} {SNP} rs12524124 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 17, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs4352629 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 18, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs7448716 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 19, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11873533 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 20, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs10062658 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 21, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs12547917 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 22, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs1038268 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 23, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide T, {\textbar} {SNP} rs2375811 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 24, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs1352671 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 25, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs364331 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 26, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide C, {\textbar} {SNP} rs1924949 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 27, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs11025990 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 28, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs3758562 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 29, wherein in one or two alleles the wild-type nucleotide A is replaced by indicator nucleotide G, {\textbar} {SNP} rs10156056 which is represented by a single polymorphic change at position 201 of {SEQ} {ID} {NO}: 30, wherein in one or two alleles the wild-type nucleotide C is replaced by indicator nucleotide G. {\textbar} The biomarkers or the group of biomarkers as described above may constitute markers for the treatment response to {CRHR}1 antagonists in patients with depressive and/or anxiety symptoms. In particular, the above defined biomarkers or groups of biomarkers are suitable to predict the treatment response to a {CRHR}1 antagonist in a patient with depressive and/or anxiety symptoms {\textbar} {\textbar} Further, the group of biomarkers may additionally comprise {REM} density. {\textbar} {\textbar} Another aspect of the invention concerns a method for detecting {CRH} overactivity in a patient with depressive symptoms and/or anxiety symptoms, comprising determining the status of a biomarker or a group of biomarkers as defined above in a nucleic acid isolated from a patient's sample, wherein the presence of indicator nucleotides as defined above is indicative for {CRH} overactivity. {\textbar} {\textbar} In some embodiments of the method for detecting {CRH} overactivity in a patient with depressive symptoms and/or anxiety symptoms, the status of at least 15, at least 20, at least 25 or all of the biomarkers as defined above is determined in a nucleic acid isolated from a patient's sample. {\textbar} {\textbar} Another aspect of the invention concerns a method for monitoring depression and/or anxiety therapy of a patient with a {CRHR}1 antagonist comprising the step of determining the status of a biomarker or a group of biomarkers as defined above before and during the therapy, optionally also after the therapy. {\textbar} {\textbar} In some embodiments of the method for monitoring depression and/or anxiety therapy of a patient with a {CRHR}1 antagonist, the status of at least 15, at least 20, at least 25 or all of the biomarkers as defined above is determined in a nucleic acid isolated from a patient's sample. {\textbar} {\textbar} The term “monitoring” as used herein relates to the accompaniment of a depression and/or anxiety therapy during a certain period of time, typically during 6 months, 1 year, 2 years, 3 years, 5 years, 10 years, or any other period of time. The term “accompaniment” means that states of disease as defined herein and, in particular, changes of these states of disease may be detected by comparing the status of a biomarker of the present invention in a sample in any type of a periodical time segment, e.g. every week, every 2 weeks, every month, every 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 or 12 month, every 1.5 year, every 2, 3, 4, 5, 6, 7, 8, 9 or 10 years, during any period of time, e.g. during 2 weeks, 3 weeks, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 months, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15 or 20 years, respectively. The term “before therapy of a patient with a {CRHR}1 antagonist” as used herein means that a patient or patient's sample may analyzed after an initial diagnosis of depression and/or anxiety and before the commencement of a treatment with a {CRHR}1 antagonist. The corresponding period of time may be 1 hour, 12 hours, 1 day, 2 days, 3 days, 4 days, 5 days, 6 days, 1 week, 2 weeks, 3 weeks, 4 weeks, 2 months, 3 months, 4 months, 5 months, 6 months, or more or any period of time in between these values. The term “during therapy of a patient with a {CRHR}1 antagonist” as used refers to the determination during the entire or during a part of a therapeutic treatment. For instance, the determination may be carried out between administration steps, or at a defined interval of 1 hour, 12 hours, 1 day, 2 days, 3 days, 4 days, 5 days, 6 days, 1 week, 2 weeks, 3 weeks, 4 weeks, 2 months, 3 months, 4 months, 5 months, 6 months, or more or any period of time in between these values. In a specific embodiment, the monitoring may also be carried out after the therapy of a patient with a {CRHR}1 antagonist, e.g. 1 hour, 12 hours, 1 day, 2 days, 3 days, 4 days, 5 days, 6 days, 1 week, 2 weeks, 3 weeks, 4 weeks, 2 months, 3 months, 4 months, 5 months, 6 months, or more or any period of time in between these values after the termination of the therapy of a patient with a {CRHR}1 antagonist. Changes of the status of biomarkers as defined herein above may provide the medical professional with indications regarding {CRH} overactivity and may lead to a modification of administration, the inclusion of other or more or less medicaments, a combination with further medicaments or any other suitable decision to increase the health of a patient. {\textbar} {\textbar} Another aspect of the invention concerns a method of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, comprising: {\textbar} {\textbar} (a) determining in a nucleic acid sample isolated from a patient's sample the status of a biomarker as defined above; {\textbar} {\textbar} (b) identifying the patient as eligible for a therapy with a {CRHR}1 antagonist, where the algorithm provided by the method of claim {\textbar} {\textbar} 1 {\textbar} predicts that patient responds to the treatment with {CRHR}1 antagonists. {\textbar} Another aspect of the invention concerns a method of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, comprising: {\textbar} {\textbar} (a) determining in a nucleic acid sample isolated from a patient's sample the status of a biomarker as defined above; {\textbar} {\textbar} (b) identifying the patient as eligible for a therapy with a {CRHR}1 antagonist, where the patient's sample is classified as showing the presence of indicator nucleotides as defined above. {\textbar} {\textbar} In some embodiments of the methods of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, the status of at least 15, at least 20, at least 25 or all of the biomarkers as defined above is determined in a nucleic acid isolated from a patient's sample. {\textbar} {\textbar} In some embodiments of the above methods of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, the method may further comprise a step of administering a {CRHR}1 antagonist. The {CRHR}1 antagonist may be a class I or a class {II} antagonist. {\textbar} {\textbar} Most of the non-peptidic {CRHR}1 antagonists can be described by or adhere to a pharmacophore model that comprises or features a lipophilic top group, a heterocyclic core containing an invariable hydrogen bond acceptor, which is almost always a heterocyclic nitrogen, and a lipophilic, usually aromatic, bottom group. {\textbar} {\textbar} Class I {CRHR}1 antagonists as used herein are characterized in that the heterocyclic hydrogen bond acceptor and the bottom group are connected by a two-atom linker as exemplified by {CRHR}1 antagonists R-121919, {NBI}-30545, {CP}-154526, {DMP}696, pexacerfont ({BMS}-562086), emicerfont ({GW}876008), or verucerfont ({GSK}561679). Class {II} {CRF}1R antagonists as used herein are characterized by a two-atom linker between hydrogen bond acceptor and the bottom group as present in {CRHR}1 antagonist {SSR}125543A. {\textbar} {\textbar} In some embodiments of the above methods of identifying a patient with depressive symptoms and/or anxiety symptoms as eligible for a therapy with a {CRHR}1 antagonist, the {CRHR}1 antagonist may be selected from the group consisting of {CP}154,526, Antalarmin, {CRA} 5626, Emicerfont, {DMP}-696, {DMP}-904, {DMP}-695, {SC}-241, {BMS}-561388, Pexacerfont, R121919, {NBI}30545, {PD}-171729, Verucerfont, {NBI}34041, {NBI}35965, {SN}003, {CRA}0450, {SSR}125543A, {CP}-316,311, {CP}-376,395, {NBI}-27914, {ONO}-2333Ms, {NBI}-34101, {PF}-572778, {GSK}561579 and {GSK}586529. {\textbar} {\textbar} The corresponding structural formulas of some of the above-mentioned {CRHR}1 antagonists for use in the present invention are set out in Table 2 below: {\textbar} {\textbar} {TABLE} 2 {\textbar} {\textbar} {CRHR}1 antagonist {\textbar} {\textbar} Structural formula {\textbar} {\textbar} (name) {\textbar} R = H R = {CH} {\textbar} {\textbar} 3 {\textbar} {CP}154,526 Antalarmin {\textbar} {CRA}5626/R317573/ {JNJ}19567470/ {TAI}-041 {\textbar} {\textbar} {GW}876008/ Emicerfont {\textbar} {\textbar} {DMP}-696 {\textbar} {\textbar} {DMP}-904 {\textbar} {\textbar} {DMP}-695 {\textbar} {\textbar} {SC}-241/{LWH}-234 {\textbar} {\textbar} {BMS}-561388 {\textbar} {\textbar} {BMS}-562086/ Pexacerfont {\textbar} {\textbar} R121919/{NBI}30775 {\textbar} {\textbar} {NBI}30545 {\textbar} {\textbar} {PD}-171729 {\textbar} {\textbar} {GSK}561679/ {NBI}-77860/ Verucerfont {\textbar} {\textbar} {SB}-723620/ {NBI}34041 {\textbar} {\textbar} {NBI}35965 {\textbar} {\textbar} {SN}003 {\textbar} {\textbar} {CRA}0450/ R278995 {\textbar} {\textbar} {SSR}125543A {\textbar} {\textbar} X = O X = {NH} {\textbar} {\textbar} {CP}-316,311 {CP}-376,395 {\textbar} {NBI}-27914 {\textbar} {\textbar} {ONO}-2333Ms, {NBI} 34101, {PF}-572778, {GSK}561579 and {GSK}586529 are described by Zorilla and Koob (Drug Discovery Today, 2010, 371-383) as corticotropin releasing factor receptor antagonists (corticotropin releasing factor is a synonym for {CRHR}1 antagonists) tested in clinical trials. {\textbar} {\textbar} Another aspect of the present invention concerns a composition for the analysis of at least one single nucleotide polymorphic indicative for the treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms, comprising a nucleic acid affinity ligand for a biomarker as defined herein. {\textbar} {\textbar} The term “nucleic acid affinity ligand” as used herein refers to a nucleic acid molecule being able to bind to a polymorphic site as defined herein. For example, the affinity ligand is able to bind a nucleic acid molecule comprising the sequence of any one of {SEQ} {ID} {NO}: 1 to 30, or fragments thereof, which comprise the polymorphic site as defined herein above, wherein said sequence of {SEQ} {ID} {NO}: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, or 30 comprises the respective indicator nucleotide as described herein. In further embodiments of the present invention the nucleic acid affinity ligand may also be able to specifically bind to a nucleic acid molecule, e.g. a {DNA} molecule comprising, essentially consisting of or consisting of a sequence being at least 90\%, 91\%, 92\%, 93\%, 94\%, 95\%, 96\%, 97\%, 98\% or 99\% or 99.5\% or 99.6\%, 99.7\%, 99.8\%, or 99.9\% identical to the sequence of {SEQ} {ID} {NO}: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, or 30, or fragments thereof, which comprise the polymorphic site as defined herein above, wherein said sequence of {SEQ} {ID} {NO}: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, or 30 comprises the respective indicator nucleotide(s) as described herein above, or to any fragments of said sequences. {\textbar} {\textbar} In further embodiments of the present invention a nucleic acid affinity ligand according to the present invention may also be able to specifically bind to a nucleic acid molecule comprising the sequences of {SEQ} {ID} {NO}: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, or 30, with the exception that the sequences do not comprise the indicator nucleotide sequence as defined herein above, i.e. to corresponding wildtype sequences which do not comprise the respective indicator nucleotide as described herein above. In further embodiments of the present invention the nucleic acid affinity ligand may also be able to specifically bind to a nucleic acid molecule comprising, essentially consisting of, or consisting of a sequence being at least 90\%, 91\%, 92\%, 93\%, 94\%, 95\%, 96\%, 97\%, 98\% or 99\% or 99.5\% or 99.6\%, 99.7\%, 99.8\%, or 99.9\% identical to the sequence of {SEQ} {ID} {NO}: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, or 30 with the exception that the sequences do not comprise the indicator nucleotide sequence as defined herein above, i.e. to corresponding wildtype sequences which do not comprise the respective indicator nucleotide as described herein above, or fragments thereof. In even further embodiments, the present invention relates to nucleic acid affinity ligands binding a nucleic acid molecule comprising a sequence complementary to any one of the sequence of {SEQ} {ID} {NO}: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, or 30, or fragments thereof, which comprises the polymorphic site as defined herein above, which may comprise or may not comprise the indicator nucleotide. {\textbar} {\textbar} The composition according to the present invention may additionally comprise further ingredients necessary or useful for the detection of protection against drug-resistant epilepsy, such as buffers, {dNTPs}, a polymerase, ions like bivalent cations or monovalent cations, hybridization solutions, etc. {\textbar} {\textbar} In yet another preferred embodiment of the present invention the affinity ligand as mentioned herein above may be an oligonucleotide specific for one or more polymorphic sites as defined herein above, or a probe specific for one or more polymorphic sites as defined herein above. The term “oligonucleotide specific for one or more polymorphic sites” as used herein refers to a nucleic acid molecule, preferably a {DNA} molecule of a length of about 12 to 38 nucleotides, preferably of about 15 to 30 nucleotides. The oligonucleotide may have, for example, a length of 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, or 30 nucleotides. These molecules may preferably be complementary to at least 2, 3, 4, 5, 6, 7, 8, 9, or 10 nucleotides on or around the indicator nucleotide(s) of {SEQ} {ID} {NO}: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, or 30, comprising the complementary sequence of said indicator nucleotide(s) as defined herein above in connection with {SEQ} {ID} {NO}: 1 to 30. In further embodiments, the molecules may preferably be complementary to at least 2, 3, 4, 5, 6, 7, 8, 9, or 10 nucleotides on or around the polymorphic site as defined herein above in connection with {SEQ} {ID} {NO}: 1 to 30, however comprising the wildtype sequence. {\textbar} {\textbar} In other embodiments of the present invention said oligonucleotide as defined herein above may have a sequence complementary to a sequence including the indicator nucleotide(s) of the {SNPs} of the present invention as defined herein above. In further embodiments the oligonucleotide may also have a complementary sequences towards the counter strand of said sequence including the indicator nucleotide of the {SNPs} of the present invention as defined herein above. {\textbar} {\textbar} In further embodiments the present invention also relates to oligonucleotide molecules specifically binding in the vicinity of the polymorphic site as indicated herein above in the context of {SEQ} {ID} {NO}: 1 to 30. These oligonucleotides may be designed in the form of a pair of primers allowing the amplification of stretch of {DNA}, e.g. of a length of 50 bp, 75 bp, 100 bp, 150 bp, 200 bp, 250 bp, 300 bp, 400 bp, 500 bp, 750 bp, 1000 bp, or more around and including the polymorphic site of the {SNPs} of the present invention. Suitable sequence information may be derived from the sequence of {SEQ} {ID} {NO}: 1 to 30, the herein above indicated genomic sequence localization, which allows the skilled person to obtain the necessary context {DNA} sequence from data repositories. {\textbar} {\textbar} The term “probe specific for one or more polymorphic sites” as used herein refers piece of {DNA}, which is capable of specifically binding to a polymorphic site according to the present invention. The probe may, for example, be designed such that it only binds to a sequence comprising the indicator nucleotide, or the wildtype sequence, or a complementary strand thereof. In other embodiments the probe may be capable of binding to a polymorphic site according to the present invention, i.e. be able to bind to the wildtype sequence, the indicator nucleotide comprising sequence or any other variant at that position as defined herein above. The specificity of the probe may further be adjusted, for example in hybridization experiments, by the changing the concentration of salts, modifying the temperature of the reaction, adding further suitable compounds to the reaction etc. The probe may also be designed such that it binds outside of the polymorphic site, e.g. within the sequence of {SEQ} {ID} {NO}: 1 to 30. {\textbar} {\textbar} The probe according to the present invention may, in further embodiments, comprise, essentially consist of, or consist of a nucleic acid molecule being at least 90\%, 91\%, 92\%, 93\%, 94\%, 95\%, 96\%, 97\%, 98\% or 99\% or 99.5\% or 99.6\%, 99.7\%, 99.8\%, or 99.9\% identical to the sequence of {SEQ} {ID} {NO}: 1 to 30, or to fragments thereof, which comprise the polymorphic site as defined herein above, wherein said sequence of {SEQ} {ID} {NO}: 1 to 30 comprises the respective indicator nucleotide as described herein above, or to any fragments of said sequences, or to the corresponding wildtype sequences as defined herein above, or to the complementary sequences of these sequences. {\textbar} {\textbar} A probe according to the present invention may have any suitable length, e.g. a length of 15, 20, 30, 40, 50, 100, 150, 200, 300, 500, 1000 or more than 1000 nucleotides. The probe may further be suitable modified, e.g. by the addition of labels, e.g. fluorescent labels, dyes, radioactive labels etc. {\textbar} {\textbar} In further embodiments, the probe may also be functionally adjusted to a detection method. {\textbar} {\textbar} In yet another aspect the present invention relates to a kit, comprising an oligonucleotide specific for one or more polymorphic sites as defined herein above, or a probe specific for one or more polymorphic sites as defined herein above. {\textbar} {\textbar} In further embodiments the kit as defined herein above may comprise accessory ingredients such as {PCR} buffers, ions like bivalent cations or monovalent cations, hybridization solutions etc. The kit may comprise an enzyme for primer elongation, nucleotides and/or lablelling agents. An enzyme for primer elongation may, for example, be a polymerase such as Taq polymerase, Pfu polymerase etc. Nucleotides may preferably be {dNTPs}, or derivatives thereof. A labeling agent may be, for example, an agent leading to the labeling with a radioactive label, an enzymatic label, a fluorescent label, a chemiluminescent or a bioluminescent label. The term “enzymatic label” relates to labels, which comprise enzymatic activities. A typical, preferred example is the horseradish peroxidase enzyme ({HRP}). This enzyme complex subsequently may catalyze the conversion of a suitable substrate, e.g. a chemiluminescent substrate into a sensitized reagent which ultimately lead to the emission of light or production of a color reaction. The term “radioactive label” relates to labels emitting radioactive radiation, preferably composed of radioactive isotopes. The term “radioactive isotope” in the context of the label relates to any such factor known to the person skilled in the art. More preferably, the term relates to {\textbar} {\textbar} 3 {\textbar} H, {\textbar} 14 {\textbar} C, {\textbar} 32 {\textbar} P, {\textbar} 33 {\textbar} P, {\textbar} 35 {\textbar} S or {\textbar} 125 {\textbar} I. The term “chemiluminescent label” relates to a label, which is capable of emitting light (luminescence) with a limited emission of heat as the result of a chemical reaction. For example, the term relates to luminol, cyalume, oxalyl chloride, {TMAE} (tetrakis(dimethylamino)ethylene), pyragallol, lucigenin, acridinumester or dioxetane. The term “bioluminescent label” relates to a label, which is capable of emitting light due to a biochemical reaction. Typically, the term refers to the production of light due to the reaction of a luciferin and a luciferase. In such a reaction scheme, the luciferase catalyzes the oxidation of luciferin resulting in light and an inactive oxyluciferin. The term “fluorescent label” relates to chemically reactive derivatives of a fluorophores. Typically common reactive groups include amine reactive isothiocyanate derivatives such as {FITC} and {TRITC} (derivatives of fluorescein and rhodamine), amine reactive succinimidyl esters such as {NHS}-fluorescein, and sulfhydryl reactive maleimide activated fluors such as fluorescein-5-maleimide. Reaction of any of these reactive dyes with another molecule results in a stable covalent bond formed between a fluorophore and a labelled molecule. Following a fluorescent labeling reaction, it is often necessary to remove any nonreacted fluorophore from the labeled target molecule. {\textbar} In further embodiments the kit may also comprise accessory ingredients like secondary affinity ligands, e.g. secondary antibodies, detection dyes, or other suitable compound or liquids necessary for the performance of a nucleic acid detection. Such ingredients as well as further details would be known to the person skilled in the art and may vary depending on the detection method carried out. Additionally, the kit may comprise an instruction leaflet and/or may provide information as to the relevance of the obtained results. {\textbar} {\textbar} In yet another aspect the present invention relates to a microarray, comprising at least one probe selective for an indicator nucleotide or the corresponding wildtype nucleotide as defined herein above. In a standard setup such a microarray comprises immobilized probes to detect a nucleic acid comprising a polymorphic site as defined herein above. The probes on the array may, for example, be complementary to one or more parts of the sequence of {SEQ} {ID} {NO}: 1 to 30 and/or to corresponding wildtype sequences. Typically, {cDNAs}, {PCR} products, and oligonucleotides may be used as probes. The microarray may comprise probes of one or more {SEQ} {ID} {NO}: 1 to 30, or corresponding wildtype sequences, or all of these biomarkers or any combination of said markers. Furthermore, any type of fragment or sub-portion of any of the markers sequences may be combined with any further fragment or sub-portion of any of said sequences {SEQ} {ID} {NO}: 1 to 30, or corresponding wildtype sequences. {\textbar} {\textbar} There is virtually no limitation on the number of probes which are spotted on a {DNA} array. Also, a marker can be represented by two or more probes, the probes hybridizing to different parts of a gene. Probes are designed for each selected marker gene. Such a probe is typically an oligonucleotide comprising 5-50 nucleotide residues. Longer {DNAs} can be synthesized by {PCR} or chemically. Methods for synthesizing such oligonucleotides and applying them on a substrate are well known in the field of micro-arrays. {\textbar} {\textbar} The methods described above are not restricted to methods related to a treatment response to {CRHR}1 antagonists in patients with depressive symptoms and/or anxiety symptoms. The treatment response to any other compound, drug or biomolecule that is capable for treating depressive symptoms and/or anxiety symptoms in patients who have {CRH} overactivity may be also be predicted by methods described herein. In particular, the disclosure can be understood to mean that the term “{CRHR}1 antagonists” can be replaced by any other compound that interferes with the {CRHR}1 pathway and leads to a remission of depressive symptoms and/or anxiety symptoms patients with {CRH} overactivity. {\textbar} {\textbar} The invention is further described in the following examples which are solely for the purpose of illustrating specific embodiments of the invention, and are also not to be construed as limiting the scope of the invention in any way. {\textbar} {\textbar} Example 1 {\textbar} {\textbar} Methods {\textbar} {\textbar} Patients: {\textbar} {\textbar} Patients with unipolar or bipolar depression admitted as in-patients to the Max Planck Institute of Psychiatry ({MPI}), Munich, Germany, for treatment of a depressive episode were included in the study. Patients were diagnosed by psychiatrists according to the Diagnostic and Statistical Manual of Mental Disorders ({DSM}) {IV} criteria. Patients with bipolar disorder or depressive disorder due to a general medical or neurological condition were excluded, as were patients with a lifetime diagnosis of drug abuse and depressive symptoms secondary to alcohol or substance abuse or dependency. Ethnicity was recorded using a self-report sheet for nationality, first language and ethnicity of the patient and of all four grandparents. All patients were Caucasian and part of the Munich-Antidepressant-Response-Signature ({MARS}) project (Hennings et al., J Psychiatr Res., 2009) (www.mars-depression.de). They were treated with antidepressant medications according to doctor's choice. Severity of depressive symptoms was assessed at admission and at the time of the dex/{CRH} test by trained raters using the 17-item Hamilton Depression Rating Scale ({HAM}-D, Hamilton, J Neurol Neurosurg Psychiatry, 1960). 192 patients fulfilling the criteria for at least a moderate to severe depressive episode ({HAM}-D≧18) at both time points and who had been administered a dex/{CRH} test within 10 days of in-patients admission and had genome-wide {SNP} data were included in this analysis. The study was approved by the Ethics Committee of the Ludwig Maximilians University in Munich, Germany, and written informed consent was obtained from all subjects. {\textbar} {\textbar} Dex/{CRH} Test: {\textbar} {\textbar} The dex/{CRH} test was administered as described in detail in Heuser et al. (J Psychiatr Res., 1994). In brief, subjects were pre-treated with 1.5 mg of dexamethasone per os at 11 pm. The following day, at 3 pm, 3.30 pm, 3.45 pm, 4 pm and 4.15 pm blood was drawn. An intravenous bolus of 100 μg of human {CRH} (Ferring, Kiel, Germany) was given at 3.02 pm. Plasma {ACTH} concentrations were assessed by an immunometric assay without extraction (Nichols Institute, San Juan Capistrano, Calif.; {USA}). The neuroendocrine response to the dex/{CRH} test was analyzed using the total area under the curve ({AUC}) of the {ACTH} response. {\textbar} {\textbar} {SNP} Genotyping: {\textbar} {\textbar} After enrollment in the study 40 ml of {EDTA} blood was drawn from each patient. {DNA} was extracted from fresh blood using the Puregene® whole blood {DNA}-extraction kit (Gentra Systems Inc; {MN}). Genotyping was performed on Illumina Human 610k quad genotyping arrays (Illumina Inc., San Diego, {USA}) according to the manufacturer's standard protocols. The average call rate exceeded 99\%, with samples below 98\% being either retyped or excluded from the study. The reproducibility for samples genotyped twice was 99.99\% or better. {\textbar} {\textbar} Data Analysis: {\textbar} {\textbar} To identify genetic predictors for the {ACTH} response to the dex/{CRH} test in patients with moderate to severe depression, the 192 patients were randomly split into a trainings (N=96) and test set (N=96). The demographic and clinical descriptors of these two samples are given in table 2. {\textbar} {\textbar} {TABLE} 2 {\textbar} {\textbar} Demographic and clinical description of the 192 patients in the {\textbar} {\textbar} trainings and test set. {\textbar} {\textbar} training set {\textbar} {\textbar} test set {\textbar} p-value {\textbar} N {\textbar} {\textbar} 96 {\textbar} 96 {\textbar} \% female {\textbar} {\textbar} 52.1 {\textbar} 57.2 {\textbar} n.s. {\textbar} \% bipolar (1 or 2) {\textbar} {\textbar} 12.5 {\textbar} 12.5 {\textbar} n.s. {\textbar} \% with psychotic {\textbar} {\textbar} 15.2 {\textbar} 11.4 {\textbar} n.s. {\textbar} symptoms {\textbar} {\textbar} age (mean years ({SD})) {\textbar} {\textbar} 47.2 {\textbar} (14.2) {\textbar} 51.3 {\textbar} (13.2) {\textbar} 0.038 {\textbar} {BMI} at admission {\textbar} {\textbar} 24.9 {\textbar} (4.1) {\textbar} 24.9 {\textbar} (4.3) {\textbar} n.s. {\textbar} (mean {SD}) {\textbar} {\textbar} age-on (mean years ({SD})) {\textbar} {\textbar} 34.72 {\textbar} (14.5) {\textbar} 36.6 {\textbar} (15.9) {\textbar} n.s. {\textbar} number of previous {\textbar} {\textbar} 3.2 {\textbar} (4.0) {\textbar} 3.3 {\textbar} (4.7) {\textbar} n.s. {\textbar} episodes (mean N ({SD})) {\textbar} {\textbar} depression severity at {\textbar} {\textbar} 26.4 {\textbar} (4.4) {\textbar} 27.7 {\textbar} (4.8) {\textbar} 0.058 {\textbar} admission (mean {HAMD}- {\textbar} {\textbar} 17 score ({SD})) {\textbar} {\textbar} depression severity at {\textbar} {\textbar} 26.9 {\textbar} (5.0) {\textbar} 28.5 {\textbar} (5.0) {\textbar} 0.029 {\textbar} dex-crh test (mean {\textbar} {\textbar} {HAMD}-17 score ({SD})) {\textbar} {\textbar} Cortisol {AUC} (mean ({SD})) {\textbar} {\textbar} 3611.4 {\textbar} (3414) {\textbar} 3688.6 {\textbar} (3491) {\textbar} n.s. {\textbar} {ACTH} {AUC} (mean ({SD})) {\textbar} {\textbar} 1246 {\textbar} (910) {\textbar} 1482.8 {\textbar} (1319) {\textbar} n.s. {\textbar} days after admission when {\textbar} {\textbar} 6.1 {\textbar} (2.2) {\textbar} 5.9 {\textbar} (2.2) {\textbar} n.s. {\textbar} dex-{CRH} test was {\textbar} {\textbar} performed {\textbar} {\textbar} After natural log transformation of the {AUC} of the {ACTH} response in the dex/{CRH} test, patients were dichotomized into high vs. low responders. For the {ACTH} {AUC} the cut-off was ln {ACTH} {AUC}{\textgreater}7.0. This placed 46.4\% (89 out of a total of 192 individuals) in the high responder class. See the corresponding histogram in {\textbar} {\textbar} {FIG}. 1 {\textbar} . {\textbar} Using an additive genetic model and a logistic regression with sex and age as covariates in {PLINK} (http://pngu.mgh.harvard.edu/purcell/plink/), the association of all {SNPs} with a {MAF}{\textgreater}0.05 were tested on the 610k arrays with the dichotomized response for cortisol and {ACTH} in the dex/{CRH} test in the training set. The top 30 associated {SNPs} were then used to predict either {ACTH} or cortisol response status in the test set using a “Probabilistic Neural Network and General Regression Neural Network” approach (implementation {DTREG} 10.3.3 www.dtreg.com). All values were derived from a 20 fold cross validation. {\textbar} {\textbar} Results: {\textbar} {\textbar} The top 30 association with {ACTH} response status are given in table 3. Association p-values ranged from 5.0 e-5 to 2.3 e-4 for the {ACTH} response. {\textbar} {\textbar} The genotypes for the 30 {SNPs} each were then used to predict {ACTH} response status in the second, independent test cohort (subgroup of the test set). {\textbar} {\textbar} {TABLE} 3 {\textbar} {\textbar} List of 30 {SNPs} used to predict {ACTH} {AUC} in the second test cohort. {\textbar} {\textbar} P-value {\textbar} {\textbar} {SNP} {\textbar} {\textbar} Chromosome {\textbar} Coordinate\_HG18 {\textbar} training {\textbar} {GeneVariant} {\textbar} {GeneName} {\textbar} rs6437726  {\textbar} {\textbar} chr3  {\textbar} 108321446 {\textbar} 5.037e−005 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs1986684  {\textbar} {\textbar} chr11 {\textbar} 110629697 {\textbar} 5.287e−005 {\textbar} {UPSTREAM} {\textbar} N/A {\textbar} rs7380830  {\textbar} {\textbar} chr5  {\textbar} 66022641 {\textbar} 5.459e−005 {\textbar} {INTRONIC} {\textbar} {ENSG}00000196567 {\textbar} rs3903768  {\textbar} {\textbar} chr13 {\textbar} 49294756 {\textbar} 6.811e−005 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs7325978  {\textbar} {\textbar} chr13 {\textbar} 71960761 {\textbar} 8.206e−005 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs13585   {\textbar} {\textbar} chr22 {\textbar} 45131843 {\textbar} 0.0001016 {\textbar} {REGULATORY}\_REGION, {\textbar} {TRMU} {\textbar} 3PRIME\_UTR {\textbar} {\textbar} rs9368373  {\textbar} {\textbar} chr6  {\textbar} 22024631 {\textbar} 0.0001063 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs10935354 {\textbar} {\textbar} chr3  {\textbar} 141026326 {\textbar} 0.0001073 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs8095703  {\textbar} {\textbar} chr18 {\textbar} 11041081 {\textbar} 0.0001183 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs10206851 {\textbar} {\textbar} chr2  {\textbar} 5381477 {\textbar} 0.0001267 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs9542977  {\textbar} {\textbar} chr13 {\textbar} 71958236 {\textbar} 0.0001499 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs4942879  {\textbar} {\textbar} chr13 {\textbar} 49314940 {\textbar} 0.0001537 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs9542954  {\textbar} {\textbar} chr13 {\textbar} 71918308 {\textbar} 0.0001643 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs1593478  {\textbar} {\textbar} chr18 {\textbar} 2292023 {\textbar} 0.0001663 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs9542951  {\textbar} {\textbar} chr13 {\textbar} 71913959 {\textbar} 0.0001664 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs2188534  {\textbar} {\textbar} chr7  {\textbar} 111837550 {\textbar} 0.0001823 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs12524124 {\textbar} {\textbar} chr6  {\textbar} 22051921 {\textbar} 0.000185  {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs4352629  {\textbar} {\textbar} chr5  {\textbar} 87792577 {\textbar} 0.0001985 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs7448716  {\textbar} {\textbar} chr5  {\textbar} 87788451 {\textbar} 0.0001985 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs11873533 {\textbar} {\textbar} chr18 {\textbar} 3732713 {\textbar} 0.0002107 {\textbar} {INTRONIC} {\textbar} {DLGAP}1 {\textbar} rs10062658 {\textbar} {\textbar} chr5  {\textbar} 102881920 {\textbar} 0.0002216 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs12547917 {\textbar} {\textbar} chr8  {\textbar} 142306580 {\textbar} 0.0002282 {\textbar} {INTRONIC} {\textbar} {SLC}45A4 {\textbar} rs1038268  {\textbar} {\textbar} chr9  {\textbar} 31967623 {\textbar} 0.000229  {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs2375811  {\textbar} {\textbar} chr9  {\textbar} 31979998 {\textbar} 0.000229  {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs1352671  {\textbar} {\textbar} chr9  {\textbar} 32033985 {\textbar} 0.000229  {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs364331   {\textbar} {\textbar} chr9  {\textbar} 32039631 {\textbar} 0.000229  {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs1924949  {\textbar} {\textbar} chr13 {\textbar} 71975473 {\textbar} 0.0002323 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} rs11025990 {\textbar} {\textbar} chr11 {\textbar} 21218608 {\textbar} 0.0002323 {\textbar} {INTRONIC} {\textbar} {NELL}1 {\textbar} rs3758562  {\textbar} {\textbar} chr10 {\textbar} 72032086 {\textbar} 0.0002369 {\textbar} {INTRONIC} {\textbar} {PRF}1 {\textbar} rs10156056 {\textbar} {\textbar} chr7  {\textbar} 22720613 {\textbar} 0.0002394 {\textbar} {INTERGENIC} {\textbar} N/A {\textbar} The results of the prediction in the test set are summarized below: {\textbar} {\textbar} For the prediction of the dichotomized {ACTH} response status in the dex/{CRH} the following prediction values were achieved: {\textbar} {\textbar} {ACTH}: {\textbar} {\textbar} Accuracy=85.33\% {\textbar} Sensitivity=87.18\% {\textbar} Specificity=83.33\% {\textbar} Geometric mean of sensitivity and specificity=85.23\% {\textbar} Positive Predictive Value ({PPV})=85.00\% {\textbar} Negative Predictive Value ({NPV})=85.71\% {\textbar} Geometric mean of {PPV} and {NPV}=85.36\% {\textbar} Precision=85.00\% {\textbar} Recall=87.18\% {\textbar} F-Measure=0.8608 {\textbar} Area under {ROC} curve ({AUC})=0.851852 {\textbar} Using genome-wide {SNP} association data for the {ACTH} response in the dex/{CRH} test, a subset of 30 {SNPs} could be identified that allowed an accurate, sensitive and specific prediction of these phenotypes in independent sets of patients. Increased {ACTH} secretion in this test has been linked to an increase in central {CRH}/{CRHR}1 function. Although environmental, pharmacological and disease state-dependent factors have previously been described to influence the endocrine response to this test in depressed patients (Ising et al., Neuropsychopharmacol Biol Psychiatry, 2005; Heim et al. Biol Psychiatry, 2008; Kunzel et al. Neuropsychopharmacology, 2003), it has now been shown that genetic polymorphisms alone are strong predictors. {\textbar} {\textbar} Patients with depression or anxiety disorders, classified into the high {ACTH} response group according to the genotypes of the presented 30 {SNPs} described in this example will be more likely to respond to {CRHR}1 antagonist treatment. This allows an enrichment of such patients for {CRHR}1 antagonist treatment studies who will most likely respond to this specific treatment. {\textbar} {\textbar} Example 2 {\textbar} {\textbar} Sleep disturbances, such as decreased slow-wave sleep, increased sleep fragmentation and rapid-eye-movement sleep ({REMS}) disinhibition, are cardinal symptoms of major depression in humans. This study aims to identify those patients where a central {CRH} hyperdrive plays a causal role and which would therefore respond favourably to a {CRHR}1 antagonist. To test the relationship between a central {CRH}-overexpression and {REM}-disinhibition in particular, transgenic mouse models where {CRH} is overexpressed as a result of genetic engineering were employed. {\textbar} {\textbar} Many animal models of depression share increases in {REM}-sleeps ({REMS}) as a common feature. Therefore, increased {REMS} in animals should reflect {REMS}-disinhibitions in humans. Mice with {CNS}-specific {CRH}-overexpression strikingly share the characteristic increases in {REMS}. As such, an increase in {REMS} indicates a central hypersecretion of {CRH} and may serve as a biomarker to identify those patients who would benefit from treatment with a {CRHR}1 antagonist. {\textbar} {\textbar} Experiments were conducted with two different mouse lines of excessive central {CRH} secretion and their respective control littermates ({CL}). Mice of the {CRH}-{COE} {\textbar} {\textbar} {CNS} {\textbar} line are characterised by {CRH}-overexpression within the whole {CNS}, whereas mice of the Cor26 {CRH} line display a {CRH}-overexpression specific to {CRH}-ergic neurons of the {CNS}. Three different {CRHR}1 antagonists were tested. While {DMP}-696 (bicyclic) and {CP}-316,311 (monocyclic) are class I {CRH}-R1 antagonists, {SSR}125543A (long off-rate, typical slow-tight binding inhibitor) belongs to class {II} {CRH}-R1 antagonists. {DMP}-696 and {SSR}125543A were applied to {CRH}-{COE} {\textbar} {CNS} {\textbar} mice (n {\textbar} {DMP}696 {\textbar} =6/6 {COE}/{CL}; n {\textbar} {SSR}125543 {\textbar} =6/5 {COE}/{CL}), while {CP}-316,311 was tested in Cor26 {CRH} mice (n {\textbar} {CP}316.311 {\textbar} =5/3 Cor26/{CL}). In all cases, animals were left to recover from {EEG}/{EMG}-electrode implantation for two weeks, after which two days of baseline recording were initiated. Treatment with {CRH}-R1 antagonist or respective vehicle control commenced thereafter for five consecutive days. Antagonists were applied through the drinking water at a daily dose of 50 mg/kg body weight. {EEG} and {EMG} recordings were manually scored as wake, non-{REMS} ({NREMS}), and {REMS} in four second epochs by an experienced evaluator. {\textbar} As previously shown, {CRH}-{COE} {\textbar} {\textbar} {CNS} {\textbar} mice display significantly higher {REMS} activity under baseline condition as compared to controls. Chronic {DMP}-696 (50 mg/kg/d {DMP}-696) treatment entails only a mild suppression of {REMS} in {CL} mice. However, {DMP}-696-treated {CRH}-{COE} {\textbar} {CNS} {\textbar} mice show a significant decrease in {REMS} activity beginning with treatment day two (P{\textless}0.05). The strongest suppression of {REMS} activity in {CRH}-{COE} {\textbar} {CNS} {\textbar} animals could be observed on treatment day three ( {\textbar} {FIG}. 2 {\textbar} ). {\textbar} Comparable to {DMP}-696 treatment, oral application of {SSR}125543A (50 mg/kg/d) affected {REMS} levels in {CRH}-overexpressing mice. No effects of {SSR}125543 on {REMS} activity in control animals could be detected. In contrast, a significant suppression of {REMS} could be observed beginning with day two in {CRH}-overexpressing animals (P≦0.035). Similar to {DMP}-696 treatment, {REMS} suppression in {CRH}-{COE} {\textbar} {\textbar} {CNS} {\textbar} mice never exceeded baseline {REMS}-levels of {CL} ( {\textbar} {FIG}. 3 {\textbar} ). {\textbar} Application of {CP}-316,311 (Pfizer) in the Cor26 {CRH} mouse line showed no significant effect on {REMS} levels in {CL} animals. Similarly, in {CRH}-overexpressing Cor26 {CRH} mice suppression in {REMS} apparently seemed weak. However, comparison of the area under the curve ({AUC}) within the light period of baseline and treatment day three showed a significant decrease (P=0.006) of {REMS} levels after {CP}-316,311 application ( {\textbar} {\textbar} {FIG}. 4 {\textbar} ). {\textbar} {CRH} is one of the major drivers of the stress response in the brain. Hyperactivity of the {CRH} system seems to be responsible for cognitive impairments, emotional responses, and behavioural changes which are typical for depression. One of those behavioural changes are sleep disturbances exemplified by {REMS} disinhibition. The link between {CRH}-overexpression and {REMS} level increases is evidenced by the mouse lines used in these experiments. Since {CRH}-overexpression in the Cor26 {CRH} mouse line is limited to {CRH}-ergic neurons, the net increase of {CRH} is lower when compared to the whole brain overexpression in {CRH}-{COE} {\textbar} {\textbar} {CNS} {\textbar} mice. As a result, the phenotype of increased {REMS} levels was less profound in Cor26 {CRH} mice as compared to {CRH}-{COE} {\textbar} {CNS} {\textbar} animals. {\textbar} The main finding of this study is that the normalization of {CRH}-elicited sleep-{EEG} disturbances is striking when (1) different chemical classes of {CRHR}1 antagonists are used and (2) different animal models for {CRH}-induced sleep-{EEG} changes that are typical for human depression are employed. {REMS} disinhibition is indicative of a central {CRH} dysfunction (i.e. hyperactivity) and as such may serve as a biomarker for the identification of depressed patients where depression is caused by central {CRH}-hyperdrive. Normalization of the sleep pattern by application of different {CRHR}1 antagonists could be shown in all of our experiments, employing different classes of {CRHR}1 receptors and different animal models overexpressing centrally {CRH}.},
}

@patent{kohn_etal21b,
	location = {{WO}},
	title = {Application for tracking progression and isolating causes of adverse medical conditions},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {An application for tracking disease, pain, and mental health symptom triggers including an input module for inputting variables from a user in electronic communication with an output variable module, an analysis module for analyzing input variables and output variables, and an output module for presenting results to the user. A method of tracking disease, pain, and mental health triggers, by a user inputting data about nutrition, medication, lifestyle, symptoms, pain, and user defined metrics in an application, performing an analysis on the data, and outputting a result from the data identifying daily activities that effect the user's disease/mental health and trigger symptoms. A method of preventing adverse events. {\textbar}   {\textbar} L'invention concerne une application pour le suivi d'une maladie, de douleur, et de déclencheurs de symptômes de santé mentale comprenant un module d'entrée pour entrer des variables d'un utilisateur en communication électronique avec un module de sortie de variables, un module d'analyse pour analyser des variables d'entrée et des variables de sortie, et un module de sortie pour présenter des résultats à l'utilisateur. L'invention concerne également un procédé consistant à effectuer le suivi d'une maladie, de douleur, et de déclencheurs de santé mentale, par un utilisateur entrant des données concernant la nutrition, des médicaments, un mode de vie, des symptômes, la douleur, et des métriques définies par l'utilisateur dans une application, effectuer une analyse sur les données, et délivrance en sortie un résultat à partir des données identifiant des activités quotidiennes qui ont des répercussions sur la maladie/la santé mentale de l'utilisateur et sur les symptômes de déclenchement. L'invention concerne en outre un procédé de prévention d'événements indésirables.
L'invention concerne une application pour le suivi d'une maladie, de douleur, et de déclencheurs de symptômes de santé mentale comprenant un module d'entrée pour entrer des variables d'un utilisateur en communication électronique avec un module de sortie de variables, un module d'analyse pour analyser des variables d'entrée et des variables de sortie, et un module de sortie pour présenter des résultats à l'utilisateur. L'invention concerne également un procédé consistant à effectuer le suivi d'une maladie, de douleur, et de déclencheurs de santé mentale, par un utilisateur entrant des données concernant la nutrition, des médicaments, un mode de vie, des symptômes, la douleur, et des métriques définies par l'utilisateur dans une application, effectuer une analyse sur les données, et délivrance en sortie un résultat à partir des données identifiant des activités quotidiennes qui ont des répercussions sur la maladie/la santé mentale de l'utilisateur et sur les symptômes de déclenchement. L'invention concerne en outre un procédé de prévention d'événements indésirables.
An application for tracking disease, pain, and mental health symptom triggers including an input module for inputting variables from a user in electronic communication with an output variable module, an analysis module for analyzing input variables and output variables, and an output module for presenting results to the user. A method of tracking disease, pain, and mental health triggers, by a user inputting data about nutrition, medication, lifestyle, symptoms, pain, and user defined metrics in an application, performing an analysis on the data, and outputting a result from the data identifying daily activities that effect the user's disease/mental health and trigger symptoms. A method of preventing adverse events.},
	type = {patent},
	author = {Kohn, Kenneth and Inwald, David and Brown, Caitlin Joline},
	urldate = {2020-08-14},
	date = {2021-02-25},
	note = {Edition: G16H001020 {\textbar} A61B000500 {\textbar} A61B0005103 {\textbar} G06N000302 {\textbar} G06N000308 {\textbar} G06N002000 {\textbar} G16H001060 {\textbar} G16H002000 {CPC} - G16H005020 {\textbar} A61B00054842 {\textbar} A61B00057267 {\textbar} A61B00057275 {\textbar} A61B00057282 {\textbar} G06N002020 {\textbar} G16H001020 {\textbar} G16H002000 {\textbar} G16H004063 {\textbar} A61B00050002 {\textbar} A61B000501 {\textbar} A61B0005024 {\textbar} A61B00050531 {\textbar} A61B00050816 {\textbar} A61B00051116 {\textbar} A61B000514532 {\textbar} A61B000514551 {\textbar} A61B00054806 {\textbar} G06N0003084 {\textbar} G06N0005003 {\textbar} G06N0007005 {\textbar} G06N002010 {\textbar} G16H002010 {\textbar} G16H002040 {\textbar} Y02A009010 {EP} {EP} {CLAIMS} {\textbar} {\textbar} 1. An application for tracking disease, pain, and mental health symptom triggers stored on non-transitory computer readable media comprising: an input module for inputting variables from a user in electronic communication with an output variable module; an analysis module for analyzing input variables and output variables; and an output module for presenting results to the user. {\textbar} 2. The application of claim 1 , wherein the disease or disorder tracked is chosen from the group consisting of digestive disorders, migraines, anxiety attacks, and suicidal thoughts. {\textbar} 3. The application of claim 1 , wherein the disease tracked is an infectious disease chosen from the group consisting of influenza, measles, {COVID}-19, {AIDS}, amebiasis, anaplasmosis, anthrax, antibiotic resistance, avian influenza, babesiosis, botulism, brucellosis, Campylobacter, cat scratch disease, chickenpox, chikungunya, chlamydia trachomatis, cholera, Clostridium perfringens, conjunctivitis, crusted scabies, cryptosporidiosis, cyclospora, dengue fever, diphtheria, ebola virus disease, E. coli, eastern equine encephalitis ({EEE}), enterovirus 68, fifth disease, genital herpes, genital warts, giardia, gonorrhea, group A Streptococcus, Guillain-Barre syndrome, Hand, Foot \& Mouth Disease, Hansen's disease, hantavirus, lice, hepatitis A, hepatitis B, hepatitis C, herpes, herpes B virus, Hib disease, histoplasmosis, {HIV}, {HPV} (Human Papillomavirus), impetigo, Kawasaki syndrome, legionellosis, leprosy, leptospirosis, listeriosis, lyme disease, lymphocytic choriomeningitis ({LCMV}), malaria, Marburg virus, meningitis, meningococcal disease, {MERS} (Middle East Respiratory Illness), monkeypox, mononucleosis, {MRSA}, mumps, mycoplasma pneumoniae, neisseria meningitis, norovirus, Orf Virus (Sore Mouth), pelvic inflammatory disease ({PID}), {PEP}, pertussis, pink eye, plague, pneumococcal disease, powassan virus, psittacosis, Q fever, rabies, raccoon roundworm, rat bite fever, Reye’s Syndrome, Rickettsialpox, ringworm, rubella, salmonella, scabies, scarlet fever, shigella, shingles, smallpox, strep throat, syphilis, tetanus, toxoplasmosis, trichinosis, trichomoniasis, tuberculosis, tularemia, varicella, vibriosis, viral hemorrhagic fevers ({VHF}), West Nile virus, whooping cough, yellow fever, yersiniosis, and zika virus. {\textbar} 4. The application of claim 1 , wherein the pain tracked is from a source chosen from the group consisting of injury, surgery, cancer, fibromyalgia, arthritis, and peripheral neuropathy. {\textbar} 5. The application of claim 1 , wherein said input module receives data from users in a nutrition question module, medication question module, and lifestyle question module. {\textbar} 6. The application of claim 1 , wherein said output variable module includes a symptom question module, and user defined metrics question module. {\textbar} 7. The application of claim 1, wherein said input module receives data from outside devices chosen from the group consisting of general fitness trackers, heartbeat trackers, heart rate trackers, skin temperature trackers, respiratory rate trackers, body posture trackers, eyesight trackers, blood oxygen trackers, glucose level trackers, sleep trackers, body temperature trackers, skin conductance trackers, and combinations thereof. {\textbar} 8. The application of claim 1, wherein said input module receives data from outside databases chosen from the group consisting of clinics, electronic medical records ({EMRs}), pharmaceutical companies, private databases, weather monitoring systems, and {CROs}. {\textbar} 9. The application of claim 8, wherein said analysis module finds other individuals with similar data as the user to predict adverse events. {\textbar} 10. The application of claim 1 , wherein said analysis module includes analysis methods of regressions, time series, random forest, classifiers, neural networks, support vector machines, Al/machine learning techniques, miscellaneous classical statistical techniques, and combinations thereof. {\textbar} 11. The application of claim 1 , wherein said analysis module finds patterns between how users live and how they feel. {\textbar} 12. The application of claim 1 , wherein said output module displays strongest trends, key performance indicators, and tracking over time and identifies disease, pain, and mental health triggers. {\textbar} 13. The application of claim 1 , wherein said application is in electronic communication with external databases and healthcare professionals. {\textbar} 14. The application of claim 1 , further including an alarm for reminding the user to input data into said input module and said output variable module. {\textbar} 15. A method of tracking disease, pain, and mental health triggers, including the steps of: a user inputting data about nutrition, medication, lifestyle, symptoms, pain, and user defined metrics in an application stored on non-transitory computer readable media; performing an analysis on the data; and outputting a result from the data identifying daily activities that effect the user’s disease/mental health/pain and trigger symptoms. {\textbar} 16. The method of claim 15, wherein said inputting step further includes the step of integrating a user’s data from outside devices chosen from the group consisting of general fitness trackers, heartbeat trackers, heart rate trackers, skin temperature trackers, respiratory rate trackers, body posture trackers, eyesight trackers, blood oxygen trackers, glucose level trackers, sleep trackers, body temperature trackers, skin conductance trackers, and combinations thereof. {\textbar} 17. The method of claim 16, further including the step of discovering triggers that do not correlate to a medical event. {\textbar} 18. The method of claim 15, wherein said inputting step further includes the step of integrating data from outside databases chosen from the group consisting of clinics, electronic medical records ({EMRs}), pharmaceutical companies, private databases, weather monitoring systems, and {CROs}. {\textbar} 19. The method of claim 18, further including the step of predicting triggers based on individuals with similar data to the user. {\textbar} 20. The method of claim 15, wherein said performing an analysis step is further defined as performing an analysis method chosen from the group consisting of regressions, time series, random forest, classifiers, neural networks, support vector machines, Al/machine learning techniques, miscellaneous classical statistical techniques, and combinations thereof. {\textbar} 21. The method of claim 15, wherein the disease or disorder tracked is chosen from the group consisting of digestive disorders, migraines, anxiety attacks, and suicidal thoughts. {\textbar} 22. The method of claim 15, wherein the disease tracked is an infectious disease chosen from the group consisting of influenza, measles, {COVID}-19, {AIDS}, amebiasis, anaplasmosis, anthrax, antibiotic resistance, avian influenza, babesiosis, botulism, brucellosis, Campylobacter, cat scratch disease, chickenpox, chikungunya, chlamydia trachomatis, cholera, Clostridium perfringens, conjunctivitis, crusted scabies, cryptosporidiosis, cyclospora, dengue fever, diphtheria, ebola virus disease, E. coli, eastern equine encephalitis ({EEE}), enterovirus 68, fifth disease, genital herpes, genital warts, giardia, gonorrhea, group A Streptococcus, Guillain-Barre syndrome, Hand, Foot \& Mouth Disease, Hansen's disease, hantavirus, lice, hepatitis A, hepatitis B, hepatitis C, herpes, herpes B virus, Hib disease, histoplasmosis, {HIV}, {HPV} (Human Papillomavirus), impetigo, Kawasaki syndrome, legionellosis, leprosy, leptospirosis, listeriosis, lyme disease, lymphocytic choriomeningitis ({LCMV}), malaria, Marburg virus, meningitis, meningococcal disease, {MERS} (Middle East Respiratory Illness), monkeypox, mononucleosis, {MRSA}, mumps, mycoplasma pneumoniae, neisseria meningitis, norovirus, Orf Virus (Sore Mouth), pelvic inflammatory disease ({PID}), {PEP}, pertussis, pink eye, plague, pneumococcal disease, powassan virus, psittacosis, Q fever, rabies, raccoon roundworm, rat bite fever, Reye’s Syndrome, Rickettsialpox, ringworm, rubella, salmonella, scabies, scarlet fever, shigella, shingles, smallpox, strep throat, syphilis, tetanus, toxoplasmosis, trichinosis, trichomoniasis, tuberculosis, tularemia, varicella, vibriosis, viral hemorrhagic fevers ({VHF}), West Nile virus, whooping cough, yellow fever, yersiniosis, and zika virus. {\textbar} 23. The method of claim 15, wherein the pain tracked is from a source chosen from the group consisting of injury, surgery, cancer, fibromyalgia, arthritis, and peripheral neuropathy. {\textbar} 24. The method of claim 15, wherein said outputting step further includes displaying strongest trends, key performance indicators, and tracking over time. {\textbar} 25. The method of claim 15, further including the step of the user changing their lifestyle to prevent identified triggers. {\textbar} 26. A method of preventing adverse events, including the steps of: a user inputting data about nutrition, medication, lifestyle, symptoms, pain and user defined metrics in an application stored on non-transitory computer readable media; integrating data from outside devices and outside databases; performing an analysis on the data; and outputting a result from the data identifying that an adverse event is likely to occur at a later time point. {\textbar} 27. The method of claim 26, further including the step of recommending that the user seek treatment for a condition that can cause the adverse event. {\textbar} 28. The method of claim 26, wherein the adverse event is chosen from the group consisting of headaches, nausea, heart attacks, seizures, allergic reactions, hemorrhages, and tissue damage. {\textbar} 29. The method of claim 25, wherein said performing an analysis step further includes the step of predicting adverse events or triggers to an adverse event based on individuals with similar data to the user. {CLAIMS} {\textbar} {\textbar} 1. An application for tracking disease, pain, and mental health symptom triggers stored on non-transitory computer readable media comprising: an input module for inputting variables from a user in electronic communication with an output variable module; an analysis module for analyzing input variables and output variables; and an output module for presenting results to the user. {\textbar} 2. The application of claim 1 , wherein the disease or disorder tracked is chosen from the group consisting of digestive disorders, migraines, anxiety attacks, and suicidal thoughts. {\textbar} 3. The application of claim 1 , wherein the disease tracked is an infectious disease chosen from the group consisting of influenza, measles, {COVID}-19, {AIDS}, amebiasis, anaplasmosis, anthrax, antibiotic resistance, avian influenza, babesiosis, botulism, brucellosis, Campylobacter, cat scratch disease, chickenpox, chikungunya, chlamydia trachomatis, cholera, Clostridium perfringens, conjunctivitis, crusted scabies, cryptosporidiosis, cyclospora, dengue fever, diphtheria, ebola virus disease, E. coli, eastern equine encephalitis ({EEE}), enterovirus 68, fifth disease, genital herpes, genital warts, giardia, gonorrhea, group A Streptococcus, Guillain-Barre syndrome, Hand, Foot \& Mouth Disease, Hansen's disease, hantavirus, lice, hepatitis A, hepatitis B, hepatitis C, herpes, herpes B virus, Hib disease, histoplasmosis, {HIV}, {HPV} (Human Papillomavirus), impetigo, Kawasaki syndrome, legionellosis, leprosy, leptospirosis, listeriosis, lyme disease, lymphocytic choriomeningitis ({LCMV}), malaria, Marburg virus, meningitis, meningococcal disease, {MERS} (Middle East Respiratory Illness), monkeypox, mononucleosis, {MRSA}, mumps, mycoplasma pneumoniae, neisseria meningitis, norovirus, Orf Virus (Sore Mouth), pelvic inflammatory disease ({PID}), {PEP}, pertussis, pink eye, plague, pneumococcal disease, powassan virus, psittacosis, Q fever, rabies, raccoon roundworm, rat bite fever, Reye’s Syndrome, Rickettsialpox, ringworm, rubella, salmonella, scabies, scarlet fever, shigella, shingles, smallpox, strep throat, syphilis, tetanus, toxoplasmosis, trichinosis, trichomoniasis, tuberculosis, tularemia, varicella, vibriosis, viral hemorrhagic fevers ({VHF}), West Nile virus, whooping cough, yellow fever, yersiniosis, and zika virus. {\textbar} 4. The application of claim 1 , wherein the pain tracked is from a source chosen from the group consisting of injury, surgery, cancer, fibromyalgia, arthritis, and peripheral neuropathy. {\textbar} 5. The application of claim 1 , wherein said input module receives data from users in a nutrition question module, medication question module, and lifestyle question module. {\textbar} 6. The application of claim 1 , wherein said output variable module includes a symptom question module, and user defined metrics question module. {\textbar} 7. The application of claim 1, wherein said input module receives data from outside devices chosen from the group consisting of general fitness trackers, heartbeat trackers, heart rate trackers, skin temperature trackers, respiratory rate trackers, body posture trackers, eyesight trackers, blood oxygen trackers, glucose level trackers, sleep trackers, body temperature trackers, skin conductance trackers, and combinations thereof. {\textbar} 8. The application of claim 1, wherein said input module receives data from outside databases chosen from the group consisting of clinics, electronic medical records ({EMRs}), pharmaceutical companies, private databases, weather monitoring systems, and {CROs}. {\textbar} 9. The application of claim 8, wherein said analysis module finds other individuals with similar data as the user to predict adverse events. {\textbar} 10. The application of claim 1 , wherein said analysis module includes analysis methods of regressions, time series, random forest, classifiers, neural networks, support vector machines, Al/machine learning techniques, miscellaneous classical statistical techniques, and combinations thereof. {\textbar} 11. The application of claim 1 , wherein said analysis module finds patterns between how users live and how they feel. {\textbar} 12. The application of claim 1 , wherein said output module displays strongest trends, key performance indicators, and tracking over time and identifies disease, pain, and mental health triggers. {\textbar} 13. The application of claim 1 , wherein said application is in electronic communication with external databases and healthcare professionals. {\textbar} 14. The application of claim 1 , further including an alarm for reminding the user to input data into said input module and said output variable module. {\textbar} 15. A method of tracking disease, pain, and mental health triggers, including the steps of: a user inputting data about nutrition, medication, lifestyle, symptoms, pain, and user defined metrics in an application stored on non-transitory computer readable media; performing an analysis on the data; and outputting a result from the data identifying daily activities that effect the user’s disease/mental health/pain and trigger symptoms. {\textbar} 16. The method of claim 15, wherein said inputting step further includes the step of integrating a user’s data from outside devices chosen from the group consisting of general fitness trackers, heartbeat trackers, heart rate trackers, skin temperature trackers, respiratory rate trackers, body posture trackers, eyesight trackers, blood oxygen trackers, glucose level trackers, sleep trackers, body temperature trackers, skin conductance trackers, and combinations thereof. {\textbar} 17. The method of claim 16, further including the step of discovering triggers that do not correlate to a medical event. {\textbar} 18. The method of claim 15, wherein said inputting step further includes the step of integrating data from outside databases chosen from the group consisting of clinics, electronic medical records ({EMRs}), pharmaceutical companies, private databases, weather monitoring systems, and {CROs}. {\textbar} 19. The method of claim 18, further including the step of predicting triggers based on individuals with similar data to the user. {\textbar} 20. The method of claim 15, wherein said performing an analysis step is further defined as performing an analysis method chosen from the group consisting of regressions, time series, random forest, classifiers, neural networks, support vector machines, Al/machine learning techniques, miscellaneous classical statistical techniques, and combinations thereof. {\textbar} 21. The method of claim 15, wherein the disease or disorder tracked is chosen from the group consisting of digestive disorders, migraines, anxiety attacks, and suicidal thoughts. {\textbar} 22. The method of claim 15, wherein the disease tracked is an infectious disease chosen from the group consisting of influenza, measles, {COVID}-19, {AIDS}, amebiasis, anaplasmosis, anthrax, antibiotic resistance, avian influenza, babesiosis, botulism, brucellosis, Campylobacter, cat scratch disease, chickenpox, chikungunya, chlamydia trachomatis, cholera, Clostridium perfringens, conjunctivitis, crusted scabies, cryptosporidiosis, cyclospora, dengue fever, diphtheria, ebola virus disease, E. coli, eastern equine encephalitis ({EEE}), enterovirus 68, fifth disease, genital herpes, genital warts, giardia, gonorrhea, group A Streptococcus, Guillain-Barre syndrome, Hand, Foot \& Mouth Disease, Hansen's disease, hantavirus, lice, hepatitis A, hepatitis B, hepatitis C, herpes, herpes B virus, Hib disease, histoplasmosis, {HIV}, {HPV} (Human Papillomavirus), impetigo, Kawasaki syndrome, legionellosis, leprosy, leptospirosis, listeriosis, lyme disease, lymphocytic choriomeningitis ({LCMV}), malaria, Marburg virus, meningitis, meningococcal disease, {MERS} (Middle East Respiratory Illness), monkeypox, mononucleosis, {MRSA}, mumps, mycoplasma pneumoniae, neisseria meningitis, norovirus, Orf Virus (Sore Mouth), pelvic inflammatory disease ({PID}), {PEP}, pertussis, pink eye, plague, pneumococcal disease, powassan virus, psittacosis, Q fever, rabies, raccoon roundworm, rat bite fever, Reye’s Syndrome, Rickettsialpox, ringworm, rubella, salmonella, scabies, scarlet fever, shigella, shingles, smallpox, strep throat, syphilis, tetanus, toxoplasmosis, trichinosis, trichomoniasis, tuberculosis, tularemia, varicella, vibriosis, viral hemorrhagic fevers ({VHF}), West Nile virus, whooping cough, yellow fever, yersiniosis, and zika virus. {\textbar} 23. The method of claim 15, wherein the pain tracked is from a source chosen from the group consisting of injury, surgery, cancer, fibromyalgia, arthritis, and peripheral neuropathy. {\textbar} 24. The method of claim 15, wherein said outputting step further includes displaying strongest trends, key performance indicators, and tracking over time. {\textbar} 25. The method of claim 15, further including the step of the user changing their lifestyle to prevent identified triggers. {\textbar} 26. A method of preventing adverse events, including the steps of: a user inputting data about nutrition, medication, lifestyle, symptoms, pain and user defined metrics in an application stored on non-transitory computer readable media; integrating data from outside devices and outside databases; performing an analysis on the data; and outputting a result from the data identifying that an adverse event is likely to occur at a later time point. {\textbar} 27. The method of claim 26, further including the step of recommending that the user seek treatment for a condition that can cause the adverse event. {\textbar} 28. The method of claim 26, wherein the adverse event is chosen from the group consisting of headaches, nausea, heart attacks, seizures, allergic reactions, hemorrhages, and tissue damage. {\textbar} 29. The method of claim 25, wherein said performing an analysis step further includes the step of predicting adverse events or triggers to an adverse event based on individuals with similar data to the user. 1. An application for tracking disease, pain, and mental health symptom triggers stored on non-transitory computer readable media comprising: an input module for inputting variables from a user in electronic communication with an output variable module; an analysis module for analyzing input variables and output variables; and an output module for presenting results to the user. 1. An application for tracking disease, pain, and mental health symptom triggers stored on non-transitory computer readable media comprising: an input module for inputting variables from a user in electronic communication with an output variable module; an analysis module for analyzing input variables and output variables; and an output module for presenting results to the user. {APPLICATION} {FOR} {TRACKING} {PROGRESSION} {AND} {ISOLATING} {CAUSES} {OF} {ADVERSE} {MEDICAL} {CONDITIONS} {\textbar} {\textbar} {BACKGROUND} {OF} {THE} {INVENTION} {\textbar} {\textbar} 1. {TECHNICAL} {FIELD} {\textbar} {\textbar} [00001] The present invention relates to methods of tracking daily activity and symptoms of diseases and mental health issues. More specifically, the present invention relates to methods of tracking symptoms of adverse events to predict adverse events related to various diseases, such as digestive diseases, migraine, panic attacks, pain, contagious diseases, and others. {\textbar} {\textbar} 2. {BACKGROUND} {ART} {\textbar} {\textbar} [00002] Nearly one-fifth of the American public faces chronic digestive problems. This includes 25 to 45 million people with Irritable Bowel Syndrome ({IBS}) and an additional 3 million with the more serious and potentially life threatening Inflammatory Bowel Disease ({IBD}, which includes Crohn’s Disease and Ulcerative Colitis). {IBS} can be caused by muscle contractions in the intestine, abnormalities in the nervous system, inflammation in the intestines, severe infections, or changes in the gut microbiome. Symptoms of {IBS} include cramping, abdominal pain, bloating, gas, diarrhea, constipation, and combinations thereof. While severe symptoms can be treated with medicine, many people can relieve their symptoms by managing their diet and lifestyle. {IBD}, on the other hand, is a chronic inflammation of the digestive tract and can involve the symptoms of diarrhea, fever and fatigue, abdominal pain and cramping, blood in the stool, reduced appetite, and weight loss. {IBD} may be caused by immune system malfunctions and can be aggravated by diet and lifestyle. {\textbar} {\textbar} [00003] Several platforms exist that help sufferers of digestive diseases track their symptoms. Oshi is an {IBD}-focused platform that includes tracking as one facet. Dimensions captured include disease activity, stress, physical activity, sleep, and diet adherence. The diet adherence requires the individual to tell it what foods they need to avoid, then it helps you track if they have avoided them. The symptoms trackers tallies bms, pain, bleeding (on a scale of 0 to 3 {OR} 4-10), and how well the individual feels the disease is in control. The insights possible with this platform are therefore very limited. {\textbar} {\textbar} [00004] {FlareDown} tracks disease symptoms and medication. However, the Crohn’s default daily check-in is just “How was your condition today?” and responding from “not active” to “extremely active”. Individuals can add other symptoms, but the list is vast and not well- organized or user friendly. Individuals also log the medications they took, as well as the foods they ate. However, the foods are “search for whatever food you want to track” approach, which is neither user friendly, not helpful. Reminders to check in are limited to email. {\textbar} {\textbar} [00005] {SymptomTracker} allows users to track symptoms over time (from pain to motivation). However, it does not include any other information and so cannot speak to what may be causing the changes in the tracked symptom. {\textbar} {\textbar} [00006] There remains a need for chronic sufferers of digestive diseases to identify how their day-to-day lives impact their symptoms. {\textbar} {\textbar} [00007] It would also be useful to track symptoms and triggers of various other diseases and mental health problems, so that individuals can learn how to avoid or change situations that trigger these issues as well as predict when an adverse event will occur to prevent the adverse event. {\textbar} {\textbar} [00008] For example, migraines are a type of headache that recur with moderate to severe pain, and can include nausea, weakness, and sensitivities to light and sound in about 12 percent of individuals in the United States. They are thought to be genetic. Many different factors can trigger migraines, such as stress, anxiety, hormonal changes, bright or flashing lights, loud noises, strong smells, medicines, sleep patterns, sudden weather changes, overexertion, tobacco use, caffeine or lack of caffeine, missed meals, and foods and additives. Treatments focus on relieving symptoms and preventing further attacks and include medicines such as pain relievers, calcitonin gene-related peptide injections, {BOTOX}® injections, mild anesthesia treatments, stress management, rest, and hormone therapy. Doctors suggest tracking triggers to avoid them. Apps exist to help individuals with this. Migraine Buddy allows an individual to record migraine frequency and duration, pain location and intensity, symptoms and medications, and can help identify triggers. Ouchie allows an individual to post data about where they feel pain, pain intensity, and treatments, and this is shared with an app community with similar symptoms where they can share tips for reducing pain. {\textbar} {\textbar} [00009] The concept of measuring patient pain is a challenging topic which is highly relevant in a time where opioid concern and addiction is a huge issue around the world. Patients are asked to rate pain on a scale of one to ten, which is subjective and up to the patient to determine. With no ability to compare pain levels to a known level, the patients provide a number that can mean they are in extreme pain when in fact, they are not in sufficient pain to require pain medication. On the other hand, patients in pain can provide a number lower than their actual pain level resulting in incorrect treatment of pain and lack of pain medication. This can lead to patients misstating pain levels to insure pain medication. [000010] For the doctor, this leaves a patient’s pain condition up to judgment and requires balancing the patient provided pain number with personal experience. While this would normally work, opioid addiction due to overprescribing and bad faith pharmaceutical distribution has led to litigation and legal ramifications for doctors that want to provide proper dosing. In certain cases, the pendulum has swung so far as to have doctors avoid prescribing pain medication needed by the patients to avoid any legal risks. {\textbar} {\textbar} [000011] While addiction and overprescribing are serious issues, patients that truly need pain relief are left in an untenable position of providing pain numbers that are subjective and doctors that cannot rely on what the patient is saying. However, not treating pain is dangerous for the patient and simply cannot be ignored. In an article written by Forest Tennant, {MD}, {DrPH}, in Practical Pain Management, Volume 10, Issue 8, {\textbar} {\textbar} [000012] “Although severe pain can have profound and negative impacts on the cardiovascular ({CV}) system, this complication has received scant attention. Pain may affect the {CV} system by multiple mechanisms, and sudden {CV} death may occur in chronic pain patients who experience a severe pain flare. One of the goals of pain treatment should be to stabilize and bring homeostasis to a pain patient’s {CV} system. This is particularly the case with older patients who have either overt or covert cardiovascular disease or who may be at risk of developing it.” {\textbar} {\textbar} [000013] Thus, not treating pain can be deadly for the patient. Therefore, there is a need for something better that can correlate pain to a pain scale and provide factual data for the doctor to verify pain and record the data in a patient chart for documentation. {\textbar} {\textbar} [000014] Dr. Tennant also writes: {\textbar} {\textbar} [000015] “Pain causes elevation of blood pressure and pulse rate by two basic mechanisms that may simultaneously operate. The sympathetic (autonomic) nervous system is stimulated by electrical pain signals that reach the central nervous system. This may occur in acute pain, during flares, or breakthrough pain. The aberrant, neuronatomic brain changes that may occur with severe constant pain appears to be capable of producing continuous sympathetic discharge. Pain also signals the hypothalamus and pituitary to release adrenocorticotropin hormone ({ACTH}) which stimulates the adrenal glands to release adrenalin with subsequent elevation of pulse and blood pressure. Recognition of sympathetic stimulation is a useful clinical tool to help guide therapy and diagnose uncontrolled pain. Besides hypertension and tachycardia, sympathetic discharge also produces mydriasis (dilated pupil), diaphoresis (sweating), hyperactive reflexes, nausea, diarrhea, vasoconstriction (cold hands and feet), anorexia, and insomnia.” {\textbar} {\textbar} [000016] Therefore, there remains a need for a method of accurately tracking pain and evaluating pain in patients. {\textbar} {\textbar} [000017] Panic or anxiety attacks cause intense fear in an individual without a real danger or cause and begin suddenly. Symptoms include a sense of impending doom or danger, fear of loss of control or death, rapid and pounding heart rate, sweating, trembling or shaking, shortness of breath, chills, hot flashes, nausea, abdominal cramping, chest pain, headaches, dizziness, lightheadedness, faintness, numbness or tingling sensation, or feeling of unreality or detachment. Causes can include genetics, stress, or changes in brain function. It is also suggested to track triggers and symptoms to cope with anxiety attacks. For example, Anxiety Reliever is an app that allows an individual to track symptoms and provides relaxation exercises. {\textbar} {\textbar} [000018] Apps also exist to help individuals having suicidal thoughts. {MY}3 allows a user to define a network of individuals with whom they can reach out to when suicidal thoughts occur. Suicidal Safety Plan designs a plan for individuals to follow to cope with suicidal thoughts. {\textbar} {\textbar} [000019] Infectious diseases are diseases caused by pathogenic microorganisms such as bacteria, viruses, parasites, or fungi that can be spread from person to person, either directly or indirectly. {\textbar} {\textbar} [000020] Coronavirus Disease 2019 ({COVID}-19) is a severe acute respiratory syndrome ({SARS}) coronavirus 2 that originated in 2019 in Wuhan, China, and has quickly spread around the world. The viral infection is spread from person to person by respiratory droplets. Symptoms include fever, cough, and shortness of breath and it is very similar to influenza. While tests are available to identify {COVID}-19, they are generally not being used on people with milder symptoms due to the lack of number of tests. Individuals who have been identified as having the virus need to quarantine themselves. It would be advantageous to track individual’s symptoms if they are not feeling well as well as tracking habits of quarantine individuals to ensure compliance. {\textbar} {\textbar} [000021] Therefore, there remains a need for a method of tracking many different diseases and mental health issues wherein the identification of triggers for adverse events is a complex process not easily identifiable by a practitioner merely reviewing a patient’s daily log, and a need for predicting adverse events so that they can be avoided or treated in time. {\textbar} {\textbar} {SUMMARY} {OF} {THE} {INVENTION} {\textbar} {\textbar} [000022] The present invention provides for an application for tracking disease, pain, and mental health symptom triggers stored on non-transitory computer readable media including an input module for inputting variables from a user in electronic communication with an output variable module, an analysis module for analyzing input variables and output variables, and an output module for presenting results to the user. {\textbar} {\textbar} [000023] The present invention provides for a method of tracking disease, pain, and mental health triggers, by a user inputting data about nutrition, medication, lifestyle, symptoms, pain, and user defined metrics in an application stored on non-transitory computer readable media, performing an analysis on the data, and outputting a result from the data identifying daily activities that effect the user’s disease/mental health and trigger symptoms. {\textbar} {\textbar} [000024] The present invention also provides for a method of preventing adverse events, by a user inputting data about nutrition, medication, lifestyle, symptoms, pain and user defined metrics in an application stored on non-transitory computer readable media, integrating data from outside devices and outside databases, performing an analysis on the data, and outputting a result from the data identifying that an adverse event is likely to occur at a later time point. {\textbar} {\textbar} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} [000025] Other advantages of the present invention are readily appreciated as the same becomes better understood by reference to the following detailed description when considered in connection with the accompanying drawings wherein: {\textbar} {\textbar} [000026] {FIGURE} 1 is a diagram of the flow of information in the application and method; and [000027] {FIGURE} 2 is a macro-level systems design of the present invention. {\textbar} {\textbar} {DETAILED} {DESCRIPTION} {OF} {THE} {INVENTION} [000028] The present invention generally provides for a user friendly application (shown at 10 in the {FIGURES}) and method of use that quickly captures daily activities, intake, and symptoms of users with diseases and mental health issues to find otherwise hidden patterns in order to determine symptom triggers and effects on their body. The information can be input by the user answering preset questions. Additionally, the information can be input from existing and newly developed outside monitoring devices. These monitoring devices can measure cardiac, circulatory or other physical properties of the user over time. The information gathered is analyzed over time along with patient gathered data gathered over time. This information enables users to tweak their lifestyle and feel better. The information can also be used to predict an adverse event happening at a later time point so that the user can either prevent the adverse event from happening with lifestyle changes or receive treatment to prevent the adverse event. {\textbar} {\textbar} [000029] The term “application” as used herein refers to a computer software application, otherwise known as an “app”, that is run and operated on a mobile device, such as, but not limited to, smart phones ({IPFIONE}® (Apple, Inc.), {ANDROID}™ devices (Google, Inc.), {WINDOWS}® devices (Microsoft)), mp3 players ({IPOD} {TOUCFI}® (Apple, Inc.)), or tablet computers ({IPAD}® (Apple, Inc.)), especially ones utilizing a touch screen. The application can also be web based and run on a computer or laptop. The application 10 includes any necessary user interface or display and storage components to display the application and store the algorithm running it. {\textbar} {\textbar} [000030] “Diseases and mental health issues” as used herein can include diseases such as digestive disorders or migraines, and mental health issues such as anxiety attacks, or suicidal thoughts, among others. The diseases and mental health issues are preferably ones that are affected by outside triggers such as diet and lifestyle or environment. {\textbar} {\textbar} [000031] “Pain” as used herein can refer to any unpleasant sensation in the body, ranging from mild to severe, as felt through the nervous system. Pain can be localized or systemic. Pain can be acute (lasting less than 30 days), subacute (lasting 1-6 months), or chronic (lasting more than 6 months). Pain can be caused by injury, surgery (especially such as orthopedic device surgery involving knees, hips, shoulders, elbows), cancer, fibromyalgia, arthritis, or peripheral neuropathy. {\textbar} {\textbar} [000032] “Infectious disease” as used herein can include an viral, protozoan, or bacterial disease such as most preferably influenza, measles, or {COVID}-19, or any of {AIDS}, amebiasis, anaplasmosis, anthrax, antibiotic resistance, avian influenza, babesiosis, botulism, brucellosis, Campylobacter, cat scratch disease, chickenpox, chikungunya, chlamydia trachomatis, cholera, Clostridium perfringens, conjunctivitis, crusted scabies, cryptosporidiosis, cyclospora, dengue fever, diphtheria, ebola virus disease, E. coli, eastern equine encephalitis ({EEE}), enterovirus 68, fifth disease, genital herpes, genital warts, giardia, gonorrhea, group A Streptococcus, Guillain-Barre syndrome, Hand, Foot \& Mouth Disease, Hansen's disease, hantavirus, lice, hepatitis A, hepatitis B, hepatitis C, herpes, herpes B virus, Hib disease, histoplasmosis, {HIV}, {HPV} (Human Papillomavirus), impetigo, Kawasaki syndrome, legionellosis, leprosy, leptospirosis, listeriosis, lyme disease, lymphocytic choriomeningitis ({LCMV}), malaria, Marburg virus, meningitis, meningococcal disease, {MERS} (Middle East Respiratory Illness), monkeypox, mononucleosis, {MRSA}, mumps, mycoplasma pneumoniae, neisseria meningitis, norovirus, Orf Virus (Sore Mouth), pelvic inflammatory disease ({PID}), {PEP}, pertussis, pink eye, plague, pneumococcal disease, powassan virus, psittacosis, Q fever, rabies, raccoon roundworm, rat bite fever, Reye’s Syndrome, Rickettsialpox, ringworm, rubella, salmonella, scabies, scarlet fever, shigella, shingles, smallpox, strep throat, syphilis, tetanus, toxoplasmosis, trichinosis, trichomoniasis, tuberculosis, tularemia, varicella, vibriosis, viral hemorrhagic fevers ({VHF}), West Nile virus, whooping cough, yellow fever, yersiniosis, or zika virus. {\textbar} {\textbar} [000033] “Trigger” as used herein, refers to an event or situation that causes or provokes a disease or condition to happen. {\textbar} {\textbar} [000034] “Adverse event” as used herein, refers to any medical occurrence that is undesired in a user. Examples can include, but are not limited to, headaches, nausea, heart attacks, seizures, allergic reactions, hemorrhages, tissue damage, or any other damage to the body. Adverse events can cause disability, permanent damage, or even death. {\textbar} {\textbar} [000035] As generally shown in {FIGURE} 1 , the application 10 includes an input module 12 for inputting variables from a user in electronic communication with an output variable module 14, an analysis module 16 that analyzes data from the input variables and output variables, and an output module 18 for presenting results to the user. Each of these modules can be run by algorithms stored on non-transitory computer readable media. {\textbar} {\textbar} [000036] The input module 12 can be used to keep a daily log of users’ lifestyle and symptoms. The questions are kept very simple so that a user can complete them in 1-2 minutes. The input module 12 can include a nutrition question module 20, a medication question module 22, and a lifestyle question module 24. Questions presented can be answered on a continuous or nominal scale. Input can also be gathered from various medical devices, such as portable monitoring systems, further described below. Accordingly, cardio, vascular, and neuro information can be input. {\textbar} {\textbar} [000037] With the nutrition question module 20, questions can be presented to the user such as (with available answer choices in brackets): {\textbar} {\textbar} [000038] How many servings of grains did you eat today? [0 to 10] {\textbar} {\textbar} [000039] How many servings of fruit did you eat today? [0 to 5 or more] {\textbar} {\textbar} [000040] How many servings of vegetables did you eat today? [0 to 5 or more] {\textbar} {\textbar} [000041] How many servings of dairy did you eat today? {\textbar} {\textbar} [000042] How much sugar did you have today? [0 to 5 scale, way less than average to way more than average] {\textbar} {\textbar} [000043] With the medication question module 22, the user can input any medication they are taking, including vitamins and supplements, with dosing schedules and amounts. {\textbar} {\textbar} [000044] With the lifestyle question module 24, questions can be presented to the user such as (with available answer choices in brackets): {\textbar} {\textbar} [000045] How many hours of sleep did you get last night? [0 to 12+, on .5 intervals] [000046] Did you work out today? [yes or no] {\textbar} {\textbar} [000047] Did you take time to relax today? [yes or no] {\textbar} {\textbar} [000048] How stressed did you feel today? [0 to 5 scale] {\textbar} {\textbar} [000049] The output variable module 14 can include a symptom question module 26 and a user defined metrics question module 28. {\textbar} {\textbar} [000050] With the symptom question module 26, questions can be presented to the user such as (with available answer choices in brackets): {\textbar} {\textbar} [000051] How much pain were you in today? [0 to 5 scale] {\textbar} {\textbar} [000052] How many bowel movements did you have today? [0 to 10+, or on Bristol scale] {\textbar} {\textbar} [000053] How many times did you pass blood? [0 to 10+] [000054] Did you have a headache today? [yes or no] {\textbar} {\textbar} [000055] The symptom question module 26 can further include questions related to infectious diseases, such as: {\textbar} {\textbar} [000056] Do you have a cough? {\textbar} {\textbar} [000057] [No] {\textbar} {\textbar} [000058] [Yes Is it a dry cough or wet cough? (a wet or productive cough means there is fluid in your airways, a dry cough means there is no fluid in your airways), select from wet cough, dry cough, or not sure] {\textbar} {\textbar} [000059] Do you have shortness of breath? [yes or no] {\textbar} {\textbar} [000060] What is your temperature? [Enter \#] {\textbar} {\textbar} [000061] [Not sure] Do you think you have a fever? [yes or no] {\textbar} {\textbar} [000062] Have you had any digestive issues? (e.g., diarrhea, vomiting, etc.) {\textbar} {\textbar} [000063] [No] {\textbar} {\textbar} [000064] [Yes] {\textbar} {\textbar} [000065] Have you had diarrhea? [yes or no] {\textbar} {\textbar} [000066] Have you felt nauseous? [yes or no] {\textbar} {\textbar} [000067] Have you vomited? [yes or no] {\textbar} {\textbar} [000068] Have you had other abdominal discomfort? [yes or no] {\textbar} {\textbar} [000069] Are you experiencing any of the following? [body aches, chills, fatigue, headache, postnasal drip, runny nose, sinus congestion, skin rash, sneezing, sore throat, swollen glands, watery eyes, loss of smell, loss of taste] {\textbar} {\textbar} [000070] Have you been in contact with anyone with a positive {COVID}-19 diagnosis? [000071] [No] {\textbar} {\textbar} [000072] [Yes] When were you in contact? {\textbar} {\textbar} [000073] Where were you in contact? {\textbar} {\textbar} [000074] On a scale of 1 (not at all anxious) to 10 (extremely anxious), how anxious did you feel today? {\textbar} {\textbar} [000075] Have you limited your daily activities? {\textbar} {\textbar} [000076] [No] {\textbar} {\textbar} [000077] [Yes] Have you self-quarantined? [Yes or No] {\textbar} {\textbar} [000078] With the user defined metrics question module 28, the user can design any other relevant questions and answers that could relate to their disease or condition that can be added to the application 10 to include in an analysis, such as alcohol intake or traveling. [000079] All the data collected from the input module 12 and the output variable module 14 is sent to the analysis module 16. The analysis module 16 can include regressions 30, classifiers 32, neural networks 34, support vector machine 36, miscellaneous Al/machine learning techniques 38, and/or miscellaneous classical statistical techniques 40 in performing the analysis of the data. {\textbar} {\textbar} [000080] In general, the analysis module 16 uses the data to find patterns between how users live and how they feel. By estimating multiple regressions 30 on time lagged variables, the application 10 can find patterns most people cannot casually notice or even calculate if they are keeping careful food diaries. With just one week of data, connections can be identified between how users live and how they feel. {\textbar} {\textbar} [000081] The symptom variables can be used as the dependent variable in a series of regressions 30. The symptom variables include both same day, as entered values and time lagged, such that the first row of data is deleted out to four days later. The nutrition, medication, and lifestyle data measured are used as the independent, or predictor, variables. Linear regressions 30 are then estimated to determine which independent variables cause an increase in the symptoms, or dependent variables. The specific mechanisms are as follows. Users input their symptoms, food intake at a high level, medication intake, and simple lifestyle measures, each on a continuous or nominal (from Likert-type items) scales. The symptom variables include both same day, as entered values, and time lagged, such that the first row of data is deleted out to four days later. The food intake, medication, and lifestyle measured are used as the independent, or predictor, variables. Linear regressions are then estimated to determine which independent variables cause an increase in the symptoms, or dependent variables. Specifically, the symptom variables are then used as the dependent variables in a series of linear, ordinary least regressions. Within the first month of use, three regressions are estimated for each symptom. One regression tests the food variables as the independent variables, one the lifestyle variables, and one the medication variables. Each regression coefficient with alpha {\textless} .2 is flagged to users as a potential factor contributing to their symptoms. After users have inputted a full month of data, one master regression is estimated for each symptom outcome, combining the food, lifestyle, and medication predictor variables, thereby allowing the relative impact across categories to be determined. With the full month of data, the significance level drops to alpha {\textless} .4. This means that the null hypothesis that the relationship between a given factor and the symptom outcome can be rejected with 60 percent certainty. As more data are collected, the threshold for significance will increase as power increases. This will be determined with a series of power analyses. A power analysis looks at the relationship between sample size, in this case the number of days of data collected, significance level, and population effect size, that is the known relationship between factor and outcome, if known. A priori power analyses determine appropriate sample size to achieve adequate power and, in the case of this application, determine the change in significance level needed as the amount of data increases. {\textbar} {\textbar} [000082] Linear regressions 30 test the null hypothesis that the relationship between the independent variable(s) and dependent variable is 0. Unlike traditional data analysis, which requires a 5\% alpha level to claim significance, the threshold for flagging potential lifestyle problems is lower. Specifically, the 5\% standard level translates to a 95\% likelihood that an effect is not due to chance, thereby rejecting the null hypothesis that the relationship is 0. But those who live with chronic illness want to know if there is a good chance, i.e., more than 60\%, that a lifestyle choice, food, is causing symptoms. Further, the system can time lag outcome variables to capture the impact of day-to-day life on symptoms the same day, the next day, and the day after that. These regressions 30 serve as the steps in an algorithm. {\textbar} {\textbar} [000083] While regressions 30 can be preferred, other methods of analysis can be used. Classifiers 32 are a broad use of artificial intelligence and machine learning that determine the relationship between input variables and output variables are categories. In the case of the present invention, it can be classified whether or not a specific user’s data classifies as fitting the profile of effective lifestyle changes to help improve symptoms. {\textbar} {\textbar} [000084] Time series is a system of data points organized by time. Time then becomes one of the key predictors of an outcome, by looking at autocorrelation, seasonality, and stationarity. Time series enable an understanding of how data vary over time and how changes in a given variable over time compare to changes in other variable over time. Medical conditions inherently change over time, with symptoms becoming better or worse but rarely static. Likewise, nutrition, medication, lifestyle, symptoms, pain, and user defined metrics vary over time. Understanding how adverse symptom outputs change over time as well as how they change over time in conjunction with nutrition, medication, lifestyle, symptoms, pain, and user defined metrics is crucial. {\textbar} {\textbar} [000085] Time series may follow several broad patterns: trends occur when there is an overtime increase or decrease in a data series; seasonal patterns occur when data over time are impacted by external changes at a fixed and known frequency, like time of the week, month, year, etc., and cycles occur when changes in data over time correlate with other, non- fixed external changes. In this application, trends may occur as medical prognosis generally improves or deteriorates. Seasonal patterns may be due to environmental factors that map to seasons or lifestyle choices that vary by day of the week. Cycles would capture changes due to weather and other external factors. . Time series analysis will enable the application to account for changes in adverse symptom outcomes over time, as well as changes in adverse symptom outcomes as they relate to related seasonal and cyclical changes in nutrition, medication, lifestyle, symptoms, pain, and user defined metrics. {\textbar} {\textbar} [000086] Neural Networks ({NNs}) 34 are another broad Al/machine learning technique that can be used to detect patterns in data. Previous use cases for neural networks include real time translation, facial recognition, and music composition. Neural networks map inputs to outputs via a series of algorithms designed to loosely model the human brain. Specifically, each input is entered as a vector that makes up the left-side layer of a broader neural network. For this application, the inputs include nutrition, medication, lifestyle, symptoms, pain, and user defined metrics The right-side layer of a neural network is the output. In this application, the output includes all adverse symptom outcomes. Between the input and output layers is a hidden layer, which is a weighted sum of the values in the input layer that projects the outcome layer, thereby determining how the inputs work together to create the outputs. This hidden layer would determine how nutrition, medication, lifestyle, symptoms, pain, and user defined metrics work together to create symptom outputs. {\textbar} {\textbar} [000087] Neural networks follow and iterative process between forward and backward propagation. In forward propagation, the weights in factors of the hidden layers are calculated to determine output layer prediction and error probability of that prediction. Backward propagation runs in the opposite direction, bringing higher error likelihood from the right output layer back into the hidden layers to adjust the weights. This in turn decreases the likelihood of error at the output layer. In this application, the hidden layers determine the weights for the different nutrition, medication, lifestyle, symptoms, pain, and user defined metrics to predict adverse symptom outcomes in the output layer. If the error of that prediction exceeds a certain level, back propagation returns to the hidden layers to adjust the weights and increase the probability that the adverse symptom prediction is accurate. Forward and backward propagation are iterative until the output, or adverse symptom event, is predicted with greater certainty. {\textbar} {\textbar} [000088] Deep neural networks add additional hidden layers that aggregate and recombine data from the previous layer. The current application will use the additional layers of deep neural networks to cluster nutrition, medication, lifestyle, symptoms, pain, and user defined metrics together over time. Thus, clusters of behavior across time will more accurately predict adverse symptom outcomes. Deep learning networks use automatic feature extraction, enabling the machine to identify patterns without the need for human intervention, thereby mitigating bias. For the present invention, neural networks are one of the strategies used to identify trends in the data. {NN} models can be used for analyzing certain symptoms or broadly over the data set. {\textbar} {\textbar} [000089] Support Vector Machines ({SVMs}) 36 can be used as part of the classification technique to identify certain features. {SVMs} are supervised learning models that rely on attempting regressions to evaluate which have the strongest fit with the data set. {\textbar} {\textbar} [000090] {SVM} assumes a binary outcome. In the case of this application: did the adverse symptom occur on a given day or not. {SVM} then makes a non-probabilistic binary linear classifier by plotting points in space. These points represent factors contributing to the likelihood of the outcome, i.e., nutrition, medication, lifestyle, symptoms, pain, and user defined metrics. The bigger the gap between the clusters, the better the predictive power, as the potential binary outcomes sit relatively farther apart. {\textbar} {\textbar} [000091] In most real world examples, however, the gap between one outcome vs. the other is non-existent, with much overlap. This is likely the case with predicting adverse symptoms, as the predicting nutrition, medication, lifestyle, symptoms, pain, and user defined metrics likely bleed together. To account for this, the application will use the Kernel Trick. Kernal functions compute the similarity between inputs according this formula, where x and y are input vectors, f is a transformation function, and {\textless}{\textgreater} refers to the dot product: {\textbar} {\textbar} [000092] If the dot product is small, the functions are different; if it is large, there is more overlap. The Kernal trick then looks for transformations in the boundaries between the x and y by plotting the functions in multi-dimensional space in order to keep a linear classifier. Because we expect overlap in the nutrition, medication, lifestyle, symptoms, pain, and user defined metrics that predict whether or not an adverse symptom will occur, the Kernel trick will enable the combinations of factors to be plotted multi-dimensionally in order to define a natural linear divide between a symptom occurring vs. not occurring. This in turn will define which nutrition, medication, lifestyle, symptoms, pain, and user defined metrics and in which combination contribute to an adverse symptom outcome. {\textbar} [000093] Random forest algorithms are a method for classification and regression that creates a series of decision trees to predict the alignment of a given input to a given tree. Specifically, random forests look at the predictive power of the full system of factors to determine the underlying function, plus noise. Random forest classification starts with a decision tree, wherein an input is entered at the top of the tree and travels down each branch. In the case of this application, the input would be an adverse symptom outcome, with each branch being the range of answers on a given predictive factor or series of predictive factors. Each day of inputted data would be its own tree, with the input being adverse symptom outcome and the branches for each of the predictors tracked. Random forests look at the average across a series of such trees to make a stronger prediction of an adverse outcome. The larger the number of trees, the more accurate the ultimate forest prediction. In this application, each tree is a day of data and the more days collected, the more accurate the predictions. Random forest algorithms identify the most important features. Random forests will therefore enable this application to identify the most salient factors from the tracked nutrition, medication, lifestyle, symptoms, pain, and user defined metrics. Random forests are also particularly adept at handling missing data, as is likely the case with user input daily logs. Random forest can help classify symptom groupings to better predict and manage symptoms. The method can include these steps: 1. Randomly select “K” features from total “m” features where k « m. 2. Among the “K” features, calculate the node “d” using the best split point. 3. Split the node into daughter nodes using the best split. 4. Repeat the a to c steps until T number of nodes has been reached. 5. Build forest by repeating steps a to d for “n” number times to create “n” number of trees [000094] Miscellaneous Classical Statistical Techniques 40 can include looking at distributions of data, means, mean comparisons, deviations, skewness, tracking over time, etc. These techniques are commonly used as a part of feature extraction (to supplement the user- submitted data when running the models). {\textbar} {\textbar} [000095] Nearest neighbor algorithms can also be performed once a large enough group of users are using the application 10. A multi-dimensional nearest neighbor algorithm is used to find those individuals from existing sets, i.e. a K-Nearest Neighbor ({KNN}) algorithm. The {KNN} algorithm is a clustering algorithm and acts as a non-parametric untrained classifier that evaluates the overall similarity between two users based on the degree of differences across multiple features. The flexibility of such an algorithm allows consideration of many parameters when searching for pertinent context data. Weights on certain factors can vary depending on the type of symptom and food/nutrient. These similar user profiles are grouped into subsets to look for trends that can be used to optimize the suggestions for the user. While the {KNN} algorithm can be preferred, other clustering algorithms can also be used, such as, but not limited to, K-Means, Affinity Propagation, Mean Shift, Spectral Clustering, Support Vector Machines. One advantage of {KNN} over other techniques is that it is easily scalable across many dimensions. Further, from case-to-case the differing dimensions and weights are easily included. {\textbar} {\textbar} [000096] The purpose of the {KNN} algorithm is to find users most similar to the present user. Once identified, the “neighboring” user data are used to evaluate the present user. To make the identification, we evaluate the differences in each parameter comprising the user data structure. While most commonly used with continuous values (weight, age, {LDL} level, etc.), the algorithm can be used with discrete values as well (race/ethnicity, familial history, presence of certain symptoms, {DNA} information etc.). The differences across each parameter are combined using a weighting scheme such that a normalized ‘distance’ is produced representing an overall difference metric between two users. The distance calculation between two users is achieved using a regression-type {KNN} algorithm. Key to the regression evaluations is the Mahalanobis distance. The Mahalanobis distance evaluates to a Euclidian distance since the covariance matrix is always the identity matrix, i.e., one parameter in this case is never to be compared independently with another parameter. The benefit of adapting the Mahalanobis distance instead of using pure Euclidian distance is that Mahalanobis distance includes the measurement of the number of deviations away from the norm. While the actual standard deviation is not always ideal, an equivalent term is used. {\textbar} {\textbar} [000097] If the present user Pi has a set of parameters where P {\textbar} {\textbar} 1 {\textbar} = \{m {\textbar} 1R1 {\textbar} , m {\textbar} 2R1 {\textbar} , R {\textbar} · {\textbar} 3 {\textbar} {RI}{\textgreater} {\textbar} ... m {\textbar} {NR}1 {\textbar} \} and an arbitrary user, R {\textbar} b {\textbar} , where R {\textbar} b {\textbar} = \{m {\textbar} 1Rb {\textbar} , m {\textbar} 2Rb {\textbar} , m {\textbar} 3Rb {\textbar} , ... P {\textbar} {NP} {\textbar} P \}, then the distance, D, between the two users is: {\textbar} [000098] Several adaptations are needed to the above generalized equation. Mainly, handling a weighting schema. Most simply, a set of weights, W, should be created with each parameter in P being assigned a weight. Weights can be applied using any technique. Shown below is an intuitive 1-10 linear weighting schema. If W = \{p {\textbar} {\textbar} 1 {\textbar} p {\textbar} 2 {\textbar} ,p {\textbar} 3 {\textbar} , ... p {\textbar} N {\textbar} \}, then the distance, D, can be evaluated by: {\textbar} [000099] In the above examples for D {\textbar} {\textbar} 1 {\textbar} and D {\textbar} 2 {\textbar} continuous values are used for m {\textbar} N {\textbar} . In this application, continuous values can be integers or rational numbers. Discrete values must be handled in a special manner. Since there is no intuitive value for the difference between two ethnicities, one must be manually supplied in a lookup table. Algorithmically, parameters with continuous values should be summated using the squared difference while parameters with continuous values are summated manually. The same W = \{p {\textbar} lt {\textbar} p {\textbar} 2 {\textbar} ,p {\textbar} 3 {\textbar} , ... p {\textbar} N {\textbar} \} weighting schema applies to discrete parameters as well. {\textbar} [0000100] The threshold for evaluating whether or not another user is sufficiently similar to the present user is situational. The ideal number of similar subjects is to be optimized on a case-to-case basis when there exists sufficient training data. {\textbar} {\textbar} [0000101] {KNN} algorithms have been used before. For example, U.S. Patent No. 10,123,748 ({IBM}) discloses a Patient Risk Analysis method that uses {KNN} to find similar patients. U.S. Patent No. 7,730,063 discloses a personalized medicine method that also mentions {KNN} as a potential algorithm for finding similar patients. The present invention’s ability to include continuous and discrete parameters as well as customized weights in the {KNN} differentiates over these prior art methods. [0000102] After the analysis, strongest trends 42, key performance indicators ({KPIs}) 44, and tracking over time 46 are sent to the output module 18 and displayed to the user. For example, predictor variables that meet a 60\% or greater threshold are output to users with the output module 18 and flagged as potential causes of their symptoms or {KPIs} 44. Users are then encouraged to keep tracking to increase the predictive power. Predictor variables meeting a more stringent 90\% threshold are flagged as likely causes, or strongest trends 42. Users are then encouraged to talk to their doctors to determine how they can improve their symptoms. Alternatively, the application 10 can be in communication with external databases and/or doctors/healthcare professionals that can suggests nutrition, medication, or lifestyle changes for the user to perform to improve their symptoms and to prevent triggers that have been identified. Users can review statistics of the outputs by week, month, or year with tracking over time 46. {\textbar} {\textbar} [0000103] The application 10 can also include any suitable alarms or notifications that can remind users to input data into the input module 12 or output variable module 14 at certain times of the day or daily. Such notifications can be pushed to the user’s mobile devices such as a smart phone, smart watch, tablet, or desktop or laptop computer. {\textbar} {\textbar} [0000104] {FIGURE} 2 shows a macro-level systems diagram. The User Client Side 42 includes the interactions the software has directly with the user. This includes interactions from native applications ({iOS}, Android), or web applications (accessed in a browser) and can include account management 44 (sign up, login, password management), serve prompts to user 46, and show output/results 48. The Admin Client Side 50 includes interactions “Admin” level users have access to, such as user management 52, analytics/hypothesis testing 54, and prompt management 56. The Server Side 58 outlines the major functions performed by the server. Application programming interface ({API}) for databases 60 can be performed. Integrations can be managed 62 including data from other health/nutrition trackers, fitness trackers, wearable devices, etc. Perform Analysis 64 refers to the breakdown represented in {FIGURE} 1. Databases of users 66, prompts 68, and responses 70 can all be in electronic communication with the Server Side 58. {\textbar} {\textbar} [0000105] The present invention also provides for a method of tracking disease and mental health symptom triggers, by a user inputting data about nutrition, medication, lifestyle, symptoms, and user defined metrics in an application, performing an analysis on the data, and outputting a result from the data identifying daily activities that effect the user’s disease/mental health and trigger symptoms, including strongest trends, key performance indicators, and tracking over time. This method can be performed with the application 10 as described above. [0000106] As mentioned above, the application 10 can integrate and analyze data (at 62) from outside devices 80 that measure physiological properties of the user and are preferably wearable medical devices. These outside devices 80 can include, but are not limited to, general fitness trackers ({FitBits}®, Apple® Watch), heartbeat trackers, heart rate trackers, skin temperature trackers, respiratory rate trackers, body posture trackers, eyesight trackers, blood oxygen trackers, glucose level trackers, sleep trackers, body temperature trackers, and skin conductance trackers. Any other suitable physiological data can also be collected. The outside devices 80 can be separate devices or a combination in a single device. Preferably, the outside devices 80 generally provide electrophysiological monitoring. Normally, one would go to a physician after a medical event (such as pain), their physiological conditions would be checked, and a wearable medical device would provide data to see what built up to the medical event to suggest activities not to do to avoid the medical event in the future. Using the application 10 with data from the outside devices 80 allows a user to discover triggers to their disease/mental health that do not necessarily correlate to a medical event that would not be found with just a physician examination and wearable device data alone. {\textbar} {\textbar} [0000107] Therefore, the present invention provides for a method of tracking disease and mental health symptom triggers, by a user inputting data about nutrition, medication, lifestyle, symptoms, and user defined metrics in an application, integrating a user’s data from outside devices, performing an analysis on the data, and outputting a result from the data identifying daily activities that effect the user’s disease/mental health and trigger symptoms, including strongest trends, key performance indicators, and tracking over time. {\textbar} {\textbar} [0000108] The application 10 can also integrate and analyze data from outside databases 90, especially having clinical trial data, such as clinics, electronic medical records ({EMRs}), pharmaceutical companies, private databases, or {CROs}, further described in U.S. Provisional Patent Application No. 62/878,066. Nearest neighbors can be identified as described above and related study or trial data can be identified in the outside databases 90 to be analyzed. By analyzing additional outside data from the outside databases 90, the application can find others who have similar data as the user and predict an adverse event or triggers to an adverse event. Further, the application 10 can integrate with weather monitoring systems. This is particularly relevant for migraines, as 75\% of migraine sufferers report a correlation between weather and headaches (National Headache Foundation). Specifically, changes in humidity, temperature, and barometric pressure, as well as thunderstorms, and dry and dusty environments contribute to migraines. The application 10 can use these external weather data as a potential factor in predicting users’ migraine incidents. {\textbar} {\textbar} [0000109] Therefore, the present invention provides for a method of tracking disease and mental health symptom triggers, by a user inputting data about nutrition, medication, lifestyle, symptoms, and user defined metrics in an application, integrating data from outside databases, performing an analysis on the data, and outputting a result from the data identifying daily activities that effect the user’s disease/mental health and trigger symptoms, including strongest trends, key performance indicators, and tracking over time. {\textbar} {\textbar} [0000110] The application 10 can further combine the analysis of data from outside devices 80 with analysis of outside databases 90 in order to predict adverse events in a user. This allows for a user to know about the likelihood of an adverse event occurring at a later time point so that they can seek appropriate treatment (such as generally having surgery, having a heart bypass or cholesterol removed from arteries, or generally taking medicine) before the adverse event actually happens. {\textbar} {\textbar} [0000111] Therefore, the present invention provides for a method of preventing adverse events, by a user inputting data about nutrition, medication, lifestyle, symptoms, and user defined metrics as well as external data as described above in an application, integrating data from outside devices and outside databases, performing an analysis on the data, and outputting a result from the data identifying that an adverse event is likely to occur at a later time point. The method can further include the step of recommending that the user seek treatment for a condition that can cause the adverse event. {\textbar} {\textbar} [0000112] Throughout this application, various publications, including United States patents, are referenced by author and year and patents by number. Full citations for the publications are listed below. The disclosures of these publications and patents in their entireties are hereby incorporated by reference into this application in order to more fully describe the state of the art to which this invention pertains. {\textbar} {\textbar} [0000113] The invention has been described in an illustrative manner, and it is to be understood that the terminology, which has been used is intended to be in the nature of words of description rather than of limitation. {\textbar} {\textbar} [0000114] Obviously, many modifications and variations of the present invention are possible in light of the above teachings. It is, therefore, to be understood that within the scope of the appended claims, the invention can be practiced otherwise than as specifically described.
Issue: {WO}2021034677A1},
}

@patent{li_etal19p,
	location = {{CN}},
	title = {Based on the brain stimulation system, method, device and storing medium of artificial intelligence},
	url = {https://www.derwentinnovation.com/tip-innovation/recordView.do?hideHighlightPanel=true&idType=uid/recordid&datasource=T3&databaseIds=PATENT&category=PAT&recordKeys=CN110522983A_20191203&TYPE=RECORDVIEW&fromExternalLink=true&fromLocation=external&isDAJImageAllowed=false},
	abstract = {The embodiment of the invention claims a data transmission method based on artificial intelligence of the brain stimulation system, method, apparatus and storage medium. The system comprises: a plurality of brain stimulation terminal and cloud platform, cloud platform for using artificial intelligent technology by learning from physiological data and mental status evaluation parameter of a plurality of brain stimulation terminal, combining the preset diagnosis and treatment of all kinds of diseases model generating multi-dimensional psychological big data, brain stimulation terminal based on multi-dimensional psychological big data using artificial intelligence techniques to the collected physiological data and mental status evaluation parameter of the target object for analysis, determining the mental state of the target object. The mental state to obtain brain stimulation parameter needed for the target object, and generate a corresponding non-invasive stimulation to the target object according to the brain stimulation parameters. The embodiment of the invention is suitable for common people to maintain mental health and adjusting the bad mood, at least early prediction to some serious mental disease, effect of professional prevention and interference in time. {\textbar}   {\textbar} 本发明实施例公开了一种基于人工智能的脑刺激系统、方法、设备和存储介质。该系统包括：多个脑刺激终端和云平台；云平台用于采用人工智能技术通过学习来自多个脑刺激终端的生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成多维度的心理大数据；脑刺激终端用于基于多维度的心理大数据采用人工智能技术对采集得到的目标对象的生理数据和心理状态评估参数进行分析，确定目标对象的精神状态，根据精神状态得到针对目标对象所需的脑刺激参数，并根据脑刺激参数对目标对象产生相应的无创伤性脑刺激。本发明实施例适用于普通人们维护精神健康和调节不良情绪，对一些严重的精神疾病至少具有提早预测、专业预防和及时干涉的作用。
本发明实施例公开了一种基于人工智能的脑刺激系统、方法、设备和存储介质。该系统包括：多个脑刺激终端和云平台；云平台用于采用人工智能技术通过学习来自多个脑刺激终端的生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成多维度的心理大数据；脑刺激终端用于基于多维度的心理大数据采用人工智能技术对采集得到的目标对象的生理数据和心理状态评估参数进行分析，确定目标对象的精神状态，根据精神状态得到针对目标对象所需的脑刺激参数，并根据脑刺激参数对目标对象产生相应的无创伤性脑刺激。本发明实施例适用于普通人们维护精神健康和调节不良情绪，对一些严重的精神疾病至少具有提早预测、专业预防和及时干涉的作用。
The embodiment of the invention claims a data transmission method based on artificial intelligence of the brain stimulation system, method, apparatus and storage medium. The system comprises: a plurality of brain stimulation terminal and cloud platform, cloud platform for using artificial intelligent technology by learning from physiological data and mental status evaluation parameter of a plurality of brain stimulation terminal, combining the preset diagnosis and treatment of all kinds of diseases model generating multi-dimensional psychological big data, brain stimulation terminal based on multi-dimensional psychological big data using artificial intelligence techniques to the collected physiological data and mental status evaluation parameter of the target object for analysis, determining the mental state of the target object. The mental state to obtain brain stimulation parameter needed for the target object, and generate a corresponding non-invasive stimulation to the target object according to the brain stimulation parameters. The embodiment of the invention is suitable for common people to maintain mental health and adjusting the bad mood, at least early prediction to some serious mental disease, effect of professional prevention and interference in time.},
	type = {patent},
	number = {{CN}110522983A},
	author = {Li, Xiao-tao and Li, Juan and Yang, Hai-yang and Wang, Li-ping},
	urldate = {2018-05-23},
	date = {2019-12-03},
	note = {Edition: A61M002102 {\textbar} A61B000500 {\textbar} A61B00050205 {\textbar} A61B000504 {\textbar} A61B00050476 {\textbar} A61B000516 {CPC}  - A61M002100 {\textbar} A61B00050077 {\textbar} A61B00050205 {\textbar} A61B0005021 {\textbar} A61B0005024 {\textbar} A61B00050816 {\textbar} A61B0005165 {\textbar} A61B000524 {\textbar} A61M002102 {\textbar} A61N000700 {\textbar} G16H002070 {\textbar} G16H005020 {\textbar} G16H005070 {\textbar} A61B000502416 {\textbar} A61B00050533 {\textbar} A61B0005369 {\textbar} A61B00057264 {\textbar} A61M20210016 {\textbar} A61M20210022 {\textbar} A61M20210027 {\textbar} A61M20210044 {\textbar} A61M20210055 {\textbar} A61M2205058 {\textbar} A61M220518 {\textbar} A61M22053303 {\textbar} A61M22053327 {\textbar} A61M22053375 {\textbar} A61M22053553 {\textbar} A61M22053569 {\textbar} A61M22053584 {\textbar} A61M22053592 {\textbar} A61M2205505 {\textbar} A61M22058206 {\textbar} A61M22100693 {\textbar} A61M223006 {\textbar} A61M223010 {\textbar} A61M223030 {\textbar} A61M223042 {\textbar} A61M223065 {\textbar} A61N00050618 {\textbar} A61N20070026 {CN}; {EP}; {US} {CN}; {EP}; {US} {CN} {US} A61M 2230/005, A61M 2230/65 {\textbar} A61M 2230/005, A61M 2230/30 {\textbar} A61M 2230/005, A61M 2230/06 {\textbar} A61M 2230/005, A61M 2230/42 {\textbar} A61M 2230/005, A61M 2230/10 1.一种基于人工智能的脑刺激系统，其特征在于，包括：多个脑刺激终端和云平台，所述多个脑刺激终端分别与所述云平台通信连接； {\textbar} 所述云平台用于采用人工智能技术通过学习来自多个所述脑刺激终端的生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成多维度的心理大数据； {\textbar}   {\textbar} 所述脑刺激终端用于基于所述多维度的心理大数据采用人工智能技术对采集得到的目标对象的生理数据和心理状态评估参数进行分析，确定所述目标对象的精神状态，根据所述精神状态得到针对所述目标对象所需的脑刺激参数，并根据所述脑刺激参数对所述目标对象产生相应的无创伤性脑刺激。 {\textbar}   {\textbar} 2.根据权利要求1所述的系统，其特征在于，所述脑刺激终端包括生理信息采集装置、心理交流互动装置、中央控制处理装置和物理输出装置； {\textbar} 所述生理信息采集装置用于采集所述目标对象的生理数据； {\textbar}   {\textbar} 所述心理交流互动装置用于采用基于自然语言处理技术与所述目标对象进行人机互动，获取所述目标对象的心理状态评估参数； {\textbar}   {\textbar} 所述中央控制处理装置用于控制所述生理信息采集装置、所述心理交流互动装置和所述物理输出装置，基于所述多维度的心理大数据采用人工智能技术对所述生理数据和所述心理状态评估参数进行分析，确定所述目标对象的精神状态，并根据所述精神状态得到对所述目标对象的脑刺激参数； {\textbar}   {\textbar} 所述物理输出装置用于根据所述脑刺激参数运行，以对所述目标对象产生脑刺激。 {\textbar}   {\textbar} 3.根据权利要求1或2所述的系统，其特征在于，所述云平台还用于采用人工智能技术对所述多维度的心理大数据进行循环计算，优化所述多维度的心理大数据。 {\textbar} 4.根据权利要求1或2所述的系统，其特征在于，所述脑刺激终端还用于根据所述精神状态预测所述目标对象出现精神疾病的可能性，并作出相应的预警提示和/或干涉调节。 {\textbar} 5.根据权利要求1或2所述的系统，其特征在于，所述脑刺激终端还用于全面记录所述目标对象的脑刺激参数，采用人工智能技术整合所述目标对象的脑刺激参数得到针对所述目标对象的脑刺激规律，并根据所述脑刺激规律对所述目标对象产生具有个体针对作用的脑刺激。 {\textbar} 6.根据权利要求2所述的系统，其特征在于，所述生理信息采集装置具体用于通过传感器采集所述生理数据，所述传感器包括皮肤电采集装置、脑电波采集装置和光电容积描记装置。 {\textbar} 7.根据权利要求6所述的系统，其特征在于，所述生理信息采集装置还用于通过摄像头采集所述目标对象的面部表情，通过麦克风采集所述目标对象的声音； {\textbar} 所述中央控制处理装置还用于采用人工智能技术对所述目标对象的面部表情和声音进行分析，确定所述目标对象的精神状态。 {\textbar}   {\textbar} 8.根据权利要求2所述的系统，其特征在于，所述物理输出装置包括以下任一种或多种：光源装置、音响装置、按摩装置、熏香装置、超声波装置和电磁波装置。 {\textbar} 9.根据权利要求8所述的系统，其特征在于，所述光源装置、所述音响装置和所述按摩装置用于对所述目标对象进行相应刺激程序所产生的感官性物理刺激。 {\textbar} 10.根据权利要求8所述的系统，其特征在于，所述熏香装置用于依靠空气传播化学气体分子进入所述目标对象的嗅觉器官，达到嗅觉给药干涉或治疗的效果。 {\textbar} 11.根据权利要求8所述的系统，其特征在于，所述超声波装置和所述电磁波装置用于对所述目标对象进行专业的脑刺激，达到特异脑区干涉治疗的效果。 {\textbar} 12.根据权利要求2所述的系统，其特征在于，所述心理交流互动装置还用于通过与所述目标对象进行人机互动对所述目标对象进行认知行为治疗，所述人机互动包括文字交流、语音对话、游戏互动、图片播放和/或视频播放。 {\textbar} 13.根据权利要求1-12中任一项所述的系统，其特征在于，所述脑刺激终端还包括：电源装置，所述电源装置用于为所述脑刺激终端供电；所述电源装置包括以下任一种或多种：一次电池、二次电池、射频供电电池和生物燃料电池装置。 {\textbar} 14.根据权利要求1-12中任一项所述的系统，其特征在于，所述生理数据包括心率、呼吸频率、血压、皮肤电和脑电波，所述心理状态评估参数包括压力指数和注意力值。 {\textbar} 15.一种基于人工智能的脑刺激方法，其特征在于，包括： {\textbar} 采集目标对象的生理数据，并采用基于自然语言处理技术与所述目标对象进行人机互动，获取所述目标对象的心理状态评估参数； {\textbar}   {\textbar} 基于多维度的心理大数据采用人工智能技术对所述生理数据和所述心理状态评估参数进行分析，确定所述目标对象的精神状态，并根据所述精神状态得到针对所述目标对象所需的脑刺激参数； {\textbar}   {\textbar} 根据所述脑刺激参数对所述目标对象产生相应的无创伤性脑刺激。 {\textbar}   {\textbar} 16.根据权利要求15所述的方法，其特征在于，还包括： {\textbar} 采用人工智能技术通过学习多个生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成所述多维度的心理大数据。 {\textbar}   {\textbar} 17.根据权利要求16所述的方法，其特征在于，还包括： {\textbar} 采用人工智能技术对所述多维度的心理大数据进行循环计算，优化所述多维度的心理大数据。 {\textbar}   {\textbar} 18.根据权利要求15所述的方法，其特征在于，还包括： {\textbar} 根据所述精神状态预测所述目标对象出现精神疾病的可能性，并发出相应的预警提示和/或干涉调节。 {\textbar}   {\textbar} 19.根据权利要求15所述的方法，其特征在于，还包括： {\textbar} 全面记录所述目标对象的脑刺激参数，采用人工智能技术整合所述目标对象的脑刺激参数得到针对所述目标对象的脑刺激规律，并根据所述脑刺激规律对所述目标对象产生更具个体针对作用的脑刺激。 {\textbar}   {\textbar} 20.根据权利要求15所述的方法，其特征在于，还包括： {\textbar} 通过摄像头采集所述目标对象的面部表情，通过麦克风采集所述目标对象的声音，采用人工智能技术对所述目标对象的面部表情和声音进行分析，确定所述目标对象的精神状态。 {\textbar}   {\textbar} 21.一种设备，包括存储器、处理器及存储在存储器上并可在处理器上运行的程序，其特征在于，所述处理器执行所述程序时实现如权利要求15-20中任一所述的基于人工智能的脑刺激方法。 {\textbar} 22.根据权利要求21所述的设备，其特征在于，所述设备包括以下任一种：智能手机、电脑、智能宠物和智能医学仪器。 {\textbar} 23.一种包含可执行指令的存储介质，其特征在于，所述可执行指令在由处理器执行时用于执行如权利要求15-20中任一所述的基于人工智能的脑刺激方法。 1. A brain stimulation system based on artificial intelligence, wherein it comprises: a plurality of brain stimulation terminal and the cloud platform, the plurality of brain stimulation terminal are respectively connected with the cloud platform communication; the cloud platform for psychological big data using artificial intelligence technology through learning from a plurality of physiological data and mental status evaluation parameter of the brain stimulation terminal, combined with diagnosis and treatment model to generate multi-dimensional preset all kinds of diseases of, the brain stimulation terminal based on the psychology of the multidimensional big data using artificial intelligence techniques to the collected physiological data and mental status evaluation parameter of the target object for analysis, determining the mental state of the target object according to the mental state for the target object to the desired brain stimulation parameter, and generating the corresponding non-traumatic brain stimulation to the target object according to the brain stimulation parameters. {\textbar} 2. The system according to claim 1, wherein the brain stimulation terminal comprises a physiological information collecting device, a psychological communication and interaction device, a central control processing device and a physical output device; the physiological information collecting device is used for collecting the physiological data of the target object, the psychological interaction device used for evaluating psychological state parameter is based on natural language processing techniques for human-computer interaction with the target object, obtaining the target object; the central control processing device is used for controlling said physiological information collecting device; the psychological communication and interaction device and the physical output device based on the psychology of the multidimensional big data using artificial intelligence technology to the physiological data and the psychological state assessment parameters for analysis, determining the mental state of the target object, and according to the mental state to obtain the brain stimulation parameter of the target object, the physical output device for brain stimulation according to the parameter operation so as to produce brain stimulation to the target object. {\textbar} 3. The system according to claim 1 or 2, wherein the cloud platform is further used for using the artificial intelligence technology to mind of the multidimensional big data performing circular calculation, optimizing the psychology of the multidimensional big data. {\textbar} 4. The system according to claim 1 or 2, wherein the brain stimulation terminal is further used for according to the mental state predicting the target object possibility of mental illness, and making the corresponding warning prompt and/or interference adjustment. {\textbar} 5. The system according to claim 1 or 2, wherein the brain stimulation terminal further for completely recording the brain stimulation parameter of the target object, using artificial intelligence technology integrated brain stimulation parameter of the target object to obtain a brain stimulation rule for the target object, and generate brain stimulation with individual against action of said target object according to said brain stimulation law. {\textbar} 6. The system according to claim 2, wherein said physiological information collecting device is specifically used for collecting the physiological data by the sensor, the sensor comprises a skin electric collecting device, a brain wave collecting device and a photoplethysmographic device. {\textbar} 7. The system according to claim 6, wherein said physiological information collecting device is further used for facial expression collecting the target object through a camera, through the microphone collecting sound of the target object, the central control processing unit is further used for using artificial intelligence technology facial expression and voice of the target object for analysis, determining the mental state of the target object. {\textbar} 8. The system according to claim 2, wherein, the physical output device comprises any one or more of the following: a light source device, a sound device, a massage device, incense device, ultrasonic device and an electromagnetic device. {\textbar} 9. The system according to claim 8, wherein the sensory physical stimulating the light source device, the sound device and the massage device is used for corresponding to said target object generated by the stimulation program. {\textbar} 10. The system according to claim 8, wherein, said incense device effect for olfactory organ by airborne chemical gas molecules into the target object to reach the olfactory administration intervention or treatment. {\textbar} 11. The system according to claim 8, wherein the effects of the ultrasonic device and the electromagnetic wave device for brain stimulation, of the target object to professional reaches a specific brain region interference treatment. {\textbar} 12. The system according to claim 2, wherein the psychological communication and interaction device is further used for cognitive behavioural therapy to the target object by man-machine interaction, with the target object for human-computer interaction comprises character communication, voice dialogue, game playing interactive, picture and/or video playing. {\textbar} 13. The system according to claim any one of claims 1-12, wherein the brain stimulation terminal further comprises: a power supply device; the power supply device for supplying power to the brain stimulation terminal; the power supply device comprises any one or more of the following: a primary battery, secondary battery, radio frequency power supply battery and bio-fuel cell device. {\textbar} 14. The process according to any one of claims 1-12, the characteristic of the said is wherein the physiological data comprises a heart rate, respiratory rate, blood pressure, skin and brain wave, the psychological state estimating parameter includes pressure index and the attention value. {\textbar} 15. A brain stimulation method based on artificial intelligence, wherein it comprises psychological state estimating parameter collecting physiological data of the target object, and based on the natural language processing technology for man-machine interaction with the target object, obtaining the target object; based on multi-dimensional psychological big data using artificial intelligence technology to the physiological data and the psychological state assessment parameters for analysis, determining the mental state of the target object, and according to the mental state for the target object needed for brain stimulation parameter; The brain stimulation parameters of the target object to generate the corresponding non-traumatic brain stimulation. {\textbar} 16. The method according to claim 15, wherein it further comprises: using artificial intelligence technology by learning a plurality of physiological data and mental status evaluation parameter, combining the diagnostic therapeutic model of various psychological disease pre-generating the dimensional big data. {\textbar} 17. The method according to claim 16, wherein it further comprises: using the artificial intelligence technology to mind of the multidimensional big data performing circular calculation, optimizing the psychology of the multidimensional big data. {\textbar} 18. The method according to claim 15, wherein, further comprising: according to the mental state predicting the likelihood that the target object appears mental disease and send out corresponding warning prompt and/or interference adjustment. {\textbar} 19. The method according to claim 15, wherein, further comprising: generally record the brain stimulation parameter of the target object, using artificial intelligence technology integrated brain stimulation parameter of the target object to obtain a brain stimulation rule for the target object, and generating the more individual brain stimulation for effect to said target object according to said brain stimulation rule. {\textbar} 20. The method according to claim 15, wherein it further comprises a facial expression collecting the target object through a camera, through the microphone collecting sound of the target object, using artificial intelligence technology facial expression and voice of the target object for analysis, determining the mental state of the target object. {\textbar} 21. A device, comprising a memory, a processor and a memory on the memory and program capable of running on a processor, wherein the processor executes the program implementing the method according to any one of claims 15-20, brain stimulation method based on artificial intelligence. {\textbar} 22. The device according to claim 21, wherein the device comprises any one of the following: an intelligent mobile phone, computer, intelligent pet and intelligent medical instrument. {\textbar} 23. A storage medium comprising executable instructions, wherein the executable instructions, when executed by a processor, for performing the method according to any one of claims 15-20 brain stimulation method based on artificial intelligence. 1.一种基于人工智能的脑刺激系统，其特征在于，包括：多个脑刺激终端和云平台，所述多个脑刺激终端分别与所述云平台通信连接； {\textbar} 所述云平台用于采用人工智能技术通过学习来自多个所述脑刺激终端的生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成多维度的心理大数据； {\textbar}   {\textbar} 所述脑刺激终端用于基于所述多维度的心理大数据采用人工智能技术对采集得到的目标对象的生理数据和心理状态评估参数进行分析，确定所述目标对象的精神状态，根据所述精神状态得到针对所述目标对象所需的脑刺激参数，并根据所述脑刺激参数对所述目标对象产生相应的无创伤性脑刺激。 1. A brain stimulation system based on artificial intelligence, wherein it comprises: a plurality of brain stimulation terminal and the cloud platform, the plurality of brain stimulation terminal are respectively connected with the cloud platform communication; the cloud platform for psychological big data using artificial intelligence technology through learning from a plurality of physiological data and mental status evaluation parameter of the brain stimulation terminal, combined with diagnosis and treatment model to generate multi-dimensional preset all kinds of diseases of, the brain stimulation terminal based on the psychology of the multidimensional big data using artificial intelligence techniques to the collected physiological data and mental status evaluation parameter of the target object for analysis, determining the mental state of the target object according to the mental state for the target object to the desired brain stimulation parameter, and generating the corresponding non-traumatic brain stimulation to the target object according to the brain stimulation parameters. 基于人工智能的脑刺激系统、方法、设备和存储介质 {\textbar}   {\textbar} 技术领域 {\textbar}   {\textbar} 本发明实施例涉及医疗器械和智能产品技术，尤其涉及一种基于人工智能的脑刺激系统、方法、设备和存储介质。 {\textbar}   {\textbar} 背景技术 {\textbar}   {\textbar} 心理学研究表明，大多数人在人生不同阶段都会碰到不同程度的心理障碍或精神疾病问题。尤其在现代信息爆炸时代中，人们面临着来自工作和生活的种种压力，经常会感到紧张、焦虑和抑郁。很多人处于身心疲惫的亚健康状态，并导致危及精神健康的因素增加。近年来，社会上罹患抑郁症、自闭症、精神分裂症等严重精神疾病的机率在呈增加趋势。另外，随着全球人口的老龄化趋势，神经退行性疾病包括阿兹海默症和帕金森症也呈患者增多的趋势。这些跟神经系统相关的各种脑疾病，除了给病人带来巨大痛苦外，也给家庭和社会带来日益沉重的负担。 {\textbar}   {\textbar} 目前针对这些脑疾病，基本上缺少非常有效的治疗手段。传统上一般采用药物治疗的方法，然而，基于药物化学和基因遗传学的药物研究目前并没有取得明显的突破，难以找到真正有效且长期安全的药物，而且这方面研发成本巨大。对一些重大的神经系统疾病还采用外科手术治疗，但囿于对大脑及神经系统复杂性的有限认知，外科手术往往稍有不慎就造成不可预知的后果。近年来，随着健康大数据和人工智能技术的发展，人类的健康医疗问题有可能从一个全新的工程角度切入并找到更佳的解决方案。目前在治疗帕金森病、抑郁症、卒中等脑疾病方面，采用微创型脑刺激技术，比较成熟的具体包括经颅直接电刺激(transcranial direct current stimulation，简称：{tDCS})、深脑电刺激(Deep brainstimulation，简称：{DBS})和重复经颅磁刺激(repetitive transcranial magneticstimulation，简称：{rTMS})等。另外，在医疗健康领域应用人工智能这一方面，目前大多是利用人工智能进行医疗诊断，例如Avalon {AI公司通过人工智能检测脑部核磁共振图像}，预测在未来患老年痴呆症的几率；{Cognoa设计出一套AI软件}，可用于儿童自闭症的早期筛查；以及刚刚在2018年2{月份通过美国FDA认证的Embrace手环}，应用于提早诊断癫痫的发作。 {\textbar}   {\textbar} 但是，上述技术产品均存在缺点，限制了它们更好地使用。在微创型脑刺激技术方面，{tDCS由于电场存在扩散效应}，使其在脑区的时空分辨率有限；{DBS虽有一些不错的疗效}，但也有不足，例如其具有一定的不可预知性，甚至会产生副作用，因为该刺激缺乏选择性和特异性，并且在许多情况下对治疗机理还不明确；光遗传学刺激虽然在动物实验上证明具有神经元特异性和选择性的明显优势，但其刺激装置长期植入脑部，会跟{DBS一样引起免疫排斥及炎症反应}，并使刺激效果逐渐减弱；{rTMS则是由于磁场强度随着距离的增加很快衰减}，因此诱发的电流基本上只能作用在大脑皮层上；超声刺激技术虽然几乎无创而且理论上可以深入到深脑区，但该技术刺激脑部核团的准确度和强度还有待进一步提高[Landhuis E,Nature 2017]。另一方面，人工智能技术在医疗健康领域的推广应用基本还处于不够成熟的发展中阶段，例如，Embrace手环虽然可以通过皮肤接触随时监测人体生理数据，并及时预报癫痫病人的病情发作，但是目前这类产品只是提供医学诊断的帮助，并没有进一步的干涉或治疗措施；以Woebot聊天机器人为典型代表的通过人机社交的方式来治疗心理疾病，虽然得到很多网友的支持，但是这种比较单一的认知行为疗法对于比较严重的心理和精神疾病的效果则比较一般；以英国{Hertfordshire大学研发的社交机器人KASPAR为代表的社交机器人对自闭症儿童的康复训练治疗有一定的效果}，但是目前的产品在智能设计和功能开发上还比较简单，需要进一步结合前沿的人工智能技术提高其康复治疗的效果。 {\textbar}   {\textbar} 发明内容 {\textbar}   {\textbar} 本发明实施例提供一种基于人工智能的脑刺激系统、方法、设备和存储介质，以适用于普通人们维护精神健康和调节不良情绪，对一些严重的精神疾病至少具有提早预测、专业预防和及时干涉的作用。 {\textbar}   {\textbar} 第一方面，本发明实施例提供了一种基于人工智能的脑刺激系统，包括：多个脑刺激终端和云平台，所述多个脑刺激终端分别与所述云平台通信连接； {\textbar}   {\textbar} 所述云平台用于采用人工智能技术通过学习来自多个所述脑刺激终端的生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成多维度的心理大数据； {\textbar}   {\textbar} 所述脑刺激终端用于基于所述多维度的心理大数据采用人工智能技术对采集得到的目标对象的生理数据和心理状态评估参数进行分析，确定所述目标对象的精神状态，根据所述精神状态得到针对所述目标对象所需的脑刺激参数，并根据所述脑刺激参数对所述目标对象产生相应的无创伤性脑刺激。 {\textbar}   {\textbar} 可选的，所述脑刺激终端包括生理信息采集装置、心理交流互动装置、中央控制处理装置和物理输出装置； {\textbar}   {\textbar} 所述生理信息采集装置用于采集所述目标对象的生理数据； {\textbar}   {\textbar} 所述心理交流互动装置用于采用基于自然语言处理技术与所述目标对象进行人机互动，获取所述目标对象的心理状态评估参数； {\textbar}   {\textbar} 所述中央控制处理装置用于控制所述生理信息采集装置、所述心理交流互动装置和所述物理输出装置，基于所述多维度的心理大数据采用人工智能技术对所述生理数据和所述心理状态评估参数进行分析，确定所述目标对象的精神状态，并根据所述精神状态得到对所述目标对象的脑刺激参数； {\textbar}   {\textbar} 所述物理输出装置用于根据所述脑刺激参数运行，以对所述目标对象产生脑刺激调节。 {\textbar}   {\textbar} 可选的，所述云平台还用于采用人工智能技术对所述多维度的心理大数据进行循环计算，优化所述多维度的心理大数据。 {\textbar}   {\textbar} 可选的，所述脑刺激终端还用于根据所述精神状态预测所述目标对象出现精神疾病的可能性，并作出相应的预警提示和/或干涉调节。 {\textbar}   {\textbar} 可选的，所述脑刺激终端还用于全面记录所述目标对象的脑刺激参数，采用人工智能技术整合所述目标对象的脑刺激参数得到针对所述目标对象的脑刺激规律，并根据所述脑刺激规律对所述目标对象产生更有个体针对作用的脑刺激。 {\textbar}   {\textbar} 可选的，所述生理信息采集装置具体用于通过传感器采集所述生理数据，所述传感器包括皮肤电采集装置、脑电波采集装置和光电容积描记装置。 {\textbar}   {\textbar} 可选的，所述生理信息采集装置还用于通过摄像头采集所述目标对象的面部表情，通过麦克风采集所述目标对象的声音； {\textbar}   {\textbar} 所述中央控制处理装置还用于采用人工智能技术对所述目标对象的面部表情和声音进行分析，确定所述目标对象的精神状态。 {\textbar}   {\textbar} 可选的，所述物理输出装置包括以下任一种或多种：光源装置、音响装置、按摩装置、熏香装置、超声波装置和电磁波装置。 {\textbar}   {\textbar} 可选的，所述光源装置、所述音响装置和所述按摩装置用于对所述目标对象进行相应刺激程序所产生的感官性物理刺激。 {\textbar}   {\textbar} 可选的，所述熏香装置用于依靠空气传播化学气体分子进入所述目标对象的嗅觉器官，达到嗅觉给药干涉或治疗的效果。 {\textbar}   {\textbar} 可选的，所述超声波装置和所述电磁波装置用于对所述目标对象进行专业的脑刺激，达到特异脑区干涉治疗的效果。 {\textbar}   {\textbar} 可选的，所述心理交流互动装置还用于通过与所述目标对象进行人机互动对所述目标对象进行认知行为治疗，所述人机互动包括文字交流、语音对话、游戏互动、图片播放和/或视频播放。 {\textbar}   {\textbar} 可选的，所述脑刺激终端还包括：电源装置，所述电源装置用于为所述脑刺激终端供电；所述电源装置包括以下任一种或多种：一次电池、二次电池、射频供电电池和生物燃料电池装置。 {\textbar}   {\textbar} 可选的，所述生理数据包括心率、呼吸频率、血压、皮肤电和脑电波，所述心理状态评估参数包括压力指数和注意力值。 {\textbar}   {\textbar} 第二方面，本发明实施例提供了一种基于人工智能的脑刺激方法，包括： {\textbar}   {\textbar} 采集目标对象的生理数据，并采用基于自然语言处理技术与所述目标对象进行人机互动，获取所述目标对象的心理状态评估参数； {\textbar}   {\textbar} 基于多维度的心理大数据采用人工智能技术对所述生理数据和所述心理状态评估参数进行分析，确定所述目标对象的精神状态，并根据所述精神状态得到针对所述目标对象所需的脑刺激参数； {\textbar}   {\textbar} 根据所述脑刺激参数对所述目标对象产生相应的无创伤性脑刺激。 {\textbar}   {\textbar} 可选的，还包括： {\textbar}   {\textbar} 采用人工智能技术通过学习多个生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成所述多维度的心理大数据。 {\textbar}   {\textbar} 可选的，还包括： {\textbar}   {\textbar} 采用人工智能技术对所述多维度的心理大数据进行循环计算，优化所述多维度的心理大数据。 {\textbar}   {\textbar} 可选的，还包括： {\textbar}   {\textbar} 根据所述精神状态预测所述目标对象出现精神疾病的可能性，并发出相应的预警提示和/或干涉调节。 {\textbar}   {\textbar} 可选的，还包括： {\textbar}   {\textbar} 全面记录所述目标对象的脑刺激参数，采用人工智能技术整合所述目标对象的脑刺激参数得到针对所述目标对象的脑刺激规律，并根据所述脑刺激规律对所述目标对象产生更具个体针对作用的脑刺激。 {\textbar}   {\textbar} 可选的，还包括： {\textbar}   {\textbar} 通过摄像头采集所述目标对象的面部表情，通过麦克风采集所述目标对象的声音，采用人工智能技术对所述目标对象的面部表情和声音进行分析，确定所述目标对象的精神状态。 {\textbar}   {\textbar} 第三方面，本发明实施例提供了一种设备，包括存储器、处理器及存储在存储器上并可在处理器上运行的程序，所述处理器执行所述程序时实现如上述第二方面中任一所述的基于人工智能的脑刺激方法。 {\textbar}   {\textbar} 可选的，所述设备包括以下任一种：智能手机、电脑、智能宠物和智能医学仪器。 {\textbar}   {\textbar} 第四方面，本发明实施例提供了一种包含可执行指令的存储介质，所述可执行指令在由处理器执行时用于执行如上述第二方面中任一所述的基于人工智能的脑刺激方法。 {\textbar}   {\textbar} 本发明实施例可以在身心健康问题的预测、预防和干涉上实现智能化、个性化、科学性和综合性的精准操作，具有心理健康检测技术，经过智能检测之后还提供个性化、综合性和科学性的预防和干涉，包括认知行为疗法、物理刺激疗法以及嗅觉给药疗法。另外，结合大数据和人工智能技术对多种脑疾病都有一定作用，特别对抑郁症、自闭症和精神分裂症至少具有提早预测、专业预防和及时干涉的作用。除了通过人机交互系统实现认知行为治疗外，还通过其它技术实现更全面和更完整的预防和干涉，其中包括精准的生理和心理监测系统、无创多感官脑刺激技术以及病情突发应急功能。因此，不仅可以帮助人们维持精神健康和调节不良情绪，而且可以帮助治疗最严重的精神疾病，包括抑郁症、自闭症和精神分裂症等。 {\textbar}   {\textbar} 附图说明 {\textbar}   {\textbar} 图1为本发明实施例提供的基于人工智能的脑刺激系统的结构示意图； {\textbar}   {\textbar} 图2为本发明实施例提供的脑刺激终端的结构示意图； {\textbar}   {\textbar} 图3为本发明实施例提供的脑刺激终端的产品示例图； {\textbar}   {\textbar} 图4为本发明实施例提供的基于人工智能的脑刺激方法的流程图； {\textbar}   {\textbar} 图5和图6为本发明实施例提供的基于人工智能的脑刺激方法的流程图； {\textbar}   {\textbar} 图7A和图7B为本发明实施例提供的脑刺激终端的产品示例图； {\textbar}   {\textbar} 图8为本发明实施例提供的一种设备的结构示意图。 {\textbar}   {\textbar} 具体实施方式 {\textbar}   {\textbar} 下面结合附图和实施例对本发明实施例作进一步的详细说明。可以理解的是，此处所描述的具体实施例仅仅用于解释本发明实施例，而非对本发明实施例的限定。另外还需要说明的是，为了便于描述，附图中仅示出了与本发明实施例相关的部分而非全部结构。 {\textbar}   {\textbar} 图1为本发明实施例提供的基于人工智能的脑刺激系统的结构示意图，参照图1，该系统包括：多个脑刺激终端和云平台，多个脑刺激终端分别与云平台通信连接；云平台用于采用人工智能技术通过学习来自多个脑刺激终端的生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成多维度的心理大数据；脑刺激终端用于基于多维度的心理大数据采用人工智能技术对采集得到的目标对象的生理数据和心理状态评估参数进行分析，确定目标对象的精神状态，根据精神状态得到针对目标对象所需的脑刺激参数，并根据脑刺激参数对目标对象产生相应的无创性脑刺激。 {\textbar}   {\textbar} 在上述技术方案的基础上，云平台还用于采用人工智能技术对多维度的心理大数据进行循环计算，优化多维度的心理大数据。脑刺激终端还用于根据精神状态预测目标对象出现精神疾病的可能性，并作出相应的预警提示和/或调节干涉。脑刺激终端还用于全面记录目标对象的脑刺激参数，采用人工智能技术整合目标对象的脑刺激参数得到针对目标对象的脑刺激规律，并根据脑刺激规律对目标对象产生更具个体针对作用的脑刺激，这样使脑刺激更科学、更有效以及更精准。 {\textbar}   {\textbar} 云平台作为云端服务器采用人工智能技术生成多维度的心理大数据，其数据来源分为已有医学知识与目标对象授权可使用的数据两部分，获取已有医学知识包括通过自然语言处理分析现有医学研究文献、公开或可购买的医学案例数据，构建知识图谱，例如目标对象心律失常、情绪低落对应可能的疾病，每类疾病各自的相关症状、指标以及症状对应的疾病类型细分，每类细分对应的调节治疗方案等等，这部分数据构成各类疾病的诊断治疗模型；获取目标对象授权可使用的数据包括接收来自各脑刺激终端的传感器的数据，各传感器会在每位目标对象允许采集的情况下，进行实时的数据采集，包括目标对象面部表情、语音、心跳、血压、呼吸频率、皮肤电等等，该部分数据可以加工出目标对象的主观情绪(目标对象面部表情、语音中的情绪词汇、语调和语音快慢等)、目标对象的生理情绪(皮肤电、心率变异性、血压、心跳等)、目标对象的精神疲劳程度(皮肤电、面部表情、语音等)、注意力、幻听幻视(目标对象语音反馈，精神分裂诊断会用到)等疾病相关的诊断指标。 {\textbar}   {\textbar} 云平台根据上述数据来源对人的心理和精神状态进行评估，并采用人工智能技术综合比较来自各传感器的生理指标参数、当前目标对象表情、语音等，整合出相对完善和准确的人体生理和心理综合指数，深入挖掘分析当前目标对象生理、心理状态，相对于临床的单一维度更具优势，例如目标对象回答我还好但实际表情抑郁、心理参数有波动，云平台可以从多维度分析当前语音和表情得到目标对象的心理数据，更为科学与精准。 {\textbar}   {\textbar} 云平台进行大数据与人工智能处理，以两个目标生成多维度的心理大数据，第一个为疾病有关指标加工、疾病诊断，通过已有医学知识来计算注意力、当前情绪、精神疲劳程度和诊断响应疾病等，根据积累的大数据进行动态调整计算方法与详细分类，例如，心跳加快、呼吸加快，可能是兴奋也可能是紧张，可以通过目标对象的语音交互内容判断当前状态，根据兴奋、紧张不同状态下目标对象生理参数的积累，对该部分参数进行详细分析，利用机器学习、深度学习等算法学习完善之前的情绪判断模型；另一方面在与目标对象互动的过程中，结合目标对象的回答与生理参数来进一步明确疾病类型，积累所有目标对象的大数据进行综合处理之后，这种模型会不断地调整、完善，达到精确的指标加工、疾病诊断等。第二个是调节治疗模型，初期模型为知识图谱中已有的疾病对应治疗方案，后续在治疗过程中实时检测和收集目标对象的数据反馈，来评估当前治疗方式的有效性，并作出优化调整，调整主要用到人工智能的算法。为了保证目标对象的长期健康，可选用强化学习算法进行方案的制定，强化学习算法与传统机器学习算法的区别在于，强化学习算法是根据环境反馈来调整模型达到长期利益，如alphago下围棋的目标在于最后赢而不是当前或最近两步多吃掉对方的子，调节治疗算法的目的在于希望目标对象能够保持长期的健康，而非短期的生理健康或当前需求。强化学习模型的具体实现可参考如下，但不拘泥如下设定，以目标对象当前的生理、精神状态作为state，输出的刺激向量作为action，该刺激向量包括刺激类型(视觉、听觉、触觉等)，刺激模式如频率、强度、时间、属性(如视觉的内容、听觉的歌曲类型、嗅觉的香型等)，目标对象的反馈作为奖赏或惩罚，根据如目标对象当前表示心情更不好的程度、心率本来偏高结果更高的比例等调整惩罚的分数大小，奖励则可以根据目标对象的情绪好转、生理参数趋于健康如血压正常的程度来制定分数，通过目标对象的系列反馈，对知识图谱指定的调节策略给予一个权重，同时对应探索其他安全方案，记录系列刺激治疗之后目标对象的不断反馈，选取能够保证目标对象state得分最高的治疗方案。由于不同目标对象的习惯偏好、生理不同，强化学习方案会使得刺激调节治疗更具个性化、精准性和连续性，保证长期的医疗健康。同时，也会综合所有目标对象方案进行大数据挖掘分析，制作出更全面、更适合的治疗方案。 {\textbar}   {\textbar} 图2为本发明实施例提供的脑刺激终端的结构示意图，参照图2，脑刺激终端包括生理信息采集装置、心理交流互动装置、中央控制处理装置和物理输出装置；生理信息采集装置用于采集目标对象的生理数据；心理交流互动装置用于采用基于自然语言处理技术与目标对象进行人机互动，获取目标对象的心理状态评估参数；中央控制处理装置用于控制生理信息采集装置、心理交流互动装置和物理输出装置，基于多维度的心理大数据采用人工智能技术对生理数据和心理状态评估参数进行分析，确定目标对象的精神状态，并根据精神状态得到对目标对象的脑刺激参数；物理输出装置用于根据脑刺激参数运行，以对目标对象产生脑刺激。 {\textbar}   {\textbar} 在上述技术方案的基础上，生理信息采集装置还用于通过摄像头采集目标对象的面部表情，通过麦克风采集目标对象的声音；中央控制处理装置还用于采用人工智能技术对目标对象的面部表情和声音进行分析，确定目标对象的精神状态。 {\textbar}   {\textbar} 生理信息采集装置负责采集和输入人体的主要生理指标参数，包括心率、呼吸频率、血压、压力指数、脑电波、注意力值等，通过蓝牙等无线技术传输数据，可兼容使用于日常的电脑、笔记本和手机上。生理信息采集装置主要使用精细型、隐蔽式、柔性材料制备的电子感受器件，电子微型元件使用具有柔软透明和生物相容性好的材料如聚二甲基硅氧烷({PDMS})材料封装。具体可以制作成：跟手机壳紧密结合的皮肤电敏感性感受器，放置在椅子坐垫里的压力敏感型感受器，以及设置在衣服、纽扣或袜子内层的相关感受器等。采集到的数据主要通过蓝牙等技术传递，可传送并兼容使用于平常所用的电脑、笔记本和手机等智能设备上，并跟这些设备的摄像头和麦克风功能结合使用。跟市场上已有的电子感受器及其系统相比，除了采集数据的准确性更有保证外，感受器元件跟人体还有更好的亲和性，因为主要是由生物相容性好的高分子材料制造。另外跟普通电脑或手机的功能兼容性更佳，能效也低。本系统负责采集人体生理健康数据，包括心跳、血压、呼吸频率、注意力、精神疲劳程度等，注重综合性和科学性，通过2种或2种以上的感受器结合使用实现功能。 {\textbar}   {\textbar} 心理交流互动装置采用常用的自然语言处理(natural language process，简称：{NLP})技术实现机器和人的交流和沟通。心理交流互动装置结合本地智能设备如电脑、笔记本和手机的交互能力，采用基于自然语言处理技术与目标对象进行人机互动，参照临床心理相关测量表获取目标对象的心理状态评估参数。 {\textbar}   {\textbar} 中央控制处理装置构建脑疾病、心理学的医学知识图谱，基于所述多维度的心理大数据对实时采集目标对象当前表情、生理参数等生理状态数据进行分析，得到更为精准的目标对象精神状态，并确定针对目标对象所需的脑刺激参数。中央控制处理装置结合本地智能设备如电脑、笔记本和手机的计算能力，以及结合云平台的大数据处理能力，实现人工智能的主要作用，其中包括脑疾病心理学的医学知识图谱、个体生理和心理大数据分类能力、多维度数据实时整合和优化能力和输出程序筛选能力。中央控制处理装置与云平台之间同步应用、实时共享数据，例如目标对象语音交互时，中央控制处理装置会分析当前该目标对象的表情、心律血压等参数，分析出当前目标对象的实际精神状态，综合得出在当前状态下，目标对象的请求或要求是否合理(如时间很晚了，目标对象生理参数显示很疲劳，但目标对象语音表示仍想听摇滚类歌曲)，推荐出目标对象喜爱的情绪调节方式(告诉目标对象以往这个时候应该睡觉了，并且目前状态不适合听亢奋类歌曲，建议播放目标对象喜爱音乐中的舒缓类歌曲)，从而达到全方位的科学、健康、良好的目标对象所需的脑刺激调节。 {\textbar}   {\textbar} 物理输出装置主要是通过无创伤、多感官的脑神经刺激技术对涉及情绪和精神调控的大脑神经环路进行有效干涉，主要刺激包括来自视觉、听觉、嗅觉、触觉的感官刺激，以及来自电磁波的大脑皮层刺激和超声波的深脑刺激。脑刺激终端可以输出三种干涉方法，包括物理刺激疗法、嗅觉给药疗法以及认知行为疗法，可以对精神健康和脑疾病问题实行有效的预测、预防和干涉作用，对严重的抑郁症、自闭症和精神分裂症患者至少具有提早预测、专业预防和及时干涉的作用。物理输出装置具有多感官结合的无创性大脑刺激功能，结合中央控制处理装置的人工智能技术具有更加科学和更加精准的刺激功效，经过机器学习的算法优化可以找到符合个人情况的更精准的刺激参数及程序，通过智能的学习记忆和循环优化，最终可得出适合个人调节的最佳参数，在脑刺激参数输出上也更加智能，包括物理刺激疗法的程序输出、嗅觉给药疗法的原料筛选、以及认知行为疗法的灵活应用。物理输出装置包括以下任一种或多种：光源装置、音响装置、按摩装置、熏香装置、超声波装置和电磁波装置，其中，光源装置、音响装置和按摩装置用于对目标对象进行相应刺激程序所产生的感官性物理刺激，超声波装置和所述电磁波装置用于对所述目标对象进行专业的医疗性脑刺激，达到医学治疗的效果。在物理刺激疗法的程序输出上，可设置多种感官，包含视觉、听觉、触觉输出的刺激组合方案，然后根据生理和心理检测数据的计算结果选择对应的刺激程序，每个刺激程序包括多种感官刺激，每种感官刺激包含特定的频率、强度、时间参数等，这些参数输出通过人工智能计算作出更精准的选择。熏香装置用于依靠空气传播化学气体分子进入目标对象的嗅觉器官，达到嗅觉给药干涉或治疗的效果。在嗅觉给药疗法中，可选择在可封闭的硬件设备环境中通过熏汽设施实现，主要靠空气传递化学气体分子进入人体嗅觉器官，然后再通过嗅觉进入大脑负责情感认知的边缘系统。采用的化学药物主要是已经公认安全有效的香精材料、中药成分以及{FDA认可的西药成分等}。原料制成具纳米结构的颗粒材料封装于熏香设备旁边，由硬件设备通过人工智能算法后自动筛选并使用。心理交流互动装置不仅用于与目标对象进行人机互动，而且还对目标对象进行认知行为治疗。人机互动包括文字交流、语音对话、游戏互动、图片播放和/或视频播放。在认知行为疗法中，通过自然语言处理技术({NLP})实现人机互动，包括程序选择、打字聊天、人机对话，结合具有临床诊断标准的测量表对人的心理和精神状态进行评估，但采用幽默诙谐的人机互动方式，包括玩笑、游戏、动画和视频方式，灵活实现认知行为疗法的功能，达到调节情绪和精神状态的目的。 {\textbar}   {\textbar} 本实施例的技术方案，可以在身心健康问题的预测、预防和干涉上实现智能化、个性化、科学性和综合性的精准操作，具有心理健康检测技术，经过智能检测之后还提供个性化、综合性和科学性的预防和干涉，包括认知行为疗法、物理刺激疗法以及嗅觉给药疗法。另外，结合大数据和人工智能对多种脑疾病的都有一定作用，特别对抑郁症、自闭症和精神分裂症至少具有提早预测、专业预防和及时干涉的作用。除了通过人机交互系统实现认知行为治疗外，还通过其它技术实现更全面和更精准的预防和干涉措施，其中包括精巧的生理和心理监测系统、无创多感官大脑刺激技术以及病情突发应急功能。因此，不仅可以帮助人们维持精神健康和调节不良情绪，而且可以帮助治疗最严重的精神疾病，包括抑郁症、自闭症和精神分裂症等。 {\textbar}   {\textbar} 在上述技术方案的基础上，脑刺激终端还包括：电源装置，电源装置用于为脑刺激终端供电；电源装置包括以下任一种或多种：一次电池、二次电池、射频供电电池和生物燃料电池装置。 {\textbar}   {\textbar} 图3为本发明实施例提供的脑刺激终端的具体产品示例图，参照图3，A是适用于大众的智能电脑椅配件，包括{BIAI} {App软件和BIAI} Chair智能坐垫。本身{BIAI} App软件通过电脑和手机的人脸识别和指纹扫描功能可以初步实现检测使用者的心情和健康状态；{B是敞开型的BIAI} Chair，具有无创多感官脑刺激功能；{C是一款新型的具有办公功能的代步车BIAI} Auto-chair，通过可闭合的系统实现完整的无创多感官脑刺激功能，同时适用于室外办公，且有自动驾驶的代步功能；D适用于自闭症儿童的智能小黄鸭，具有{BIAI产品完整的监测功能}、互动功能和脑刺激功能；E是适用于抑郁症患者的智能熊猫，具有{BIAI产品完整的监测功能}、互动功能和脑刺激功能；F是适用于精神分裂症患者的智能高飞护士，具有{BIAI产品完整的监测功能}、互动功能和脑刺激功能。 {\textbar}   {\textbar} 脑刺激终端可以包括两种类型：一种是普适型，即面向大众消费的，另一种是疾病型，即面向那些具有脑疾病的患者。普适型产品可体现为直接在手机和电脑里面使用的App软件，以及放置在手机和电脑旁边的一些硬件设备，如智能手机壳、智能坐垫和智能电脑椅(如图3{中的A}、{B和C所示})等。{APP软件通过跟手机壳紧密结合的皮肤电感受器}、放在电脑椅坐垫里的压力敏感型感受器等采集人体基本生理参数包括心跳、呼吸和血压等数值，再结合电脑和手机自带的摄像头和/或麦克风可以采集目标对象的面部表情和/或目标对象的声音，可实现人体综合生理数据更加精准地采集。另一方面App软件里的人机互动功能，可通过打字交流和语音对话方式，获得使用者的心理评估参数。人工智能算法通过这些来自生理和心理的大数据计算和分析出使用者的精神状态，可以通过电脑或手机输出视听形式的感官刺激进行调节。另外再结合智能电脑椅，可以实现来自触觉、嗅觉以及超声波和电磁波的多感官综合调节。另一种疾病型产品，重点用于照顾、监护和帮助具有脑疾病的患者，将给人以良好亲和力的宠物形象出现(如图3{中的D}、{E和F所示})，同样具有上面所述的三大系统的完整功能。负责采集人体生理数据的感受器除上述所述形式外，以更隐蔽形式存在，如隐藏于衣服纽扣或袜子内层。人机交互功能使用友好、风趣、贴心和默契的方式跟使用者进行日常互动，可以像真的宠物一样朝夕相处。通过大数据积累得到的生理和心理的综合参数，利用人工智能进行计算、整合和优化，为患者提供一套最优的调节程序。通过无创伤的多感官输入的神经环路刺激，对患者的精神疾病进行有益的干涉调节。在病情突然发作或恶化时，可以提前发出预警，有效预防并且及时干涉。平时无人监护时也可以通过综合性的无创多感官大脑刺激技术所包含的认知行为疗法、物理刺激疗法以及嗅觉给药疗法，系统、科学和智能地调节患者的精神健康状态。 {\textbar}   {\textbar} 图4为本发明实施例提供的基于人工智能的脑刺激方法的流程图，具体包括如下步骤： {\textbar}   {\textbar} 步骤101、采集目标对象的生理数据，并采用基于自然语言处理技术与目标对象进行人机互动，获取目标对象的心理状态评估参数； {\textbar}   {\textbar} 步骤102、基于多维度的心理大数据采用人工智能技术对生理数据和心理状态评估参数进行分析，确定目标对象的精神状态，并根据精神状态得到针对目标对象所需的脑刺激参数； {\textbar}   {\textbar} 步骤103、根据脑刺激参数对目标对象产生相应的无创性脑刺激。 {\textbar}   {\textbar} 在上述技术方案的基础上，还包括：采用人工智能技术通过学习多个生理数据和心理状态评估参数，结合预设的各类疾病的诊断治疗模型生成多维度的心理大数据。采用人工智能技术对多维度的心理大数据进行循环计算，优化多维度的心理大数据。根据精神状态预测目标对象出现精神疾病的可能性，并作出相应的预警提示和/或干涉调节。全面记录目标对象的脑刺激参数，采用人工智能技术整合目标对象的脑刺激参数得到针对目标对象的脑刺激规律，并根据脑刺激规律对目标对象产生更科学、更有效以及更精准的脑刺激。通过摄像头采集目标对象的面部表情，通过麦克风采集目标对象的声音，采用人工智能技术对目标对象的面部表情和声音进行分析，确定目标对象的精神状态。 {\textbar}   {\textbar} 图5和图6为本发明实施例提供的基于人工智能的脑刺激方法的具体流程图，整个过程可以分为本地和云端两部分，如图5，通过多个传感器采集到目标对象的数据，传输到手机或电脑上，一方面由本地系统即手机和电脑进行计算处理，另一方面由云端服务器进行大数据的人工智能算法处理。本地系统主要根据已有智能程序和算法进行分析、整合和优化，生产个性化的健康报告和干涉治疗方案，以及输出最优的调节程序。云端服务器主要收集脱敏性的生理和心理整合后的大数据，对来自个体的健康大数据进行进一步挖掘，不断优化人工智能算法，提高和完善系统的智能性和精准性。另外，如图6所示，智能系统输出刺激参数后，各刺激装置接受到程序指令实施刺激。首先是通过手机或电脑的App功能目标对象自主选择主要的程序模式，然后人工智能输出的参数结合所选模式进一步优化再输出。最后参数输出到各个物理设备，包括光学系统、音响设施、熏香装置、人机交互系统等。参数刺激后感受器系统同时采集和收集反馈性数据。 {\textbar}   {\textbar} 图7A和图7B为本发明实施例提供的脑刺激终端的产品示例图，参照图7A，是脑刺激系统的配套硬件形式之一，智能电脑椅。在该硬件设置里，配置有各感官刺激的装置，包括音响装置、脑波刺激装置、握力器、熏香装置和触觉装置，另外还有在座位处的压力敏感坐垫和位于椅背处的中央控制器。参照图7B是脑刺激系统的另一种配套硬件形式，智能宠物。在该硬件设置里，配置有各感官刺激的装置，包括脑波刺激装置、熏香装置、音响与语音交互装置、和视频输出装置，另外还有红外摄像头和生物电敏感感受器，以及中央控制器和智能手机设备。手机设备具传输数据和通讯联络功能，可把人体状态数据发送给另一端的监护人并在有需要的时候自动联系监护人。 {\textbar}   {\textbar} 图8为本发明实施例提供的一种设备的结构示意图，如图8所示，该设备包括处理器10、存储器11、输入装置12和输出装置13；设备中处理器10的数量可以是一个或多个，图8中以一个处理器10为例；设备中的处理器10、存储器11、输入装置12和输出装置13可以通过总线或其他方式连接，图8中以通过总线连接为例。 {\textbar}   {\textbar} 存储器11作为一种计算机可读存储介质，可用于存储软件程序、计算机可执行程序以及模块，如本发明实施例中的基于人工智能的脑刺激方法对应的程序指令/模块。处理器10通过运行存储在存储器11中的软件程序、指令以及模块，从而执行设备的各种功能应用以及数据处理，即实现上述的基于人工智能的脑刺激方法。 {\textbar}   {\textbar} 存储器11可主要包括存储程序区和存储数据区，其中，存储程序区可存储操作系统、至少一个功能所需的应用程序；存储数据区可存储根据终端的使用所创建的数据等。此外，存储器11可以包括高速随机存取存储器，还可以包括非易失性存储器，例如至少一个磁盘存储器件、闪存器件、或其他非易失性固态存储器件。在一些实例中，存储器11可进一步包括相对于处理器10远程设置的存储器，这些远程存储器可以通过网络连接至设备。上述网络的实例包括但不限于互联网、企业内部网、局域网、移动通信网及其组合。 {\textbar}   {\textbar} 输入装置12可用于接收输入的数字或字符信息，以及产生与设备的目标对象设置以及功能控制有关的键信号输入。输出装置13可包括显示屏等显示设备。 {\textbar}   {\textbar} 本发明实施例所提供的一种包含可执行指令的存储介质,其可执行指令可以执行本发明任意实施例所提供的基于人工智能的脑刺激方法中的相关操作。 {\textbar}   {\textbar} 通过以上关于实施方式的描述，所属领域的技术人员可以清楚地了解到，本发明实施例可借助软件及必需的通用硬件来实现，当然也可以通过硬件实现，但很多情况下前者是更佳的实施方式。基于这样的理解，本发明实施例的技术方案本质上或者说对现有技术做出贡献的部分可以以软件产品结合相关配套硬件的形式体现出来，该计算机软件产品可以存储在计算机可读存储介质中，如计算机的软盘、只读存储器(Read-Only Memory,{ROM})、随机存取存储器(Random Access Memory,{RAM})、闪存({FLASH})、硬盘或光盘等，包括若干指令用以使得一台计算机设备(可以是个人计算机，服务器，或者网络设备等)执行本发明实施例各个实施例所述的方法。 {\textbar}   {\textbar} 注意，上述仅为本发明实施例的较佳实施例及所运用技术原理。本领域技术人员会理解，本发明实施例不限于这里所述的特定实施例，对本领域技术人员来说能够进行各种明显的变化、重新调整和替代而不会脱离本发明实施例的保护范围。因此，虽然通过以上实施例对本发明实施例进行了较为详细的说明，但是本发明实施例不仅仅限于以上实施例，在不脱离本发明实施例构思的情况下，还可以包括更多其他等效实施例，而本发明实施例的范围由所附的权利要求范围决定。
Issue: {CN}110522983A},
}

@patent{park_lim22,
	location = {{KR}},
	title = {Hospital reception relay system and operation method thereof},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {The present invention relates to a hospital reception relay system and an operating method thereof, and more particularly, to a hospital reception relay system capable of providing a list of hospitals that specialize in treating a medical subject corresponding to user disease information, and an operating method thereof will be. For this purpose, it is a method of operating a hospital reception relay system that generates and manages {AI}-based diagnosis algorithms for each type of mental illness by learning the collected patient group images and disease information of the corresponding patient group through machine learning. and receiving location information, and collecting user images corresponding to the user's abnormal reaction through an image analysis-based diagnostic test for diagnosing the type of mental illness based on the diagnosis history detected from the user information Step, using the {AI}-based diagnosis algorithm for each type of mental illness, deriving user disease information for the user images and registering it in a storage {DB}, corresponding to the user disease information among a plurality of pre-registered hospitals Classify a list of hospitals that specialize in treatment, Sorting the hospital list in the order of proximity according to the user location information and relaying the treatment reservation between the user and the hospital based on the hospital information and the treatment time selected as the hospital list is relayed to the user terminal including the steps of {\textbar}   {\textbar} 본 발명은 병원접수 중계 시스템 및 그 동작 방법에 관한 것으로서, 보다 상세하게는, 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 제공할 수 있는 병원접수 중계 시스템 및 그 동작 방법에 관한 것이다. 이를 위해 기수집된 환자군 이미지들과 해당 환자군의 질환 정보를 머신 러닝을 통해 학습함에 따라 인공지능 기반의 정신질환 종류별 진단 알고리즘을 생성하여 관리하는 병원접수 중계 시스템의 동작 방법으로서, 사용자 단말로부터 사용자 정보와 위치 정보를 전송받는 단계, 상기 사용자 정보로부터 탐지되는 진단 이력 여부에 기초하여, 상기 정신 질환의 종류를 진단하기 위한 영상분석 기반의 진단테스트를 통해 사용자의 이상반응에 해당하는 사용자 이미지들을 수집하는 단계, 상기 인공지능 기반의 정신질환 종류별 진단 알고리즘을 이용하여, 상기 사용자 이미지들에 대한 사용자 질환 정보를 도출하여 저장 {DB에} 등록하는 단계, 기등록된 복수의 병원들 중 상기 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 분류하고, 상기 사용자 위치 정보에 따라 근거리 순으로 상기 병원 리스트를 정렬하는 단계 및 상기 병원 리스트를 상기 사용자 단말에 중계함에 따라 선택받는 병원 정보와 진료 시간에 기초하여, 상기 사용자와 해당 병원 간의 진료 예약을 중계 처리하는 단계를 포함한다. 
본 발명은 병원접수 중계 시스템 및 그 동작 방법에 관한 것으로서, 보다 상세하게는, 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 제공할 수 있는 병원접수 중계 시스템 및 그 동작 방법에 관한 것이다. 이를 위해 기수집된 환자군 이미지들과 해당 환자군의 질환 정보를 머신 러닝을 통해 학습함에 따라 인공지능 기반의 정신질환 종류별 진단 알고리즘을 생성하여 관리하는 병원접수 중계 시스템의 동작 방법으로서, 사용자 단말로부터 사용자 정보와 위치 정보를 전송받는 단계, 상기 사용자 정보로부터 탐지되는 진단 이력 여부에 기초하여, 상기 정신 질환의 종류를 진단하기 위한 영상분석 기반의 진단테스트를 통해 사용자의 이상반응에 해당하는 사용자 이미지들을 수집하는 단계, 상기 인공지능 기반의 정신질환 종류별 진단 알고리즘을 이용하여, 상기 사용자 이미지들에 대한 사용자 질환 정보를 도출하여 저장 {DB에} 등록하는 단계, 기등록된 복수의 병원들 중 상기 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 분류하고, 상기 사용자 위치 정보에 따라 근거리 순으로 상기 병원 리스트를 정렬하는 단계 및 상기 병원 리스트를 상기 사용자 단말에 중계함에 따라 선택받는 병원 정보와 진료 시간에 기초하여, 상기 사용자와 해당 병원 간의 진료 예약을 중계 처리하는 단계를 포함한다.
The present invention relates to a hospital reception relay system and an operating method thereof, and more particularly, to a hospital reception relay system capable of providing a list of hospitals that specialize in treating a medical subject corresponding to user disease information, and an operating method thereof will be. For this purpose, it is a method of operating a hospital reception relay system that generates and manages {AI}-based diagnosis algorithms for each type of mental illness by learning the collected patient group images and disease information of the corresponding patient group through machine learning. and receiving location information, and collecting user images corresponding to the user's abnormal reaction through an image analysis-based diagnostic test for diagnosing the type of mental illness based on the diagnosis history detected from the user information Step, using the {AI}-based diagnosis algorithm for each type of mental illness, deriving user disease information for the user images and registering it in a storage {DB}, corresponding to the user disease information among a plurality of pre-registered hospitals Classify a list of hospitals that specialize in treatment, Sorting the hospital list in the order of proximity according to the user location information and relaying the treatment reservation between the user and the hospital based on the hospital information and the treatment time selected as the hospital list is relayed to the user terminal including the steps of},
	type = {patent},
	author = {Park, Sun Ok and Lim, Sujin},
	urldate = {2021-10-27},
	date = {2022-04-20},
	note = {Edition: G16H004020 {\textbar} G06Q001002 {\textbar} G16H001020 {\textbar} G16H001060 {\textbar} G16H002070 {\textbar} G16H003040 {\textbar} G16H005070 {\textbar} H04N000714 1. 기수집된 환자군 이미지들과 해당 환자군의 질환 정보를 머신 러닝을 통해 학습함에 따라 인공지능 기반의 정신질환 종류별 진단 알고리즘을 생성하여 관리하는 병원접수 중계 시스템의 동작 방법으로서, 사용자 단말로부터 사용자 정보와 위치 정보를 전송받는 단계; {\textbar} 상기 사용자 정보로부터 탐지되는 진단 이력 여부에 기초하여, 상기 정신 질환의 종류를 진단하기 위한 영상분석 기반의 진단테스트를 통해 사용자의 이상반응에 해당하는 사용자 이미지들을 수집하는 단계; {\textbar}   {\textbar} 상기 인공지능 기반의 정신질환 종류별 진단 알고리즘을 이용하여, 상기 사용자 이미지들에 대한 사용자 질환 정보를 도출하여 저장 {DB에} 등록하는 단계; {\textbar}   {\textbar} 기등록된 복수의 병원들 중 상기 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 분류하고, 상기 사용자 위치 정보에 따라 근거리 순으로 상기 병원 리스트를 정렬하는 단계; 및 상기 병원 리스트를 상기 사용자 단말에 중계함에 따라 선택받는 병원 정보와 진료 시간에 기초하여, 상기 사용자와 해당 병원 간의 진료 예약을 중계 처리하는 단계를 포함하고, 상기 영상분석 기반의 진단테스트는 기설정된 컨텐츠 영상에서 이상 반응을 유도하기 위한 질의를 제공함에 따라 상기 사용자로부터 응답받는 화상통화 방식 서비스인, 병원접수 중계 시스템의 동작 방법. {\textbar}   {\textbar} 2. 제1항에 있어서, 상기 중계 처리하는 단계는, 상기 진료 예약이 중계 처리될 때, 상기 사용자 질환 정보를 해당 병원 서버에 제공함에 따라 응답받는 의료진 진료결과에 기초하여, 상기 정신질환 종류별 진단 알고리즘의 가중치 조절 여부를 판단하는 단계; {\textbar} 상기 사용자 질환 정보와 상기 의료진 진료결과가 서로 다른 경우, 상기 정신질환 종류별 진단 알고리즘의 각 가중치를 조절하는 단계; 및 상기 사용자 질환 정보와 상기 의료진 진료결과가 서로 동일한 경우, 상기 사용자 질환 정보의 질환 상태를 분석하기 위한 심리테스트를 제공함에 따라 출력되는 테스트결과에 기초하여, 병행상담 치료 방법들 중 어느 하나의 병행 상담 치료 방법을 상기 사용자 단말에 제공하는 단계를 포함하는, 병원접수 중계 시스템의 동작 방법. {\textbar}   {\textbar} 3. 제2항에 있어서, 상기 사용자 이미지들을 수집하는 단계는 상기 사용자 정보가 진단 이력이 탐지되지 않는 경우, 상기 사용자 단말을 통해 촬영된 사용자 영상을 전송받는 단계; {\textbar} 상기 사용자 영상과 상기 기설정된 컨텐츠 영상을 합성 처리한 반응 유도 영상을 상기 사용자 단말에 제공하는 단계; 상기 반응 유도 영상이 재생되는 동안, 상기 사용자 영상으로부터 기설정된 이상 객체에 대응되는 상기 사용자 이미지들을 추출하여 수집하는 단계; 및 상기 사용자 정보로부터 진단 이력이 탐지된 경우, 상기 저장 {DB로부터} 등록된 상기 사용자 질환 정보를 검출하여, 상기 사용자 질환 정보에 대한 도출 동작을 스킵시키는 단계를 포함하는, 병원접수 중계 시스템의 동작 방법. {\textbar}   {\textbar} 4. 제1항에 있어서, 상기 병원 리스트를 정렬하는 단계는, 상기 진료과목을 진료받은 복수의 타 사용자 단말들로부터 병원 후기 정보를 등록받는 후기 게시판 웹페이지를 제공하는 단계; {\textbar} 상기 후기 게시판 웹페이지에 등록된 병원 후기 정보에 기초하여 병원 리스트에서 추천 병원 정보를 선별하는 단계; 및 상기 해당 추천 병원 정보를 사용자가 식별가능하게 하도록 병원 리스트를 특정 색상을 통해 보정하는 단계를 포함하는, 병원접수 중계 시스템의 동작 방법. {\textbar}   {\textbar} 5. 제1항에 있어서, 상기 진료 예약을 중계 처리하는 단계는, 상기 병원 리스트를 상기 사용자 단말에 중계함에 따라 선택받는 상기 병원 정보에 응답하여, 해당 병원 서버에 접속하여 진료 가능 시간을 검색하는 단계; {\textbar} 상기 진료 가능 시간을 상기 사용자 단말에 중계함에 따라 선택받는 상기 진료 시간에 응답하여, 상기 해당 병원 서버에 상기 사용자 정보에 대한 해당 병원의 진료 예약을 신청하는 단계; 및 상기 해당 병원의 진료 예약이 신청 완료됨에 따라, 상기 해당 병원 서버로부터 발급되는 진료 예약 정보를 전송받아 상기 사용자 단말에 중계하는 단계를 포함하는, 병원 접수 시스템의 동작 방법. 1. A method of operating a hospital reception relay system that generates and manages {AI}-based diagnostic algorithms for each type of mental illness as it learns collected patient group images and disease information of the patient group through machine learning. receiving information; {\textbar} collecting user images corresponding to the user's abnormal reaction through an image analysis-based diagnostic test for diagnosing the type of mental illness based on the diagnosis history detected from the user information; {\textbar}   {\textbar} using the {AI}-based diagnosis algorithm for each type of mental illness, deriving user disease information on the user images and registering it in a storage {DB}; {\textbar}   {\textbar} classifying a list of hospitals that professionally treats a medical subject corresponding to the user's disease information among a plurality of previously registered hospitals, and arranging the hospital list in order of proximity according to the user location information; and relaying the treatment reservation between the user and the hospital based on the hospital information and the treatment time selected as the hospital list is relayed to the user terminal, wherein the image analysis-based diagnostic test is preset A method of operating a hospital reception relay system, which is a video call service that receives a response from the user by providing a query for inducing an abnormal reaction in the content image. {\textbar}   {\textbar} 2. The method of claim 1, wherein the relay processing comprises: when the treatment reservation is relayed, the diagnosis algorithm for each type of mental illness is based on the medical treatment result received by providing the user disease information to the corresponding hospital server. determining whether to adjust the weight; {\textbar} adjusting each weight of the diagnosis algorithm for each type of mental illness when the user disease information and the medical treatment result are different from each other; and when the user's disease information and the medical treatment result are identical to each other, based on the test result output by providing a psychological test for analyzing the disease state of the user's disease information, any one of the parallel counseling treatment methods in parallel A method of operating a hospital reception relay system, comprising the step of providing a counseling treatment method to the user terminal. {\textbar}   {\textbar} 3. The method of claim 2 , wherein the collecting of the user images comprises: receiving a captured user image through the user terminal when a diagnosis history is not detected in the user information; {\textbar} providing a reaction-inducing image obtained by synthesizing the user image and the preset content image to the user terminal; while the reaction-inducing image is being reproduced, extracting and collecting the user images corresponding to a preset abnormal object from the user image; and when a diagnosis history is detected from the user information, detecting the user disease information registered from the storage {DB}, and skipping a derivation operation for the user disease information. {\textbar}   {\textbar} 4. The method of claim 1 , wherein the arranging of the hospital list comprises: providing a review bulletin board web page for registering hospital review information from a plurality of other user terminals that have received the treatment; {\textbar} selecting recommended hospital information from a hospital list based on the hospital review information registered on the review bulletin board webpage; and correcting the hospital list through a specific color so that the user can identify the recommended hospital information. {\textbar}   {\textbar} 5. According to claim 1, wherein the relay processing of the treatment reservation comprises: in response to the hospital information selected as the hospital list is relayed to the user terminal, accessing the hospital server and searching for available treatment time; {\textbar} In response to the treatment time selected as the available treatment time is relayed to the user terminal, applying to the hospital server for a treatment reservation of the corresponding hospital for the user information; and receiving treatment reservation information issued from the hospital server and relaying the received treatment reservation information to the user terminal as the treatment reservation of the corresponding hospital is completed. 1. 기수집된 환자군 이미지들과 해당 환자군의 질환 정보를 머신 러닝을 통해 학습함에 따라 인공지능 기반의 정신질환 종류별 진단 알고리즘을 생성하여 관리하는 병원접수 중계 시스템의 동작 방법으로서, 사용자 단말로부터 사용자 정보와 위치 정보를 전송받는 단계; {\textbar} 상기 사용자 정보로부터 탐지되는 진단 이력 여부에 기초하여, 상기 정신 질환의 종류를 진단하기 위한 영상분석 기반의 진단테스트를 통해 사용자의 이상반응에 해당하는 사용자 이미지들을 수집하는 단계; {\textbar}   {\textbar} 상기 인공지능 기반의 정신질환 종류별 진단 알고리즘을 이용하여, 상기 사용자 이미지들에 대한 사용자 질환 정보를 도출하여 저장 {DB에} 등록하는 단계; {\textbar}   {\textbar} 기등록된 복수의 병원들 중 상기 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 분류하고, 상기 사용자 위치 정보에 따라 근거리 순으로 상기 병원 리스트를 정렬하는 단계; 및 상기 병원 리스트를 상기 사용자 단말에 중계함에 따라 선택받는 병원 정보와 진료 시간에 기초하여, 상기 사용자와 해당 병원 간의 진료 예약을 중계 처리하는 단계를 포함하고, 상기 영상분석 기반의 진단테스트는 기설정된 컨텐츠 영상에서 이상 반응을 유도하기 위한 질의를 제공함에 따라 상기 사용자로부터 응답받는 화상통화 방식 서비스인, 병원접수 중계 시스템의 동작 방법. 1. A method of operating a hospital reception relay system that generates and manages {AI}-based diagnostic algorithms for each type of mental illness as it learns collected patient group images and disease information of the patient group through machine learning. receiving information; {\textbar} collecting user images corresponding to the user's abnormal reaction through an image analysis-based diagnostic test for diagnosing the type of mental illness based on the diagnosis history detected from the user information; {\textbar}   {\textbar} using the {AI}-based diagnosis algorithm for each type of mental illness, deriving user disease information on the user images and registering it in a storage {DB}; {\textbar}   {\textbar} classifying a list of hospitals that professionally treats a medical subject corresponding to the user's disease information among a plurality of previously registered hospitals, and arranging the hospital list in order of proximity according to the user location information; and relaying the treatment reservation between the user and the hospital based on the hospital information and the treatment time selected as the hospital list is relayed to the user terminal, wherein the image analysis-based diagnostic test is preset A method of operating a hospital reception relay system, which is a video call service that receives a response from the user by providing a query for inducing an abnormal reaction in the content image. 병원접수 중계 시스템 및 그 동작 방법\{{HOSPITAL} {RECEPTION} {RELAY} {SYSTEM} {AND} {OPERATION} {METHOD} {THEREOF}\} {\textbar}   {\textbar} 100: 병원접수 중계 시스템 110: 통신부 120: 수집부 130: 도출부 140: 정렬부 150: 중계 처리부 {\textbar}   {\textbar} 한국등록특허 제10-1769480호 {\textbar}   {\textbar} 본 발명은 병원접수 중계 시스템 및 그 동작 방법에 관한 것으로서, 보다 상세하게는, 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 제공할 수 있는 병원접수 중계 시스템 및 그 동작 방법에 관한 것이다.  {\textbar}   {\textbar} 도 1은 본 발명의 일 실시예에 따른 병원접수 중계 시스템을 개략적으로 나타내는 도이다. 도 2는 도 1의 중계 처리부의 일 실시예에 따른 동작을 설명하기 위한 블록도이다. 도 3은 도 1의 병원접수 중계 시스템의 동작 프로세스이다. 도 4는 도 2의 중계 처리부의 일 실시예에 따른 동작 프로세스이다. 도 5는 도 1의 수집부의 동작 프로세스이다. 도 6은 도 1의 정렬부의 동작 프로세스이다. 도 7은 도 1의 중계 처리부의 동작 프로세스이다.  {\textbar}   {\textbar} 의료 서비스가 점점 발전하고 있음에도 불구하고, 의료 소비자들은 의료 서비스의 제공자인 병원 또는 의원에 대한 정확한 정보를 알기 어려워 대부분이 주변의 지인들로부터 들은 정보에 의존하고 있다. 마찬가지로 병원이나 의원도 자신의 서비스를 제대로 홍보할 수 있는 상태가 아닌 상태이다. {\textbar}   {\textbar} 이로 인하여 의료 소비자는 높은 수준의 서비스를 선택하지 못하고 있으며 병원 또는 의원도 서비스 경쟁을 통한 마케팅의 필요성을 느끼지 못하고 있다. 의료 소비자가 병원 또는 의원에 손쉽게 예약하고 서비스 받을 수 있을 것임에도 불구하고, 그러한 서비스 부재의 장기화 및 고착화된 상태에 있다. {\textbar}   {\textbar} 병원 또는 의원이 운영하는 홈페이지에 접속하여 담당 전문의의 스케쥴을 확인하여 진료 일자를 예약하는 방법도 존재하여 직접 병의원을 방문하거나 병원 콜센터를 통해 진료예약하는 방법보다는 진보된 방법일 수 있으나, 만일 전문의의 스케쥴이 포화된 상태에 있거나 아예 담당 전문의가 없는 경우에는 예약 자체가 불가하다. {\textbar}   {\textbar} 최근에 포털 사이트 또는 검색 사이트를 통해 병원과 전문의에 대한 정보를 검색할 수 있지만, 포털 사이트의 검색 방식이나 검색인의 수가 급증하여 의료 소비자는 적절한 전문 병원과 전문의를 확인하기 어렵다. {\textbar}   {\textbar} 특히, 정신 건강 의학과를 처음 방문하거나 아직 현재 질환 상태 또는 질환 종류를 파악하고 있지 못하는 경우, 진료과목을 전문적으로 진료하는 병원 정보를 파악하기 어렵기 때문에, 병원 방문에 따른 예약 접수, 원활한 상담 및 치료가 곤란한 문제가 있다.  {\textbar}   {\textbar} 본 발명은 상기와 같은 문제점을 해결하기 위한 것으로서, 본 발명의 목적은 인공지능 기반의 정신질환 종류별 진단 알고리즘을 통해 도출되는 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 분류하여 사용자에게 제공할 수 있는 병원접수 중계 시스템 및 그 동작 방법을 제공하는 데 있다.  {\textbar}   {\textbar} 또한, 사용자와 해당 병원 간의 진료 예약을 보다 효율적이고 신속하게 중계할 수 있는 병원접수 중계 시스템 및 그 동작 방법을 제공하는 데 있다.  {\textbar}   {\textbar} 본 발명의 상기 및 다른 목적과 이점은 바람직한 실시예를 설명한 하기의 설명으로부터 분명해질 것이다. {\textbar}   {\textbar} 상기 목적은, 기수집된 환자군 이미지들과 해당 환자군의 질환 정보를 머신 러닝을 통해 학습함에 따라 인공지능 기반의 정신질환 종류별 진단 알고리즘을 생성하여 관리하는 병원접수 중계 시스템의 동작 방법으로서, 사용자 단말로부터 사용자 정보와 위치 정보를 전송받는 단계, 상기 사용자 정보로부터 탐지되는 진단 이력 여부에 기초하여, 상기 정신 질환의 종류를 진단하기 위한 영상분석 기반의 진단테스트를 통해 사용자의 이상반응에 해당하는 사용자 이미지들을 수집하는 단계, 상기 인공지능 기반의 정신질환 종류별 진단 알고리즘을 이용하여, 상기 사용자 이미지들에 대한 사용자 질환 정보를 도출하여 저장 {DB에} 등록하는 단계, 기등록된 복수의 병원들 중 상기 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 분류하고, 상기 사용자 위치 정보에 따라 근거리 순으로 상기 병원 리스트를 정렬하는 단계 및 상기 병원 리스트를 상기 사용자 단말에 중계함에 따라 선택받는 병원 정보와 진료 시간에 기초하여, 상기 사용자와 해당 병원 간의 진료 예약을 중계 처리하는 단계를 포함하고, 상기 영상분석 기반의 진단테스트는 기설정된 컨텐츠 영상에서 이상 반응을 유도하기 위한 질의를 제공함에 따라 상기 사용자로부터 응답받는 화상통화 방식 서비스인, 병원접수 중계 시스템의 동작 방법에 의해 해결될 수 있다.  {\textbar}   {\textbar} 상기 중계 처리하는 단계는 상기 진료 예약이 중계 처리될 때, 상기 사용자 질환 정보를 해당 병원 서버에 제공함에 따라 응답받는 의료진 진료결과에 기초하여, 상기 정신질환 종류별 진단 알고리즘의 가중치 조절 여부를 판단하는 단계, 상기 사용자 질환 정보와 상기 의료진 진료결과가 서로 다른 경우, 상기 정신질환 종류별 진단 알고리즘의 각 가중치를 조절하는 단계 및 상기 사용자 질환 정보와 상기 의료진 진료결과가 서로 동일한 경우, 상기 사용자 질환 정보의 질환 상태를 분석하기 위한 심리테스트를 제공함에 따라 출력되는 테스트결과에 기초하여, 병행상담 치료 방법들 중 어느 하나의 병행 상담 치료 방법을 상기 사용자 단말에 제공하는 단계를 포함한다.  {\textbar}   {\textbar} 상기 사용자 이미지들을 수집하는 단계는 상기 사용자 정보가 진단 이력이 탐지되지 않는 경우, 상기 사용자 단말을 통해 촬영된 사용자 영상을 전송받는 단계, 상기 사용자 영상과 상기 기설정된 컨텐츠 영상을 합성 처리한 반응 유도 영상을 상기 사용자 단말에 제공하는 단계, 상기 반응 유도 영상이 재생되는 동안, 상기 사용자 영상으로부터 기설정된 이상 객체에 대응되는 상기 사용자 이미지들을 추출하여 수집하는 단계 및 상기 사용자 정보로부터 진단 이력이 탐지된 경우, 상기 저장 {DB로부터} 등록된 상기 사용자 질환 정보를 검출하여, 상기 사용자 질환 정보에 대한 도출 동작을 스킵시키는 단계를 포함한다.  {\textbar}   {\textbar} 상기 병원 리스트를 정렬하는 단계는 상기 진료과목을 진료받은 복수의 타 사용자 단말들로부터 병원 후기 정보를 등록받는 후기 게시판 웹페이지를 제공하는 단계, 상기 후기 게시판 웹페이지에 등록된 병원 후기 정보에 기초하여 병원 리스트에서 추천 병원 정보를 선별하는 단계 및 상기 해당 추천 병원 정보를 사용자가 식별가능하게 하도록 병원 리스트를 특정 색상을 통해 보정하는 단계를 포함한다.  {\textbar}   {\textbar} 상기 진료 예약을 중계 처리하는 단계는 상기 병원 리스트를 상기 사용자 단말에 중계함에 따라 선택받는 상기 병원 정보에 응답하여, 해당 병원 서버에 접속하여 진료 가능 시간을 검색하는 단계, 상기 진료 가능 시간을 상기 사용자 단말에 중계함에 따라 선택받는 상기 진료 시간에 응답하여, 상기 해당 병원 서버에 상기 사용자 정보에 대한 해당 병원의 진료 예약을 신청하는 단계 및 상기 해당 병원의 진료 예약이 신청 완료됨에 따라, 상기 해당 병원 서버로부터 발급되는 진료 예약 정보를 전송받아 상기 사용자 단말에 중계하는 단계를 포함한다.  {\textbar}   {\textbar} 본 발명의 실시예에 따르면, 인공지능 기반의 정신질환 종류별 진단 알고리즘을 이용하여, 사용자 질환 정보를 도출함으로써, 사용자에게 적합한 진료과목 및 병원을 보다 정확하게 제공할 수 있다.  {\textbar}   {\textbar} 또한, 사용자와 해당 병원 간의 진료 예약을 보다 효율적이고 신속하게 중계할 수 있다.  {\textbar}   {\textbar} 또한, 영상분석 기반의 진단테스트를 사용자 단말에 제공하여, 사용자의 이상반응에 해당하는 사용자 이미지를 용이하게 수집할 수 있다.  {\textbar}   {\textbar} 이하, 본 발명의 실시예와 도면을 참조하여 본 발명을 상세히 설명한다. 이들 실시예는 오로지 본 발명을 보다 구체적으로 설명하기 위해 예시적으로 제시한 것일 뿐, 본 발명의 범위가 이들 실시예에 의해 제한되지 않는다는 것은 당업계에서 통상의 지식을 가지는 자에 있어서 자명할 것이다. {\textbar}   {\textbar} 또한, 달리 정의하지 않는 한, 본 명세서에서 사용되는 모든 기술적 및 과학적 용어는 본 발명이 속하는 기술 분야의 숙련자에 의해 통상적으로 이해되는 바와 동일한 의미를 가지며, 상충되는 경우에는, 정의를 포함하는 본 명세서의 기재가 우선할 것이다. {\textbar}   {\textbar} 도면에서 제안된 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 그리고, 어떤 부분이 어떤 구성 요소를 "포함"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에서 기술한 "부"란, 특정 기능을 수행하는 하나의 단위 또는 블록을 의미한다. {\textbar}   {\textbar} 각 단계들에 있어 식별부호(제1, 제2, 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 실시될 수도 있고 실질적으로 동시에 실시될 수도 있으며 반대의 순서대로 실시될 수도 있다. {\textbar}   {\textbar} 도 1은 본 발명의 일 실시예에 따른 병원접수 중계 시스템(100)을 개략적으로 나타내는 도이다.  {\textbar}   {\textbar} 도 1을 참조하여 설명하면, 본 발명의 일 실시예에 따른 병원접수 중계 시스템(100)은 통신부(110), 수집부(120), 도출부(130), 정렬부(140) 및 중계 처리부(150)를 포함할 수 있다.  {\textbar}   {\textbar} 먼저, 통신부(110)는 사용자 단말(10)로부터 사용자 정보와 사용자 위치 정보를 전송받아 저장 {DB}(200)에 저장할 수 있다. 여기서, 사용자 정보는 개인 정보, 생체 정보 및 진단 이력 여부 정보를 포함할 수 있다.  {\textbar}   {\textbar} 다음으로, 수집부(120)는 사용자 정보로부터 탐지되는 진단 이력 여부에 기초하여, 정신 질환의 종류를 진단하기 위한 영상분석 기반의 진단테스트를 통해 사용자 이미지들을 수집할 수 있다.  {\textbar}   {\textbar} 여기서, 영상분석 기반의 진단테스트는 영상분석 기반의 진단테스트는 기설정된 컨텐츠 영상에서 이상 반응을 유도하기 위한 질의를 제공함에 따라 상기 사용자로부터 응답받는 화상통화 방식 서비스일 수 있다.  {\textbar}   {\textbar} 구체적으로, 수집부(120)는 사용자 정보로부터 진단 이력이 탐지되지 않는 경우, 사용자 단말(10)을 통해 촬영된 사용자 영상을 전송받을 수 있다. 그런 다음, 수집부(120)는 사용자의 이상 반응을 유도하기 위한 기설정된 컨텐츠 영상과 사용자 영상을 합성 처리한 반응 유도 영상을 사용자 단말(10)에 제공할 수 있다. 이때, 수집부(120)는 반응 유도 영상이 재생되는 동안, 사용자 영상으로부터 기설정된 이상객체에 대응되는 사용자 이미지들을 추출하여 수집할 수 있다.  {\textbar}   {\textbar} 한편, 수집부(120)는 사용자 정보로부터 진단 이력이 탐지된 경우, 저장 {DB}(200)로부터 등록된 사용자 질환 정보를 검출하여, 후술할 도출부(130)의 도출동작을 스킵시키고 정렬부(140)로 전송할 수 있다.  {\textbar}   {\textbar} 다음으로, 도출부(130)는 인공지능 기반의 정신질환 종류별 진단 알고리즘을 이용하여, 수집부(120)를 통해 수집된 사용자 이미지들에 대한 사용자 질환 정보를 도출하여 저장 {DB}(200)에 등록할 수 있다.  {\textbar}   {\textbar} 여기서, 사용자 질환 정보는 우울증, 조울증, 공황장애, 조현증, 치매 및 망상장애 중 적어도 하나의 정신과 질환의 종류를 의미할 수 있다.  {\textbar}   {\textbar} 한편, 저장 {DB}(200)는 환자군 대표 이미지들과 해당 환자군의 정신질환 종류를 사전에 수집하여 빅데이터로 저장 및 관리할 수 있다. 이때, 도출부(130)는 저장 {DB}(200)에 기수집된 환자군 이미지들과 해당 환자군의 정신질환 종류를 머신 러닝을 통해 학습함에 따라 인공지능 기반의 정신질환 종류별 진단 알고리즘을 사전에 생성하여 저장 {DB}(200)에 저장 및 관리할 수 있다.  {\textbar}   {\textbar} 여기서, 정신질환 종류별 진단 알고리즘은 사용자 이미지들을 각각 입력받아 정신질환의 종류마다 각 확률값을 도출하기 위한 복수의 알고리즘들을 포함할 수 있다. 예를 들면, 정신질환 종류별 진단 알고리즘은 우울증 진단 알고리즘, 조울증 진단 알고리즘, 공황장애 진단 알고리즘, 조현증 진단 알고리즘, 치매 진단 알고리즘 및 망상장애 진단 알고리즘을 포함할 수 있다.  {\textbar}   {\textbar} 즉, 정신질환 종류별 진단 알고리즘은 기수집된 환자군 대표 이미지들을 입력으로 입력받고, 해당 환자군의 정신질환 종류를 출력으로 입력받아 머신 러닝을 통해 생성되는 인공 신경 회로망(Artificial Neural Network), {SVM}(Support Vector Machine), 의사 결정 트리(Decision Tree) 및 랜덤 포레스트(Random Forest) 중 어느 하나의 알고리즘일 수 있다.  {\textbar}   {\textbar} 실시예에 따른 도출부(130)는 사용자 이미지들을 인공지능 기반의 정신질환 종류별 진단 알고리즘에 각각 적용함에 따라 도출되는 각 출력값의 크기에 기초하여, 대상자의 정신질환정보를 진단할 수 있다. 구체적으로, 도출부(130)는 각 인공지능 기반의 정신질환 종류별 진단 알고리즘을 통해 도출되는 출력값들 중 가장 큰 출력값에 해당하는 진단 알고리즘의 정신질환 종류를 사용자 질환 정보로 도출할 수 있다.  {\textbar}   {\textbar} 예를 들면, 우울증 진단 알고리즘을 통해 도출된 출력값이 50이고, 조울증 진단 알고리즘을 통해 도출된 출력값이 20이며, 공황장애 진단 알고리즘을 통해 도출된 출력값이 40이며, 나머지 진단 알고리즘을 통해 도출된 출력값이 10이하인 경우, 도출부(130)는 출력값이 가장 높은 우울증 진단 알고리즘에 대응되는 우울증을 사용자 질환 정보로 진단할 수 있다.  {\textbar}   {\textbar} 다음으로, 정렬부(140)는 기등록된 복수의 병원들 중 도출부(130)를 통해 도출되는 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 분류할 수 있다. 이때, 정렬부(140)는 분류된 병원 리스트를 사용자 위치 정보에 따라 근거리 순으로 정렬할 수 있다.  {\textbar}   {\textbar} 여기서, 병원 리스트는 병원마다 병원 이름, 진료과목 의사 정보, 위치 정보, 길안내 지도 정보 및 전화번호정보를 포함할 수 있다.  {\textbar}   {\textbar} 이때, 저장 {DB}(200)는 복수의 병원 서버들(11\_1{\textasciitilde}11\_N)을 사전에 등록하여, 해당 병원 리스트를 진료과목마다 분류하여 저장 및 관리할 수 있다.  {\textbar}   {\textbar} 실시예에 따라, 정렬부(140)는 사용자 질환 정보에 대응되는 진료과목을 진료받은 복수의 타 사용자 단말들(20\_1{\textasciitilde}20\_N)로부터 병원 후기 정보를 등록받는 후기 게시판 웹페이지를 제공할 수 있다.  {\textbar}   {\textbar} 이때, 정렬부(140)는 후기 게시판 웹페이지에 등록된 병원 후기 정보에 기초하여 병원 리스트에서 추천 병원 정보를 선별하고, 해당 추천 병원 정보를 사용자가 식별가능하게 하도록 병원 리스트를 특정 색상을 통해 보정할 수 있다.  {\textbar}   {\textbar} 다음으로, 중계 처리부(150)는 정렬부(140)를 통해 정렬된 병원 리스트를 사용자 단말(10)에 중계함에 따라 선택받는 병원 정보와 진료 시간에 기초하여, 사용자와 해당 병원 간의 진료 예약을 중계 처리할 수 있다.  {\textbar}   {\textbar} 구체적으로, 중계 처리부(150)는 정렬부(140)를 통해 정렬된 병원 리스트를 사용자 단말(10)에 중계함에 따라 선택받는 병원 정보에 응답하여, 해당 병원 서버(예컨대, 11\_1)에 접속하고 진료 가능 시간을 검색할 수 있다. 그런 다음, 중계 처리부(150)는 진료 가능 시간을 사용자 단말(10)에 중계함에 따라 선택받는 진료 시간에 응답하여, 해당 병원 서버(예컨대, 11\_1)에 사용자 정보에 대한 해당 병원의 진료 예약을 신청할 수 있다. 이때, 중계 처리부(150)는 해당 병원의 진료 예약이 신청 완료됨에 따라, 해당 병원 서버(예컨대, 11\_1)로부터 발급되는 진료 예약 정보를 전송받아 사용자 단말(10)에 중계할 수 있다.  {\textbar}   {\textbar} 일 실시예에 따라, 사용자와 해당 병원 간의 거리가 기설정된 거리를 초과할 때, 중계 처리부(150)는 사용자와 해당 병원 간의 진료 예약을 중계 처리하는 동안 사용자 위치로부터 해당 병원 까지의 길안내 정보를 기설정된 날짜에 사용자 단말(10)에 제공할 수 있다.  {\textbar}   {\textbar} 다른 실시예에 따라, 중계 처리부(150)는 진료 예약 시간을 기준으로, 사용자 단말(10)로부터 전송받는 사용자 위치 정보 변화에 기초하여 이동 동선을 확인하고, 이동 동선에 따른 이동 평균 속도에 기초하여 해당 병원 도착 시간을 산출하며, 사용자 이미지와 해당 병원 도착 시간을 해당 병원 서버(예컨대, 11\_1)에 제공할 수 있다. 이때, 중계 처리부(150)는 해당 병원 도착 시간을 해당 병원 서버(예컨대, 11\_1)에 제공함에 따라 전송받는 대기 환자 리스트를 사용자 단말(10)에 중계할 수 있다.  {\textbar}   {\textbar} 또 다른 실시예에 따라, 대기 환자 리스트가 기설정된 환자수 미만인 경우, 중계 처리부(150)는 사용자 단말(10)에 요청함에 따라 응답받는 사용자의 기본 상태 정보를 해당 병원 서버(예컨대, 11\_1)에 중계함으로써, 빠른 진료를 수행할 수 있게 지원할 수 있다. 여기서, 기본 상태 정보는 병원 진료시 사용자의 기본 상태를 체크하는 정보로, 식사 여부, 수면 시간, 고통 정도, 혈압, 키, 몸무게, 컨디션 상태 등을 포함할 수 있다.  {\textbar}   {\textbar} 이하, 구체적인 실시예와 비교예를 통하여 본 발명의 구성 및 그에 따른 효과를 보다 상세히 설명하고자 한다. 그러나, 본 실시예는 본 발명을 보다 구체적으로 설명하기 위한 것이며, 본 발명의 범위가 이들 실시예에 한정되는 것은 아니다. {\textbar}   {\textbar} 도 2는 도 1의 중계 처리부(150)의 일 실시예에 따른 동작을 설명하기 위한 도이다.  {\textbar}   {\textbar} 도 2를 참조하면, 중계 처리부(150)는 판단부(151), 가중치 조절부(152) 및 심리테스트 제공부(153)를 포함할 수 있다.  {\textbar}   {\textbar} 먼저, 판단부(151)는 상기 진료 예약이 중계 처리될 때, 사용자 질환 정보를 해당 병원 서버(예컨대, 11\_1)에 제공함에 따라 응답받는 의료진 진료결과에 기초하여, 인공지능 기반의 정신질환 종류별 진단 알고리즘에 대한 가중치의 조절 여부를 판단할 수 있다.  {\textbar}   {\textbar} 여기서, 의료진 진료결과는 사용자 정보에 대하여 진단되는 우울증, 조울증, 공황장애, 조현증, 치매 및 망상장애 중 적어도 어느 하나의 정신질환 종류를 의미할 수 있다. {\textbar}   {\textbar} 다음으로, 사용자 질환 정보와 의료진 진료결과가 서로 다른 경우, 가중치 조절부(152)는 인공지능 기반의 정신질환 종류별 진단 알고리즘의 각 가중치를 조절할 수 있다.  {\textbar}   {\textbar} 예를 들면, 사용자 질환 정보가 우울증이고, 의료진 진료결과가 조울증인 경우, 가중치 조절부(152)는 인공지능 기반의 정신질환 종류별 진단 알고리즘 중 우울증에 해당하는 우울증 진단 알고리즘을 통해 도출되는 출력값이 가장 크게 출력되도록 인공지능 기반의 정신질환 종류별 진단 알고리즘의 각 가중치를 조절할 수 있다.  {\textbar}   {\textbar} 다음으로, 사용자 질환 정보와 의료진 진료결과가 서로 동일한 경우, 심리테스트 제공부(153)는 질환 상태를 분석하기 위한 심리테스트를 제공함에 따라 출력되는 테스트결과에 기초하여, 상기 병행상담 치료 방법들 중 어느 하나의 병행 상담 치료 방법을 사용자 단말(10)에 제공할 수 있다.  {\textbar}   {\textbar} 여기서, 심리테스트는 질환 상태를 자가 판별하기 위하여, 기설정된 질의 사항에 따라 사용자 입력 정보를 입력받는 객관식 질의-응답 테스트일 수 있다. 이때, 병행상담 치료 방법들은 상담 치료, 놀이 치료, 미술 치료, 언어 치료, 독서 치료, 음악 치료, 연극 치료 및 학습 치료 중 적어도 하나 이상을 포함할 수 있다.  {\textbar}   {\textbar} 즉, 병행상담 치료 방법들은 객관식 질의-응답 테스트에 따른 테스트결과의 수치점수별로 대응될 수 있다.  {\textbar}   {\textbar} 도 3은 도 1의 병원접수 중계 시스템(100)의 동작 프로세스이다.  {\textbar}   {\textbar} 도 1과 도 3을 참조하면, 먼저, S110 단계에서, 통신부(110)는 사용자 단말(10)로부터 사용자 정보와 사용자 위치 정보를 전송받을 수 있다.  {\textbar}   {\textbar} 그런 다음, S120 단계에서, 수집부(120)는 사용자 정보로부터 탐지되는 진단 이력 여부에 기초하여, 정신 질환의 종류를 진단하기 위한 영상분석 기반의 진단테스트를 통해 사용자의 이상반응에 해당하는 사용자 이미지들을 수집할 수 있다.  {\textbar}   {\textbar} 이때, S130 단계에서, 도출부(130)는 저장 {DB}(200)에 사전에 저장된 인공지능 기반의 정신질환 종류별 진단 알고리즘을 이용하여, 수집부(120)를 통해 수집된 사용자 이미지들에 대한 사용자 질환 정보를 도출하고 저장 {DB}(200)에 등록할 수 있다.  {\textbar}   {\textbar} 한편, 도출부(130)는 S110 단계 이전에, 저장 {DB}(200)에 기수집된 환자군 이미지들과 해당 환자군의 정신질환 종류를 머신 러닝을 통해 학습함에 따라 정신질환 종류마다 인공지능 기반의 정신질환 종류별 진단 알고리즘을 생성하고 저장 {DB}(200)에 저장할 수 있다.  {\textbar}   {\textbar} 그런 다음, S140 단계에서, 정렬부(140)는 기등록된 복수의 병원들 중 도출부(130)를 통해 도출되는 사용자 질환 정보에 대응되는 진료과목을 전문적으로 진료하는 병원 리스트를 분류하고, 사용자 위치 정보에 따라 근거리 순으로 정렬할 수 있다.  {\textbar}   {\textbar} 이후, S150 단계에서, 중계 처리부(150)는 정렬부(140)를 통해 정렬된 병원 리스트를 사용자 단말(10)에 중계함에 따라 선택받는 병원 정보와 진료 시간에 기초하여, 사용자와 해당 병원 간의 진료 예약을 중계 처리할 수 있다.  {\textbar}   {\textbar} 도 4는 도 2의 중계 처리부(150)의 일 실시예에 따른 동작 프로세스이다.  {\textbar}   {\textbar} 도 1 내지 도 4를 참조하면, S210 단계에서, 상기 진료 예약이 중계 처리될 때, 판단부(151)는 사용자 질환 정보를 해당 병원 서버(예컨대, 11\_1)에 제공함에 따라 응답받는 의료진 진료결과에 기초하여, 인공지능 기반의 정신질환 종류별 진단 알고리즘에 대한 가중치 조절 여부를 판단할 수 있다.  {\textbar}   {\textbar} 이때, S220 단계에서, 사용자 질환 정보와 의료진 진료결과가 서로 다른 경우, 가중치 조절부(152)는 인공지능 기반의 정신질환 종류별 진단 알고리즘의 각 가중치를 조절할 수 있다.  {\textbar}   {\textbar} 한편, S230 단계에서, 사용자 질환 정보와 의료진 진료결과가 서로 동일한 경우, 심리테스트 제공부(153)는 질환 상태를 분석하기 위한 심리테스트를 제공함에 따라 출력되는 테스트결과에 기초하여, 병행상담 치료 방법들 중 어느 하나의 병행 상담 치료 방법을 사용자 단말(10)에 제공할 수 있다.  {\textbar}   {\textbar} 도 5는 도 1의 수집부(120)의 동작 프로세스이다.  {\textbar}   {\textbar} 도 1, 도 3 및 도 5를 참조하면, 먼저, S121 단계에서, 수집부(120)는 사용자 정보로부터 진단 이력이 탐지되지 않는 경우, 사용자 단말(10)을 통해 촬영된 사용자 영상을 전송받을 수 있다.  {\textbar}   {\textbar} 그런 다음, S122 단계에서, 수집부(120)는 사용자의 이상 반응을 유도하기 위한 기설정된 컨텐츠 영상과 사용자 영상을 합성 처리한 반응 유도 영상을 사용자 단말(10)에 제공할 수 있다.  {\textbar}   {\textbar} 이때, S123 단계에서, 수집부(120)는 반응 유도 영상이 재생되는 동안, 사용자 영상으로부터 기설정된 이상객체에 대응되는 사용자 이미지들을 추출하여 수집할 수 있다.  {\textbar}   {\textbar} 한편, S124 단계에서, 수집부(120)는 사용자 정보로부터 진단 이력이 탐지된 경우, 저장 {DB}(200)로부터 등록된 사용자 질환 정보를 검출하여, 상기 사용자 질환 정보에 대한 도출 동작을 스킵시킬 수 있다.  {\textbar}   {\textbar} 도 6은 도 1의 정렬부(140)의 동작 프로세스이다.  {\textbar}   {\textbar} 도 1, 도 3 및 도 6을 참조하면, 먼저, S141 단계에서, 정렬부(140)는 복수의 타 사용자 단말들(20\_1{\textasciitilde}20\_N)로부터 사용자 질환 정보에 대응되는 진료과목을 진료받은 병원 후기 정보를 등록받는 후기 게시판 웹페이지를 제공할 수 있다.  {\textbar}   {\textbar} 이때, S142 단계에서, 정렬부(140)는 후기 게시판 웹페이지에 등록된 병원 후기 정보에 기초하여 병원 리스트에서 추천 병원 정보를 선별할 수 있다.  {\textbar}   {\textbar} 이후, S143 단계에서, 정렬부(140)는 해당 추천 병원 정보를 사용자가 식별가능하게 하도록 병원 리스트를 특정 색상을 통해 보정할 수 있다.  {\textbar}   {\textbar} 도 7은 도 1의 중계 처리부(150)의 동작 프로세스이다.  {\textbar}   {\textbar} 도 1, 도 3 및 도 7을 참조하면, 먼저, S151 단계에서, 중계 처리부(150)는 병원 리스트를 사용자 단말(10)에 중계함에 따라 선택받는 병원 정보에 응답하여, 해당 병원 서버(예컨대, 11\_1)에 접속하고 진료 가능 시간을 검색할 수 있다.  {\textbar}   {\textbar} 그런 다음, S152 단계에서, 중계 처리부(150)는 진료 가능 시간을 사용자 단말(10)에 중계함에 따라 선택받는 진료 시간에 응답하여, 해당 병원 서버(예컨대, 11\_1)에 사용자 정보에 대한 해당 병원의 진료 예약을 신청할 수 있다.  {\textbar}   {\textbar} 이후, S153 단계에서, 중계 처리부(150)는 해당 병원의 진료 예약이 신청 완료됨에 따라, 해당 병원 서버(예컨대, 11\_1)로부터 발급되는 진료 예약 정보를 전송받아 사용자 단말(10)에 중계할 수 있다.  {\textbar}   {\textbar} 본 명세서에서는 본 발명자들이 수행한 다양한 실시예 가운데 몇 개의 예만을 들어 설명하는 것이나 본 발명의 기술적 사상은 이에 한정하거나 제한되지 않고, 당업자에 의해 변형되어 다양하게 실시될 수 있음은 물론이다.
Issue: {KR}2388763B1},
}

@patent{rajan_etal21,
	location = {{US}},
	title = {Methods and machine learning for disease diagnosis},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {A machine learning classifier that diagnoses autism spectrum disorder ({ASD}) is described that transforms data obtained from a patient medical history and a patients saliva into data that correspond to a test panel of features, the data for the features including human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for {ASD}. The classifier classifies the transformed data by applying the data to the classifier that has been trained to detect {ASD} using training data associated with the features of the test panel. The trained classifier includes vectors that define a classification boundary and predicts a probability of {ASD} based on results of the classifying.
A machine learning classifier that diagnoses autism spectrum disorder ({ASD}) is described that transforms data obtained from a patient medical history and a patients saliva into data that correspond to a test panel of features, the data for the features including human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for {ASD}. The classifier classifies the transformed data by applying the data to the classifier that has been trained to detect {ASD} using training data associated with the features of the test panel. The trained classifier includes vectors that define a classification boundary and predicts a probability of {ASD} based on results of the classifying.
A machine learning classifier that diagnoses autism spectrum disorder ({ASD}) is described that transforms data obtained from a patient medical history and a patients saliva into data that correspond to a test panel of features, the data for the features including human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for {ASD}. The classifier classifies the transformed data by applying the data to the classifier that has been trained to detect {ASD} using training data associated with the features of the test panel. The trained classifier includes vectors that define a classification boundary and predicts a probability of {ASD} based on results of the classifying.},
	type = {patent},
	author = {Rajan, Alexander and Hicks, Steven D. and Middleton, Frank A.},
	urldate = {2021-04-23},
	date = {2021-12-09},
	note = {Edition: G16H005020 {\textbar} G16B004000 {\textbar} G16H001020 {\textbar} G16H001040 {\textbar} G16H001060 {CPC} - G16H005020 {\textbar} C12Q000104 {\textbar} C12Q000114 {\textbar} G16B002000 {\textbar} G16B004000 {\textbar} G16H001020 {\textbar} G16H001040 {\textbar} G16H001060 {\textbar} C12Q00016883 {\textbar} C12Q0001689 {\textbar} C12Q2600178 {\textbar} G01N0033487 {\textbar} G01N28002835 {\textbar} G01N280038 {\textbar} Y02A009010 {EP}; {US} {EP}; {US} {US} {US} What is claimed is: {\textbar} {\textbar} 1 {\textbar} . A machine learning classifier that diagnoses autism spectrum disorder ({ASD}), comprising: {\textbar} processing circuitry that {\textbar} {\textbar} transforms data obtained from a patient medical history and a patient's saliva into data that correspond to a test panel of features, the data for the features including human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for {ASD}; and {\textbar} {\textbar} classifies the transformed data by applying the data to the processing circuitry that has been trained to detect {ASD} using training data associated with the features of the test panel, {\textbar} {\textbar} wherein the trained processing circuitry includes vectors that define a classification boundary. {\textbar} {\textbar} 2 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the trained processing circuitry is a support vector machine and the vectors that define the classification boundary are support vectors. {\textbar} 3 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the trained processing circuitry predicts a probability of {ASD} based on results of the classifying. {\textbar} 4 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the trained processing circuitry is a deep learning system that continues to learn based on additional transcriptome data. {\textbar} 5 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one micro {RNA} selected from the group consisting of hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410, hsa-mir-4461, hsa-{miR}-15a-5p, hsa-{miR}-6763-3p, hsa-{miR}-196a-5p, hsa-{miR}-4668-5p, hsa-{miR}-378d, hsa-{miR}-142-3p, hsa-mir-30c-1, hsa-mir-101-2, hsa-mir-151a, hsa-{miR}-125b-2-3p, hsa-mir-148a-5p, hsa-mir-548I, hsa-{miR}-98-5p, hsa-{miR}-8065, hsa-mir-378d-1, hsa-let-7f-1, hsa-let-7d-3p, {\textbar} hsa-let-7a-2, hsa-let-7f-2, hsa-let-7f-5p, hsa-mir-106a, hsa-mir-107, hsa-{miR}-10b-5p, hsa-{miR}-1244, hsa-{miR}-125a-5p, hsa-mir-1268a, hsa-{miR}-146a-5p, hsa-mir-155, hsa-mir-18a, hsa-mir-195, hsa-mir-199a-1, hsa-mir-19a, hsa-{miR}-218-5p, hsa-mir-29a, hsa-{miR}-29b-3p, hsa-{miR}-29c-3p, hsa-{miR}-3135b, hsa-mir-3182, hsa-mir-3665, hsa-mir-374a, hsa-mir-421, hsa-mir-4284, hsa-{miR}-4436b-3p, hsa-{miR}-4698, hsa-mir-4763, hsa-mir-4798, hsa-mir-502, hsa-{miR}-515-5p, hsa-mir-5572, hsa-{miR}-6724-5p, hsa-mir-6739, hsa-{miR}-6748-3p, and hsa-{miR}-6770-5p. {\textbar} {\textbar} 6 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one {piRNA} selected from the group consisting of {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684, {piR}-hsa-3405, {piR}-hsa-324, {piR}-hsa-18905, {piR}-hsa-23248, {piR}-hsa-28223, {piR}-hsa-28400, {piR}-hsa-1177, {piR} hsa-26592, {\textbar} {piR}-hsa-1136, R-hsa-26131, {piR}-hsa-27133, {piR}-hsa-27134, {piR}-hsa-27282, and {piR}-hsa-27728. {\textbar} {\textbar} 7 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one ribosomal {RNA} selected from the group consisting of {RNA}5S, {MTRNR}2L4, and {MTRNR}2L8. {\textbar} 8 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one small nucleolar {RNA} selected from the group consisting of {SNORD}118, {SNORD}29, {SNORD}53B, {SNORD}68, {SNORD}20, {SNORD}41, {SNORD}30, {SNORD}34, {SNORD}110, {SNORD}28, {SNORD}45B, and {SNORD}92. {\textbar} 9 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel which includes features of at least one long non-coding {RNA}. {\textbar} 10 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one microbe selected from the group consisting of {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIB}122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus, Rothia, Cryptococcus gattii {\textbar} {WM}276, {\textbar} Neisseriaceae, Rothia dentocariosa {\textbar} {ATCC} 17931, {\textbar} Chryseobacterium {\textbar} sp. {IHB} B 17019, {\textbar} Streptococcus agalactiae {\textbar} {CNCTC} 10/84, {\textbar} Streptococcus pneumoniae {\textbar} {SPNA}45, {\textbar} Tsukamurella paurometabola {\textbar} {DSM} 20162, {\textbar} Streptococcus mutans {\textbar} {UA}159-{FR}, {\textbar} Actinomyces oris, Comamonadaceae, Streptococcus halotolerans, Flavobacterium columnare, Streptomyces griseochromogenes, Neisseria, Porphyromonas, Streptococcus salivarius {\textbar} {CCHSS}3, {\textbar} Megasphaera elsdenii {\textbar} {DSM} 20460, {\textbar} Pasteurellaceae {\textbar} , an unclassified {\textbar} Burkholderiales, Arthrobacter, Dickeya, Jeotgalibacillus, Kocuria, Leuconostoc, Lysinibacillus, Maribacter, Methylophilus, Mycobacterium, Ottowia, Trichormus {\textbar} . {\textbar} 11 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the data from the patient's medical history corresponds to categorical patient features and numerical patient features, {\textbar} wherein the processing circuitry projects the categorical patient features onto principal components. {\textbar} {\textbar} 12 {\textbar} . The machine learning classifier of {\textbar} claim 11 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which comprises: {\textbar} seven of the patient data principal components and patient age; {\textbar} {\textbar} micro {RNAs} including: hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410; {\textbar} {\textbar} {piRNAs} including: {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684; {\textbar} {\textbar} small nucleolar {RNA} including: {SNORD}118; and {\textbar} {\textbar} microbes including: {\textbar} {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIF}3122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus {\textbar} . {\textbar} 13 {\textbar} . The machine learning classifier of {\textbar} claim 11 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which comprises: {\textbar} seven of the patient data principal components, patient age, and patient sex; {\textbar} {\textbar} micro {RNAs} including: hsa-let-7a-2, hsa-{miR}-10b-5p, hsa-{miR}-125a-5p, hsa-{miR}-125b-2-3p, hsa-{miR}-142-3p, hsa-{miR}-146a-5p, hsa-{miR}-218-5p, hsa-mir-378d-1, hsa-mir-410, hsa-mir-421, hsa-mir-4284, hsa-{miR}-4698, hsa-mir-4798, hsa-{miR}-515-5p, hsa-mir-5572, hsa-{miR}-6748-3p; {\textbar} {\textbar} {piRNAs} including: {piR}-hsa-12423, {piR}-hsa-15023, {piR}-hsa-18905, {piR}-hsa-23638, {piR}-hsa-24684, {piR}-hsa-27133, {piR}-hsa-324, {piR}-hsa-9491; {\textbar} {\textbar} long nucleolar {RNA}; {\textbar} {\textbar} microbes including: {\textbar} {\textbar} Actinomyces, Arthrobacter, Jeotgalibacillus, Leadbetterella, Leuconostoc, Mycobacterium, Ottowia, Saccharomyces {\textbar} ; and {\textbar} a microbial activity including: K00520, K14221, K01591, K02111, K14255, K1432, K00133, K03111. {\textbar} {\textbar} 14 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the test panel of features and the vectors that define the classification boundary are determined by the processing circuitry by fitting a predictive model with an increasing number of features in a Master Panel of features in ranked order until a predictive performance reaches a plateau. {\textbar} 15 {\textbar} . The machine learning classifier of {\textbar} claim 14 {\textbar} , wherein the predictive model is a support machine model. {\textbar} 16 {\textbar} . The machine learning classifier of {\textbar} claim 14 {\textbar} , wherein the predictive model is a support vector machine model with radial kernel. {\textbar} 17 {\textbar} . The machine learning classifier of {\textbar} claim 14 {\textbar} , wherein the data from the patient's medical history corresponds to categorical patient features and numerical patient features, {\textbar} wherein the processing circuitry projects the categorical patient features onto principal components, {\textbar} {\textbar} wherein the processing circuitry transforms the data into data that corresponds to the Master Panel of features which comprises: {\textbar} {\textbar} nine of the patient data principal components and patient age; {\textbar} {\textbar} micro {RNAs} including: hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410, hsa-mir-4461 hsa-{miR}-15a-5p, hsa-{miR}-6763-3p, hsa-{miR}-196a-5p, hsa-{miR}-4668-5p, hsa-{miR}-378d, hsa-{miR}-142-3p, hsa-mir-30c-1, hsa-mir-101-2, hsa-mir-151a, hsa-{miR}-125b-2-3p, hsa-mir-148a-5p, hsa-mir-548I, hsa-{miR}-98-5p, hsa-{miR}-8065, hsa-mir-378d-1, hsa-let-7f-1, and hsa-let-7d-3p; {\textbar} {\textbar} {piRNAs} including: {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684, {piR}-hsa-3405, {piR}-hsa-324, {piR}-hsa-18905, {piR}-hsa-23248, {piR}-hsa-28223, {piR}-hsa-28400, {piR}-hsa-1177, and {piR}-hsa-26592; {\textbar} {\textbar} small nucleolar {RNAs} including: {SNORD}118, {SNORD}29, {SNORD}53B, {SNORD}68, {SNORD}20, {SNORD}41, {SNORD}30, and {SNORD}34; {\textbar} {\textbar} ribosomal {RNAs} including: {RNA}5S, {MTRNR}2L4, and {MTRNR}2L8; {\textbar} {\textbar} long non-coding {RNA} including: {LOC}730338; {\textbar} {\textbar} microbes including: {\textbar} {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIB}122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus, Rothia, Cryptococcus gattii {\textbar} {WM}276, {\textbar} Neisseriaceae, Rothia dentocariosa {\textbar} {ATCC} 17931, {\textbar} Chryseobacterium {\textbar} sp. {IHB} B 17019, {\textbar} Streptococcus agalactiae {\textbar} {CNCTC} 10/84, {\textbar} Streptococcus pneumoniae {\textbar} {SPNA}45, {\textbar} Tsukamurella paurometabola {\textbar} {DSM} 20162, {\textbar} Streptococcus mutans {\textbar} {UA}159-{FR}, {\textbar} Actinomyces oris, Comamonadaceae, Streptococcus halotolerans, Flavobacterium columnare, Streptomyces griseochromogenes, Neisseria, Porphyromonas, Streptococcus salivarius {\textbar} {CCHSS} {\textbar} 3 {\textbar} , {\textbar} Megasphaera elsdenii {\textbar} {DSM} 20460, {\textbar} Pasteurellaceae {\textbar} , and an unclassified {\textbar} Burkholderiales {\textbar} . {\textbar} 18 {\textbar} . The machine learning classifier of {\textbar} claim 14 {\textbar} , wherein the processing circuitry determines the Test Panel of features which comprises: {\textbar} micro {RNAs} including: hsa\_let\_7d\_5p, hsa\_let\_7g\_5p, hsa\_miR\_101\_3p, hsa\_miR\_1307\_5p, hsa\_miR\_142\_5p, hsa\_miR\_151a\_3p, hsa\_miR\_15a\_5p, hsa\_miR\_210\_3p, hsa\_miR\_28\_3p, hsa\_miR\_29a\_3p, hsa\_miR\_3074\_5p, hsa\_miR 374a\_5p, hsa\_miR\_92a\_3p; {\textbar} {\textbar} {piRNAs} including: hsa-{piRNA}\_3499, hsa-{piRNA}\_1433, hsa-{piRNA}\_9843, hsa-{piRNA}\_2533; {\textbar} {\textbar} microbes including: {\textbar} {\textbar} Actinomyces meyeri, Eubacterium, Kocuria flava, Kocuria rhizophila, Kocuria turfanensis, Lactobacillus fermentum, Lysinibacillus sphaericus, Micrococcus luteus, Ottowia, Rothia dentocariosa, Streptococcus dysgalactiae {\textbar} ; {\textbar} a microbial activity including: K01867, K02005, K02795, K19972. {\textbar} {\textbar} 19 {\textbar} . A classification machine learning system, comprising: {\textbar} a data input device that receives as inputs human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; {\textbar} {\textbar} processing circuitry that transforms a plurality of features into an ideal form, determines and ranks each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranking across all the transcriptome data; {\textbar} {\textbar} the processing circuitry learns to detect the target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau, sets the features as a test panel, and sets a test model for the target medical condition based on patterns of the test panel features. {\textbar} {\textbar} 20 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the categories of the microtranscriptome data which include one or more of mature {microRNA}, precursor {microRNA}, {piRNA}, {snoRNA}, ribosomal {RNA}, long non-coding {RNA}, and microbes identified by {RNA}. {\textbar} 21 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the processing circuitry transforms the features which include {RNA} derived from saliva via {RNA} sequencing and microbial taxa identified by {RNA} derived from the saliva. {\textbar} 22 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the input data which includes patient data extracted from surveys and patient charts, {\textbar} wherein the processor circuitry modifies the rank of specific features that vary depending on the patient data. {\textbar} {\textbar} 23 {\textbar} . The classification machine learning system of {\textbar} claim 22 {\textbar} , wherein the processing circuitry transforms the features including patient data that varies based on circadian patient data, including one or more of time of collection of saliva sample, time since last meal, time since teeth hygiene treatment. {\textbar} 24 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the processing circuitry includes a stochastic gradient boosting machine circuitry that increases prediction accuracy for each feature type information identified with the categories, ranks each feature type information in order of prediction performance, and selects the top features within each category. {\textbar} 25 {\textbar} . The classification machine learning system of {\textbar} claim 24 {\textbar} , wherein the stochastic gradient boosting machine is a random forest variant of a stochastic gradient boosting logistic regression machine. {\textbar} 26 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the processor circuitry includes a support vector machine. {\textbar} 27 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the human data and microbial data that are specific to the target medical condition. {\textbar} 28 {\textbar} . The classification machine learning system of {\textbar} claim 27 {\textbar} , wherein the target medical condition is a condition from the group consisting of autism spectrum disorder, Parkinson's disease, and traumatic brain injury. {\textbar} 29 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the genetic data which includes other biomarkers. {\textbar} 30 {\textbar} . The classification machine learning system of {\textbar} claim 22 {\textbar} , wherein the data input device receives the patient data which includes one or more of time of day, body mass index, age, weight, geographical region of residence at a time that a biological sample is provided by the patient for purposes of obtaining the genetic data. {\textbar} 31 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the human microtranscriptome data which includes nucleotide sequences and a count for each sequence indicating abundance in a biological sample. {\textbar} 32 {\textbar} . A method performed by a machine learning system, the machine learning system including a data input device, and processor circuitry, the method comprising: {\textbar} receiving as inputs human microtranscriptome and microbial transcriptome data via the data input device, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; {\textbar} {\textbar} transforming, by the processing circuitry, a plurality of features into an ideal form; {\textbar} {\textbar} determining and ranking by the processor circuitry each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranking across all the transcriptome data; {\textbar} {\textbar} learning, by the processing circuitry, to detect a target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau; {\textbar} {\textbar} setting, by the processing circuitry, the features included as a test panel; and {\textbar} {\textbar} setting, by the processing circuitry, a test model for the target medical condition based on patterns of the test panel features. {\textbar} {\textbar} 33 {\textbar} . The method of {\textbar} claim 32 {\textbar} , wherein the receiving includes receiving categories of the microtranscriptome data which include one or more of mature {microRNA}, precursor {microRNA}, {piRNA}, {snoRNA}, ribosomal {RNA}, long non-coding {RNA}, and identified by {RNA}. {\textbar} 34 {\textbar} . The method of {\textbar} claim 32 {\textbar} , wherein the receiving includes receiving the features which include {RNA} derived from saliva via {RNA} sequencing and microbial taxa identified by {RNA} derived from the saliva. {\textbar} 35 {\textbar} . The method of {\textbar} claim 32 {\textbar} , further comprising receiving patient data extracted from surveys and patient charts; and {\textbar} modifying, by the circuitry, the rank of specific features that vary depending on the patient data. {\textbar} {\textbar} 36 {\textbar} . The method of {\textbar} claim 35 {\textbar} , wherein the receiving includes receiving the patient data that vary based on circadian patient data, including one or more of time of collection of saliva sample, time since last meal, time since teeth hygiene treatment. {\textbar} 37 {\textbar} . The method of {\textbar} claim 32 {\textbar} , wherein the target medical condition is a condition from the group consisting of autism spectrum disorder, Parkinson's disease, and traumatic brain injury. {\textbar} 38 {\textbar} . A non-transitory computer-readable storage medium storing program code, which when executed by a machine learning system, the machine learning system including a data input device, and processor circuitry, the program code performs a method comprising: {\textbar} receiving as inputs human microtranscriptome and microbial transcriptome data via the data input device, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; {\textbar} {\textbar} transforming a plurality of features into an ideal form; {\textbar} {\textbar} determining and ranking each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranking across all the transcriptome data; {\textbar} {\textbar} learning to detect a target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau; {\textbar} {\textbar} setting the features included as a test panel; and {\textbar} {\textbar} setting a test model for the target medical condition based on patterns of the test panel features. What is claimed is: {\textbar} {\textbar} 1 {\textbar} . A machine learning classifier that diagnoses autism spectrum disorder ({ASD}), comprising: {\textbar} processing circuitry that {\textbar} {\textbar} transforms data obtained from a patient medical history and a patient's saliva into data that correspond to a test panel of features, the data for the features including human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for {ASD}; and {\textbar} {\textbar} classifies the transformed data by applying the data to the processing circuitry that has been trained to detect {ASD} using training data associated with the features of the test panel, {\textbar} {\textbar} wherein the trained processing circuitry includes vectors that define a classification boundary. {\textbar} {\textbar} 2 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the trained processing circuitry is a support vector machine and the vectors that define the classification boundary are support vectors. {\textbar} 3 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the trained processing circuitry predicts a probability of {ASD} based on results of the classifying. {\textbar} 4 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the trained processing circuitry is a deep learning system that continues to learn based on additional transcriptome data. {\textbar} 5 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one micro {RNA} selected from the group consisting of hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410, hsa-mir-4461, hsa-{miR}-15a-5p, hsa-{miR}-6763-3p, hsa-{miR}-196a-5p, hsa-{miR}-4668-5p, hsa-{miR}-378d, hsa-{miR}-142-3p, hsa-mir-30c-1, hsa-mir-101-2, hsa-mir-151a, hsa-{miR}-125b-2-3p, hsa-mir-148a-5p, hsa-mir-548I, hsa-{miR}-98-5p, hsa-{miR}-8065, hsa-mir-378d-1, hsa-let-7f-1, hsa-let-7d-3p, {\textbar} hsa-let-7a-2, hsa-let-7f-2, hsa-let-7f-5p, hsa-mir-106a, hsa-mir-107, hsa-{miR}-10b-5p, hsa-{miR}-1244, hsa-{miR}-125a-5p, hsa-mir-1268a, hsa-{miR}-146a-5p, hsa-mir-155, hsa-mir-18a, hsa-mir-195, hsa-mir-199a-1, hsa-mir-19a, hsa-{miR}-218-5p, hsa-mir-29a, hsa-{miR}-29b-3p, hsa-{miR}-29c-3p, hsa-{miR}-3135b, hsa-mir-3182, hsa-mir-3665, hsa-mir-374a, hsa-mir-421, hsa-mir-4284, hsa-{miR}-4436b-3p, hsa-{miR}-4698, hsa-mir-4763, hsa-mir-4798, hsa-mir-502, hsa-{miR}-515-5p, hsa-mir-5572, hsa-{miR}-6724-5p, hsa-mir-6739, hsa-{miR}-6748-3p, and hsa-{miR}-6770-5p. {\textbar} {\textbar} 6 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one {piRNA} selected from the group consisting of {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684, {piR}-hsa-3405, {piR}-hsa-324, {piR}-hsa-18905, {piR}-hsa-23248, {piR}-hsa-28223, {piR}-hsa-28400, {piR}-hsa-1177, {piR} hsa-26592, {\textbar} {piR}-hsa-1136, R-hsa-26131, {piR}-hsa-27133, {piR}-hsa-27134, {piR}-hsa-27282, and {piR}-hsa-27728. {\textbar} {\textbar} 7 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one ribosomal {RNA} selected from the group consisting of {RNA}5S, {MTRNR}2L4, and {MTRNR}2L8. {\textbar} 8 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one small nucleolar {RNA} selected from the group consisting of {SNORD}118, {SNORD}29, {SNORD}53B, {SNORD}68, {SNORD}20, {SNORD}41, {SNORD}30, {SNORD}34, {SNORD}110, {SNORD}28, {SNORD}45B, and {SNORD}92. {\textbar} 9 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel which includes features of at least one long non-coding {RNA}. {\textbar} 10 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which includes at least one microbe selected from the group consisting of {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIB}122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus, Rothia, Cryptococcus gattii {\textbar} {WM}276, {\textbar} Neisseriaceae, Rothia dentocariosa {\textbar} {ATCC} 17931, {\textbar} Chryseobacterium {\textbar} sp. {IHB} B 17019, {\textbar} Streptococcus agalactiae {\textbar} {CNCTC} 10/84, {\textbar} Streptococcus pneumoniae {\textbar} {SPNA}45, {\textbar} Tsukamurella paurometabola {\textbar} {DSM} 20162, {\textbar} Streptococcus mutans {\textbar} {UA}159-{FR}, {\textbar} Actinomyces oris, Comamonadaceae, Streptococcus halotolerans, Flavobacterium columnare, Streptomyces griseochromogenes, Neisseria, Porphyromonas, Streptococcus salivarius {\textbar} {CCHSS}3, {\textbar} Megasphaera elsdenii {\textbar} {DSM} 20460, {\textbar} Pasteurellaceae {\textbar} , an unclassified {\textbar} Burkholderiales, Arthrobacter, Dickeya, Jeotgalibacillus, Kocuria, Leuconostoc, Lysinibacillus, Maribacter, Methylophilus, Mycobacterium, Ottowia, Trichormus {\textbar} . {\textbar} 11 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the data from the patient's medical history corresponds to categorical patient features and numerical patient features, {\textbar} wherein the processing circuitry projects the categorical patient features onto principal components. {\textbar} {\textbar} 12 {\textbar} . The machine learning classifier of {\textbar} claim 11 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which comprises: {\textbar} seven of the patient data principal components and patient age; {\textbar} {\textbar} micro {RNAs} including: hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410; {\textbar} {\textbar} {piRNAs} including: {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684; {\textbar} {\textbar} small nucleolar {RNA} including: {SNORD}118; and {\textbar} {\textbar} microbes including: {\textbar} {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIF}3122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus {\textbar} . {\textbar} 13 {\textbar} . The machine learning classifier of {\textbar} claim 11 {\textbar} , wherein the processing circuitry transforms the data into data that corresponds to the test panel of features which comprises: {\textbar} seven of the patient data principal components, patient age, and patient sex; {\textbar} {\textbar} micro {RNAs} including: hsa-let-7a-2, hsa-{miR}-10b-5p, hsa-{miR}-125a-5p, hsa-{miR}-125b-2-3p, hsa-{miR}-142-3p, hsa-{miR}-146a-5p, hsa-{miR}-218-5p, hsa-mir-378d-1, hsa-mir-410, hsa-mir-421, hsa-mir-4284, hsa-{miR}-4698, hsa-mir-4798, hsa-{miR}-515-5p, hsa-mir-5572, hsa-{miR}-6748-3p; {\textbar} {\textbar} {piRNAs} including: {piR}-hsa-12423, {piR}-hsa-15023, {piR}-hsa-18905, {piR}-hsa-23638, {piR}-hsa-24684, {piR}-hsa-27133, {piR}-hsa-324, {piR}-hsa-9491; {\textbar} {\textbar} long nucleolar {RNA}; {\textbar} {\textbar} microbes including: {\textbar} {\textbar} Actinomyces, Arthrobacter, Jeotgalibacillus, Leadbetterella, Leuconostoc, Mycobacterium, Ottowia, Saccharomyces {\textbar} ; and {\textbar} a microbial activity including: K00520, K14221, K01591, K02111, K14255, K1432, K00133, K03111. {\textbar} {\textbar} 14 {\textbar} . The machine learning classifier of {\textbar} claim 1 {\textbar} , wherein the test panel of features and the vectors that define the classification boundary are determined by the processing circuitry by fitting a predictive model with an increasing number of features in a Master Panel of features in ranked order until a predictive performance reaches a plateau. {\textbar} 15 {\textbar} . The machine learning classifier of {\textbar} claim 14 {\textbar} , wherein the predictive model is a support machine model. {\textbar} 16 {\textbar} . The machine learning classifier of {\textbar} claim 14 {\textbar} , wherein the predictive model is a support vector machine model with radial kernel. {\textbar} 17 {\textbar} . The machine learning classifier of {\textbar} claim 14 {\textbar} , wherein the data from the patient's medical history corresponds to categorical patient features and numerical patient features, {\textbar} wherein the processing circuitry projects the categorical patient features onto principal components, {\textbar} {\textbar} wherein the processing circuitry transforms the data into data that corresponds to the Master Panel of features which comprises: {\textbar} {\textbar} nine of the patient data principal components and patient age; {\textbar} {\textbar} micro {RNAs} including: hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410, hsa-mir-4461 hsa-{miR}-15a-5p, hsa-{miR}-6763-3p, hsa-{miR}-196a-5p, hsa-{miR}-4668-5p, hsa-{miR}-378d, hsa-{miR}-142-3p, hsa-mir-30c-1, hsa-mir-101-2, hsa-mir-151a, hsa-{miR}-125b-2-3p, hsa-mir-148a-5p, hsa-mir-548I, hsa-{miR}-98-5p, hsa-{miR}-8065, hsa-mir-378d-1, hsa-let-7f-1, and hsa-let-7d-3p; {\textbar} {\textbar} {piRNAs} including: {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684, {piR}-hsa-3405, {piR}-hsa-324, {piR}-hsa-18905, {piR}-hsa-23248, {piR}-hsa-28223, {piR}-hsa-28400, {piR}-hsa-1177, and {piR}-hsa-26592; {\textbar} {\textbar} small nucleolar {RNAs} including: {SNORD}118, {SNORD}29, {SNORD}53B, {SNORD}68, {SNORD}20, {SNORD}41, {SNORD}30, and {SNORD}34; {\textbar} {\textbar} ribosomal {RNAs} including: {RNA}5S, {MTRNR}2L4, and {MTRNR}2L8; {\textbar} {\textbar} long non-coding {RNA} including: {LOC}730338; {\textbar} {\textbar} microbes including: {\textbar} {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIB}122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus, Rothia, Cryptococcus gattii {\textbar} {WM}276, {\textbar} Neisseriaceae, Rothia dentocariosa {\textbar} {ATCC} 17931, {\textbar} Chryseobacterium {\textbar} sp. {IHB} B 17019, {\textbar} Streptococcus agalactiae {\textbar} {CNCTC} 10/84, {\textbar} Streptococcus pneumoniae {\textbar} {SPNA}45, {\textbar} Tsukamurella paurometabola {\textbar} {DSM} 20162, {\textbar} Streptococcus mutans {\textbar} {UA}159-{FR}, {\textbar} Actinomyces oris, Comamonadaceae, Streptococcus halotolerans, Flavobacterium columnare, Streptomyces griseochromogenes, Neisseria, Porphyromonas, Streptococcus salivarius {\textbar} {CCHSS} {\textbar} 3 {\textbar} , {\textbar} Megasphaera elsdenii {\textbar} {DSM} 20460, {\textbar} Pasteurellaceae {\textbar} , and an unclassified {\textbar} Burkholderiales {\textbar} . {\textbar} 18 {\textbar} . The machine learning classifier of {\textbar} claim 14 {\textbar} , wherein the processing circuitry determines the Test Panel of features which comprises: {\textbar} micro {RNAs} including: hsa\_let\_7d\_5p, hsa\_let\_7g\_5p, hsa\_miR\_101\_3p, hsa\_miR\_1307\_5p, hsa\_miR\_142\_5p, hsa\_miR\_151a\_3p, hsa\_miR\_15a\_5p, hsa\_miR\_210\_3p, hsa\_miR\_28\_3p, hsa\_miR\_29a\_3p, hsa\_miR\_3074\_5p, hsa\_miR 374a\_5p, hsa\_miR\_92a\_3p; {\textbar} {\textbar} {piRNAs} including: hsa-{piRNA}\_3499, hsa-{piRNA}\_1433, hsa-{piRNA}\_9843, hsa-{piRNA}\_2533; {\textbar} {\textbar} microbes including: {\textbar} {\textbar} Actinomyces meyeri, Eubacterium, Kocuria flava, Kocuria rhizophila, Kocuria turfanensis, Lactobacillus fermentum, Lysinibacillus sphaericus, Micrococcus luteus, Ottowia, Rothia dentocariosa, Streptococcus dysgalactiae {\textbar} ; {\textbar} a microbial activity including: K01867, K02005, K02795, K19972. {\textbar} {\textbar} 19 {\textbar} . A classification machine learning system, comprising: {\textbar} a data input device that receives as inputs human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; {\textbar} {\textbar} processing circuitry that transforms a plurality of features into an ideal form, determines and ranks each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranking across all the transcriptome data; {\textbar} {\textbar} the processing circuitry learns to detect the target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau, sets the features as a test panel, and sets a test model for the target medical condition based on patterns of the test panel features. {\textbar} {\textbar} 20 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the categories of the microtranscriptome data which include one or more of mature {microRNA}, precursor {microRNA}, {piRNA}, {snoRNA}, ribosomal {RNA}, long non-coding {RNA}, and microbes identified by {RNA}. {\textbar} 21 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the processing circuitry transforms the features which include {RNA} derived from saliva via {RNA} sequencing and microbial taxa identified by {RNA} derived from the saliva. {\textbar} 22 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the input data which includes patient data extracted from surveys and patient charts, {\textbar} wherein the processor circuitry modifies the rank of specific features that vary depending on the patient data. {\textbar} {\textbar} 23 {\textbar} . The classification machine learning system of {\textbar} claim 22 {\textbar} , wherein the processing circuitry transforms the features including patient data that varies based on circadian patient data, including one or more of time of collection of saliva sample, time since last meal, time since teeth hygiene treatment. {\textbar} 24 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the processing circuitry includes a stochastic gradient boosting machine circuitry that increases prediction accuracy for each feature type information identified with the categories, ranks each feature type information in order of prediction performance, and selects the top features within each category. {\textbar} 25 {\textbar} . The classification machine learning system of {\textbar} claim 24 {\textbar} , wherein the stochastic gradient boosting machine is a random forest variant of a stochastic gradient boosting logistic regression machine. {\textbar} 26 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the processor circuitry includes a support vector machine. {\textbar} 27 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the human data and microbial data that are specific to the target medical condition. {\textbar} 28 {\textbar} . The classification machine learning system of {\textbar} claim 27 {\textbar} , wherein the target medical condition is a condition from the group consisting of autism spectrum disorder, Parkinson's disease, and traumatic brain injury. {\textbar} 29 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the genetic data which includes other biomarkers. {\textbar} 30 {\textbar} . The classification machine learning system of {\textbar} claim 22 {\textbar} , wherein the data input device receives the patient data which includes one or more of time of day, body mass index, age, weight, geographical region of residence at a time that a biological sample is provided by the patient for purposes of obtaining the genetic data. {\textbar} 31 {\textbar} . The classification machine learning system of {\textbar} claim 19 {\textbar} , wherein the data input device receives the human microtranscriptome data which includes nucleotide sequences and a count for each sequence indicating abundance in a biological sample. {\textbar} 32 {\textbar} . A method performed by a machine learning system, the machine learning system including a data input device, and processor circuitry, the method comprising: {\textbar} receiving as inputs human microtranscriptome and microbial transcriptome data via the data input device, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; {\textbar} {\textbar} transforming, by the processing circuitry, a plurality of features into an ideal form; {\textbar} {\textbar} determining and ranking by the processor circuitry each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranking across all the transcriptome data; {\textbar} {\textbar} learning, by the processing circuitry, to detect a target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau; {\textbar} {\textbar} setting, by the processing circuitry, the features included as a test panel; and {\textbar} {\textbar} setting, by the processing circuitry, a test model for the target medical condition based on patterns of the test panel features. {\textbar} {\textbar} 33 {\textbar} . The method of {\textbar} claim 32 {\textbar} , wherein the receiving includes receiving categories of the microtranscriptome data which include one or more of mature {microRNA}, precursor {microRNA}, {piRNA}, {snoRNA}, ribosomal {RNA}, long non-coding {RNA}, and identified by {RNA}. {\textbar} 34 {\textbar} . The method of {\textbar} claim 32 {\textbar} , wherein the receiving includes receiving the features which include {RNA} derived from saliva via {RNA} sequencing and microbial taxa identified by {RNA} derived from the saliva. {\textbar} 35 {\textbar} . The method of {\textbar} claim 32 {\textbar} , further comprising receiving patient data extracted from surveys and patient charts; and {\textbar} modifying, by the circuitry, the rank of specific features that vary depending on the patient data. {\textbar} {\textbar} 36 {\textbar} . The method of {\textbar} claim 35 {\textbar} , wherein the receiving includes receiving the patient data that vary based on circadian patient data, including one or more of time of collection of saliva sample, time since last meal, time since teeth hygiene treatment. {\textbar} 37 {\textbar} . The method of {\textbar} claim 32 {\textbar} , wherein the target medical condition is a condition from the group consisting of autism spectrum disorder, Parkinson's disease, and traumatic brain injury. {\textbar} 38 {\textbar} . A non-transitory computer-readable storage medium storing program code, which when executed by a machine learning system, the machine learning system including a data input device, and processor circuitry, the program code performs a method comprising: {\textbar} receiving as inputs human microtranscriptome and microbial transcriptome data via the data input device, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; {\textbar} {\textbar} transforming a plurality of features into an ideal form; {\textbar} {\textbar} determining and ranking each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranking across all the transcriptome data; {\textbar} {\textbar} learning to detect a target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau; {\textbar} {\textbar} setting the features included as a test panel; and {\textbar} {\textbar} setting a test model for the target medical condition based on patterns of the test panel features. 1 {\textbar} . A machine learning classifier that diagnoses autism spectrum disorder ({ASD}), comprising: {\textbar} processing circuitry that {\textbar} {\textbar} transforms data obtained from a patient medical history and a patient's saliva into data that correspond to a test panel of features, the data for the features including human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for {ASD}; and {\textbar} {\textbar} classifies the transformed data by applying the data to the processing circuitry that has been trained to detect {ASD} using training data associated with the features of the test panel, {\textbar} {\textbar} wherein the trained processing circuitry includes vectors that define a classification boundary. 1 {\textbar} . A machine learning classifier that diagnoses autism spectrum disorder ({ASD}), comprising: {\textbar} processing circuitry that {\textbar} {\textbar} transforms data obtained from a patient medical history and a patient's saliva into data that correspond to a test panel of features, the data for the features including human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for {ASD}; and {\textbar} {\textbar} classifies the transformed data by applying the data to the processing circuitry that has been trained to detect {ASD} using training data associated with the features of the test panel, {\textbar} {\textbar} wherein the trained processing circuitry includes vectors that define a classification boundary. {CROSS}-{REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar} {\textbar} This application is related to Provisional Patent Application Nos. 62/816,328 filed Mar. 11, 2019; 62/750,378, filed Oct. 25, 2018; 62/750,401, tiled Oct. 25, 2018; 62/474,339, filed Mar. 21, 2017; 62/484,357, filed Apr. 11, 2017; 62/484,332, filed Apr. 11, 2017; 62/502,124, filed May 5, 2017; 62/554,154, filed Sep. 5, 2017; 62/590,446, filed Nov. 24, 2017; 62/622,319, filed Jan. 26, 2018; 62/622,341, filed Jan. 26, 2018; and 62/665,056, tiled May 1, 2018, the entire contents of which are incorporated herein by reference. {\textbar} {\textbar} This application is related to International Application Nos. {PCT}/{US}18/23336, filed Mar. 20, 2018; {PCT}/{US}18/23821, filed Mar. 22, 2018; and {PCT}/{US}18/24111, filed Mar. 23, 2018, the entire contents of which are incorporated herein by reference. {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} A more complete appreciation of the invention and many of the attendant advantages thereof will be readily obtained as the same becomes better understood by reference to the following detailed description when considered in connection with the accompanying drawings, wherein: {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a flowchart for a method of developing a machine learning model to diagnose a target medical condition in accordance with exemplary aspects of the disclosure; {\textbar} {FIG}. 2 {\textbar} {\textbar} is a flowchart for the data collection step of {\textbar} {FIG}. 1 {\textbar} ; {\textbar} {FIG}. 3 {\textbar} {\textbar} is a system diagram for development and testing a machine learning model for diagnosing a medical condition in accordance with exemplary aspects of the disclosure; {\textbar} {FIG}. 4 {\textbar} {\textbar} is a flowchart for the data transforming step of {\textbar} {FIG}. 1 {\textbar} ; {\textbar} {FIG}. 5 {\textbar} {\textbar} is a flowchart for the feature selection and ranking step of {\textbar} {FIG}. 1 {\textbar} ; {\textbar} {FIG}. 6 {\textbar} {\textbar} is a flowchart for the test panel selecting step of {\textbar} {FIG}. 1 {\textbar} ; {\textbar} {FIG}. 7 {\textbar} {\textbar} is a flowchart for the test sample testing step of {\textbar} {FIG}. 1 {\textbar} ; {\textbar} {FIG}. 8 {\textbar} {\textbar} is a diagram for a neural network architecture in accordance with an exemplary aspect of the disclosure. {\textbar} {FIG}. 9 {\textbar} {\textbar} is a schematic for an exemplary deep learning architecture. {\textbar} {FIG}. 10 {\textbar} {\textbar} is a schematic for a hierarchical classifier in accordance with an exemplary aspect of the disclosure. {\textbar} {FIG}. 11 {\textbar} {\textbar} is a flowchart for developing a machine learning model for {ASD} in accordance with exemplary aspects of the disclosure; {\textbar} {FIGS}. 12A, 12B, 12C {\textbar} {\textbar} is an exemplary Master Panel resulting from applying processing according to the method of {\textbar} {FIG}. 8 {\textbar} ; {\textbar} {FIGS}. 13A, 13B, 13C, 13D {\textbar} {\textbar} is a further exemplary Master Panel resulting from applying processing according to the method of {\textbar} {FIG}. 8 {\textbar} ; {\textbar} {FIG}. 14 {\textbar} {\textbar} is an exemplary Test Panel resulting from applying processing according to the method of {\textbar} {FIG}. 8 {\textbar} ; {\textbar} {FIG}. 15 {\textbar} {\textbar} is a flowchart for a machine learning model for determining a probability of being affected by {ASD}; and {\textbar} {FIG}. 16 {\textbar} {\textbar} is a system diagram for a computer in accordance with exemplary aspects of the disclosure. {\textbar} {BACKGROUND} {\textbar} {\textbar} Field of the Disclosure {\textbar} {\textbar} The present disclosure relates generally to a machine learning system and method that may be used, for example, diagnosing of mental disorders and diseases, including Autism Spectrum Disorder and Parkinson's Disease, or brain injuries, including Traumatic Brain Injury and Concussion. {\textbar} {\textbar} Description of the Related Art {\textbar} {\textbar} Certain biological molecules are present, absent, or have different abundances in people with a particular medical condition as compared to people without the condition. These biological molecules have the potential to be used as an aid to diagnose medical conditions accurately and early in the course of development of the condition. As such, certain biological molecules are considered as a type of biomarker that can indicate the presence, absence, or degree of severity of a medical condition. Principal types of biomarkers include proteins and nucleic acids; {DNA} and {RNA}. Diagnostic tests using biomarkers require obtaining a sample of a biologic material, such as tissue or body fluid, from which the biomarkers can be extracted and quantified. Diagnostic tests that use a non-invasive sampling procedure, such as collecting saliva, are preferred over tests that require an invasive sampling procedure such as biopsy or drawing blood. {RNA} is an attractive candidate biomarker because certain types of {RNA} are secreted by cells, are present in saliva, and are accessible via non-invasive sampling. {\textbar} {\textbar} A problem that affects use of biomarkers as diagnostic aids is that while the relative quantities of a biomarker or a set of biomarkers may differ in biologic samples between people with and without a medical condition, tests that are based on differences in quantity often are not sensitive and specific enough to be effectively used for diagnosis. In other words, the quantities of many biomarkers vary between people with and without a condition, but very few biomarkers have an established normal range which has a simple relationship with a condition, such that if a measurement of a person's biomarker is outside of the range there is a high probability that the person has the condition. {\textbar} {\textbar} Although extensive studies have been made on biomarkers and their relationship to medical conditions, the relationships are often complex with no simple biomarker quantity range that can accurately predict with high probability that a person has a medical condition. Other factors are involved, such as environmental factors and differences in patient characteristics. Huge numbers of microorganisms inhabit the human body, especially the gastrointestinal tract, and it is known that there are many biologic interactions between a person and the population of microbes that inhabit the person's body. The species, abundance, and activity of microbes that make up the human microbiome vary between individuals for a number of reasons, including diet, geographic region, and certain medical conditions. Biomarker quantities may not only vary due to medical conditions, but may also be affected by characteristics of a patient and conditions under which samples are taken. Biomarker quantities may be affected by differences in patient characteristics, such as age, sex, body mass index, and ethnicity. Biomarker quantities may be impacted by clinical characteristics, such as time of sample collection and time since last meal. Thus, the potential number of factors that may need to be considered in order to accurately predict a medical condition may be very large. {\textbar} {\textbar} {SUMMARY} {OF} {THE} {INVENTION} {\textbar} {\textbar} With a large number of possible factors to consider and no easy way of correlating the factors with a medical condition, machine learning methods have been viewed as viable techniques for medical diagnosis, Machine learning methods have been used in designing test models that are implemented in software for use in identifying patterns of information and classifying the patterns of information. However, even machine learning methods require a certain level of knowledge, such as which factors represent a medical condition and which of those factors are necessary for achieving high prediction accuracy. If a machine learning method is accurate on data it was trained on but does not accurately predict diagnosis in new patients, the model may be overfitting the training cohort and not generalize well to the general population. In order to develop a machine learning model to accurately diagnose a medical condition, a set of features that best predicts the medical condition needs to be discovered. A problem occurs, however, that the set of features that best predicts the medical condition is typically not yet known. {\textbar} {\textbar} There is a need for a method of accurately predicting a medical condition in a patient characterized by feature values that a machine learning method has not previously seen by way of a training method that can determine a set of features that will enable prediction of the medical condition with high precision and recall. {\textbar} {\textbar} These and other objects of the present invention will become more apparent in conjunction with the following detailed description of the preferred embodiments, either alone or in combinations thereof. {\textbar} {\textbar} {DETAILED} {DESCRIPTION} {\textbar} {\textbar} As used herein any reference to “one embodiment” or “some embodiments” or “an embodiment” means that a particular element, feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase “in one embodiment” in various places in the specification are not necessarily all referring to the same embodiment. Conditional language used herein, such as, among others, “can,” “could,” “might,” “may,” “e.g.,” and the like, unless specifically stated otherwise, or otherwise understood within the context as used, is generally intended to convey that certain embodiments include, while other embodiments do not include, certain features, elements and/or steps. In addition, the articles “a” and “an” as used in this application and the appended claims are to be construed to mean “one or more” or “at least one” unless specified otherwise. {\textbar} {\textbar} The following description relates to a system and method for diagnosing a medical condition, i.n particular medical conditions related to the central nervous system and brain injury. The method optimizes the diagnostic capability of a machine learning model for the particular medical condition. {\textbar} {\textbar} Supervised machine learning is a category of methods for developing a predictive model using labelled training examples, and once trained a machine learning model may be used to predict the disorder state of a patient using a machine learned, previously unknown function, Supervised machine learning models may be taught to learn linear and non-linear functions. The training examples are typically a set of features and a known classification of the sampled features. {\textbar} {\textbar} From another perspective, the data itself may not be ideal. For example, photographs used for training a machine learning model may not clearly show a person's hair, or clearly distinguish a person's hair from a background. There will be noise in the data, introduced by biological or technical variation and imperfect methods. Also, there may be correlations between features: features may not be independent from one another. In such a case, highly correlated features may be removed as redundant. {\textbar} {\textbar} As described above, features related to diagnosis of a medical condition may be extensive and the relationship between the features and condition is not as simple as a range of quantities of biological molecules that are contained in a sample. The range of quantities themselves may vary due to other environmental and patient-related factors. An objective of the present disclosure is to combine human {RNA} biomarkers, microbial {RNA} biomarkers, and patient information or health records in order to select a subset of features that improves the performance of a machine learning model. Doing so may additionally optimize the diagnostic capability of the machine learning model to aid diagnosis of patients at earlier developmental stages or stages of disease progression. {\textbar} {\textbar} A molecular biomarker is a measurable indicator of the presence, absence, or severity of some disease state. Among types of molecules that can be used as biomarkers, {RNA} is an attractive candidate biomarker because certain types of {RNA} are secreted by cells, are present in saliva, and are accessible via non-invasive sampling. Human non-coding regulatory {RNAs}, oral microbiota identities (a taxonomic class, such as species, genus, or family), and {RNA} activity are able to provide biological information at many different levels: genomic, epigenomic, proteomic, and metabolomic. {\textbar} {\textbar} Human non-coding regulatory {RNA} ({ncRNA}) is a functional {RNA} molecule. {ncRNAs} are considered non-coding because they are not translated into proteins. Types of human non-coding {RNA} include transfer {RNAs} ({tRNAs}) and ribosomal {RNAs} ({rRNAs}), as well as small {RNAs} such as {microRNAs} ({miRNAs}), short interfering {RNAs} ({siRNAs}), {PIWI}-interacting {RNAs} ({piRNAs}), small nucleolar {RNAs} ({snoRNAs}), small nuclear {RNAs} ({snRNAs}), and the long {ncRNAs} such as long intergenic noncoding {RNAs} ({lincRNAS}). {\textbar} {\textbar} {MicroRNAs} are short non-coding {RNA} molecules containing 19-24 nucleotides that bind to {mRNA}, and silence and regulate gene expression via the binding (see Ambros et al., 2004; Bartel et al, 2004). {MicroRNAs} affect expression of the majority of human genes, including {CLOCK}, {BMAL}1, and other circadian genes. Each {miRNA} can bind to many {mRNAs}, and each {mRNA} may be targeted by several {miRNAs}. Notably, {miRNAs} are released by the cells that make them and circulate throughout the body in all extracellular fluids, where they interact with other tissues and cells. Recent evidence has shown that human {miRNAs} even interact with the population of bacterial cells that inhabit the lower gastrointestinal tract, termed the gut microbiome (Yuan et al., 2018). Moreover, circadian changes in {miRNA} abundance have recently been established (Hicks et al., 2018). {\textbar} {\textbar} The many-to-many divergence and convergence, combined with cell-to-cell transport of {miRNAs}, suggests a critical systemic regulatory role for {miRNAs}. Nearly 70\% of mi.{RNAs} are expressed in the brain, and their expression changes throughout neurodevelopment and varies across brain regions. Neurogenesis, synaptogenesis, neuronal migration, and memory all involve {miRNAs}, which are readily transported across the blood-brain-barrier. Together, these features explain why {miRNA} expression may be “altered” in the {CNS} of people with neurological disorders, and why these alterations are easily measured in peripheral biofluids, such as saliva. {\textbar} {\textbar} A {miRNA} standard nomenclature system uses “{miR}” followed by a dash and a number, the latter often indicating order of naming. For example, {miR}-120 was named and likely discovered prior to {miR}-241. A capitalized “{miR}-” refers to the mature form of the {miRNA}, while the uncapitalized “mir-” refers to the pre-{miRNA} and the pri-{miRNA}, and “{MIR}” refers to the gene that encodes them. Human {miRNAs} are denoted with the prefix “hsa-”. {\textbar} {\textbar} {miRNA} elements. Extracellular transport of {miRNA} via exosomes and other microvesicles and lipophilic carriers is an established epigenetic mechanism for cells to alter gene expression in nearby and distant cells. The microvesicles and carriers are extruded into the extracellular space, where they can dock and enter and the transported {miRNA} may then block the translation of {mRNA} into proteins (see Xu et al., 2012). In addition, the microvesicles and carriers are present in various bodily fluids, such as blood and saliva (see Gallo et al., 2012), enabling the measurement of epigenetic material that may have originated from the central nervous system ({CNS}) simply by collecting saliva. Many of the detected {miRNAs} in saliva may be secreted into the oral cavity via sensory nerve afferent terminals and motor nerve efferent terminals that innervate the tongue and salivary glands and thereby provide a relatively direct window to assay {miRNAs} which might be dysregulated in the {CNS} of individuals with neurological disorders. {\textbar} {\textbar} Transfer {RNA} is an adaptor molecule composed of {RNA}, typically 76 to 90 nucleotides in length, that serves as the physical link between the {mRNA} and the amino acid sequence of proteins. {\textbar} {\textbar} Ribosomal {RNA} is the {RNA} component of the ribosome, and is essential for protein synthesis. {\textbar} {\textbar} {SiRNA} is a class of double-stranded {RNA} molecules, 20-25 base pairs in length, similar to {miRNA}, and operating within the {RNA} interference ({RNAi}) pathway. It interferes with the expression of specific genes with complementary nucleotide sequences by degrading {mRNA} after transcription, preventing translation. {\textbar} {\textbar} {piRNAs} are a class of {RNA} molecules 26-30 nucleotides in length that form {RNA}-protein complexes through interactions with piwi proteins. These complexes are believed to silence transposons, methylate genes, and can be transmitted maternally. {SnoRNAs} are a class of small {RNA} molecules that primarily guide chemical modifications of other {RNAs}, mainly ribosomal {RNAs}, transfer {RNAs} and small nuclear {RNAs}. The functions of {snoRNAs} include modification (methylation and pseudouridylation) of ribosomal {RNAs}, transfer {RNAs} ({tRNAs}), and small nuclear {RNAs}, affecting ribosomal and cellular functions, including {RNA} maturation and pre-{mRNA} splicing. {snoRNAs} may also produce functional analogs to {miRNAs} and {piRNAs}.{SnRNA} is a class of small {RNA} molecules that are found within the splicing speckles and Cajal bodies of the cell nucleus in eukaryotic cells. The length of an average {snRNA} is approximately 150 nucleotides. {\textbar} {\textbar} Long non-coding {RNAs} play roles in regulating chromatin structure, facilitating or inhibiting transcription, facilitating or inhibiting translation, and inhibiting {miRNA} activity. {\textbar} {\textbar} microbiome elements. Huge numbers of microorganisms inhabit the human body, especially the gastrointestinal tract, and it is known that there are many biologic interactions between a person and the population of microbes that inhabit the person's body. The species, abundance, and activity of microbes that make up the human microbiome vary between individuals for a number of reasons, including diet, geographic region, and certain medical conditions. There is growing evidence for the role of the gut-brain axis in {ASD} and it has even been suggested that abnormal microbiome profiles propel fluctuations in centrally-acting neuropeptides and drive autistic behavior (see Mulle et al., 2013). {\textbar} {\textbar} Microbial Activity. Aside from {RNA} and microbes, functional orthologs may be identified based on a database of molecular functions. Kyoto Encyclopedia of Genes and Genomes ({KEGG}) maintains a database to aid in understanding high-level functions and utilities of a biological system from molecular-level information. Molecular functions for {KEGG} Orthology are maintained in a database containing orthologs of experimentally characterized genes/proteins. Molecular functions in the {KEGG} Orthology ({KO}) are identified by a K number. For example, a molecule mercuric reductase is identified as K00520. A {tRNA} is identified as K14221. A molecule orotidine-5′-phosphate decarboxylase is identified as K01591. F-type H+/Na+-transporting {ATPase} subunit alpha is identified as K02111. Other {tRNAs} include K14225, K14232. A molecule aspartate-semialdehyde dehydrogenase is identified as K00133. A {DNA} binding protein is identified as K03111. These and other molecular functions have orthologs that may serve as biomarkers for medical conditions. {\textbar} {\textbar} The present disclosure begins with a description of development of a machine learning model for diagnosis of a medical condition. A practical example is then provided for the embodiment of early diagnosis of Autism Spectrum disorder ({ASD}). {\textbar} {\textbar} {FIG}. 1 {\textbar} is a flowchart for development of a machine learning model and testing in accordance with exemplary aspects of the present disclosure. Development of a machine learning model includes data collection (S {\textbar} 101 {\textbar} ), transforming data into features (S {\textbar} 103 {\textbar} ), selecting and ranking features that are associated with a medical condition for a Master Panel (S {\textbar} 105 {\textbar} ), selecting a Test Panel of features from ranked Master Panel (S {\textbar} 107 {\textbar} ), determining a set of Test Panel features which serve as a Test Model that can be used to distinguish people with and without a target condition (S {\textbar} 109 {\textbar} ), and analyzing test samples from patients by comparing there against the set of Test Panel features patterns that comprise the Test Model (S {\textbar} 111 {\textbar} ). {\textbar} Data collection (S {\textbar} {\textbar} 101 {\textbar} ) is performed from samples obtained through a fast and non-invasive sampling, such as a saliva swab. Among other things, non-invasive sampling facilities collecting a large quantity of data required in the development of a machine learning model. For example, participants reluctant to have blood drawn will have higher compliance. Data is collected for subjects that include patients with the medical condition for which the test is to be used, healthy individuals that do not have the medical condition, and individuals with disorders that are similar to the medical condition. {\textbar} Thus, the cohort for building and training a model should be as similar as possible to the intended population for the diagnostic test. For example, a diagnostic model to identify children aged 2-6 years with {ASD} includes subjects across the age range, with and without {ASD}, and with and without non-{ASD} developmental delays, a population which is historically difficult to differentiate from children with {ASD}. Likewise, to develop a diagnostic model to identify adults aged 60 to 80 with Parkinson's disease ({PD}), subjects preferably span the age range and include adults with {PD}, without {PD}, and with non-Parkinsonian motor disorders. Subjects are preferably sampled with a range of comorbid conditions. Further, to ensure generalizability of the diagnostic aid, subjects are preferably drawn from the range of ethnic, regional, and other variable characteristics to whom the diagnostic aid may be targeted. {\textbar} {\textbar} The ratio of subjects with the disease/disorder to subjects without the disorder should be selected. with respect to the machine learning models to be evaluated, regardless of the disorder incidence and prevalence. For example, most types of machine learning perform best with balanced class samples. Accordingly, the class balance within the sampled subjects should be close to 1:1, rather than the prevalence of the disorder (e.g., 1:51). {\textbar} {\textbar} Test subjects, who are not used for development of the machine learning model, should accordingly be within the ranges of characteristics from the training data. For example, a diagnostic aid for {ASD} in children ages 2-6 should not be applied to a 7-year-old child. {\textbar} {\textbar} {FIG}. 2 {\textbar} {\textbar} is a flowchart for the data collecting of {\textbar} {FIG}. 1 {\textbar} . In some embodiments, {RNA} data is collected for non-coding {RNA} (S {\textbar} 201 {\textbar} ) and microbial {RNA} (S {\textbar} 201 {\textbar} ). Also, patient data (S {\textbar} 205 {\textbar} ) is collected as it relates to the patient medical history, age, and sex as well as with respect to the sampling (e.g., time of collection and time since last meal). {\textbar} Data is collected from samples obtained from the subjects. In some embodiments, {RNA} data are derived from saliva via next generation {RNA} sequencing and identified using third party aligners and library databases, and categorical {RNA} class membership is retained. The {RNA} classes utilized are mature micro {RNA} ({miRNA}), precursor micro {RNA} (pre-{miRNA}), {PIWI}-interacting {RNA} ({piRNA}), small nucleolar {RNA} ({snoRNA}), long non-coding {RNA} ({lncRNA}), ribosomal {RNA} ({rRNA}), microbial taxa identified by {RNA} (microbes), and microbial gene expression (microbial activity). Together these {RNAs} components comprise the human microtranscriptome and microbial transcriptome. In the case of saliva samples, this is referred to as the oral transcriptome. These non-coding and microbial {RNAs} play key regulatory roles in cellular processes and have been implicated in both normal and disrupted neurological states, including neurodevelopmental disorders such as autism spectrum disorder ({ASD}), neurodegenerative diseases such as Parkinson's Disease ({PD}), and traumatic brain injuries ({TBI}). {\textbar} {\textbar} Biomarkers may be extracted from saliva, blood, serum, cerebrospinal fluid, tissue biopsy, or other biological samples. in the one embodiment, the biological sample can be obtained by non-invasive means, in particular, a saliva sample. A swab may be used to sample whole-cell saliva and the biomarkers may be extracellular {RNAs}. Extracellular {RNAs} can be extracted from the saliva sample using existing known methods. {\textbar} {\textbar} Optionally, saliva may be replaced by or complemented with other tissues or biofluids, including blood, blood serum, buccal sample, cerebrospinal fluid, brain tissue, and/or other tissues. {\textbar} {\textbar} Optionally, {RNA} may be replaced by or complemented with metabolites or other regulatory molecules. {RNA} also may be replaced by or complemented with the products of the {RNA}, or with the biological pathways in which they participate. {RNA} may be replaced by or complemented with {DNA}, such as aneuploidy, indels, copy number variants, trinucleotide repeats, and or single nucleotide variants. {\textbar} {\textbar} An optional second collection, of the same or other biological tissue as the first sample, may be collected at the same or different time as the original swab, to allow for replication of the results, or provide additional material if the first swab does not pass subsequent quality assurance and quantification procedures. {\textbar} {\textbar} In one embodiment, the sample container may contain a medium to stabilize the target biomarkers to prevent degradation of the sample. For example, {RNA} biomarkers in saliva may be collected with a kit containing {RNA} stabilizer and an oral saliva swab. Stabilized saliva may be stored for transport or future processing and analysis as needed, for example to allow for batch processing of samples. {\textbar} {\textbar} Patient data may include, but is not limited to, the following: age, sex, region, ethnicity, birth age, birth weight, perinatal complications, current weight, body mass index, oropharyngeal status (e.g. allergic rhinitis), dietary restrictions, medications, chronic medical issues, immunization status, medical allergies, early intervention services, surgical history, and family psychiatric history. Given the prevalence of attention deficit hyperactivity disorder ({ADHD}) and gastrointestinal ({GI}) disturbance among children with {ASD}, for purposes of the embodiment directed to {ASD}, survey questions were included to identify these two common medical co-morbidities. {GI} disturbance is defined by presence of constipation, diarrhea, abdominal pain, or reflux on parental report, {ICD}-10 chart review, or use of stool softeners/laxatives in the child's medication list. {ADHD} is defined by physician or parental report, or {ICD}-10 chart review. {\textbar} {\textbar} Patient data may be collected via questionnaire completed by the patient, by the patient's parent(s) or caregiver(s), by the patient's physician, or by a trained person, and/or may be obtained from patient's medical charts. Optionally, answers collected within the questionnaire may be validated, confirmed, or made complete by the patient, patient's parent(s) or caregiver(s), or by the patient's physician. {\textbar} {\textbar} To confirm diagnosis or lack of diagnosis for patients whose samples were used to train and test the Test Model, standard measurements of behavioral, psychological, cognitive, and medical may be performed. In the preferred embodiment of a diagnostic test for {ASD} in children, adaptive skills in communication, socialization, and daily living activities may be measured in all participants using the Vineland Adaptive Behavior Scale ({VABS})-{II}. Evaluation of autism symptomology ({ADOS}-{II}) may be completed when possible for {ASD} and {DD} participants (n=164). Social affect ({SA}), restricted repetitive behavior ({RRB}) and total {ADOS}-{II} scores may be recorded. Mullen Scales of Early Learning may also be used. An example of a compilation of patient data is shown below in Table 1. {\textbar} {\textbar} {TABLE} 1 {\textbar} {\textbar} Participant characteristics {\textbar} {\textbar} Characteristic {\textbar} {\textbar} All groups (n = 381) {\textbar} {ASD} (n = 187) {\textbar} {TD} (n = 125) {\textbar} {DD} (n = 69) {\textbar} Demographics and anthropometrics {\textbar} {\textbar} Age, months ({SD}) {\textbar} {\textbar} 51 {\textbar} (16) {\textbar} 54 {\textbar} (15) {\textbar} 47 {\textbar} (18) {\textbar} a {\textbar} 50 {\textbar} (13) {\textbar} Male, no. (\%) {\textbar} {\textbar} 285 {\textbar} (75) {\textbar} 161 {\textbar} (86) {\textbar} 76 {\textbar} (60) {\textbar} a {\textbar} 48 {\textbar} (70) {\textbar} a {\textbar} Caucasian, no. (\%) {\textbar} {\textbar} 274 {\textbar} (72) {\textbar} 132 {\textbar} (71) {\textbar} 95 {\textbar} (76) {\textbar} 47 {\textbar} (69) {\textbar} Body mass index, {\textbar} {\textbar} 18.9 {\textbar} (11) {\textbar} 17.2 {\textbar} (7) {\textbar} 21.2 {\textbar} (16) {\textbar} 19.5 {\textbar} (10) {\textbar} kg/m {\textbar} {\textbar} 2 {\textbar} ({SD}) {\textbar} Clinical characteristics {\textbar} {\textbar} Asthma, no. (\%) {\textbar} {\textbar} 43 {\textbar} (11) {\textbar} 19 {\textbar} (10) {\textbar} 10 {\textbar} (8) {\textbar} 14 {\textbar} (20) {\textbar} {GI} disturbance, no. {\textbar} {\textbar} 50 {\textbar} (13) {\textbar} 35 {\textbar} (19) {\textbar} 2 {\textbar} (2) {\textbar} a {\textbar} 13 {\textbar} (19) {\textbar} (\%) {\textbar} {\textbar} {ADHD}, no (\%) {\textbar} {\textbar} 74 {\textbar} (19) {\textbar} 43 {\textbar} (23) {\textbar} 10 {\textbar} (8) {\textbar} a {\textbar} 21 {\textbar} (30) {\textbar} Allergic rhinitis, no. {\textbar} {\textbar} 81 {\textbar} (21) {\textbar} 47 {\textbar} (25) {\textbar} 19 {\textbar} (15) {\textbar} 15 {\textbar} (22) {\textbar} (\%) {\textbar} {\textbar} Oropharyngeal factors {\textbar} {\textbar} Time of collection, {\textbar} {\textbar} 13:00 {\textbar} (3) {\textbar} 13:00 {\textbar} (3) {\textbar} 13:00 {\textbar} (2) {\textbar} 13:00 {\textbar} (3) {\textbar} hrs ({SD}) {\textbar} {\textbar} Time since last {\textbar} {\textbar} 2.8 {\textbar} (2.5) {\textbar} 2.9 {\textbar} (2.5) {\textbar} 3.0 {\textbar} (2.9) {\textbar} 2.1 {\textbar} (1.1) {\textbar} a {\textbar} meal, hrs ({SD}) {\textbar} {\textbar} Dietary restrictions, {\textbar} {\textbar} 50 {\textbar} (13) {\textbar} 28 {\textbar} (15) {\textbar} 10 {\textbar} (8) {\textbar} 12 {\textbar} (18) {\textbar} no. (\%) {\textbar} {\textbar} Neuropsychiatric factors {\textbar} {\textbar} Communication, {\textbar} {\textbar} 83 {\textbar} (23) {\textbar} 73 {\textbar} (20) {\textbar} 103 {\textbar} (17) {\textbar} a {\textbar} 79 {\textbar} (18) {\textbar} a {\textbar} {VABS}-{II} standard {\textbar} {\textbar} score ({SD}) {\textbar} {\textbar} Socialization, {\textbar} {\textbar} 85 {\textbar} (23) {\textbar} 73 {\textbar} (15) {\textbar} 108 {\textbar} (18) {\textbar} a {\textbar} 82 {\textbar} (20) {\textbar} a {\textbar} {VABS}-{II} standard {\textbar} {\textbar} score ({SD}) {\textbar} {\textbar} Activities of daily {\textbar} {\textbar} 85 {\textbar} (20) {\textbar} 75 {\textbar} (15) {\textbar} 103 {\textbar} (15) {\textbar} 83 {\textbar} (19) {\textbar} a {\textbar} living, {VABS}-{II} {\textbar} {\textbar} standard score ({SD}) {\textbar} {\textbar} Social affect, {\textbar} {\textbar} — {\textbar} 13 {\textbar} (5) {\textbar} — {\textbar} 5 {\textbar} (3) {\textbar} a {\textbar} {ADOS}-{II} score ({SD}) {\textbar} {\textbar} Restrictive/repetitive {\textbar} {\textbar} — {\textbar} 3 {\textbar} (2) {\textbar} — {\textbar} 1 {\textbar} (1) {\textbar} a {\textbar} behavior, {ADOS}-{II} {\textbar} {\textbar} score ({SD}) {\textbar} {\textbar} {ADOS}-{II} total score {\textbar} {\textbar} — {\textbar} 16 {\textbar} (6) {\textbar} — {\textbar} 6 {\textbar} (4) {\textbar} a {\textbar} ({SD}) {\textbar} {\textbar} In machine learning, using too many features in a training model can lead to overfitting. Overfitting is a case where once trained using training samples that include a large number of features, the machine learning model primarily only knows the training samples that it has been trained for. In other words, the machine learning model may have difficulty recognizing a sample that does not substantially match at least one of the training samples and it is therefore not general enough to identify variations of the feature set that are in fact associated with the target condition. It is desirable for a machine learning model to generalize to an extent that it can correctly recognize a new sample that differs from, but is similar-enough to, training samples to be associated with the target condition. On the other hand, it is also desirable for a machine learning model to include the most important features for accurately determining the presence or absence of the existence of a medical condition, ie those that differ the most between people with and without a target medical condition. {\textbar} {\textbar} The present disclosure includes transformations of raw data to enable meaningful comparison of features, feature selection and ranking to create a Master Panel of ranked features with which the Test Model will be developed, and test model development that determines the fewest number of features that are necessary to achieve the highest performance accuracy and uses the features to implement a test model that defines a classification boundary that separates people with and without the target medical condition. The present disclosure includes testing that compares a test panel comprised of patient measures, human microtranscriptome, and microbial transcriptome features extracted from a patient's saliva against the implemented test model. {\textbar} {\textbar} {FIG}. 3 {\textbar} {\textbar} is a system diagram for development and testing a machine learning model for diagnosing a medical condition in accordance with exemplary aspects of the disclosure. The machine learning methods that will be used for constructing the test model may be optimized by first transforming the raw data into normalized and scaled numeric features. Data may need to be corrected using standard batch effects methods, including within-lane corrections and between-lane corrections, and normalizing according to house-keeping {RNAs}. The data transformation methods used in the invention are chosen to facilitate identification of the {RNA} biomarkers with the most variability between the normal and target condition states and to convert, or transform, them to a unified scale so that disparate variables can meaningfully be compared. This ensures that only the most meaningful features will be subjected to analysis and eliminates data that could obscure or dilute the meaningful information. {\textbar} The inputs required for application of the method may include the patient data described above and the relative quantities of the {RNA} biomarkers present in a saliva sample. Several methods of preparing biological samples containing extracellular {RNA} biomarkers and quantifying the relative amounts of {RNA} in the sample are known, and selection of a set of appropriate methods is a prerequisite to optimizing the inputs to be used for the method. {\textbar} {\textbar} Transforming Data into Features {\textbar} {\textbar} In 301, one or more processes to quantify {RNA} abundance in biological tissues may include the following: perform {RNA} purification to remove {RNases}, {DNA}, and other non-{RNA} molecules and contaminants; perform {RNA} quality assurance as determined by the {RNA} Integrity Number ({RIN}); perform {RNA} quantification to ensure sufficient amounts of {RNA} exist in the sample; perform {RNA} sequencing to create a digital {FASTQ} format file; perform {RNA} alignment to match sequences to known {RNA} molecules; and perform {RNA} quantification to determine the abundance of detected {RNA} molecules. {\textbar} {\textbar} The {RNA} Integrity Number is a score of the quality of {RNA} in a sample, calculated based on quantification of ribosomal {RNA} compared with shorter {RNA} sequences, using a proprietary algorithm implemented by an Agilent Bioanalyzer system. A higher proportion of shorter {RNA} sequences may indicate that {RNA} degradation has occurred, and therefore that the sample contains low quality or otherwise unstable {RNA}. {\textbar} {\textbar} {RNA} sequencing itself may include many individual processes, including adapter ligation, {PCR} reverse transcription and amplification, {cDNA} purification, library validation and normalization, cluster amplification, and sequencing. {\textbar} {\textbar} Sequencing results may be stored in a single {FASTQ} file per sample. {FASTQ} files are an industry standard file format that encodes the nucleotide sequence and accuracy of each nucleotide. In the event that the sequencing system used generates multiple {FASTQ} files per sample (i.e., one per sample per flow lane), the files may be joined using conventional methods. The {FASTQ} format has four lines for each {RNA} read: a sequence identifier beginning with “@” (unique to each read, may optionally include additional information such as the sequencer instrument used and flow lane), the read sequence of nucleotides, either a line consisting of only a “+” or the sequence identifier repeated with the “@” replaced by a “+”, and the sequence quality score per nucleotide. {\textbar} {\textbar} @{SIM}:1:{FCX}:1:15:6329:1045 1:N:0:2 {\textbar} {\textbar} {TCGCACTCAACGCCCTGCATATGACAAGACAGAATC} {\textbar} {\textbar} + {\textbar} {\textbar} {\textless}{\textgreater};\#\#={\textgreater}{\textless}9={AAAAAAAAAA}9\#:{\textless}\#{\textless};{\textless}{\textless}0 for training observations on the incorrect side of the margin, and ϵ {\textbar} i {\textbar} {\textgreater}1 for incorrectly classified observations on the wrong side of the hyperplane. {\textbar} An alternative definition of the optimally separating hyperplane allows for simplification and an efficient solution: the constraint ∥β∥=1 may be dropped by subjecting the optimization to {\textbar} {\textbar} 1 {\textbar} {\textbar}  {\textbar} β {\textbar}  {\textbar} ⁢ {\textbar} y {\textbar} i {\textbar} ⁡ {\textbar} ( {\textbar} x {\textbar} i {\textbar} T {\textbar} ⁢ {\textbar} β {\textbar} + {\textbar} β {\textbar} 0 {\textbar} ) {\textbar} ≥ {\textbar} M {\textbar} . {\textbar} This formulation allows β and β {\textbar} {\textbar} 0 {\textbar} to be scaled by any constant or multiple, and lets {\textbar}  {\textbar} {\textbar} β {\textbar}  {\textbar} = {\textbar} 1 {\textbar} M {\textbar} . {\textbar} In this form, maximizing the margin is equivalent to minimizing ∥β∥. Further, minimizing ∥β∥ may be reformulated as minimizing ,1/2∥β∥ {\textbar} {\textbar} 2 {\textbar} , allowing among other things, the gradient to be linear and the optimization problem to be solved with quadratic programming. {\textbar} Thus, the optimization problem is now defined as {\textbar} {\textbar} min {\textbar} {\textbar} β {\textbar} , {\textbar} β {\textbar} 0 {\textbar} ⁢ {\textbar} 1 {\textbar} 2 {\textbar} ⁢ {\textbar}  {\textbar} β {\textbar}  {\textbar} 2 {\textbar} + {\textbar} {CΣ} {\textbar} i {\textbar} = {\textbar} 1 {\textbar} N {\textbar} ⁢ {\textbar} ɛ {\textbar} i {\textbar} , {\textbar} subject to y {\textbar} {\textbar} i {\textbar} (x {\textbar} i {\textbar} T {\textbar} β+β {\textbar} 0 {\textbar} )≥1−ε {\textbar} i {\textbar} , ∀i and ε {\textbar} i {\textbar} ≥0. This is equivalent to the primal Lagrangian {\textbar} ℒ {\textbar} {\textbar} P {\textbar} β {\textbar} , {\textbar} β {\textbar} 0 {\textbar} = {\textbar} 1 {\textbar} 2 {\textbar} ⁢ {\textbar}  {\textbar} β {\textbar}  {\textbar} 2 {\textbar} + {\textbar} {CΣ} {\textbar} i {\textbar} - {\textbar} 1 {\textbar} N {\textbar} ⁢ {\textbar} ɛ {\textbar} i {\textbar} - {\textbar} Σ {\textbar} i {\textbar} - {\textbar} 1 {\textbar} N {\textbar} ⁢ {\textbar} α {\textbar} i {\textbar} ⁡ {\textbar} [ {\textbar} y {\textbar} i {\textbar} ⁡ {\textbar} ( {\textbar} x {\textbar} i {\textbar} T {\textbar} ⁢ {\textbar} β {\textbar} + {\textbar} β {\textbar} 0 {\textbar} ) {\textbar} - {\textbar} ( {\textbar} 1 {\textbar} - {\textbar} ɛ {\textbar} i {\textbar} ) {\textbar} ] {\textbar} - {\textbar} Σ {\textbar} i {\textbar} = {\textbar} 1 {\textbar} N {\textbar} ⁢ {\textbar} μ {\textbar} i {\textbar} ⁢ {\textbar} ɛ {\textbar} i {\textbar} . {\textbar} The dual problem (finding the minimum) is accordingly {\textbar} {\textbar} D {\textbar} =Σ {\textbar} i=1 {\textbar} N {\textbar} α {\textbar} i {\textbar} −1/2Σ {\textbar} i=1 {\textbar} N {\textbar} Σ {\textbar} j=1 {\textbar} N {\textbar} α {\textbar} i {\textbar} α {\textbar} j {\textbar} y {\textbar} i {\textbar} y {\textbar} j {\textbar} x {\textbar} i {\textbar} T {\textbar} x {\textbar} j {\textbar} . Note that α {\textbar} i {\textbar} is the relative importance of each observation, such that α {\textbar} i {\textbar} ={\textgreater}0 for support vectors and α {\textbar} i {\textbar} =0 for non-support vectors, and thus i=1 . . . N may become i ∈ {SV}. {\textbar} This convenient form makes clear an implementation of kernels, in which the dual problem may be written as {\textbar} {\textbar} D {\textbar} =Σ {\textbar} i ∈ {SV} {\textbar} α {\textbar} i {\textbar} −1/2Σ {\textbar} i ∈ {SV} {\textbar} Σ {\textbar} j ∈ {SV} {\textbar} α {\textbar} i {\textbar} α {\textbar} j {\textbar} y {\textbar} i {\textbar} y {\textbar} j {\textbar} h(x {\textbar} i {\textbar} ),h(x {\textbar} j {\textbar} ) {\textbar} . As h(x) only requires the calculation of inner products, the specific transformation h(x) need not be provided, but may be replaced by a kernel function K(x,x′)= {\textbar} h(x),h(x′) {\textbar} . {\textbar} A radial kernel, also known as a radial basis function or Gaussian, is defined by K(x,x′)=exp(−γ∥x−x′∥ {\textbar} {\textbar} 2 {\textbar} ), where λ is the radius or size of the Gaussian. Alternative kernel functions include polynomial kernels and neural network, hyperbolic tangent, or sigmoid kernels. A polynomial kernel of the dth-degree is defined by K(x,x′)=(1+ {\textbar} x,x′ {\textbar} d {\textbar} , where d is the degree of the polynomial. A neural network, hyperbolic tangent, or sigmoid kernel, is defined by K(x,x′)=tanh(k {\textbar} 1 {\textbar} x,x′ {\textbar} +k {\textbar} 2 {\textbar} ), where k {\textbar} 1 {\textbar} and k {\textbar} 2 {\textbar} define the slope and offset of the sigmoid. {\textbar} {SVM} and kernel parameters are empirically derived, ideally with K-fold cross-validated training data in which 100/K \% training samples are held out to measure the predictive performance, which may be repeated multiple times with different train/cross-validation splits. These parameters may be selected from a range expected to perform well, as known to persons skilled in the art, or specified explicitly. {\textbar} {\textbar} If different kernels are used, relevant parameters may be derived as above. {\textbar} {\textbar} Measures of predictive performance may include area under the receiver operator curve ({AUC}/{AUROC}/{ROC} {AUC}), sensitivity, specificity, accuracy, Cohen's kappa, F1, and Mathew's correlation coefficient ({MCC}). {\textbar} {\textbar} The preferred number of features is found by building competing models with increasing numbers of input features, drawn in rank order from the master panel. Predictive performance, such as {ROC} or {MCC}, on the training data can then be viewed as a function of number of input features. The test model is the model with the fewest input features that approaches an asymptote or reaches a plateau of predictive performance. It is the model type with the best performance, with the kernel with the best performance, with the parameters with the best performance, requiring the fewest features. {\textbar} {\textbar} The Test Model consists of the set of Support Vectors that were selected in the round of training that achieved maximum performance in classifying samples with the fewest features, and the dimension of the Support Vectors is equal to this smallest number of features. The list of features used in the samples for the round of training that yielded the Test Model set of Support Vectors is the Test Panel of features. {\textbar} {\textbar} In one embodiment, the Support Vector Machine is used as the model class, with variant, radial kernel, features may range from 20 to 100; and model parameters include the cost budget (C) and kernel size (A). {\textbar} {\textbar} Analyzing Test Samples {\textbar} {\textbar} {FIG}. 7 {\textbar} {\textbar} is a flowchart for the test sample testing step of {\textbar} {FIG}. 1 {\textbar} . Test samples represent a naïve sample from a subject or patient for whom the disease status is not known to the model, because the naïve sample was not used in training the test model. Test samples are new data on which the {GBM} and {SVM} models described above were not trained. Test samples are comprised of human microtranscriptome and microbial transcriptome and patient features that are included in the Test Panel; they need not include features which are removed prior to creating the Master Panel or not included in the Test Panel. {\textbar} In S {\textbar} {\textbar} 701 {\textbar} , test sample features are transformed in the same way as the training samples were transformed, using parameters derived from the training data ( {\textbar} {FIG}. 3, 331, 333, 335, 337, 341, 343, 347 {\textbar} ). These parameters include the mean for centering, standard deviation for scaling, and norm for spatial sign projection, as well as the trained {SVM} model (and also the fitted parametric sigmoid defined below for the Platt calibration). {\textbar} As the optimally separating hyperplane is defined only by the support vectors, in S {\textbar} {\textbar} 703 {\textbar} test samples need only be measured against each support vector in the Test Model, using the radial kernel defined above. {\textbar} In S {\textbar} {\textbar} 705 {\textbar} , the output of the {SVM} Test Model, for test sample x*, is determined by a comparison of the sample against the set of Support Vectors comprising the Test Model. Specifically, the output is determined by f(x)=h(x) {\textbar} T {\textbar} β+β {\textbar} 0 {\textbar} =Σ {\textbar} i ∈ {SV} {\textbar} α {\textbar} i {\textbar} y {\textbar} i {\textbar} K(x {\textbar} i {\textbar} ,x*), and is in the form of unsealed numeric values. {\textbar} In some embodiments, the output of a Test Model includes class (disease status)and probability of membership to the class (probability of the disease). If the output is a value which does not explicitly indicate probability, the magnitude may be converted to a probability using a calibration method ( {\textbar} {\textbar} {FIG}. 3 {\textbar} , 351). The goal of such a method is to transform an unsealed output to a probability ( {\textbar} {FIG}. 3 {\textbar} , 353). Common calibration methods are the Platt calibration and isotonic regression calibration, although other methods are viable. {\textbar} In the Platt calibration, the disorder/disease state and the magnitudes of the test model outputs are fit to a parametric sigmoid. The fitting parameters may be determined in the cross-validation folds mentioned previously for training the test model or derived in a separate cross-validation process. If the output of the trained {SVM} model for a test sample x is f(x)=Σ {\textbar} {\textbar} i ∈{SV} {\textbar} α {\textbar} i {\textbar} y {\textbar} i {\textbar} K(x {\textbar} i {\textbar} ,x), then we may define the probability as P(y=1{\textbar}f)=1/(1+exp(Af+B)), where P(y=1) is the probability of the disorder/disease state, and A and B are parameters to fit the sigmoid. {\textbar} In S {\textbar} {\textbar} 707 {\textbar} , the {SVM} output is converted to a probability of disease state using Platt calibration, in which a parametric sigmoid is fit to cross-validated training data, and the assumption is made that the output of the {SVM} is proportional to the log odds of a positive (disease state) example. Thus, {\textbar} P {\textbar} {\textbar} ⁡ {\textbar} ( {\textbar} y {\textbar} = {\textbar} 1 {\textbar} {\textbar} {\textbar} f {\textbar} ) {\textbar} = {\textbar} 1 {\textbar} 1 {\textbar} + {\textbar} exp {\textbar} ⁡ {\textbar} ( {\textbar} Af {\textbar} ⁡ {\textbar} ( {\textbar} x {\textbar} ) {\textbar} + {\textbar} B {\textbar} ) {\textbar} . {\textbar} Optionally, after definition of the Test Panel and parameters to create the Test Model, a Production Model may be built on both the training and testing dataset using the parameters from the Test Model. If this step is not performed, the Test Model may constitute the Production Model. {\textbar} {\textbar} Alternative Machine Learning Models {\textbar} {\textbar} As the amount of data available for training a machine learning model increases, in particular related to diagnosis of mental disorders/diseases s as {ASD} and Parkinson's Disease, other machine learning methods may be used instead of, or in conjunction with, Support Vector Machines. {\textbar} {\textbar} {FIG}. 8 {\textbar} is a diagram for a neural network architecture in accordance with an exemplary aspect of the disclosure. The diagram shows a few connections, but for purposes of simplicity in understanding does not show every connection that may be included in a network. The network architecture of {\textbar} {FIG}. 8 {\textbar} preferably includes a connection between each node in a layer and each node in a following layer. Regarding {\textbar} {FIG}. 8 {\textbar} , a neural network architecture may be provided with a panel of features {\textbar} 801 {\textbar} just as the Support Vector Machine of the present disclosure. The same output for classification {\textbar} 803 {\textbar} that was used for the Support Vector Machine model may also be used in the architecture of a neural network. Instead of learning a set of support vectors that define a classification boundary, a neural network learns weighted connections between nodes {\textbar} 805 {\textbar} in the network. Weighted connections in a neural network may be calculated using various algorithms. One technique that has proven successful for training neural networks having hidden layers is the backpropagation method. The backpropagation method iteratively updates weighted connections between nodes until the error reaches a predetermined minimum. The name backpropagation is due to a step in which outputs are propagated back through the network. The back propagation step calculates the gradient of the error. Also, similar to the support vector machine of the present disclosure, a neural network architecture may be trained using radial basis functions as activation functions. {\textbar} Further, there are training methods for neural networks, as well as support vector machines, that enable them to be incrementally trained as more data becomes available. Incremental learning is a model in which a learning model can continue to learn as new data becomes available, without having to relearn based on the original data and new data. Of course, most learning models, such as neural networks, may be retrained using all data that is available. {\textbar} {\textbar} Still further, the number of internal layers of a neural network may be increased to accommodate deep learning as the amount of data and processing approaches levels where deep learning may provide improvements in diagnosis. Several machine learning methods have been developed for deep learning. Similar to Support Vector Machines, deep learning may be used to determine features used for classification during the training process. In the case of deep learning, the number of hidden layers and nodes in each layer may be adjusted in order to accommodate a hierarchy of features. Alternatively, several deep learning models may be trained, each having a different number of hidden layers and different numbers of hidden nodes that reflect variations in feature sets. {\textbar} {\textbar} In some embodiments, a deep learning neural network may accommodate a full set of features froth a Master Panel and the arrangement of hidden nodes may themselves learn a subset of features while performing classification. {\textbar} {\textbar} {FIG}. 9 {\textbar} is a schematic for an exemplary deep learning architecture. As in {\textbar} {FIG}. 8 {\textbar} , not all connections are shown. In some embodiments, less than fully interconnection between each node in the network may be used in a learning model. However, in most cases, each node in a layer is connected to each node in a following layer in the network. It is possible that some connections may have a weight with a value of zero. In addition, the blocks shown in the figure may correspond to one or more nodes. The input layer {\textbar} 901 {\textbar} may consist of a Master Panel of 100 features. In some embodiments, each feature may be associated with a single node. The series of hidden layers may extract increasingly abstract features {\textbar} 905 {\textbar} , leading to the final classification categories {\textbar} 903 {\textbar} . {\textbar} Deep learning classifiers may be arranged as a hierarchy of classifiers, where top level classifiers perform general classifications and lower level classifiers perform more specific classifications. {\textbar} {\textbar} {FIG}. 10 {\textbar} is a schematic for a hierarchical classifier in accordance with an exemplary aspect of the disclosure. Lower level classifiers may be trained based on specific features or a greater number of features. Regarding {\textbar} {FIG}. 10 {\textbar} , one or more deep learning classifiers {\textbar} 1003 {\textbar} may be trained on a small set of features from a Master Panel {\textbar} 1001 {\textbar} and detect early on that a patient is clearly typical development, or clearly has a target disorder. bower level deep learning classifiers {\textbar} 1005 {\textbar} may have a greater number of hidden layers than higher level classifiers, and may consider a greater number of features in order to more finely discern the presence or absence of the target disorder in a patient. {\textbar} Example Machine Learning Model—{ASD} Diagnostics {\textbar} {\textbar} There is a need to establish reliable diagnostic criteria for {ASD} as early as possible and, at the same time, differentiate those subgroups with distinct developmental concerns. However, a panel of biomarkers that has sufficient sensitivity and specificity must be identified in order to develop a useful molecular diagnostic tool for {ASD}. Defining the oral transcriptome profile and machine learning predictive model focused on the time of initial {ASD} diagnosis will help differentiate between {ASD} and non-{ASD} children, including those with {DD}. {\textbar} {\textbar} In one embodiment, a machine learning model is determined as a diagnostic tool in detecting autism spectrum disorder ({ASD}). Multifactorial genetic and environmental risk factors have been identified in {ASD}. Subsequently, one or more epigenetic mechanisms play a role in {ASD} pathogenesis. Among these potential mechanisms are non-coding {RNA}, including micro {RNAs} ({miRNAs}), {piRNAs}, small interfering {RNAs} ({siRNAs}), small nuclear {RNAs} ({snRNAs}), small nucleolar {RNAs} ({snoRNAs}), ribosomal {RNAs} ({rRNAs}), and long non-coding {RNAs} ({lncRNAs}). {\textbar} {\textbar} {MicroRNAs} are non-coding nucleic acids that can regulate expression of entire gene networks by repressing the transcription of {mRNA} into proteins, or by promoting the degradation of target {mRNAs}. {MiRNAs} are known to be essential for normal brain development and function. {\textbar} {\textbar} {miRNA} isolation from biological samples such as saliva and their analysis may be performed by methods known in the art, including the methods described by Yoshizawa, et al., {\textbar} {\textbar} Salivary {MicroRNAs} and Oral Cancer Detection {\textbar} , Methods Mol Biol. 2013; 936: 313-324; doi: 10.1007/978-1-62703-083-0 (incorporated by reference) or by using commercially available kits, such as {mirVana}™ {miRNA} Isolation Kit which is incorporated by reference to the literature available at https://\_tools.thermofisher.com/content/sfs/manuals/fm\_1560.pdf (last accessed Jan. 9, 2018). {\textbar} {miRNAs} can be packaged within exosomes and other lipophilic carriers as a means of extracellular signaling. This feature allows non-invasive measurement of {miRNA} levels in extracellular biofluids such as saliva, and renders them attractive biomarker candidates for disorders of the central nervous system ({CNS}). In fact, a pilot study of 24 children with {ASD} demonstrated that salivary {miRNAs} are altered in {ASD} and broadly correlate with {miRNAs} reported to be altered in the brain of children with {ASD}. A procedure has been developed to establish a diagnostic panel of salivary {miRNAs} for prospective validation. Using this procedure, characterization of salivary {miRNA} concentrations in children with {ASD}, non-autistic developmental delay ({DD}), and typical development ({TD}) may identify panels of {miRNAs} for screening ({ASD} vs. {TD}) and diagnostic ({ASD} vs. {DD}) potential. {\textbar} {\textbar} {miRNAs} that may be good biomarkers for {ASD} include hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410, hsa-mir-4461, hsa-{miR}-15a-5p, hsa-{miR}-6763-3p, hsa-{miR}-196a-5p, hsa-{miR}-4668-5p, hsa-{miR}-378d, hsa-{miR}-142-3p, hsa-mir-30c-1, hsa-mir-101-2, hsa-mir-151a, hsa-{miR}-125b-2-3p, hsa-mir-148a-5p, hsa-mir-548I, hsa-{miR}-98-5p, hsa-{miR}-8065, hsa-mir-378d-1, hsa-let-7f-1, hsa-let-7d-3p, hsa-let-7a-2, hsa-let-7f-2, hsa-let-7f-5p, hsa-mir-106a, hsa-mir-107, hsa-{miR}-10b-5p, hsa-{miR}-1244, hsa-{miR}-125a-5p, hsa-mir-1268a, hsa-{miR}-146a-5p, hsa-mir-155, hsa-mir-18a, hsa-mir-195, hsa-mir-199a-1, hsa-mir-19a, hsa-{miR}-218-5p, hsa-mir-29a, hsa-{miR}-29b-3p, hsa-{miR}-29c-3p, hsa-{miR}-3135b, hsa-mir-3182, hsa-mir-3665, hsa-mir-374a, hsa-mir-421, hsa-mir-4284, hsa-{miR}-4436b-3p, hsa-{miR}-4698, hsa-mir-4763, hsa-mir-4798, hsa-mir-502, hsa-{miR}-515-5p, hsa-mir-5572, hsa-{miR}-6724-5p, hsa-mir-6739, hsa-{miR}-6748-3p, hsa-{miR}-6\%70-5p, hsa\_let\_7d\_5p, hsa\_let\_7e\_5p, hsa\_let 7g\_5p, hsa\_miR\_101\_3p, hsa\_miR\_1307\_5p. hsa\_miR\_142\_5p, hsa\_miR\_148a\_5p, hsa\_miR\_151a\_3p, hsa\_miR 210\_3p hsa\_miR\_28\_3p, hsa\_miR29a\_3p, hsa\_miR\_3074\_5p, hsa\_miR\_374a\_5p. {\textbar} {\textbar} Other non-coding {RNAs}, such as {piRNAs}, have been shown to also be good biomarkers for {ASD}. {piRNA} biomarkers for {ASD} include {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684, {piR}-hsa-3405, {piR}-hsa-324, {piR}-hsa-18905, {piR}-hsa-23248, {piR}-hsa-28223, {piR}-hsa-28400, {piR}-hsa-1177, {piR}-hsa-26592, {piR}-hsa-11361, {piR}-hsa-26131, {piR}-hsa-27133, {piR}-hsa-27134, {piR}-hsa-27282, {piR}-hsa-27728, {wiRNA}-1433, {wiRNA}-2533, {wiRNA}-3499, {wiRNA}-9843. {\textbar} {\textbar} Ribosomal {RNA} that may be good biomarkers for {ASD} include {RNA}5S, {MTRNR}2L4, {MTRNR}2L8. {\textbar} {\textbar} {snoRNA} that may be good biomarkers for {ASD} include {SNORD}118, {SNORD}29, {SNORD}53B, {SNORD}68, {SNORD}20, {SNORD}41, {SNORD}30, {SNORD}34, {SNORD}110, {SNORD}28, {SNORD}45B, {SNORD}92. {\textbar} {\textbar} Long non-coding {RNA} that may be a good biomarker for {ASS} includes {LOC}730338. {\textbar} {\textbar} In addition to panels, associations of salivary {miRNA} expression and clinical/demographic characteristics may also be considered. For example, time of saliva collection may affect {miRNA} expression. Some {miRNA}, such as {miR}-23b-3p, may be associated with time since last meal. {\textbar} {\textbar} However, factors that may influence salivary {RNA} expression may also be crucial. For example, it is known that components of the oral microbiome may correlate with the diagnosis of {ASD} and/or specific behavioral symptoms. Microbial genetic sequence ({mBIOME}) present in the saliva sample that may be biomarkers for {ASD} include: {\textbar} {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIB}122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus, Rothia, Cryptococcus gattii {\textbar} {WM}276, {\textbar} Neisseriaceae, Rothia dentocariosa {\textbar} {ATCC} 17931, {\textbar} Chryseobacterium {\textbar} sp. {MB} B 17019, {\textbar} Streptococcus agalactiae {\textbar} {CNCTC} 10/84, {\textbar} Streptococcus pneumoniae {\textbar} {SPINA}45, {\textbar} Tsukamurella paurometabola {\textbar} {DSM} 20162, {\textbar} Streptococcus mutans {\textbar} {UA}159-{FR}, {\textbar} Actinomyces oris, Comamonadaceae, Streptococcus halotolerans, Flavobacterium columnare, Streptomyces griseochromogenes, Neisseria, Porphyromonas, Streptococcus salivarius {\textbar} {CCHSS}3, {\textbar} Megasphaera elsdenii {\textbar} {DSM} 20460, {\textbar} Pasteurellaceae {\textbar} , and an unclassified {\textbar} Burkholderiales {\textbar} . Other microbes that may be biomarkers for {ASD} include {\textbar} Prevotella timonensis, Streptococcus vestibularis, Enterococcus faecalis, Acetomicrobium hydrogeniformans, Streptococcus {\textbar} sp. {HMSC}073D05, {\textbar} Rothia dentocariosa, Prevotella marshii, Prevotells {\textbar} sp. {HMSC}073D09, Propionibacterium acnes, Campylobacter, Arthrobacter, Dickeya, Jeatgalibacillus, Leuconostoc, Maribacter, Methylophilus, Mycobacteriutn, Ottowia, Trichormus. Further, other microbes that may be biomarkers for {ASD} include {\textbar} Actinomyces meyeri, Actinomyces radicidentis, Eubacterium, Kocuria flava, Kocuria rhizophila, Kocuria turfanensis, Lactobacillus fermentum, Lysinibacillus sphaericus, Micrococcus luteus, Streptococcus dysgalactiae {\textbar} . {\textbar} Microbial taxonomic classification is imperfect, particularly from {RNA} sequencing data. Most, if not all, classifiers assign reads to the lowest common taxonomic ancestor, which in many cases is not at the same level of specificity as other reads. For example, some reads may be classified down to the sub-species level, whereas others are only classified at the genus level. Accordingly, some embodiments prefer to view the data only at specific levels, either species, genus, or family, to remove such biases in the data. {\textbar} {\textbar} Another method to avoid such inconsistent biases are to instead interrogate the functional activity of the genes identified, either in isolation from or in conjunction with the taxonomic classification of the reads. As mentioned above, the {KEGG} Orthology database contains orthologs for molecular functions that may serve as biomarkers. In particular, molecular functions in the {KEGG} Orthology database that may be good biomarkers include K00088, K00133, K00520, K00549, K00963, K01372, K01591, K01624, K01835, K01867, K19972, K02005, K02111, K2795, K02879, K02919, K02967, K03040, K03100, K03111, K14220, K14221, K14225, K14232, K19972. {\textbar} {\textbar} As mentioned above, a problem that affects use of biomarkers as diagnostic aids is that while the relative quantities of a biomarker or a set of biomarkers may differ in biologic samples between people with and without a medical condition, tests that are based on differences in quantity often are not sensitive and specific enough to be effectively used for diagnosis. An objective is to develop and implement a test model that can be used to evaluate the patterns of quantities of a number of {RNA} biomarkers that are present in biologic samples in order to accurately determine the probability that the patient has a particular medical condition. {\textbar} {\textbar} An embodiment of the machine learning algorithm has been developed as a test model that may be used as a diagnostic aid in detecting autism spectrum disorder ({ASD}). In one embodiment, the test model is a support vector machine with radial basis function kernel. The number of features in the Test Panel found to achieve the asymptote of the predictive performance curve is 40. However, the number of features in a Test Panel is not limited to 40. The number of features in a Test Panel may vary as more data becomes available for use in constructing the test model. {\textbar} {\textbar} {FIG}. 11 {\textbar} {\textbar} is a flowchart for developing a machine learning model for {ASD} in accordance with exemplary aspects of the disclosure. In S {\textbar} 1101 {\textbar} , input data is collected from cohorts both with and without {ASD}, including controls with related disorders which complicate other diagnostic methods, such as developmental delays. In S {\textbar} 1103 {\textbar} , the data is split into training and test sets. In S {\textbar} 1105 {\textbar} , data is transformed using parameters derived on training data, as in {\textbar} 311 {\textbar} of {\textbar} {FIG}. 3 {\textbar} . {\textbar} Within each {RNA} category, abundance levels are normalized, scaled, transformed and ranked. Patient data are scaled and transformed. Oral transcriptome and patient data are merged and ranked to create the Master Panel. {\textbar} {\textbar} In S {\textbar} {\textbar} 1107 {\textbar} , a disease specific Master Panel of ranked {RNAs} and patient information is identified from which the Test Panel will be derived. The Master Panel is determined using the {GBM} model as in {\textbar} 315 {\textbar} of {\textbar} {FIG}. 3 {\textbar} . {\textbar} {FIGS}. 12A, 12B and 12C {\textbar} are an exemplary Master Panel of features that has been determined based on the Meta transcriptome and patient history data for {ASD} The first column in the figure is a list of principal components, {RNA}, microbes and patient history data provided as the features. Features listed in the first column as {PC}1, {PC}2, etc. are principal components that are results of performing principal component analysis. The second column in the figure is a list of importance values for the respective features. The third column in the figure is a list of categories of the respective features. The number of features in the Master Panel is not limited to those shown in {\textbar} {FIGS}. 12A, 12B, 12C {\textbar} , because the features that make up the Master Panel may vary as the Test Model algorithm is updated to include in the development process more data or other methods. For example, {\textbar} {FIGS}. 13A, 13B, 13C, 13D {\textbar} are a further exemplary Master Panel of features that have been determined based on the Metatranscriptome and patient history data for {ASD}. {\textbar} In S {\textbar} {\textbar} 1109 {\textbar} , a set of Support Vectors with elements consisting of a disease specific Test Panel of patient information and oral transcriptome {RNAs} is identified to be used for the Test Model. The Test Panel is a subset of a ranked Master Panel. Regarding {\textbar} {FIGS}. 12A, 12B and 12C {\textbar} , an exemplary Test Panel is the top 40 features listed in the Master Panel. Similarly, {\textbar} {FIGS}. 13A, 13B, 13C and 13D {\textbar} show, in bold, features that may be included in a Test Panel. {\textbar} {FIG}. 14 {\textbar} is an exemplary Test Panel of features that have been determined based on the Metatranscriptome and patient history data for {ASD}. The number of features may vary depending on the training data and the number of features that are required to reach a plateau in the predictive performance curve. The Test Panel may be derived from the Master Panel using the radial kernel {SVM} model as in {\textbar} 321 {\textbar} . The {SVM} is trained in successive training rounds using increasing numbers of features in the Master Panel as inputs, until predictive performance levels off, i.e., reaches a plateau. {\textbar} It has been determined that Test Panels derived using the {SVM} differ from the Test Panels of diagnostic {microRNAs} produced using methods without machine learning. Non-machine learning methods diagnosis a disease/condition by a generic comparison of abundances between test samples from normal subjects and subjects affected by the condition. The {SVM} derived Test Panels provide superior accuracy over the simple comparison of abundances of the non-machine learning methods. {\textbar} {\textbar} In S {\textbar} {\textbar} 1111 {\textbar} , a Support Vector Machine Model is trained on increasing numbers of the features from the Master Panel of features. The Model determines an optimally separating hyperplane with a soft margin. This margin is defined by the support vectors, as described above. The Test Model is the support vector machine model with the fewest input parameters with comparable performance to {SVMs} with successively more input parameters. The Test Panel is the set of features that comprise the components of the support vectors used in the Test Model. {\textbar} {FIG}. 15 {\textbar} {\textbar} is a flowchart for a machine learning model for determining the probability that a patient may be affected by {ASD}. In S {\textbar} 1501 {\textbar} , the Test Panel set of rave data ({RNA} abundances and patient information) obtained from the patient to be tested ({RNA} from saliva, patient information from interview) is transformed into a Test Panel set of Features as in {\textbar} 341 {\textbar} and {\textbar} 343 {\textbar} of {\textbar} {FIG}. 3 {\textbar} . In S {\textbar} 1503 {\textbar} , the Transformed. Test Panel set of Features obtained from the patient is compared against the set of Support Vectors that define the classification hyperplane boundary (Support Vector Library), {\textbar} 321 {\textbar} in {\textbar} {FIG}. 3 {\textbar} . Comparison of the Test Panel set of Features from the patient to be tested is compared against the Test Model's Support Vector Library using the comparison function f(x)=h(x) {\textbar} T {\textbar} β+α {\textbar} 0 {\textbar} =Σ {\textbar} i ∈ {SV} {\textbar} α {\textbar} i {\textbar} y {\textbar} i {\textbar} K(x {\textbar} i {\textbar} ,x*). The output of the comparison is an unsealed numeric value. {\textbar} In S {\textbar} {\textbar} 1505 {\textbar} , the numeric output result of the comparison of the Test Panel set of Features from the patient against the Test Model is converted into a probability of being affected by the {ASD} target condition using the Platt calibration method, as in {\textbar} 351 {\textbar} of {\textbar} {FIG}. 3 {\textbar} . {\textbar} The disclosed machine learning algorithms may be implemented as hardware, firmware, or in software. A software pipeline of steps may be implemented such that the speed and reliability of interrogating new samples may be increased. Accordingly, the required input data, collected from patients via questionnaire and sequenced saliva swab, are preferably processed and digitized. The biological data is preferably aligned to reference libraries and quantified to provide the abundance levels of biomarker molecules. These, and the patient data, are transformed as determined in the above steps, using parameters determined on the training data. {\textbar} {\textbar} The data used for training the test model may be combined with data that had been used for determining a master panel in order to obtain a more comprehensive training set of data which may yield a Test Model and Test Panel that has better sensitivity and specificity in predicting the {ASD} target condition. The combined transformed data may then be used to develop the Production Model, the output of which is transformed using the calibration method, and a probability of condition is determined. Thus, the Production Model uses the same inputs and parameters as derived in the Test Model, but it is trained on both the training and test data sets. In this preferred embodiment, a Production Model to aid diagnosis of {ASD} is defined using a larger data set and a software pipeline is implemented. Biological samples have the {RNA} purified, sequenced, aligned, and quantified; patient data is digitized. {\textbar} {\textbar} Subjects to be tested may have samples collected in the same manner as samples were collected from training subjects. Data from subjects to be tested preferably undergo identical sequencing, preprocessing, and transformations as training data. If the same methods are no longer available or possible, new methods may be substituted if they produce substantially equivalent results or data may be normalized, scaled, or transformed to substantially equivalent results. {\textbar} {\textbar} Quantified features from test samples may at least include the test panel, but may include the master panel or all input features. Test samples may be processed individually, or as a batch. {\textbar} {\textbar} A Test Panel is selected from the data, and data from both sources are transformed, likely using combinations of {PCA}, {IHS}, and {SS}. Transformed data are input into the Production Model, an {SVM} with radial kernel, and the output is calibrated to a probability that the patient has or does not have a medical condition, particularly, a mental disorder such as {ASD} or {PD}, a mental condition or a brain injury. {\textbar} {\textbar} Exemplary Application of the Disclosed Process {\textbar} {\textbar} In a non-limiting example of application of the disclosed process, saliva is collected in a kit, for example, provided by {DNA} Genotek. A swab is used to absorb saliva from under the tongue and pooled in the cheek cavities and is then suspended in {RNA} stabilizer. The kit has a shelf life of 2 years, and the stabilized saliva is stable at room temperature for 60 days after collection. Samples may be shipped without ice or insulation. Upon receipt at a molecular sequencing lab, samples are incubated to stabilize the {RNA} until a hatch of 48 samples has accumulated. {\textbar} {\textbar} At this time, {RNA} is extracted using standard Qiazol (Qiagen) procedures, and {cDNA} libraries are built using Illumina Small {RNA} reagents and protocols. {RNA} sequencing is performed on, for example, Illumina {NextSeq} equipment, which produces {BCL} files. These image files capture the brightness and wavelength (color) of each putative nucleotide in each {RNA} sequence. Software, for example Illumina's bcl2fastq, converts the {BCL} files into {FASTQ} files. {FASTQs} are digital records of each detected {RNA} sequence and the quality of each nucleotide based on the brightness and wavelength of each nucleotide. Average quality scores (or quality by nucleotide position) may be calculated and used as a quality control metric. {\textbar} {\textbar} Third-party aligners are used to align these nucleotide sequences within the {FASTQ} files to published reference databases, which identifies the known {RNA} sequences in the saliva sample. An aligner, for example the Bowtie1 aligner, is used to align reads to human databases, specifically {miRBase} v22, {piRBase} v1, and hg38. The outputs of the aligner (Bowtie1) are {BAM} files, which contain the detected {FASTQ} sequence and reference sequence to which the detected sequence aligns. The {SAMtools} idx software tool may be used to tabulate how many detected sequences align to each reference sequence, providing a high-dimensional vector for each {FASTQ} sample which represents the abundance of each reference {RNA} in the sample. (Each vector is comprised of many components, each of which represents an {RNA} abundance.) Thus, nucleotide sequences are transformed into counts of known human {miRNAs} and {piRNAs}. {\textbar} {\textbar} Sequences that do not align to hg38 are then aligned to the {NCBI} microbial database using k-{SLAM}. K-{SLAM} creates pseudo-assemblies of the detected {RNA} sequences, which are then compared to known microbial sequences and assigned to microbial genes, which are then quantified to microbial identity (eg, genus \& species) and activity (eg, metabolic pathway). {\textbar} {\textbar} These abundances of human short non-coding {RNAs}, microbial taxa, and metabolic pathways affected by the microbial taxa are then normalized using standard short {RNA} normalization methods and mathematical adjustments. These include normalizing by the total sum of each {RNA} category per sample, centering each {RNA} across samples to 0, and scaling by dividing each {RNA} by the standard deviation across samples. {\textbar} {\textbar} As each reference database includes thousands or tens of thousands of reference {RNAs}, microbes, or cellular pathways, statistical and machine learning feature selection methods are used to reduce the number of potential {RNA} candidates. Specifically, information theory, random forests, and prototype supervised classification models are used to identify candidate features within subsets of data. Features which are reliably selected across multiple cross-validation splits and feature selection methods comprise the Master Panel of input features. {\textbar} {\textbar} Features within the Master Panel are ranked using the variable importance within stochastic gradient boosted linear logistic regression machines. Features with high importance are then used as inputs to radial kernel support vector machines, which are used to classify saliva. samples as from {ASD} or non-{ASD} children, based on the highly ranked {RNA} and patient features. In this exemplary application, the features in {\textbar} {\textbar} {FIG}. 14 {\textbar} are used as the molecular test panel. {\textbar} Patient features include age, sex, pregnancy or birth complications, body mass index ({BMI}), gastrointestinal disturbances, and sleep problems. By including these key features, the {SVM} model identifies different {RNA} patterns within patient clusters. The output of the {SVM} model is both a sign (side of the decision boundary) and magnitude (distance from the decision boundary). Thus, each sample can be positioned relative to the decision boundary and assigned a class ({ASD} or non-{ASD}) and probability (relative distance from the boundary, as scaled by Platt calibration). In other words, the test model determines the distance from and side of the decision boundary of the patient's test panel sample. This distance of similarity is then translated into a probability that the patient has {ASD}. {\textbar} {\textbar} Results for Operation of the Production Model {\textbar} {\textbar} A non-limiting exemplary production model is configured to differentiate between young children with autism spectrum disorder ({ASD}) and other children, either typically developing ({JD}) or children with developmental delays ({DD}). The average age of diagnosis in the U.S. is approximately 4 years old, yet studies suggest that early intervention for {ASD}, before age 2, leads to the best long term prognosis for children with {ASD}. During the development of this exemplary production model, a sample included children 18 to 83 months (1.5 to 6 years) in order to provide clinical utility aiding in the early childhood diagnostic process. {\textbar} {\textbar} Prior to operation of the production model, a saliva swab and short online questionnaire are performed and, using the disclosed machine learning procedure classifies the microbiome and non-coding human {RNA} content in the child's saliva. in particular, each saliva swab is sent to a lab (for example, Admera Health) for {RNA} extraction and sequencing, and then bioinformatics processing is performed to quantify the amount of 30,000 {RNAs} found in the saliva. The machine learning procedure identified a panel of 32 {RNA} features, which are combined with information about the child (age, sex, {BMI}, etc) to provide a probability that the child will receive a diagnosis of {ASD}. {\textbar} {\textbar} The panel includes human {microRNAs}, {piRNAs}, microbial species, genera, and {RNA} activity. {MicroRNAs} and {piRNAs} are epigenetic molecules that regulate how active specific genes are. Microbes are known to interact with the brain. The saliva represents both a window into the functioning of the brain, and the microbiome and its relationship with brain health. By quantifying the {RNAs} found in the mouth, the machine learning procedure identified patterns of {RNAs} that are useful in differentiating children with {ASD} from those without. {\textbar} {\textbar} The panel of 32 {RNA} features includes 13 {miRNAs}, 4 {piRNAs}, 11 microbes, and 4 microbial pathways. These features, adjusted for age, sex, and other medical features, are used in the machine learning procedure to provide a probability that a child will be diagnosed with {ASD}. {\textbar} {\textbar} The production model then provides a probability that the child will receive a diagnosis of {ASD}. {\textbar} {\textbar} As indicated in the Table below, the study population is representative of children receiving diagnoses of {ASD}: ages 18 to 83 months, 74\% male, with a mixed history of {ADHD}, sleep problems, {GI} issues, and other comorbid factors. Children participating in the study represent diverse ethnicities and geographic backgrounds. {\textbar} {\textbar} Population characteristics {\textbar} {\textbar} Total {\textbar} {ASD} {\textbar} {DD} {\textbar} {TD} {\textbar} Children \# (\%) {\textbar} {\textbar} 692 {\textbar} (100\%) {\textbar} 383 (55\%) {\textbar} 121 {\textbar} (17\%) {\textbar} 188 {\textbar} (27\%) {\textbar} Male/Female \# {\textbar} {\textbar} 514/178 {\textbar} 313/70  {\textbar} 86/35 {\textbar} 115/73  {\textbar} \% {\textbar} {\textbar} 74\%/26\% {\textbar} 82\%/18\% {\textbar} 71\%/29\% {\textbar} 61\%/39\% {\textbar} Age (months) range {\textbar} {\textbar} 18-83 {\textbar} 20-83 {\textbar} 19-83 {\textbar} 18-83 {\textbar} Mean ± {SD} {\textbar} {\textbar} 47.5 ± 16.6 {\textbar} 48.5 ± 16.4 {\textbar} 45.6 ± 14.6 {\textbar} 46.5 ± 18.0 {\textbar} {BMI} range {\textbar} {\textbar} 12-40 {\textbar} 12-35 {\textbar} 12-36 {\textbar} 13-40 {\textbar} Mean ± {SD} {\textbar} {\textbar} 16.9 ± 2.8  {\textbar} 16.9 ± 2.6  {\textbar} 17.1 ± 2.9  {\textbar} 16.8 ± 3.0  {\textbar} {ADHD} \# (\%) {\textbar} {\textbar} 57 {\textbar} (8\%) {\textbar} 39 {\textbar} (10\%) {\textbar} 14 {\textbar} (12\%) {\textbar} 4 {\textbar} (2\%) {\textbar} Asthma {\textbar} {\textbar} 69 {\textbar} (10\%) {\textbar} 37 {\textbar} (10\%) {\textbar} 16 {\textbar} (13\%) {\textbar} 16 {\textbar} (9\%) {\textbar} Gastrointestinal Issues {\textbar} {\textbar} 196 {\textbar} (28\%) {\textbar} 137 {\textbar} (36\%) {\textbar} 39 {\textbar} (32\%) {\textbar} 20 {\textbar} (11\%) {\textbar} Sleep Issues {\textbar} {\textbar} 263 {\textbar} (38\%) {\textbar} 181 {\textbar} (47\%) {\textbar} 50 {\textbar} (41\%) {\textbar} 32 {\textbar} (17\%) {\textbar} Race - White - \# (\%) {\textbar} {\textbar} 535 {\textbar} (77\%) {\textbar} 283 {\textbar} (74\%) {\textbar} 93 {\textbar} (77\%) {\textbar} 159 {\textbar} (85\%) {\textbar} African American {\textbar} {\textbar} 70 {\textbar} (10\%) {\textbar} 44 {\textbar} (11\%) {\textbar} 16 {\textbar} (13\%) {\textbar} 10 {\textbar} (5\%) {\textbar} Hispanic {\textbar} {\textbar} 66 {\textbar} (9.5\%) {\textbar} 47 {\textbar} (12\%) {\textbar} 8 {\textbar} (7\%) {\textbar} 11 {\textbar} (6\%) {\textbar} In children with consensus diagnoses, the production model was found to be highly accurate in identifying children with {ASD} and children who are typically developing. As expected, the production model tends to give high values to children with {ASD} and lower values to {ID} children. In this operation, children who received a score below 25\% were most likely typically developing, and most children who received a score above 67\% were likely to have {ASD}. {\textbar} {\textbar} Exemplary Hardware {\textbar} {\textbar} {FIG}. 16 {\textbar} {\textbar} is a block diagram illustrating an example computer system for implementing the machine learning method according to an exemplary aspect of the disclosure. The computer system may be at least one server or workstation running a server operating system, for example Windows Server, a version of Unix {OS}, or Mac {OS} Server, or may be a network of hundreds of computers in a data center providing virtual operating system environments. The computer system {\textbar} 1600 {\textbar} for a server, workstation or networked computers may include one or more processing cores {\textbar} 1650 {\textbar} and one or more graphics processors ({GPU}) {\textbar} 1612 {\textbar} . including one or more processing cores. In an exemplary non-limiting embodiment, the main processing circuitry is an Intel Core i7 and the graphics processing circuitry is the Nvidia Geforce {GTX} 960 graphics card. The one or more graphics processing cores {\textbar} 1612 {\textbar} may perform many of the mathematical operations of the above machine learning method. The main processing circuitry, graphics processing circuitry, bus and various memory modules that perform each of the functions of the described embodiments may together constitute processing circuitry for implementing the present invention. In some embodiments, processing circuitry may include a programmed processor, as a processor includes circuitry. Processing circuitry may also include devices such as an application specific integrated circuit ({ASIC}) and circuit components arranged to perform the recited functions. In some embodiments, the processing circuitry may be a specialized circuit for performing artificial neural network algorithms. {\textbar} The computer system {\textbar} {\textbar} 1600 {\textbar} for a server, workstation or networked computer generally includes main memory {\textbar} 1602 {\textbar} , typically random access memory {RAM}, which contains the software being executed by the processing cores {\textbar} 1650 {\textbar} and graphics processor {\textbar} 1612 {\textbar} , as well as a non-volatile storage device {\textbar} 1604 {\textbar} for storing data and the software programs. Several interfaces for interacting with the computer system {\textbar} 1600 {\textbar} may be provided, including an I/O Bus Interface {\textbar} 1610 {\textbar} , Input/Peripherals {\textbar} 1618 {\textbar} such as a keyboard, touch pad, mouse, Display interface {\textbar} 1616 {\textbar} and one or more Displays {\textbar} 1608 {\textbar} , and a Network Controller {\textbar} 1606 {\textbar} to enable wired or wireless communication through a network {\textbar} 99 {\textbar} . The interfaces, memory and processors may communicate over the system bus {\textbar} 1626 {\textbar} . The computer system {\textbar} 1600 {\textbar} includes a power supply {\textbar} 1621 {\textbar} , which may be a redundant power supply. {\textbar} Numerous modifications and variations are possible in light of the above teachings. It is therefore to be understood that within the scope of the appended claims, the invention may be practiced otherwise than as specifically described herein. {\textbar} {\textbar} The various elements, features and processes described herein may be used independently of one another, or may be combined in various ways. All possible combinations and subcombinations are intended to fall within the scope of this disclosure. Further, nothing in the foregoing description is intended to imply that any particular feature, element, component, characteristic, step, module, method, process, task, or block is necessary or indispensable. The example systems and components described herein may be configured differently than described. For example, elements or components may be added to, removed from, or rearranged compared to the disclosed examples. {\textbar} {\textbar} Thus, the foregoing discussion discloses and describes merely exemplary embodiments of the present invention. As will be understood by those skilled in the art, the present invention may be embodied in other specific forms without departing from the spirit or essential characteristics thereof. Accordingly, the disclosure of the present invention is intended to be illustrative, but not limiting of the scope of the invention, as well as other claims. The disclosure, including any readily discernible variants of the teachings herein, defines, in part, the scope of the foregoing claim terminology such that no inventive subject matter is dedicated to the public. {\textbar} {\textbar} The above disclosure also encompasses the embodiments listed below. {\textbar} {\textbar} (1) A machine learning classifier that diagnoses autism spectrum disorder ({ASD}), includes processing circuitry that transforms data obtained from a patient medical history and a patient's saliva into data that correspond to a test panel of features, the data for the features including human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for {ASD}; and classifies the transformed data by applying the data to the processing circuitry that has been trained to detect {ASD} using training data associated with the features of the test panel. The trained processing circuitry includes vectors that define a classification boundary. {\textbar} {\textbar} (2) The machine learning classifier of feature (1), in which the trained processing circuitry is a support vector machine and the vectors that define the classification boundary are support vectors. {\textbar} {\textbar} (3) The machine learning classifier of features (1) or (2), in which the trained processing circuitry predicts a probability of {ASD} based on results of the classifying. {\textbar} {\textbar} (4) The machine learning classifier of any of features (1) to (3), in which the trained processing circuitry is a deep learning system that continues to learn based on additional transcriptome data. {\textbar} {\textbar} (5) The machine learning classifier of any of features (1) to (4), in which the processing circuitry transforms the data into data that corresponds to the test panel which includes features of at least one micro {RNA} selected from the group consisting of hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410, hsa-mir-4461 hsa-{miR}-15a-5p hsa-{miR}-6763-3p, hsa-{miR}-196a-5p, hsa-{miR}-4668-5p, hsa-{miR}-378d, hsa-{miR}-142-3p, hsa-mir-30c-1, hsa-mir-101-2, hsa-mir-151a, hsa-{miR}-125b-2-3p, hsa-mir-148a-5p, hsa-mir-548I, hsa-{miR}-98-5p, hsa-{miR}-8065, hsa-mir-378d-1, hsa-let-7f-1, hsa-let-7d-3p, hsa-let-7a-2, hsa-let-7f-2, hsa-let-7f-5p, hsa-mir-106a, hsa-mir-107, hsa-{miR}-10b-5p, hsa-{miR}-1244, hsa-{miR}-125a-5p, hsa-mir-1268a, hsa-{miR}-146a-5p, hsa-mir-155, hsa-mir-18a, hsa-mir-195, hsa-mir-199a-1, hsa-mir-19a, hsa-{miR}-218-5p, hsa-mir-29a, hsa-{miR}-29b-3p, hsa-{miR}-29c-3p, hsa-{miR}-3135b, hsa-mir-3182, hsa-mir-3665, hsa-mir-374a, hsa-mir-421, hsa-mir-4284, hsa-{miR}-4436b-3p, hsa-{miR}-4698, hsa-mir-4763, hsa-mir-4798, hsa-mir-502, hsa-{miR}-515-5p, hsa-mir-5572, hsa-{tniR}-6724-5p, hsa-mir-6739, hsa-{miR}-6748-3p, and hsa-{miR}-6770-5p. {\textbar} {\textbar} (6) The machine learning classifier of any of features (1) to (5), in which the processing circuitry transforms the data into data that corresponds to the test panel which includes features of at least one {piRNA} selected from the group consisting of {piR}-hsa-15023, {piR}-hsa.-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, ,{piR}-hsa-12423, {piR}-hsa-24684, {piR}-hsa-3405, {piR}-hsa-324, {piR}-hsa-18905, {piR}-hsa-23248, {piR}-hsa-28223, {piR}-hsa-28400, {piR}-hsa-1177, {piR}-hsa-26592, {piR}-hsa-11361, {piR}-hsa-26131, {piR}-hsa-27133, {piR}-hsa-27134, R-hsa-27282, and {piR}-hsa-27728. {\textbar} {\textbar} (7) The machine learning classifier of any of features (1) to (6), in which the processing circuitry transforms the data into data that corresponds to the test panel which includes features of at least one ribosomal {RNA} selected from the group consisting of {RNA}5S, {MTRNR}2L4, and {MTRNR}2L8. {\textbar} {\textbar} (8) The machine learning classifier of any of features (1) to (7), in which the processing circuitry transforms the data into data that corresponds to the test panel which includes features of at least one small nucleolar {RNA} selected from the group consisting of {SNORD}118, {SNORD}29, {SNORD}53B, {SNORD}68, {SNORD}20, {SNORD}41, {SNORD}30, {SNORD}34, {SNORD}110, {SNORD}28, {SNORD}45B, and {SNORD}92. {\textbar} {\textbar} (9). The machine learning classifier of any of features (1) to (8), in which the processing circuitry transforms the data into data that corresponds to the test panel which includes features of at least one long non-coding {RNA}. {\textbar} {\textbar} (10) The machine learning classifier of any of features (1) to (9), in which the processing circuitry transforms the data into data that corresponds to the test panel which includes features of at least one microbe selected from the group consisting of {\textbar} {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIB}122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, Pasteurella multocida subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus, Rothia, Cryptococcus gattii {\textbar} {WM}276, {\textbar} Neisseriaceae, Rothia dentocariosa {\textbar} {ATCC} 17931, {\textbar} Chryseobacterium {\textbar} sp. {IHB} B 17019, {\textbar} Streptococcus agalactiae {\textbar} {CNCTC} 10/84, {\textbar} Streptococcus pneumoniae {\textbar} {SPNA}45, {\textbar} Tsukamurella paurometabola {\textbar} {DSM} 20162, {\textbar} Streptococcus mutans {\textbar} {UA}159-{FR}, {\textbar} Actinomyces oris, Comamonadaceae, Streptococcus halotolerans, Flavobacterium columnare, Streptomyces griseochromogenes, Neisseria, Porphyromonas, Streptococcus salivarius {\textbar} {CCHSS} {\textbar} 3 {\textbar} , {\textbar} Megasphaera elsdenii {\textbar} . {DSM} 20460, {\textbar} Pasteurellaceae {\textbar} , an unclassified {\textbar} Burkholderiales {\textbar} , {\textbar} Arthrobacter, Dickeya, Jeotgallibacillus, Kocuria, Leuconostoc, Lysinibacillus, Maribacter, Methylophilus, Mycobacterium, Ottowia, Trichormus {\textbar} {\textbar} . {\textbar} (11) The machine learning classifier of any of features (1) to (10), in which the data from the patient's medical history corresponds to categorical patient features and numerical patient features. The transformation processing circuitry projects the categorical patient features onto principal components. {\textbar} {\textbar} (12) The machine learning classifier of feature (11), in which the processing circuitry transforms the data into data that corresponds to the test panel which includes features of seven of the patient data principal components and patient age; micro {RNAs} including: hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-{miR}-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410; {piRNAs} including: {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684; small nucleolar {RNA} including: {SNORD}118; and microbes including: {\textbar} {\textbar} Streptococcus gallolyticus {\textbar} subsp. gallolyticus {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIB}122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} multocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus {\textbar} . {\textbar} (13) The machine learning classifier of feature (11), in which the test panel includes features of seven of the patient data principal components, patient age, and patient sex; micro {RNAs} including: hsa-let-7a-2, hsa-{miR}-10b-5p, hsa-{miR}-125a-5p, hsa-{miR}-125b-2-3p, hsa-{miR}-142-3p, hsa-{miR}-146a-5p, hsa-{miR}-218-5p, hsa-mir-378d-1, hsa-mir-410, hsa-mir-421, hsa-mir-4284, hsa-{miR}-4698, hsa-mir-4798, hsa-{miR}-515-5p, hsa-mir-5572, hsa-{miR}-6748-3p; {piRNAs} including: {piR}-hsa-12423, {piR}-hsa-15023, {piR}-hsa-18905, {piR}-hsa-23638, {piR}-hsa-24684, {piR}-hsa-27133, {piR}-hsa-324, {piR}-hsa-9491; long nucleolar {RNA}; microbes including: {\textbar} {\textbar} Actinomyces, Arthrobacter, Jeotgalibacillus, Leadbetterelia, Leuconostoc, Mycobacterium, Ottowia, Saccharomyces {\textbar} ; and a microbial activity including: K00520, K14221, K01591, K02111, K14255, K1432, K00133, K03111. {\textbar} (14) The machine learning classifier of feature (1), in which the test panel of features and the vectors that define the classification boundary are determined by the processing circuitry by fitting a predictive model with an increasing number of features in a Master Panel of features in ranked order until a predictive performance reaches a plateau. {\textbar} {\textbar} (15) The machine learning classifier of feature (14), in which the predictive model is a support vector machine model. {\textbar} {\textbar} (16) The machine learning classifier of features (14) or (15), in which the predictive model is a support vector machine model with radial kernel. {\textbar} {\textbar} (17) The machine learning classifier of any of features (14) to (16), in which the data from the patient's medical history corresponds to categorical patient features and numerical patient features. The transformation processing circuitry projects the categorical patient features onto principal components. The Master Panel includes features of nine of the patient data principal components and patient age; micro {RNAs} including: hsa-mir-146a, hsa-mir-146b, hsa-{miR}-92a-3p, hsa-{miR}-106-5p, hsa-{miR}-3916, hsa-mir-10a, hsa-{miR}-378a-3p, hsa-{miR}-125a-5p, hsa-{miR}146b-5p, hsa-{miR}-361-5p, hsa-mir-410, hsa-mir-4461, hsa-{miR}-15a-5p, hsa-{miR}-6763-3p, hsa-{miR}-196a-5p, hsa-{miR}-4668-5p, hsa-{miR}-378d, hsa-{miR}-142-3p, hsa-mir-30c-1, hsa-mir-101-2, hsa-mir-151a, hsa-milk-125b-2-3p, hsa-mir-148a-5p, hsa-mir-548I, hsa-{miR}-98-5p, hsa-{miR}-8065, hsa-mir-378d-1, hsa-let-7f-1, and hsa-let-7d-3p; {piRNAs} including: {piR}-hsa-15023, {piR}-hsa-27400, {piR}-hsa-9491, {piR}-hsa-29114, {piR}-hsa-6463, {piR}-hsa-24085, {piR}-hsa-12423, {piR}-hsa-24684, {piR}-hsa-3405, {piR}-hsa-324, {piR}-hsa-18905, {piR}-hsa-23248, {piR}-hsa-28223, {piR}-hsa-28400, {piR}-hsa-1177, and {piR}-hsa-26592; small nucleolar {RNAs} including: {SNORD}118, {SNORD}29, {SNORD}53B, {SNORD}68, {SNORD}20, {SNORD}41, {SNORD}30, and {SNORD}34; ribosomal {RNAs} including: {RNASS}, {MTRNR}2L4, and {MTRNR}2L8; long non-coding {RN} A including: {LOC}730338, microbes including: {\textbar} {\textbar} Streptococcus gallolyticus {\textbar} subsp. {\textbar} gallolyticus {\textbar} {DSM} 16831, {\textbar} Yarrowia lipolytica {\textbar} {CLIB}122, {\textbar} Clostridiales, Oenococcus oeni {\textbar} {PSU}-1, {\textbar} Fusarium, Alphaproteobacteria, Lactobacillus fermentum, Corynebacterium uterequi, Ottowia {\textbar} sp. oral taxon 894, {\textbar} Pasteurella multocida {\textbar} subsp. {\textbar} muitocida {\textbar} {OH}4807, {\textbar} Leadbetterella byssophila {\textbar} {DSM} 17132, {\textbar} Staphylococcus, Rothia, Cryptococcus gattii {\textbar} {WM}276, {\textbar} Neissedaceae, Rothia dentocariosa {\textbar} {ATCC} 17931, {\textbar} Chryseobacterium {\textbar} sp. {IHB} B 17019, {\textbar} Streptococcus agalactiae {\textbar} {CNCTC} 10/84, {\textbar} Streptococcus pneumoniae {\textbar} {SPNA}45, {\textbar} Tsukamurella paurometabola {\textbar} {DSM} 20162, {\textbar} Streptococcus mutans {\textbar} {UA}159-{FR}, {\textbar} Actinomyces oris, Comamonadaceae, Streptococcus halotolerans, Flavobacterium columnare, Streptomyces griseochromogenes, Neisseria, Porphyromonas, Streptococcus salivarius {\textbar} {CCHSS} {\textbar} 3 {\textbar} , {\textbar} Megasphaera elsdenii {\textbar} {DSM} 20460, {\textbar} Pasteurellaceae {\textbar} , and an unclassified {\textbar} Burkholderiales {\textbar} . {\textbar} (18) The machine learning classifier of any of features (14) to (17), in which the processing circuitry determines the Test Panel of features which includes micro {RNAs} including: hsa\_let 7\_d\_5p, hsa\_let\_7g\_5p, hsa-Mir\_101\_3p, hsa-{miR}\_1307\_5p, hsa\_miR\_142\_5p, hsa\_miR\_151a\_3p, hsa\_miR\_15a\_5p, hsa\_miR\_10\_3p, hsa\_miR\_28\_3p, hsa\_miR\_29a\_3p, hsa\_miR\_3074\_5p, hsa\_miR\_374a\_5p, hsa\_miR\_92a\_3p; {piRNAs} including: hsa-{piRNA}\_3499, hsa-{piRNA}\_1433, hsa-{piRNA}\_9843, hsa-{piRNA}\_2533; microbes including: {\textbar} {\textbar} Actinomyces meyeri, Eubacterium, Kocuria flava, Kocuria rhizophila, Kocuria turfanensis, Lactobacillus fermentum, Lysinibacillus sphaericus, Micrococcus luteus, Ottowia, Rothia dentocariosa, Streptococcus dysgalactiae {\textbar} ; a microbial activity including: K01867, K02005, K02795, K19972. {\textbar} (19) A classification machine learning system, includes a data input device that receives as inputs human microtranscriptome and microbial transcriptome data, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; processor circuitry that transforms a plurality of features into an ideal form, determines and ranks each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranking across all the transcriptome data; the processor circuitry that learns to detect the target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau, sets the features as a test panel, and sets a test model for the target medical condition based on patterns of the test panel features. {\textbar} {\textbar} (20) The classification machine learning system of feature (19), in which the data input device receives categories of the microtranscriptome data which include one or more of mature {microRNA}, precursor {microRNA}, {piRNA}, {snoRNA}, ribosomal {RNA}, long non-coding {RNA}, and microbes identified by {RNA}. {\textbar} {\textbar} (21) The classification machine learning system of features (191 or (20), in which the processing circuitry transforms the features which include {RNA} derived from saliva via {RNA} sequencing and microbial taxa identified by {RNA} derived from the saliva. {\textbar} {\textbar} (22) The classification machine learning system of any of features (19) to (21), in which the data input device receives the input data which includes patient data extracted from surveys and patient charts. The processor circuitry modifies the rank of specific features that vary depending on the patient data. {\textbar} {\textbar} (23) The classification machine learning system of feature (22), in which the processing circuitry transforms the features including patient data that varies based on circadian patient data, including one or more of time of collection of saliva sample, time since last meal, time since teeth hygiene treatment. {\textbar} {\textbar} (24) The classification machine learning system of any of features (19) to (23), in which the processor circuitry includes a stochastic gradient boosting machine circuitry that increases prediction accuracy for each feature type information identified with the categories, ranks each feature type information in order of prediction performance, and selects the top features within each category. {\textbar} {\textbar} (25) The classification machine learning system of feature (24), in which the stochastic gradient boosting machine is a random forest variant of a stochastic gradient boosting logistic regression machine. {\textbar} {\textbar} (26) The classification machine learning system of any of features (19) to (25), in which the processor circuitry includes a support vector machine. {\textbar} {\textbar} (27) The classification machine learning system of any of features (19) to (26), in which the data input device receives the human data and microbial data that are specific to the target medical condition. {\textbar} {\textbar} (28) The classification machine learning system of feature (27), in which the target medical condition is a condition from the group consisting of autism spectrum disorder, Parkinson's disease, and traumatic brain injury. {\textbar} {\textbar} (9) The classification machine learning system of any of features (19), in which the data input device receives the genetic data which includes other biomarkers. {\textbar} {\textbar} (30) The classification machine learning system of feature (22), in which the data input device receives the patient data which includes one or more of time of day, body mass index, age, weight, geographical region of residence at a time that a biological sample is provided by the patient for purposes of obtaining the genetic data. {\textbar} {\textbar} (31) The classification machine learning system of any of features (19) to (30), in which the data input device receives the human microtranscriptome data which includes nucleotide sequences and a count for each sequence indicating abundance in a biological sample. {\textbar} {\textbar} (32) A method performed by a machine learning system, the machine learning system including a data input device, and processing circuitry, the method includes receiving as inputs human microtranscriptome and microbial transcriptome data via the data input device, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; transforming a plurality of features into an ideal form; determining and ranking via the processor circuitry each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranting across all the transcriptome data; learning to detect a target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau; setting the features included as a test panel; and setting a test model for the target medical condition based on patterns of the test panel features. {\textbar} {\textbar} (33) The method of feature (32), in which the receiving includes receiving categories of the microtranscriptome data which include one or more of mature {microRNA}, precursor {microRNA}, {piRNA}, {snoRNA}, ribosomal {RNA}, long non-coding {RNA}, and identified by {RNA}. {\textbar} {\textbar} (34) The method of features (32) or (33), in which the receiving includes receiving the features which include {RNA} derived from saliva via {RNA} sequencing and microbial taxa identified by {RNA} derived from the saliva. {\textbar} {\textbar} (35) The method of any of features (32) to (34), further includes receiving patient data extracted from surveys and patient charts; and modifying, by the processing circuitry, the rank of specific features that vary depending on the patient data. {\textbar} {\textbar} (36) The method of feature (35), in which the receiving includes receiving the patient data that vary based on circadian patient data, including one or more of time of collection of saliva sample, time since last meal, time since teeth hygiene treatment. {\textbar} {\textbar} (37) The method of feature (32), in which the target medical condition is a condition from the group consisting of autism spectrum. disorder, Parkinson's disease, and traumatic brain injury. {\textbar} {\textbar} (38) A non-transitory computer-readable storage medium storing program code, which when executed by a machine learning system, the machine learning system including a data input device, and processor circuitry, the program code performs a method including receiving as inputs human microtranscriptome and microbial transcriptome data via the data input device, wherein the transcriptome data are associated with respective {RNA} categories for a target medical condition; transforming a plurality of features into an ideal form; determining and ranking each transformed feature from the human microtranscriptome and microbial transcriptome data in terms of predictive power relative to similar features, selects top ranked transformed features from each {RNA} category, and calculates a joint ranking across all the transcriptome data; learning to detect a target medical condition by fitting a predictive model with an increasing number of features from the joint data in ranked order until predictive performance reaches a plateau; setting the features included as a test panel; and setting a test model for the target medical condition based on patterns of the test panel features. {\textbar} {\textbar} All publications, patent applications, patents, and other references mentioned herein are incorporated by reference in their entirety. Further, the materials, methods, and examples are illustrative only and are not intended to be limiting, unless otherwise specified. {\textbar} {\textbar} {LITERATURE} {\textbar} {\textbar} 1. Ambros et al. The functions of animal {microRNAs}, Nature, 431 (7006):350-5 (Sep. 16, 2004), herein incorporated by reference in its entirety. {\textbar} {\textbar} 2. Bartel et al., {MicroRNAs}: genomics, biogenesis, mechanism, and function, Cell, 116 (2): 281-97 (Jan. 23, 2004), herein incorporated by reference in its entirety. {\textbar} 3. Xu L M, Li J R, Huang Y, Zhao M, Tang X, Wei L. {AutismKB}: an evidence-based knowledgebase of autism genetics. Nucleic Acids Res 2012;40:D1016-22, herein incorporated by reference in its entirety. {\textbar} 4. Gallo A, Tandon M, Alevizos I, Illei G G. The majority of {microRNAs} detectable in serum and saliva is concentrated in exosomes. {PLOS} One 2012;7:e30679, herein incorporated by reference in its entirety. {\textbar} 5. Mulle, J. G., Sharp, W. G., \& Cubells, J. F., The gut microbiome: a new frontier in autism research, Current Psychiatry Eeports, 15(2), 337 (2013), herein incorporated by reference in its entirety.
Issue: {US}20210383924A1},
}

@patent{eckstein_petah21,
	location = {{US}},
	title = {A method for determining a {DHEA} intensity dose for specific patient},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {A method operating on a processor or a machine learning processor for determining a specific dose of {DHEA} for a specific patient, by providing a dynamic predictive analytics using the biochemical parameters of the specific patient based on his blood test or saliva test, his molecular epigenetic map, his medical parameters regarding the level of his depression, anxiety, quality of life and intense of craving, and his psychological parameters.
A method operating on a processor or a machine learning processor for determining a specific dose of {DHEA} for a specific patient, by providing a dynamic predictive analytics using the biochemical parameters of the specific patient based on his blood test or saliva test, his molecular epigenetic map, his medical parameters regarding the level of his depression, anxiety, quality of life and intense of craving, and his psychological parameters.
A method operating on a processor or a machine learning processor for determining a specific dose of {DHEA} for a specific patient, by providing a dynamic predictive analytics using the biochemical parameters of the specific patient based on his blood test or saliva test, his molecular epigenetic map, his medical parameters regarding the level of his depression, anxiety, quality of life and intense of craving, and his psychological parameters.},
	type = {patent},
	author = {Eckstein, Eitan Nathan and Petah, Tikva},
	urldate = {2019-01-19},
	date = {2021-11-18},
	note = {Edition: G16H005020 {\textbar} G16H001020 {\textbar} G16H001040 {\textbar} G16H001060 {\textbar} G16H002010 {CPC}  - G16H005020 {\textbar} G16H001020 {\textbar} G16H001040 {\textbar} G16H001060 {\textbar} G16H002010 {\textbar} G16H002070 {\textbar} G16H003020 {EP}; {US} {EP}; {US} {US} {US} What is claimed is: {\textbar}   {\textbar} 1 {\textbar} . A method operating on a processor or a machine learning processor for determining an intensity dose of {DHEA} for a personalized medicine, comprising:  {\textbar} (a) providing biochemical parameters of said specific patient based on his blood test or saliva test wherein said biochemical parameters includes a level of {DHEA} and Cortisol; {\textbar}   {\textbar} (b) providing molecular epigenetic map of said specific patient based on his blood test or saliva test; {\textbar}   {\textbar} (c) providing medical parameters of said specific patient based on medical diagnosis regarding his level of depression, anxiety, quality of life and intense of craving; {\textbar}   {\textbar} (d) providing psychological parameters of said specific patient based on psychological questionnaire regarding his impulsiveness; {\textbar}   {\textbar} (e) providing said processor and entering to it said biochemical parameters, said molecular epigenetic map, said medical parameters, and said psychological parameters and assigning a particular weight to each of said biochemical parameters, said molecular epigenetic map, each of said medical parameters, and each of said psychological parameters; {\textbar}   {\textbar} (f) estimating a weigh composition of said particulars weights; {\textbar}   {\textbar} whereby said weigh composition enables to determine an optimized intensity dose of {DHEA} for said specific patient when he is addict during a detoxification and rehabilitation periods. {\textbar}   {\textbar} 2 {\textbar} . The method operating on a processor for determining an intensity dose of {DHEA} for a specific patient of  {\textbar} claim 1 {\textbar} , further comprising:  {\textbar} (a) providing a brain imaging data of said specific patient and entering said brain imaging data to said processor; {\textbar}   {\textbar} (b) assigning a particular predictive analytics weight for said brain imaging for calculating said estimation of said weigh composition. {\textbar}   {\textbar} 3 {\textbar} . A method for determining dose of {DHEA} for a specific patient, comprising:  {\textbar} (a) providing biochemical parameters of said specific patient based on his blood test or saliva test wherein said biochemical parameters includes a level of {DHEA} and Cortisol; {\textbar}   {\textbar} (b) providing molecular epigenetic map of said specific patient based on his blood test or saliva test; {\textbar}   {\textbar} (c) providing medical parameters of said specific patient based on medical diagnosis regarding his level of depression, anxiety, quality of life and intense of craving; side effects {\textbar}   {\textbar} (d) providing psychological parameters of said specific patient based on psychological questionnaire regarding his impulsiveness; {\textbar}   {\textbar} (e) assigning a particular weight to each of said biochemical parameters, said molecular epigenetic map, each of said medical parameters, and each of said psychological parameters; based on a specific algorithm {\textbar}   {\textbar} (f) estimating a weigh composition of said particulars weights; {\textbar}   {\textbar} whereby said weigh composition enables to determine an optimized the dose of {DHEA} for said specific addict during a detoxification and rehabilitation periods. {\textbar}   {\textbar} 4 {\textbar} . The method for determining an intensity of {DHEA} treatment for a specific patient of  {\textbar} claim 3 {\textbar} , further comprising:  {\textbar} (a) providing a brain imaging data of said specific patient; {\textbar}   {\textbar} (b) assigning a particular predictive analytics weight for said brain imaging for calculating said estimation of said weigh composition. What is claimed is: {\textbar}   {\textbar} 1 {\textbar} . A method operating on a processor or a machine learning processor for determining an intensity dose of {DHEA} for a personalized medicine, comprising:  {\textbar} (a) providing biochemical parameters of said specific patient based on his blood test or saliva test wherein said biochemical parameters includes a level of {DHEA} and Cortisol; {\textbar}   {\textbar} (b) providing molecular epigenetic map of said specific patient based on his blood test or saliva test; {\textbar}   {\textbar} (c) providing medical parameters of said specific patient based on medical diagnosis regarding his level of depression, anxiety, quality of life and intense of craving; {\textbar}   {\textbar} (d) providing psychological parameters of said specific patient based on psychological questionnaire regarding his impulsiveness; {\textbar}   {\textbar} (e) providing said processor and entering to it said biochemical parameters, said molecular epigenetic map, said medical parameters, and said psychological parameters and assigning a particular weight to each of said biochemical parameters, said molecular epigenetic map, each of said medical parameters, and each of said psychological parameters; {\textbar}   {\textbar} (f) estimating a weigh composition of said particulars weights; {\textbar}   {\textbar} whereby said weigh composition enables to determine an optimized intensity dose of {DHEA} for said specific patient when he is addict during a detoxification and rehabilitation periods. {\textbar}   {\textbar} 2 {\textbar} . The method operating on a processor for determining an intensity dose of {DHEA} for a specific patient of  {\textbar} claim 1 {\textbar} , further comprising:  {\textbar} (a) providing a brain imaging data of said specific patient and entering said brain imaging data to said processor; {\textbar}   {\textbar} (b) assigning a particular predictive analytics weight for said brain imaging for calculating said estimation of said weigh composition. {\textbar}   {\textbar} 3 {\textbar} . A method for determining dose of {DHEA} for a specific patient, comprising:  {\textbar} (a) providing biochemical parameters of said specific patient based on his blood test or saliva test wherein said biochemical parameters includes a level of {DHEA} and Cortisol; {\textbar}   {\textbar} (b) providing molecular epigenetic map of said specific patient based on his blood test or saliva test; {\textbar}   {\textbar} (c) providing medical parameters of said specific patient based on medical diagnosis regarding his level of depression, anxiety, quality of life and intense of craving; side effects {\textbar}   {\textbar} (d) providing psychological parameters of said specific patient based on psychological questionnaire regarding his impulsiveness; {\textbar}   {\textbar} (e) assigning a particular weight to each of said biochemical parameters, said molecular epigenetic map, each of said medical parameters, and each of said psychological parameters; based on a specific algorithm {\textbar}   {\textbar} (f) estimating a weigh composition of said particulars weights; {\textbar}   {\textbar} whereby said weigh composition enables to determine an optimized the dose of {DHEA} for said specific addict during a detoxification and rehabilitation periods. {\textbar}   {\textbar} 4 {\textbar} . The method for determining an intensity of {DHEA} treatment for a specific patient of  {\textbar} claim 3 {\textbar} , further comprising:  {\textbar} (a) providing a brain imaging data of said specific patient; {\textbar}   {\textbar} (b) assigning a particular predictive analytics weight for said brain imaging for calculating said estimation of said weigh composition. 1 {\textbar} . A method operating on a processor or a machine learning processor for determining an intensity dose of {DHEA} for a personalized medicine, comprising:  {\textbar} (a) providing biochemical parameters of said specific patient based on his blood test or saliva test wherein said biochemical parameters includes a level of {DHEA} and Cortisol; {\textbar}   {\textbar} (b) providing molecular epigenetic map of said specific patient based on his blood test or saliva test; {\textbar}   {\textbar} (c) providing medical parameters of said specific patient based on medical diagnosis regarding his level of depression, anxiety, quality of life and intense of craving; {\textbar}   {\textbar} (d) providing psychological parameters of said specific patient based on psychological questionnaire regarding his impulsiveness; {\textbar}   {\textbar} (e) providing said processor and entering to it said biochemical parameters, said molecular epigenetic map, said medical parameters, and said psychological parameters and assigning a particular weight to each of said biochemical parameters, said molecular epigenetic map, each of said medical parameters, and each of said psychological parameters; {\textbar}   {\textbar} (f) estimating a weigh composition of said particulars weights; {\textbar}   {\textbar} whereby said weigh composition enables to determine an optimized intensity dose of {DHEA} for said specific patient when he is addict during a detoxification and rehabilitation periods. 1 {\textbar} . A method operating on a processor or a machine learning processor for determining an intensity dose of {DHEA} for a personalized medicine, comprising:  {\textbar} (a) providing biochemical parameters of said specific patient based on his blood test or saliva test wherein said biochemical parameters includes a level of {DHEA} and Cortisol; {\textbar}   {\textbar} (b) providing molecular epigenetic map of said specific patient based on his blood test or saliva test; {\textbar}   {\textbar} (c) providing medical parameters of said specific patient based on medical diagnosis regarding his level of depression, anxiety, quality of life and intense of craving; {\textbar}   {\textbar} (d) providing psychological parameters of said specific patient based on psychological questionnaire regarding his impulsiveness; {\textbar}   {\textbar} (e) providing said processor and entering to it said biochemical parameters, said molecular epigenetic map, said medical parameters, and said psychological parameters and assigning a particular weight to each of said biochemical parameters, said molecular epigenetic map, each of said medical parameters, and each of said psychological parameters; {\textbar}   {\textbar} (f) estimating a weigh composition of said particulars weights; {\textbar}   {\textbar} whereby said weigh composition enables to determine an optimized intensity dose of {DHEA} for said specific patient when he is addict during a detoxification and rehabilitation periods. {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar}   {\textbar} The intention of the drawings attached to the application is not to limit the scope of the invention and its application. The drawings are intended only to illustrate the invention and they constitute only one of its many possible implementations. {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  describes schematically the main concept of the method that includes a computer processor ( {\textbar} 1 {\textbar} ), the biochemical parameters ({BP}), the molecular epigenetic map ({MEM}), the medical parameters ({MP}), the psychological parameters ({PP}), and the brain imaging ({BI}). {\textbar} {TECHNICAL} {FIELD} {\textbar}   {\textbar} The present invention refers to a method for determining a {DHEA} intensity (dose per interval) for a specific patient based on his biochemical, molecular, epigenetic, medical, psychological, and his brain imaging parameters. {\textbar}   {\textbar} {BACKGROUND} {ART} {\textbar}   {\textbar} Drug rehab includes a detoxification and rehabilitation periods. It is known that high percent of drug addicts who successfully went through the detoxification period failed in the rehabilitation period and unfortunately come back to drugs relapse Research has shown deficiencies in {DHEA} secretion in drug addicts. The {DHEA} is produced in the central nervous system and in the gonads and overy) during stressful situations the ratio of {DHEA}/cortisol is altered and this parameter is believed to be associated with the ability to cope with stress maladaptation. These raised the possibility that integration of exogenous {DHEA} application addiction treatment can enhance the rehabilitation process. Since the 90 {\textbar}   {\textbar} th  {\textbar} the {DHEA} is manufactured and marketed as a neurosteroid nutritional supplement. {\textbar} In 2015, the inventors of the invention subject matter of the present patent application published the article: “Effect of dehydroepiandrosterone add-on therapy on mood, decision making and subsequent relapse of polydrug users”. In this article the inventors show that a {DHEA} treatment causes a significant decrease in detoxification symptoms, including depression and anxiety and also alleviate the intense craving for drugs in the rehabilitation period and enhance the chances for longer term success, decreasing relapse rate to drug usage. {\textbar}   {\textbar} In addition, the addicts cannot assimilate and implement new experiences, and remain affixed to their old experiences, which heighten drug craving. As their ability to acquire new habits is attenuated, and they cannot free themselves from the memories of cue-associated sensations of the drug offered Hence can (easily relapse) to their previous harmful drug-associated habits, even long time after conclusion of the rehabilitation program. The studies of the inventors demonstrated that {DHEA} treatment positively affected decision-making, mood and well-being as early as one month treatment, and had a long-lasting preventive effect on relapse to drug use. The {DHEA}-treated group reported fewer negative emotions, and showed more advantageous choosing in a decision-making task as compared to the placebo-treated patients in parallel to their cling period. {\textbar}   {\textbar} The inventors take their results a further step and developed a computer program to analyze the rehab process. They found out that the {DHEA} treatment is highly efficient when a specific patient receive a dose of {DHEA} which is tailored to his specific behavioral, cognitive and medical parameters. The inventors developed a method which employed algorithms, using mathematical and statistical calculations of the biochemical parameters, molecular epigenetic map, medical parameters, and psychological parameters of a specific patient for determining the intensity of {DHEA} treatment for a specific patient. The computer program also predicts the success of treatment and by that provides necessary information as to the period in which the patient should be supervised. {\textbar}   {\textbar} {THE} {INVENTION} {\textbar}   {\textbar} The objective of the present invention is to provide a computer program for determining an intensity dose of {DHEA} for a specific patient. The method may be operated on a processor or on a machine learning processor, and uses the biochemical parameters ({BP}), the molecular epigenetic map ({MEM}), the medical parameters ({MP}), the psychological parameters ({PP}), and the brain imaging ({BI}) of the specific patient. {\textbar}   {\textbar} The biochemical parameters ({BP}) of the specific patient may be based on his blood test or saliva. These biochemical parameters include the level of {DHEA}, {DHEA}-S and Cortisol. The molecular epigenetic map ({MEM}) of the specific patient may be based on his blood test or saliva test. The medical parameters ({MP}) of the specific patient may be based on medical diagnosis regarding his level of depression, anxiety, and quality of life and intense of craving. These medical parameters may be based on the Hamilton rating scale for depression, Quality of Life Enjoyment and Satisfaction Questionnaires, Beck Anxiety Inventory, Brief Substance Craving Scale, {PANAS} scale and other kind of such questionnaires. The psychological parameters ({PP}) of the specific patient may be based on psychological questionnaire regarding his impulsiveness. These psychological parameters may be also based on the {ASI} Questionnaire, Iowa Gambling Task, and other kind of such questionnaires. {\textbar}   {\textbar} These data may be entered to the computer machine learning processor and after that the method includes the stage of assigning a particular weight to each of these biochemical parameters, molecular epigenetic map, each of the medical parameters, each of the psychological parameters, and the brain imaging. After this stage, the method can calculate dynamically/longitudinally the stage of estimating a weigh composition of these particulars cluster. This weigh composition enables to determine the optimized intensity dose of {DHEA} treatment for a specific addict longitudinally through the detoxification and rehabilitation progress. The method may further uses the brain imaging data of the specific patient, assigning a particular weight for this brain imaging for calculating and estimating the weigh composition. {\textbar}   {\textbar} The method can be used by rehab clinics which may enter these secure/confidential data to the computer program and receive the optimized intensity dose of {DHEA} for this specific patient as to its response to the treatment (machine learning). It is recommended to analyze data collected at the beginning of the detoxification period and then to repeat this action every month for several months consecutively. The method takes in account also the results of former data of the specific patient that were entered to the computer. {\textbar}   {\textbar} This weigh composition (predictive analytics) also enables to predict the probability of the specific patient to succeed in his rehabilitation process and therefore enables the rehab clinic to decide whether to release him of supervised care. {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  describes schematically the main concept of the method that includes a computer (machine learning) processor (Processor), the biochemical parameters ({BP}), the molecular epigenetic map ({MEM}), the medical parameters ({MP}), the psychological parameters ({PP}), and the brain imaging ({BI}).
Issue: {US}20210358623A1},
}

@patent{zhang_etal20i,
	location = {{CN}},
	title = {Children {ADHD} screening evaluation system based on multi-mode deep learning},
	url = {https://www.derwentinnovation.com/tip-innovation/recordView.do?hideHighlightPanel=true&idType=uid/recordid&datasource=T3&databaseIds=PATENT&category=PAT&recordKeys=CN111528859A_20200814&TYPE=RECORDVIEW&fromExternalLink=true&fromLocation=external&isDAJImageAllowed=false},
	abstract = {A children {ADHD} screening evaluation system based on multi-mode deep learning, comprising: a meter testing module for collecting and evaluating the diagnosis children by the {ADHD} diagnosis psychology meter; software and hardware cooperation module, for developing the test software to finish the task of the diagnosis children; the hardware module is used for recording the eye movement attention, expression and body posture information in the task test process; an intelligent analysis module, for using computer vision technology to do eye movement attention, analysis of expression and posture, also moving the mouse of the tester, clicking and keyboard input action is also recorded and tracked, and fusion with the same quality vector; multi-mode information fusion model, using the time sequence multi-mode information fusion model {BERT}, pre-training the same quality vector combined test result obtained in a certain time slice; finally generating the model to judge whether the patient has the classification result of abnormal behaviour in this time period. The invention has high efficiency and good accuracy. {\textbar}   {\textbar} 一种基于多模态深度学习技术的儿童{ADHD筛查评估系统}，包括：量表测试模块，用于通过{ADHD诊断心理学量表采集和评估就诊儿童}；软硬件协同模块，用于开发测试软件让就诊儿童完成任务，硬件模组用于记录任务测试过程中的眼动注意力、表情和身体姿态三方面信息；智能分析模块，用于运用计算机视觉技术进行眼动注意力、表情、姿态的分析，还对测试者的鼠标移动、点击和键盘输入动作也做了记录和跟踪，与同质化向量融合；多模态信息融合模型，采用时序多模态信息融合模型{BERT}，对某个特定时间片段中获取的同质化向量结合测试结果进行预训练，最终生成的模型判断患者在本时间段是否存在异常行为的分类结果。本发明效率较高、准确性较好。
一种基于多模态深度学习技术的儿童{ADHD筛查评估系统}，包括：量表测试模块，用于通过{ADHD诊断心理学量表采集和评估就诊儿童}；软硬件协同模块，用于开发测试软件让就诊儿童完成任务，硬件模组用于记录任务测试过程中的眼动注意力、表情和身体姿态三方面信息；智能分析模块，用于运用计算机视觉技术进行眼动注意力、表情、姿态的分析，还对测试者的鼠标移动、点击和键盘输入动作也做了记录和跟踪，与同质化向量融合；多模态信息融合模型，采用时序多模态信息融合模型{BERT}，对某个特定时间片段中获取的同质化向量结合测试结果进行预训练，最终生成的模型判断患者在本时间段是否存在异常行为的分类结果。本发明效率较高、准确性较好。
A children {ADHD} screening evaluation system based on multi-mode deep learning, comprising: a meter testing module for collecting and evaluating the diagnosis children by the {ADHD} diagnosis psychology meter; software and hardware cooperation module, for developing the test software to finish the task of the diagnosis children; the hardware module is used for recording the eye movement attention, expression and body posture information in the task test process; an intelligent analysis module, for using computer vision technology to do eye movement attention, analysis of expression and posture, also moving the mouse of the tester, clicking and keyboard input action is also recorded and tracked, and fusion with the same quality vector; multi-mode information fusion model, using the time sequence multi-mode information fusion model {BERT}, pre-training the same quality vector combined test result obtained in a certain time slice; finally generating the model to judge whether the patient has the classification result of abnormal behaviour in this time period. The invention has high efficiency and good accuracy.},
	type = {patent},
	number = {{CN}111528859A},
	author = {Zhang, Liu and Pu, Shi-liang and Zhu, Qiang and Kong, Ming and Hong, Wen-chen and Zhao, Tian-qi},
	urldate = {2020-05-13},
	date = {2020-08-14},
	note = {Edition: A61B000511 {\textbar} A61B000500 {\textbar} A61B000516 {\textbar} G06K000900 {\textbar} G06K000962 {\textbar} G06N000304 {\textbar} G06N000308 {CPC}  - A61B0005168 {\textbar} A61B00051116 {\textbar} A61B0005163 {\textbar} A61B0005165 {\textbar} A61B00054082 {\textbar} A61B00054088 {\textbar} A61B00057267 {\textbar} G06K00096256 {\textbar} G06K00096267 {\textbar} G06N00030445 {\textbar} G06N00030454 {\textbar} G06N0003082 {\textbar} G06N0003084 {\textbar} G06V004070 {\textbar} A61B250306 {CN} {CN} 1.一种基于多模态深度学习技术的儿童{ADHD筛查评估系统}，其特征在于，所述系统包括： {\textbar} 量表测试模块，用于通过{ADHD诊断心理学量表采集和评估就诊儿童各方面的行为表现和相关能力}； {\textbar}   {\textbar} 软硬件协同模块，用于开发测试软件让就诊儿童完成任务，硬件模组包括是多摄像头组及同步控制系统，用于记录任务测试过程中的眼动注意力、表情和身体姿态三方面信息； {\textbar}   {\textbar} 智能分析模块，用于将对软硬件协同模块中采集到的多媒体信息进行智能处理，运用计算机视觉技术进行眼动注意力、表情、姿态的分析、跟踪和识别，并转化为同质化向量表示，同时，还对测试者的鼠标移动、点击和键盘输入动作也做了记录和跟踪，与同质化向量融合； {\textbar}   {\textbar} 多模态信息融合模型，采用时序多模态信息融合模型{BERT}，对某个特定时间片段中获取的同质化向量结合测试结果进行预训练，最终生成的模型判断患者在本时间段是否存在异常行为的分类结果。 {\textbar}   {\textbar} 2.如权利要求1{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于，所述软硬件协同模块中，位于电脑显示屏后方的1号摄像头用于拍摄测试者的正面图像，采集测试者的眼动与表情变化信息；位于测试者座位侧面的2、3号双目深度摄像头模组用于拍摄测试者全身，采集测试者三维身体姿态信息。 {\textbar} 3.如权利要求1或2{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于，所述软硬件协同模块中，在拍摄期间测试者需要完成{ADHD临床诊断的三种心理学测试}：Stroop测试、威斯康辛卡片分类测试和表情识别测试，这三种测试分别对患者注意力、抑制认知干扰、抽象思维和认知转移、情绪和社交等认知功能进行评估，Stroop测试通过字义与字体颜色冲突来评测测试者抑制认知干扰的能力；威斯康辛卡片分类测试通过变换颜色、形状、数量的测试规则来评测测试者的认知转移能力；表情测试通过对人脸图片的表情进行分类来评测测试者的社交认知能力；将以上三种执行功能测试整合到一套任务测试软件中。 {\textbar} 4.如权利要求1或2{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于，三种测试的过程中，测试软件能够与摄像头模组进行交互，当测试者开始测试时，软件会启动摄像头模组开始录制，记录下测试者眼部、表情及姿态视频信息，用于智能分析模块分析提取关键特征；当测试完成时，测试软件会同步停止摄像头模组的录制工作；同时测试软件能够对测量指标进行整合与统计，并记录答题操作的关键时间节点及被测人员的鼠标键盘动作，这些形成了多模态融合机制的数据基础。 {\textbar} 5.如权利要求1或2{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于，所述智能分析模块包括眼动注意力特征向量计算单元、表情特征向量计算单元和肢体动作特征向量计算单元。 {\textbar} 6.如权利要求5{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于，所述眼动注意力特征向量计算单元，输入为采集到的正面视频V {\textbar} Front {\textbar} 和相机标定矩阵C {\textbar} r {\textbar} ，输出为产生的眼动注意力特征向量F {\textbar} g {\textbar} ，包括以下步骤: {\textbar} 1.1瞳孔位置计算：首先通过基于{HOG的算法确认脸部位置}，对脸部关键点的检测通过连续条件神经场模型框架实现，由此计算出平面中的瞳孔位置e {\textbar}   {\textbar} h {\textbar} ；接着，利用{EPnP算法}，将检测到的人脸与平均标准3D{脸模F进行对齐}，计算出相机坐标系下头部的旋转矩阵R {\textbar} r {\textbar} 以及平移向量t {\textbar} r {\textbar} ，此步骤的输出为眼部空间位置e {\textbar} r {\textbar} ＝t {\textbar} r {\textbar} +e {\textbar} h {\textbar} ； {\textbar} 1.2视线方向计算，视线方向特征表示为一个包含偏航角和俯仰角的二维向量g，所述偏航角为视线方向与垂直平面的夹角，所述俯仰角为视线方向与水平面的夹角； {\textbar}   {\textbar} 1.3屏幕位置换算：通过外部标定的方式，确定屏幕所在平面的空间位置，根据视线方向特征向量g以及眼部位置e {\textbar}   {\textbar} r {\textbar} 计算视线与屏幕平面的交点，即为视线在屏幕上的落点p {\textbar} s {\textbar} ，再根据屏幕结构得到眼部注意力区域r； {\textbar} 1.4将瞳孔位置、视线方向及屏幕注意力三者进行结合，得到最终的眼动注意力特征向量，表示为F {\textbar}   {\textbar} g {\textbar} ＝[e {\textbar} r {\textbar} ,g,r]。 {\textbar} 7.如权利要求6{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于，所述步骤1.2中，先对眼部图像进行归一化处理：将原图像乘以相机投影矩阵的逆矩阵 {\textbar} 转化为三维空间中的头部位姿；再将此时的头部原姿态乘以变换矩阵M来固定眼部位置，最后再将归一化后的眼部姿态乘以一个标准相机投影矩阵C {\textbar} n {\textbar} ，得到归一化后的眼部二维图像e；为了计算视线向量，将归一化旋转矩阵R {\textbar} n {\textbar} ＝M R {\textbar} r {\textbar} 变换为二维旋转矢量h，将得到的2D头部姿态信息h和单通道灰度眼部图像e输入卷积神经网络模型，输出视线方向特征向量，所述特征向量为包含偏航角和俯仰角的二维向量g。 {\textbar} 8.如权利要求5{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于所述表情特征向量计算单元，通过对22{种Facial} Action Coding System描述的面部运动单元和动作对测试者表情变化进行描述，对微表情进行检测，表情特征计算的输入为采集到的正面视频V {\textbar} Front {\textbar} ，输出为产生的{AU概率序列表达F} {\textbar} exp {\textbar} ，包括与以下步骤： {\textbar} 2.1首先需要识别出面部关键特征点集合，然后根据这些关键特征点的位置P {\textbar}   {\textbar} L {\textbar} 推得与表情运动单元相关的对应肌肉的位置P {\textbar} {AU} {\textbar} ，在此基础上，构建基于{VGGNet的ROI} Nets，通过裁剪出网络第12层得到的feature map，由此得到对应每个{AU的特征表示}，将所有特征向量拼接即得到表示该时刻表情特征的整体向量F {\textbar} {AU} {\textbar} ； {\textbar} 2.2由于表情识别任务的输入形式是视频数据,通过前面时刻的表情状态下更准确、更平滑的预测当前时刻的表情状态，利用一个多层{LSTM结构对时序化的表情特征向量进行处理}，完成对多{AU的多任务二值分类问题}，得出基于{AU特征激活概率的表情特征序列表达F} {\textbar}   {\textbar} exp {\textbar} 。 {\textbar} 9.如权利要求5{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于所述肢体动作特征向量计算单元中，输入为采集到的侧面视频V {\textbar} Side {\textbar} ，输出为产生的3D{骨架序列F} {\textbar} 3D {\textbar} ，包括以下步骤： {\textbar} 3.1{置信图与PAF计算}：对于图片输入，首先通过10{层VGG}-19{提取图片特征F}，再将{F输入两个多阶段CNN}，一个网络通过置信图的方式确定人体关节点位置，另一个网络通过{PartAffinity} Fields({PAF})确定肢体方向；最终得到置信图S＝(S {\textbar}   {\textbar} 1 {\textbar} ,S {\textbar} 2 {\textbar} ,…S {\textbar} J {\textbar} )与{PAF} L＝(L {\textbar} 1 {\textbar} ,L {\textbar} 2 {\textbar} ,…,L {\textbar} C {\textbar} )，其中J，C分别表示关节点和肢体的种类数量； {\textbar} 3.2关节点匹配优化：根据置信图得到关节点的位置， {\textbar}   {\textbar} 表示第j类关节点中的第m个，通过L计算关节点组 {\textbar} 相连的置信度 {\textbar} 其中p是两点之间的插值函数： {\textbar}   {\textbar} 其中，u表示预测点到 {\textbar}   {\textbar} 的距离占 {\textbar} 与 {\textbar} 距离的比值； {\textbar} 3.3最后再将有共同关节点的肢体相连接，形成完整的人体2D骨架特征f {\textbar}   {\textbar} 2D {\textbar} ，最终将2D骨架序列输入一个神经网络，得到3D骨架序列f {\textbar} 3D {\textbar} ，对于整段视频，最终的3D骨架序列即为：F {\textbar} 3D {\textbar} ＝[f {\textbar} 3D1 {\textbar} ,f {\textbar} 3D2 {\textbar} ,…,f {\textbar} 3DN {\textbar} ]； {\textbar} 对于整个答题过程，有正面视频V {\textbar}   {\textbar} Front {\textbar} ，侧面视频V {\textbar} Side {\textbar} ，以及答题操作序列A＝\{a {\textbar} 1 {\textbar} ,a {\textbar} 2 {\textbar} ,…,a {\textbar} K {\textbar} \}，a {\textbar} i {\textbar} 代表第i题答题的时间戳，K为答题总数，按照答题时间戳将整个答题流程切分成K个时间段，对于每个时间段，V {\textbar} Front {\textbar} 和V {\textbar} side {\textbar} 所对应的视频帧构成一个图像序列，对应的，有从视频帧提取得到对应的眼动注意力向量F {\textbar} g {\textbar} 、微表情F {\textbar} exp {\textbar} 、动作特征向量F {\textbar} 3D {\textbar} ； {\textbar} 对于时刻i，将智能分析模块所得到的三种不同向量f {\textbar}   {\textbar} gi {\textbar} (9-d)、f {\textbar} exp i {\textbar} (22-d)、f {\textbar} 3D i {\textbar} (75-d)以及该测试者当前的答题情况f {\textbar} ans i {\textbar} 拼接起来，得到表示该时刻测试者行为特征的向量；对于一个片段，得到表示当前时刻的行为特征x {\textbar} i {\textbar} ＝[f {\textbar} g i {\textbar} ,f {\textbar} exp i {\textbar} ,f {\textbar} 3D i {\textbar} ,f {\textbar} ans i {\textbar} ](1-d)，由此，对于整段测试，得到{N维行为特征向量序列X}＝\{x {\textbar} 0 {\textbar} ,x {\textbar} 1 {\textbar} ,x {\textbar} 2 {\textbar} ,…,x {\textbar} N {\textbar} \}，其中x {\textbar} 0 {\textbar} 是一个固定的起始向量。 {\textbar} 10.如权利要求1或2{所述的基于多模态深度学习技术的儿童ADHD筛查评估系统}，其特征在于所述多模态信息融合模型中，异常行为检测模块由12{层Transformer编码器组成}，每层编码器包括注意力层和前向反馈层，在注意力层中，对于输入x，经过点积-乘积注意力机制计算，得到表示每个序列单元对当前单元的影响权重的向量组Z： {\textbar} 其中Q，K，V为注意力机制中的隐变量， {\textbar}   {\textbar} 为向量组K中向量维度的平方根，对于多头注意力模型，需要利用多组独立的Q,K,V隐变量产生多个向量组\{Z {\textbar} 1 {\textbar} ,Z {\textbar} 2 {\textbar} ,…,Z {\textbar} T {\textbar} \}，T为向量组的总数，以获取更加丰富的模型表达能力，将所有向量组拼接加权求和得多头注意力的输出Z {\textbar} final {\textbar} ： {\textbar} Z {\textbar}   {\textbar} final {\textbar} ＝Concat(Z {\textbar} 1 {\textbar} ,Z {\textbar} 2 {\textbar} ,…,Z {\textbar} T {\textbar} )W {\textbar} o {\textbar} 前向反馈层由2层全连接层组成，负责对注意力层的输出做进一步处理；此外，注意力层和前向反馈层均被加入残差，以防止编码器层数较多时，反向传播过程中，梯度消失现象的出现； {\textbar}   {\textbar} 输出向量组记为Y＝\{y {\textbar}   {\textbar} 0 {\textbar} ,y {\textbar} 1 {\textbar} ,y {\textbar} 2 {\textbar} ,…,y {\textbar} N {\textbar} \}，y {\textbar} i {\textbar} ∈R {\textbar} L {\textbar} ，其中二维向量y {\textbar} 0 {\textbar} 为x {\textbar} 0 {\textbar} 对应的输出，代表整个时间片段的向量表示，将y {\textbar} 0 {\textbar} 输入到全连接层形式的分类器，得到该片段是否存在异常的分类结果。 1. A children {ADHD} screening evaluation system based on multi-mode deep learning technology, wherein the system comprises: a meter testing module for collecting and evaluating the behavioral performance and relative ability of each aspect of the child by the {ADHD} diagnosis psychology meter; software and hardware cooperation module, for developing the test software to finish the task of the diagnosis children; the hardware module comprises a multi-camera group and a synchronous control system, for recording the eye movement attention, expression and body posture information in the task test process; an intelligent analysis module, for intelligently processing the multimedia information collected in the software and hardware cooperative module; using computer vision technology to do eye movement attention; analyzing, tracking and identifying the expression and posture, and converting into homogeneous vector representation; at the same time, also moving the mouse of the tester, clicking and keyboard input action also makes recording and tracking, fusion with the same quality vector; multi-mode information fusion model, using the time sequence multi-mode information fusion model {BERT}, pre-training the same quality vector combined test result obtained in a certain time slice; finally generating the model to judge whether the patient has the classification result of abnormal behaviour in this time period. {\textbar} 2. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 1, wherein the software and hardware cooperative module, the computer display screen of the 1 \# camera for shooting the front image of the tester, collecting the eye movement and expression change information of the tester; 2, 3 number binocular depth camera module located at the side of the tester seat for shooting the whole body of the tester; collecting the three-dimension body posture information of the tester. {\textbar} 3. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 1 or 2, wherein the software and hardware cooperative module in the shooting period, the tester needs to complete three psychology tests of {ADHD} clinical diagnosis: Stroop test, Wisconsin card classification test and expression identification test; the three tests respectively attention to the patient, inhibiting cognitive interference, abstract thinking and cognitive transfer, emotion and social and other cognitive function, Stroop test through word meaning and font color conflict to evaluate the ability of the tester for inhibiting cognitive interference; Wisconsin card classification test by changing color, shape, number of test rules to evaluate the cognitive transfer capability of the tester; the expression test classifies the expression of the human face picture to evaluate the social cognitive ability of the tester; integrating said three execution function tests into a set of task test software. {\textbar} 4. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 1 or 2, wherein, in the process of three test, test software can interact with the camera module, when the tester starts testing, software starts the camera module starts recording, recording the eye, expression and posture video information of the tester, for intelligent analysis module analyzing and extracting key features; when the test is finished, the test software will stop the recording work of the camera module synchronously; at the same time, the test software can integrate and count the measurement index, and recording the key time node of the answer operation and the mouse keyboard action of the tested person, these forms the data base of the multi-mode fusion mechanism. {\textbar} 5. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 1 or 2, wherein the intelligent analysis module comprises eye movement attention characteristic vector calculation unit, expression characteristic vector calculation unit and the limb action characteristic vector calculation unit. {\textbar} 6. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 5, wherein the eye movement attention feature vector calculation unit, input is collected front video {VFront} and camera calibration matrix Cr. outputting the generated eye movement attention feature vector Fg, comprising the following steps: 1.1 pupil position calculation: firstly confirming the face position by algorithm based on {HOG}; the detection of the face key point is realized by the continuous condition neural model frame, so as to calculate the pupil position in the plane; then, using the {EPnP} algorithm, aligning the detected human face with the average standard 3 D face model F; calculating the rotating matrix Rr of the head under the camera coordinate system and the translation vector tr, the output of the step is the eye space position er=tr + eh; 1.2 sight direction calculation, wherein the sight direction characteristic represents a two-dimensional vector g comprising yaw angle and pitch angle, the yaw angle is the included angle between the sight direction and the vertical plane; the pitch angle is the included angle between the sight direction and the horizontal plane; 1.3 screen position conversion: by means of external calibration, determining the space position of the plane of the screen; according to the sight direction feature vector g and the eye position er, calculating the intersection point of the sight line and the screen plane, namely the falling point ps of the sight line on the screen, and obtaining the eye attention area r according to the screen structure; 1.4, combining the pupil position, the sight direction and the screen attention to obtain the final eye movement attention feature vector, representing Fg = [er, g, r]. {\textbar} 7. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 6, wherein, in said step 1.2, firstly performing normalization processing to the eye image: multiplying the original image by the inverse matrix of the camera projection matrix  {\textbar} converting into the head pose in the three-dimensional space; then multiplying the head original posture by the transformation matrix M to fix the eye position, at last, multiplying the normalized eye posture by a standard camera projection matrix Cn, obtaining the normalized eye two-dimensional image e; in order to calculate the sight vector, converting the normalized rotation matrix Rn=M Rr into a two-dimensional rotation vector h, inputting the obtained 2 D head posture information h and the single-channel grey eye image e into the convolutional neural network model, outputting the sight direction characteristic vector, the feature vector is a two-dimensional vector g comprising yaw angle and pitch angle. {\textbar} 8. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 5, wherein the expression characteristic vector calculating unit, through 22 Facial Action Coding System description of facial movement unit and action to describe the expression change of the tester, detecting the micro-expression, the input of the expression characteristic calculation is the collected front video {VFront}, output is generated {AU} probability sequence expression Fexp, comprising the following steps: 2.1 firstly need to identify the face key feature point set, then according to the position {PL} of the key feature point to obtain the position {PAU} corresponding to the muscle corresponding to the expression motion unit, on the basis, constructing the {ROI} Nets based on {VGGNet}, by cutting out feature map obtained by network 12 layer, thereby obtaining characteristic representation corresponding to each {AU}; splicing all the feature vectors to obtain the whole vector {FAU}; representing the time-scale expression characteristic; 2.2 because the input form of the expression recognition task is video data, through the expression state of the previous time is more accurate, more smoothly predicting the expression state of the current time; using one multi-layer {LSTM} structure to process the time-ordered expression characteristic vector; finishing multi-task binary classification problem of multiple {AU}; obtaining expression characteristic sequence expression Fexp based on {AU} characteristic activation probability. {\textbar} 9. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 5, wherein the limb action feature vector calculation unit, input is the side video Vside collected, output is generated 3D framework sequence F3D, comprising the following steps: 3.1 confidence map and {PAF} calculation: for the picture input, firstly extracting picture feature F by 10 layers of {VGG}-19, then inputting the F into two multi-stage {CNN}, one network determines the position of the human closing node by means of confidence map, and the other network determines limb direction by {PartAffinity} Fields ({PAF}) ; finally obtaining the confidence map S = (S1, S2, ..., {SJ}) and {PAF} L = (L1, L2, ..., {LC}), wherein J, C respectively represents the type number of the node and the limb; 3.2: node matching optimization: obtaining the position of the node according to the confidence map,  {\textbar} represents the m-th of the j-th gateway node, calculating the node group through L  {\textbar} Confidence  {\textbar} wherein p is the interpolation function between two points:  {\textbar} wherein u represents the prediction point to  {\textbar} the distance  {\textbar} and  {\textbar} the ratio of the distance; 3.3, then connecting the limb of common joint node; forming a complete human body 2D skeleton characteristic f2D, finally inputting the 2D skeleton sequence into a neural network to obtain the 3D skeleton sequence f3D, for the whole segment of video, the final 3D skeleton sequence is: F3D = [f3D1, f3D2, ..., f3DN]; for the whole answer process, a front video {VFront}, a side video Vside, and a answering operation sequence A = (a1, a2, ..., {aK}), ai represents the i-th answering time stamp; K is the answer total number; according to the answer timestamp, the whole answer flow is divided into K time periods, for each time period, {VFront} and Vside corresponding to the video frame to form an image sequence, corresponding to the extracted from the video frame to obtain the corresponding eye movement attention vector Fg, micro expression Fexp, action characteristic vector F3D; for time i, the intelligent analysis module to obtain the three different vectors fgi (9-d), fexp i (22-d), f3D i (75-d) and the test of the current answer condition is spliced, to obtain the vector representing the time tester behaviour characteristic; for a fragment, to obtain the current time of the behaviour characteristic xi = [fg i, fexp i, f3D i, i] (1-d), thereby, for the whole section test to obtain the N-dimensional behaviour characteristic vector sequence X = (x0, x1, x2, ..., {xN}), wherein x0 is a fixed initial vector. {\textbar} 10. The children {ADHD} screening evaluation system based on multi-mode deep learning according to claim 1 or 2, wherein the multi-mode information fusion model, abnormal behaviour detection module is composed of 12 layers of coder, each encoder comprises an attention layer and a forward feedback layer; in the attention layer, for the input x, calculating by dot product-product attention mechanism, obtaining the vector group Z representing the influence weight of each sequence unit to the current unit:  {\textbar} wherein Q, K, V are the hidden variables in the attention mechanism,  {\textbar} is the square root of vector dimension in vector group K; for multi-head attention model, multiple groups of independent Q, K, V hidden variables are needed to generate multiple vector groups (Z1, Z2, ..., {ZT}), T is the total number of the vector group, so as to obtain more abundant model expression capability, the output Zfinal of the multi-head attention is obtained by splicing and weighting all the vector groups: Zfinal=Concat (Z1, Z2, ..., {ZT}) forward feedback layer is composed of 2 layers of full connection layer, responsible for further processing the output of the attention layer; In addition, the attention layer and the forward feedback layer are added with residual error, so as to prevent the number of the encoder is more, in the reverse propagation process, the gradient disappears; output vector group is marked as Y = (y0, y1, y2, ..., {yN}), yi belongs to {RL}, wherein the two-dimensional vector y0 is the output corresponding to x0, representing the vector representation of the whole time segment, inputting y0 into the classifier in the form of the full connection layer, obtaining the classification result of whether the segment is abnormal. 1.一种基于多模态深度学习技术的儿童{ADHD筛查评估系统}，其特征在于，所述系统包括： {\textbar} 量表测试模块，用于通过{ADHD诊断心理学量表采集和评估就诊儿童各方面的行为表现和相关能力}； {\textbar}   {\textbar} 软硬件协同模块，用于开发测试软件让就诊儿童完成任务，硬件模组包括是多摄像头组及同步控制系统，用于记录任务测试过程中的眼动注意力、表情和身体姿态三方面信息； {\textbar}   {\textbar} 智能分析模块，用于将对软硬件协同模块中采集到的多媒体信息进行智能处理，运用计算机视觉技术进行眼动注意力、表情、姿态的分析、跟踪和识别，并转化为同质化向量表示，同时，还对测试者的鼠标移动、点击和键盘输入动作也做了记录和跟踪，与同质化向量融合； {\textbar}   {\textbar} 多模态信息融合模型，采用时序多模态信息融合模型{BERT}，对某个特定时间片段中获取的同质化向量结合测试结果进行预训练，最终生成的模型判断患者在本时间段是否存在异常行为的分类结果。 1. A children {ADHD} screening evaluation system based on multi-mode deep learning technology, wherein the system comprises: a meter testing module for collecting and evaluating the behavioral performance and relative ability of each aspect of the child by the {ADHD} diagnosis psychology meter; software and hardware cooperation module, for developing the test software to finish the task of the diagnosis children; the hardware module comprises a multi-camera group and a synchronous control system, for recording the eye movement attention, expression and body posture information in the task test process; an intelligent analysis module, for intelligently processing the multimedia information collected in the software and hardware cooperative module; using computer vision technology to do eye movement attention; analyzing, tracking and identifying the expression and posture, and converting into homogeneous vector representation; at the same time, also moving the mouse of the tester, clicking and keyboard input action also makes recording and tracking, fusion with the same quality vector; multi-mode information fusion model, using the time sequence multi-mode information fusion model {BERT}, pre-training the same quality vector combined test result obtained in a certain time slice; finally generating the model to judge whether the patient has the classification result of abnormal behaviour in this time period. 基于多模态深度学习技术的儿童{ADHD筛查评估系统} {\textbar}   {\textbar} 技术领域 {\textbar}   {\textbar} 本发明涉及一种儿童注意缺陷多动障碍({ADHD})筛查评估系统。 {\textbar}   {\textbar} 背景技术 {\textbar}   {\textbar} 注意缺陷多动障碍({ADHD})，俗称多动症，是儿童青少年期最常见的神经发育障碍，其临床表现是注意集中困难、活动过度、冲动，情绪不稳定、学习困难等。 {\textbar}   {\textbar} 目前的{ADHD医学影像的智能识别技术主要是基于脑部功能性核磁共振和脑电图等病理方面的研究}，或者单独基于眼动或面部表情等观察患者的行为特征。前者的技术操作过程十分复杂，对于很难控制自己行为的儿童而言更为困难，而且这些技术的价格非常昂贵，目前很难有大规模落地的可能。后者的信息维度单一，很难全面的对儿童的行为作出评估，而{ADHD儿童的表现形式是多种多样的}，单独观察眼动或肢体动作都可能遗漏其他重要的行为特征。 {\textbar}   {\textbar} 发明内容 {\textbar}   {\textbar} 为了克服已有儿童{ADHD筛查评估方式的效率低下}、准确性较差的不足，本发明提供了一种效率较高、准确性较好的基于多模态深度学习技术的儿童{ADHD筛查评估系统}。 {\textbar}   {\textbar} 本发明解决其技术问题所采用的技术方案是： {\textbar}   {\textbar} 一种基于多模态深度学习技术的儿童{ADHD筛查评估系统}，包括： {\textbar}   {\textbar} 量表测试模块，用于通过{ADHD诊断心理学量表采集和评估就诊儿童各方面的行为表现和相关能力}； {\textbar}   {\textbar} 软硬件协同模块，用于开发测试软件让就诊儿童完成任务，硬件模组包括是多摄像头组及同步控制系统，用于记录任务测试过程中的眼动注意力、表情和身体姿态三方面信息； {\textbar}   {\textbar} 智能分析模块，用于将对软硬件协同模块中采集到的多媒体信息进行智能处理，运用计算机视觉技术进行眼动注意力、表情、姿态的分析、跟踪和识别，并转化为下一步机器学习可兼容的同质化向量表示，同时，还对测试者的鼠标移动、点击和键盘输入动作也做了记录和跟踪，可与同质化向量融合； {\textbar}   {\textbar} 多模态信息融合模型，采用时序多模态信息融合模型{BERT}(Devlin et al.,2018)，对某个特定时间片段中获取的同质化向量结合测试结果进行预训练，最终生成的模型判断患者在本时间段是否存在异常行为的分类结果。 {\textbar}   {\textbar} 进一步，所述软硬件协同模块中，位于电脑显示屏后方的1号摄像头用于拍摄测试者的正面图像，采集测试者的眼动与表情变化信息；位于测试者座位侧面的2、3号双目深度摄像头模组可用于拍摄测试者全身，采集测试者三维身体姿态信息。 {\textbar}   {\textbar} 再进一步，所述软硬件协同模块中，在拍摄期间测试者需要完成{ADHD临床诊断的三种心理学测试}：Stroop测试、威斯康辛卡片分类测试和表情识别测试，这三种测试分别对患者注意力、抑制认知干扰、抽象思维和认知转移、情绪和社交等认知功能进行评估，Stroop测试通过字义与字体颜色冲突来评测测试者抑制认知干扰的能力；威斯康辛卡片分类测试通过变换颜色、形状、数量的测试规则来评测测试者的认知转移能力；表情测试通过对人脸图片的表情进行分类来评测测试者的社交认知能力；将以上三种执行功能测试整合到一套任务测试软件中。 {\textbar}   {\textbar} 优选的，三种测试的过程中，测试软件能够与摄像头模组进行交互，当测试者开始测试时，软件会启动摄像头模组开始录制，记录下测试者眼部、表情及姿态视频信息，用于智能分析模块分析提取关键特征；当测试完成时，测试软件会同步停止摄像头模组的录制工作。同时测试软件能够对测量指标进行整合与统计，并记录答题操作的关键时间节点及被测人员的鼠标键盘动作，这些形成了多模态融合机制的数据基础。 {\textbar}   {\textbar} 所述摄像头模组主要采集了两类视频信息：1)面向测试者面部的摄像头关注测试者眼动(注意力聚焦)及面部肌肉动作(异常表情)；2)侧向的双目深度摄像头运用三维视觉感知技术提取每一时刻的人体骨架位置，进行姿态分析。 {\textbar}   {\textbar} 更进一步，所述智能分析模块包括眼动注意力特征向量计算单元、表情特征向量计算单元和肢体动作特征向量计算单元。 {\textbar}   {\textbar} 优选的，所述眼动注意力特征向量计算单元，输入为采集到的正面视频V {\textbar}   {\textbar} Front {\textbar} 和相机标定矩阵C {\textbar} r {\textbar} ，输出为产生的眼动注意力特征向量F {\textbar} g {\textbar} ，包括以下步骤: {\textbar} 1.1瞳孔位置计算：首先通过基于{HOG的算法确认脸部位置}，对脸部关键点的检测通过连续条件神经场({CCNF})模型框架实现，由此可以计算出平面中的瞳孔位置e {\textbar}   {\textbar} h {\textbar} ；接着，利用{EPnP算法}，可将检测到的人脸与平均标准3D{脸模F进行对齐}，计算出相机坐标系下头部的旋转矩阵R {\textbar} r {\textbar} 以及平移向量t {\textbar} r {\textbar} ，此步骤的输出为眼部空间位置e {\textbar} r {\textbar} ＝t {\textbar} r {\textbar} +e {\textbar} h {\textbar} ； {\textbar} 1.2视线方向计算，视线方向特征可表示为一个包含偏航角(yaw)和俯仰角(pitch)的二维向量g，所述偏航角为视线方向与垂直平面的夹角，所述俯仰角为视线方向与水平面的夹角； {\textbar}   {\textbar} 1.3屏幕位置换算：通过外部标定的方式，可以确定屏幕所在平面的空间位置，根据视线方向特征向量g以及眼部位置e {\textbar}   {\textbar} r {\textbar} 可以计算视线与屏幕平面的交点，即为视线在屏幕上的落点p {\textbar} s {\textbar} ，再根据屏幕结构得到眼部注意力区域r； {\textbar} 将瞳孔位置、视线方向及屏幕注意力三者进行结合，得到最终的眼动注意力特征向量，表示为f {\textbar}   {\textbar} g {\textbar} ＝[e {\textbar} r {\textbar} ,g,r]。 {\textbar} 所述步骤1.2中，先对眼部图像进行归一化处理：将原图像乘以相机投影矩阵的逆矩阵 {\textbar}   {\textbar} 转化为三维空间中的头部位姿；再将此时的头部原姿态乘以变换矩阵M来固定眼部位置，最后再将归一化后的眼部姿态乘以一个标准相机投影矩阵C {\textbar} n {\textbar} ，得到归一化后的眼部二维图像e；为了计算视线向量，将归一化旋转矩阵R {\textbar} n {\textbar} ＝M R {\textbar} r {\textbar} 变换为二维旋转矢量h，将得到的2D头部姿态信息h和单通道灰度眼部图像e输入卷积神经网络模型，输出视线方向特征向量，所述特征向量为包含偏航角和俯仰角的二维向量g。 {\textbar} 再优选的，所述表情特征向量计算单元，通过对22{种Facial} Action {CodingSystem}(Hamm et al.,2011)描述的面部运动单元和动作对测试者表情变化进行描述，具体的，采用了一种结合Region of Interests({ROI})adaptation，Multi-label Learning,以及optimal {LSTM}-based temporal fusing的结构对微表情进行检测，表情特征计算的输入为采集到的正面视频V {\textbar}   {\textbar} Front {\textbar} ，输出为产生的{AU概率序列表达F} {\textbar} exp {\textbar} ，包括与以下步骤： {\textbar} 2.1首先需要识别出面部关键特征点集合，然后根据这些关键特征点的位置P {\textbar}   {\textbar} L {\textbar} 推得与表情运动单元相关的对应肌肉的位置P {\textbar} {AU} {\textbar} ，在此基础上，可以构建基于{VGGNet的ROIcropping} nets({ROI} Nets)，通过裁剪出网络第12层得到的feature map，由此得到对应每个{AU的特征表示}，将所有特征向量拼接即得到表示该时刻表情特征的整体向量F {\textbar} {AU} {\textbar} ； {\textbar} 2.2由于表情识别任务的输入形式是视频数据,通过前面时刻的表情状态下更准确、更平滑的预测当前时刻的表情状态，利用一个多层{LSTM结构对时序化的表情特征向量进行处理}，完成对多{AU的多任务二值分类问题}，得出基于{AU特征激活概率的表情特征序列表达F} {\textbar}   {\textbar} exp {\textbar} 。 {\textbar} 更优选的，所述肢体动作特征向量计算单元中，输入为采集到的侧面视频V {\textbar}   {\textbar} Side {\textbar} ，输出为产生的3D{骨架序列F} {\textbar} 3D {\textbar} ，包括以下步骤： {\textbar} 3.1{置信图与PAF计算}：对于图片输入，首先通过10{层VGG}-19{提取图片特征F}，再将{F输入两个多阶段CNN}，一个网络通过置信图的方式确定人体关节点位置，另一个网络通过Part Affinity Fields({PAF})确定肢体方向；最终得到置信图S＝(S {\textbar}   {\textbar} 1 {\textbar} ,S {\textbar} 2 {\textbar} ,…S {\textbar} J {\textbar} )与{PAF} L＝(L {\textbar} 1 {\textbar} ,L {\textbar} 2 {\textbar} ,…,L {\textbar} C {\textbar} )，其中J，C分别表示关节点和肢体的种类数量； {\textbar} 3.2关节点匹配优化：根据置信图得到关节点的位置， {\textbar}   {\textbar} 表示第j类关节点中的第m个，通过L计算关节点组 {\textbar} 相连的置信度 {\textbar} 其中p是两点之间的插值函数： {\textbar}   {\textbar} 其中，u表示预测点到 {\textbar}   {\textbar} 的距离占 {\textbar} 与 {\textbar} 距离的比值； {\textbar} 3.3最后再将有共同关节点的肢体相连接，形成完整的人体2D骨架特征f {\textbar}   {\textbar} 2D {\textbar} ，最终将2D骨架序列输入一个神经网络，得到3D骨架序列f {\textbar} 3D {\textbar} ，对于整段视频，最终的3D骨架序列即为：F {\textbar} 3D {\textbar} ＝[f {\textbar} 3D1 {\textbar} ,f {\textbar} 3D2 {\textbar} ,…,f {\textbar} 3DN {\textbar} ]。 {\textbar} 对于整个答题过程，有正面视频V {\textbar}   {\textbar} Front {\textbar} ，侧面视频V {\textbar} Side {\textbar} ，以及答题操作序列A＝\{a {\textbar} 1 {\textbar} ,a {\textbar} 2 {\textbar} ,…,a {\textbar} K {\textbar} \}，a {\textbar} i {\textbar} 代表第i题答题的时间戳，K为答题总数。按照答题时间戳可将整个答题流程切分成K个时间段，对于每个时间段，V {\textbar} Front {\textbar} 和V {\textbar} side {\textbar} 所对应的视频帧可以构成一个图像序列，对应的，有从视频帧提取得到对应的眼动注意力向量F {\textbar} g {\textbar} 、微表情F {\textbar} exp {\textbar} 、动作特征向量F {\textbar} 3D {\textbar} ； {\textbar} 对于时刻i，将智能分析模块所得到的三种不同向量f {\textbar}   {\textbar} g i {\textbar} (9-d)、f {\textbar} exp i {\textbar} (22-d)、f {\textbar} 3D i {\textbar} (75-d)以及该测试者当前的答题情况f {\textbar} ans i {\textbar} 拼接起来，可以得到表示该时刻测试者行为特征的向量；对于一个片段，可以得到表示当前时刻的行为特征x {\textbar} i {\textbar} ＝[f {\textbar} g i {\textbar} ,f {\textbar} exp i {\textbar} ,f {\textbar} 3D i {\textbar} ,f {\textbar} ans i {\textbar} ](1-d)，由此，对于整段测试，可以得到107{维行为特征向量序列X}＝\{x {\textbar} 0 {\textbar} ,x {\textbar} 1 {\textbar} ,x {\textbar} 2 {\textbar} ,…,x {\textbar} N {\textbar} \}，其中x {\textbar} 0 {\textbar} 是一个固定的起始向量。 {\textbar} 所述多模态信息融合模型中，异常行为检测模块由12{层Transformer编码器组成}，每层编码器包括注意力层和前向反馈层(Vaswani et al.,2017)，在注意力层中，对于输入x，经过点积-乘积注意力机制计算，得到表示每个序列单元对当前单元的影响权重的向量组Z： {\textbar}   {\textbar} 其中Q，K，V为注意力机制中的隐变量， {\textbar}   {\textbar} 为向量组K中向量维度的平方根，对于多头注意力模型，需要利用多组独立的Q,K,V隐变量产生多个向量组\{Z {\textbar} 1 {\textbar} ,Z {\textbar} 2 {\textbar} ,…,Z {\textbar} T {\textbar} \}，T为向量组的总数，以获取更加丰富的模型表达能力，将所有向量组拼接加权求和得多头注意力的输出Z {\textbar} final {\textbar} ： {\textbar} Z {\textbar}   {\textbar} final {\textbar} ＝Concat(Z {\textbar} 1 {\textbar} ,Z {\textbar} 2 {\textbar} ,…,Z {\textbar} T {\textbar} )W {\textbar} o {\textbar} 前向反馈层由2层全连接层组成，负责对注意力层的输出做进一步处理；此外，注意力层和前向反馈层均被加入残差，以防止编码器层数较多时，反向传播过程中，梯度消失现象的出现； {\textbar}   {\textbar} 输出向量组记为Y＝\{y {\textbar}   {\textbar} 0 {\textbar} ,y {\textbar} 1 {\textbar} ,y {\textbar} 2 {\textbar} ,…,y {\textbar} N {\textbar} \}，y {\textbar} i {\textbar} ∈R {\textbar} L {\textbar} ，其中二维向量y {\textbar} 0 {\textbar} 为x {\textbar} 0 {\textbar} 对应的输出，代表整个时间片段的向量表示，将y {\textbar} 0 {\textbar} 输入到全连接层形式的分类器，得到该片段是否存在异常的分类结果。 {\textbar} 本发明的有益效果主要表现在：1.本系统可以提供辅助参考，通过人工智能可以提高工作效率，为患者制定更准确和个体化的治疗方案；2.对患者而言，通过人工智能可以快速地完成各项检查，获得更为精准的诊断和治疗建议；3.人工智能可以尝试去模拟医疗专家的诊疗思维和推理过程，给出较为可靠的辅助参照中间结果。 {\textbar}   {\textbar} 附图说明 {\textbar}   {\textbar} 图1{是儿童ADHD筛查评估系统的示意图}。 {\textbar}   {\textbar} 图2是眼动注意力特征向量计算单元的流程图。 {\textbar}   {\textbar} 图3是表情特征向量计算单元的流程图。 {\textbar}   {\textbar} 图4是肢体动作特征向量计算单元的流程图。 {\textbar}   {\textbar} 具体实施方式 {\textbar}   {\textbar} 下面结合附图对本发明作进一步描述。 {\textbar}   {\textbar} 参照图1～图4，一种基于多模态深度学习技术的儿童{ADHD筛查评估系统}，包括： {\textbar}   {\textbar} 量表测试模块，用于通过{ADHD诊断心理学量表采集和评估就诊儿童各方面的行为表现和相关能力}；传统的纸质问卷手段存在患者填写麻烦、后期数据整理流程重复且繁琐、数据保存及分析不易等问题。因此，我们开发了全套微信小程序代替传统纸质问卷，测试者只需手机扫描二维码即可填写，测试结果能自动整合到最终生成的智能辅助诊断报告中供医生参考； {\textbar}   {\textbar} 软硬件协同模块，用于采纳三种执行功能测试，并开发相应的测试软件让就诊儿童完成相关任务，硬件模组包括是多摄像头组及同步控制系统，可以记录任务测试过程中的眼动注意力、表情和身体姿态三方面信息，后期可进行进一步智能分析； {\textbar}   {\textbar} 智能分析模块，用于将对软硬件协同模块中采集到的多媒体信息进行智能处理，运用计算机视觉技术进行眼动注意力、表情、姿态的分析、跟踪和识别，并转化为下一步机器学习可兼容的同质化向量表示，同时，还对测试人员的鼠标移动、点击、键盘输入等动作也做了记录和跟踪，可与上述多媒体信息融合分析。 {\textbar}   {\textbar} 多模态信息融合模型，采用时序多模态信息融合模型{BERT}(Devlin et al.,2018)，对某个特定时间片段中获取的同质化向量结合其他测试结果进行预训练，最终生成的模型可判断患者在本时间段是否存在异常行为，并将异常行为的类型及发生频度作为最终辅助诊断的重要参考依据，取代了传统诊断中完全依赖于医生经验水平的主观观察和描述。 {\textbar}   {\textbar} 图1描述了摄像头与被测试者的关系，位于电脑显示屏后方的1号摄像头用于拍摄测试者的正面图像，采集测试者的眼动与表情变化信息。位于测试者座位侧面的2、3号双目深度摄像头模组可用于拍摄测试者全身，采集测试者三维身体姿态信息。 {\textbar}   {\textbar} 在拍摄期间测试者需要完成{ADHD临床诊断常用的三种心理学测试}：Stroop测试、威斯康辛卡片分类测试和表情识别测试。这三种测试分别对患者注意力、抑制认知干扰、抽象思维和认知转移、情绪和社交等认知功能进行评估，Stroop测试主要通过字义与字体颜色冲突来评测测试者抑制认知干扰的能力；威斯康辛卡片分类测试主要通过变换颜色、形状、数量的测试规则来评测测试者的认知转移能力；表情测试主要通过对人脸图片的表情进行分类来评测测试者的社交认知能力。 {\textbar}   {\textbar} 将以上三种执行功能测试整合到一套任务测试软件中，整套任务完成时间大致控制在20～30分钟。除了功能上的实现，让专业软件设计人员和儿童心理学专业人员对软件交互、界面设计提出了指导意见，可让被测儿童能在规定时间内顺利完成设计任务在测试者完成。 {\textbar}   {\textbar} 上述三种测试的过程中，测试软件能够与摄像头模组进行交互，当测试者开始测试时，软件会启动摄像头模组开始录制，记录下测试者眼部、表情及姿态等视频信息，用于智能分析模块分析提取关键特征。当测试完成时，测试软件会同步停止摄像头模组的录制工作。同时测试软件能够对测量指标进行整合与统计，并记录答题操作的关键时间节点及被测人员的鼠标键盘动作，这些形成了我们后续多模态融合机制的数据基础。 {\textbar}   {\textbar} 摄像头模组主要采集了两类视频信息：1)面向测试者面部的摄像头主要关注测试者眼动(注意力聚焦)及面部肌肉动作(异常表情)；2)侧向的双目深度摄像头主要运用三维视觉感知技术提取每一时刻的人体骨架位置，进行姿态分析。 {\textbar}   {\textbar} 所述智能分析模块包括眼动注意力特征向量计算单元、表情特征向量计算单元和肢体动作特征向量计算单元； {\textbar}   {\textbar} 所述眼动注意力特征向量计算单元，输入为采集到的正面视频V {\textbar}   {\textbar} Front {\textbar} 和相机标定矩阵C {\textbar} r {\textbar} ，输出为产生的眼动注意力特征向量F {\textbar} g {\textbar} ，包括以下步骤: {\textbar} 1.1瞳孔位置计算：首先通过基于{HOG的算法确认脸部位置}，对脸部关键点的检测通过连续条件神经场({CCNF})模型框架实现，由此可以计算出平面中的瞳孔位置e {\textbar}   {\textbar} h {\textbar} ；接着，利用{EPnP算法}，可将检测到的人脸与平均标准3D{脸模F进行对齐}，计算出相机坐标系下头部的旋转矩阵R {\textbar} r {\textbar} 以及平移向量t {\textbar} r {\textbar} ，此步骤的输出为眼部空间位置e {\textbar} r {\textbar} ＝t {\textbar} r {\textbar} +e {\textbar} h {\textbar} ； {\textbar} 1.2视线方向计算，视线方向特征可表示为一个包括包含偏航角(yaw)和俯仰角(pitch)的二维向量g，所述偏航角为视线方向与垂直平面的夹角，所述俯仰角为视线方向与水平面的夹角； {\textbar}   {\textbar} 为了获取视线向量，先对眼部图像进行归一化处理：将原图像乘以相机投影矩阵的逆矩阵 {\textbar}   {\textbar} 转化为三维空间中的头部位姿；再将此时的头部原姿态乘以变换矩阵M来固定眼部位置，最后再将归一化后的眼部姿态乘以一个标准相机投影矩阵C {\textbar} n {\textbar} ，得到归一化后的眼部二维图像e；为了计算视线向量，将归一化旋转矩阵R {\textbar} n {\textbar} ＝M R {\textbar} r {\textbar} 变换为二维旋转矢量h，将得到的2D头部姿态信息h和单通道灰度眼部图像e输入卷积神经网络模型，输出视线方向特征向量，所述特征向量为包含偏航角和俯仰角的二维向量g； {\textbar} 1.3屏幕位置换算：通过外部标定的方式，可以确定屏幕所在平面的空间位置，根据视线方向特征向量g以及眼部位置e {\textbar}   {\textbar} r {\textbar} 可以计算视线与屏幕平面的交点，即为视线在屏幕上的落点p {\textbar} s {\textbar} ，再根据屏幕结构得到眼部注意力区域r； {\textbar} 1.4将瞳孔位置、视线方向及屏幕注意力三者进行结合，得到最终的眼动注意力特征向量，表示为F {\textbar}   {\textbar} g {\textbar} ＝[e {\textbar} r {\textbar} ,g,r]。 {\textbar} 所述表情特征向量计算单元，通过对22{种Facial} Action Coding System(Hammet al.,2011)描述的面部运动单元和动作对测试者表情变化进行描述，具体的，采用了一种结合Region of Interests({ROI})adaptation，Multi-label Learning,以及{optimalLSTM}-based temporal fusing的结构对微表情进行检测，表情特征计算的输入为采集到的正面视频V {\textbar}   {\textbar} Front {\textbar} ，输出为产生的{AU概率序列表达F} {\textbar} exp {\textbar} ，包括与以下步骤： {\textbar} 2.1首先需要识别出面部关键特征点集合，然后根据这些关键特征点的位置P {\textbar}   {\textbar} L {\textbar} 推得与表情运动单元相关的对应肌肉的位置P {\textbar} {AU} {\textbar} ，在此基础上，可以构建基于{VGGNet的ROIcropping} nets({ROI} Nets)，通过裁剪出网络第12层得到的feature map，由此得到对应每个{AU的特征表示}，将所有特征向量拼接即得到表示该时刻表情特征的整体向量F {\textbar} {AU} {\textbar} ； {\textbar} 2.2由于表情识别任务的输入形式是视频数据,通过前面时刻的表情状态下更准确、更平滑的预测当前时刻的表情状态，利用一个多层{LSTM结构对时序化的表情特征向量进行处理}，完成对多{AU的多任务二值分类问题}，得出基于{AU特征激活概率的表情特征序列表达F} {\textbar}   {\textbar} exp {\textbar} 。 {\textbar} 所述肢体动作特征向量计算单元中，输入为采集到的侧面视频V {\textbar}   {\textbar} Side {\textbar} ，输出为产生的3D{骨架序列F} {\textbar} 3D {\textbar} ，包括以下步骤： {\textbar} 3.1{置信图与PAF计算}：对于图片输入，首先通过10{层VGG}-19{提取图片特征F}，再将{F输入两个多阶段CNN}，一个网络通过置信图的方式确定人体关节点位置，另一个网络通过Part Affinity Fields({PAF})确定肢体方向；最终得到置信图S＝(S {\textbar}   {\textbar} 1 {\textbar} ,S {\textbar} 2 {\textbar} ,…S {\textbar} J {\textbar} )与{PAF} L＝(L {\textbar} 1 {\textbar} ,L {\textbar} 2 {\textbar} ,…,L {\textbar} C {\textbar} )，其中J，C分别表示关节点和肢体的种类数量； {\textbar} 3.2关节点匹配优化：根据置信图得到关节点的位置， {\textbar}   {\textbar} 表示第j类关节点中的第m个，通过L计算关节点组 {\textbar} 相连的置信度 {\textbar} 其中p是两点之间的插值函数： {\textbar}   {\textbar} 其中，u表示预测点到 {\textbar}   {\textbar} 的距离占 {\textbar} 与 {\textbar} 距离的比值； {\textbar} 3.3最后再将有共同关节点的肢体相连接，形成完整的人体2D骨架特征f {\textbar}   {\textbar} 2D {\textbar} ，最终将2D骨架序列输入一个神经网络，得到3D骨架序列f {\textbar} 3D {\textbar} ，对于整段视频，最终的3D骨架序列即为：F {\textbar} 3D {\textbar} ＝[f {\textbar} 3D1 {\textbar} ,f {\textbar} 3D2 {\textbar} ,…,f {\textbar} 3DN {\textbar} ]。 {\textbar} 对于整个答题过程，有正面视频V {\textbar}   {\textbar} Front {\textbar} ，侧面视频V {\textbar} Side {\textbar} ，以及答题操作序列A＝\{a {\textbar} 1 {\textbar} ,a {\textbar} 2 {\textbar} ,…,a {\textbar} K {\textbar} \}，a {\textbar} i {\textbar} 代表第i题答题的时间戳，K为答题总数。按照答题时间戳可将整个答题流程切分成K个时间段，对于每个时间段，V {\textbar} Front {\textbar} 和V {\textbar} side {\textbar} 所对应的视频帧可以构成一个图像序列，对应的，有从视频帧提取得到对应的眼动注意力向量F {\textbar} g {\textbar} 、微表情F {\textbar} exp {\textbar} 、动作特征向量F {\textbar} 3D {\textbar} ； {\textbar} 对于时刻i，将智能分析模块所得到的三种不同向量f {\textbar}   {\textbar} g i {\textbar} (9-d)、f {\textbar} exp i {\textbar} (22-d)、f {\textbar} 3D i {\textbar} (75-d)以及该测试者当前的答题情况f {\textbar} ans i {\textbar} 拼接起来，可以得到表示该时刻测试者行为特征的向量；对于一个片段，可以得到表示当前时刻的行为特征x {\textbar} i {\textbar} ＝[f {\textbar} g i {\textbar} ,f {\textbar} exp i {\textbar} ,f {\textbar} 3D i {\textbar} ,f {\textbar} ans i {\textbar} ](1-d)，由此，对于整段测试，可以得到107{维行为特征向量序列X}＝\{x {\textbar} 0 {\textbar} ,x {\textbar} 1 {\textbar} ,x {\textbar} 2 {\textbar} ,…,x {\textbar} N {\textbar} \}，其中x {\textbar} 0 {\textbar} 是一个固定的起始向量。 {\textbar} 所述多模态信息融合模型中，异常行为检测模块由12{层Transformer编码器组成}，每层编码器包括注意力层和前向反馈层(Vaswani et al.,2017)，在注意力层中，对于输入x，经过点积-乘积注意力机制计算，得到表示每个序列单元对当前单元的影响权重的向量组Z： {\textbar}   {\textbar} 其中Q，K，V为注意力机制中的隐变量， {\textbar}   {\textbar} 为向量组K中向量维度的平方根，对于多头注意力模型，需要利用多组独立的Q,K,V隐变量产生多个向量组\{Z {\textbar} 1 {\textbar} ,Z {\textbar} 2 {\textbar} ,…,Z {\textbar} T {\textbar} \}，T为向量组的总数，以获取更加丰富的模型表达能力，将所有向量组拼接加权求和得多头注意力的输出Z {\textbar} final {\textbar} ： {\textbar} Z {\textbar}   {\textbar} final {\textbar} ＝Concat(Z {\textbar} 1 {\textbar} ,Z {\textbar} 2 {\textbar} ,…,Z {\textbar} T {\textbar} )W {\textbar} o {\textbar} 前向反馈层由2层全连接层组成，负责对注意力层的输出做进一步处理；此外，注意力层和前向反馈层均被加入残差，以防止编码器层数较多时，反向传播过程中，梯度消失现象的出现； {\textbar}   {\textbar} 输出向量组记为Y＝\{y {\textbar}   {\textbar} 0 {\textbar} ,y {\textbar} 1 {\textbar} ,y {\textbar} 2 {\textbar} ,…,y {\textbar} N {\textbar} \}，y {\textbar} i {\textbar} ∈R {\textbar} L {\textbar} ，其中二维向量y {\textbar} 0 {\textbar} 为x {\textbar} 0 {\textbar} 对应的输出，代表整个时间片段的向量表示，将y {\textbar} 0 {\textbar} 输入到全连接层形式的分类器，得到该片段是否存在异常的分类结果。 {\textbar} 在接受执行功能测试之前，测试者将接受一系列{ADHD诊断常见的心理学量表测试}，对测试者的智力、情绪、社交能力等进行初步评估。师长反馈量表的主要目的是对患者的日常行为功能进行初步评估，作为医生诊断的依据之一。而智力、情绪等评估主要是了解患者完成执行功能测试时的状态，排除智力障碍、短期情绪异常等干扰因素，结合智能分析结果，得出更加准确的诊断结论。具体的评估量表模块名称及测试内容如表1所示。 {\textbar}   {\textbar} 表1 {\textbar}   {\textbar} 将医生在诊断{ADHD时使用的Conners}、{WFIRS}-{P和SNAP}-Ⅳ三个量表做成微信小程序的形式让儿童的家长和老师填写，结合量表测试结果，执行功能测试结果，及对眼动注意力、表情和动作多模态信息进行异常行为识别后的结果，可以自动生成一份标准规范、客观量化的可解释性{ADHD评估报告}。 {\textbar}   {\textbar} 本实施例的方案，成本较低，使用寿命长，占用空间小，操作流程上也方便快捷，对操作人员的要求很低。 {\textbar}   {\textbar} 本说明书的实施例所述的内容仅仅是对构思的实现形式的列举，仅作说明用途。本发明的保护范围不应当被视为仅限于本实施例所陈述的具体形式，本发明的保护范围也及于本领域的普通技术人员根据本发明构思所能想到的等同技术手段。 Children {ADHD} screening evaluation system based on multi-mode deep learning {\textbar}   {\textbar} Technical Field {\textbar}   {\textbar} The present invention relates to a child attention deficit hyperactivity disorder ({ADHD}) screening assessment system. {\textbar}   {\textbar} Background {\textbar}   {\textbar} attention deficit hyperactivity disorder ({ADHD}), commonly referred to as hyperactivity disorder, is child juvenile juvenile most common neural developmental disorder, its clinical manifest is attention to centralized difficulty, hyperactivity, impulsitive, emotional labile, learning difficulty and so on. {\textbar}   {\textbar} The present intelligent recognition technology of {ADHD} medical image is mainly based on brain functional nuclear magnetic resonance and electroencephalogram and other pathological aspects of research, or independently based on eye movement or facial expression and observing behaviour characteristics of the patient. The former technical operation process is very complicated. It is more difficult for children who are hard to control their behavior. Moreover, the prices of these technologies are very expensive. It is difficult to have a large scale of landing at present. the information dimension of the latter is single, it is difficult to comprehensively evaluate the behavior of children, and the expression form of {ADHD} children is various, independently observing eye movement or limb action may be omitted other important behavior characteristics. {\textbar}   {\textbar} Contents of the Invention {\textbar}   {\textbar} In order to overcome the existing children {ADHD} screening evaluation mode of low efficiency, poor accuracy, the invention claims a children {ADHD} screening evaluation system with high efficiency and good accuracy based on multi-mode deep learning {\textbar}   {\textbar} The technical solution adopted by the present invention to solve the technical problem is as follows: {\textbar}   {\textbar} A children {ADHD} screening evaluation system based on multi-mode deep learning, comprising: {\textbar}   {\textbar} a meter testing module for collecting and evaluating the behavioral performance and relative ability of each aspect of the child by the {ADHD} diagnosis psychology meter; {\textbar}   {\textbar} software and hardware cooperation module, for developing the test software to finish the task of the diagnosis children; the hardware module comprises a multi-camera group and a synchronous control system, for recording the eye movement attention, expression and body posture information in the task test process; {\textbar}   {\textbar} an intelligent analysis module, for intelligently processing the multimedia information collected in the software and hardware cooperative module; using computer vision technology to perform eye movement attention; analysis of expression and posture, tracking and identifying, and converting into the next machine learning compatible homochemical vector representation; at the same time, also moving the mouse of the tester; clicking and keyboard input action also as recording and tracking; it can be fused with the same quality vector; {\textbar}   {\textbar} multi-mode information fusion model, using the time sequence multi-mode information fusion model {BERT} (Devlin et al., 2018), pre-training the same quality vector combined test result obtained in a specific time slice, finally generating the model to judge whether the patient has the classification result of the abnormal behaviour in this time period. {\textbar}   {\textbar} Further, in the software and hardware cooperative module, the 1 \# camera located behind the computer display screen is used for shooting the front image of the tester, collecting the eye movement and expression change information of the tester; 2, 3 \# binocular depth camera module located at the side of the test person can be used for shooting the whole body of the tester; collecting the three-dimensional body posture information of the tester. {\textbar}   {\textbar} Further, in the software and hardware cooperative module, three psychology tests needed to complete {ADHD} clinical diagnosis during shooting period of the tester: Stroop test, Wisconsin card classification test and expression identification test; the three tests respectively attention to the patient, inhibiting cognitive interference, abstract thinking and cognitive transfer, emotion and social and other cognitive function, Stroop test through word meaning and font color conflict to evaluate the ability of the tester for inhibiting cognitive interference; Wisconsin card classification test by changing color, shape, number of test rules to evaluate the cognitive transfer capability of the tester; the expression test classifies the expression of the human face picture to evaluate the social cognitive ability of the tester; integrating said three execution function tests into a set of task test software. {\textbar}   {\textbar} Preferably, in the process of three tests, the test software can interact with the camera module, when the tester starts testing, the software starts the camera module to start recording, recording the eye, expression and posture video information of the tester, for intelligent analysis module analyzing and extracting key features; when the test is finished, the test software will stop the recording work of the camera module synchronously. at the same time, the test software can integrate and count the measurement index, and recording the key time node of the answer operation and the mouse keyboard action of the tested person, these forms the data base of the multi-mode fusion mechanism. {\textbar}   {\textbar} the camera module mainly collects two types of video information: 1) The camera of the face of the tester is concerned with the eye movement (attention focus) and facial muscle action (abnormal expression) of the tester; 2) the lateral binocular depth camera uses three-dimensional visual sensing technology to extract human body skeleton position of each time, performing attitude analysis. {\textbar}   {\textbar} Further, the intelligent analysis module comprises eye movement attention characteristic vector calculation unit, expression characteristic vector calculation unit and the limb action characteristic vector calculation unit. {\textbar}   {\textbar} Preferably, the eye movement attention feature vector calculation unit, input is the collected front video {VFront} and camera calibration matrix Cr, output is generated eye movement attention feature vector Fg, comprising the following steps: {\textbar}   {\textbar} 1.1 pupil position calculation: firstly confirming the face position by algorithm based on {HOG}; the detection of the face key point is realized by continuous condition neural field ({CCNF}) model frame, so as to calculate the pupil position in the plane; then, using the {EPnP} algorithm, the detected human face and the average standard 3 D face model F is aligned, calculating the camera coordinate system lower head of the rotating matrix Rr and translation vector tr, the output of the step is the eye space position er=tr + eh; {\textbar}   {\textbar} 1.2 sight direction calculation, the sight direction characteristic can be represented as a two-dimensional vector g comprising yaw angle (yaw) and pitch angle (pitch), the yaw angle is the included angle of the sight direction and the vertical plane; the pitch angle is the included angle between the sight direction and the horizontal plane; {\textbar}   {\textbar} 1.3 screen position conversion: by means of external calibration, can determine the space position of the plane of the screen; according to the sight direction feature vector g and the eye position er can calculate the intersection point of the sight and the screen plane, namely the line falling point ps on the screen, and then obtaining the eye attention area r according to the screen structure; {\textbar}   {\textbar} combining the pupil position, sight direction and screen attention to obtain the final eye movement attention feature vector, expressed as fg = [er, g, r]. {\textbar}   {\textbar} In the step 1.2, the eye image is subjected to normalization processing: multiplying the original image by the inverse matrix of the camera projection matrix  {\textbar}   {\textbar} converting into the head pose in the three-dimensional space; then multiplying the head original posture by the transformation matrix M to fix the eye position, at last, multiplying the normalized eye posture by a standard camera projection matrix Cn, obtaining the normalized eye two-dimensional image e; in order to calculate the sight vector, converting the normalized rotation matrix Rn=M Rr into a two-dimensional rotation vector h, inputting the obtained 2 D head posture information h and the single-channel grey eye image e into the convolutional neural network model, outputting the sight direction characteristic vector, the feature vector is a two-dimensional vector g comprising yaw angle and pitch angle. {\textbar} then preferably, the expression characteristic vector calculation unit, through the 22 Facial Action {CodingSystem} (Hamm et al., 2011) description of facial movement unit and action to describe the expression change of the tester, specifically, using a combined Region of Intesti ({ROI}), Multi-label Learning, and {LSTM}-based the structure of the micro-expression for detecting the expression characteristic calculation input is collected front video {VFront}, output is generated {AU} probability sequence expression Fexp, comprising the following steps: {\textbar}   {\textbar} 2.1 firstly need to identify the face key feature point set, then according to the position {PL} of the key feature point to obtain the position {PAU} of the corresponding muscle associated with the expression motion unit, on this basis, it can construct {ROIcropping} ({ROI}) based on {VGGNet} Nets), by cutting out the network 12 layer to obtain the feature map, thereby obtaining the corresponding characteristic representation of each {AU}, the all feature vector splicing to obtain the whole vector {FAU}; {\textbar}   {\textbar} 2.2 because the input form of the expression recognition task is video data, through the expression state of the previous time is more accurate, more smoothly predicting the expression state of the current time; using one multi-layer {LSTM} structure to process the time-ordered expression characteristic vector; finishing multi-task binary classification problem of multiple {AU}; obtaining expression characteristic sequence expression Fexp based on {AU} characteristic activation probability. {\textbar}   {\textbar} more preferably, the limb action characteristic vector calculation unit, the input is the side video Vside collected, output is generated 3D framework sequence F3D, comprising the following steps: {\textbar}   {\textbar} 3.1 confidence map and {PAF} calculation: for the picture input, firstly extracting picture feature F by 10 layers of {VGG}-19, then inputting the F into two multi-stage {CNN}, one network determines the position of the human closing node by means of confidence map, and the other network determines limb direction by Part Affinity Fields ({PAF}) ; finally obtaining the confidence map S = (S1, S2, ..., {SJ}) and {PAF} L = (L1, L2, ..., {LC}), wherein J, C respectively represents the type number of the node and the limb; {\textbar}   {\textbar} 3.2: node matching optimization: obtaining the position of the node according to the confidence map,  {\textbar}   {\textbar} represents the m-th of the j-th gateway node, calculating the node group through L  {\textbar} Confidence  {\textbar} wherein p is the interpolation function between two points: {\textbar}   {\textbar} wherein u represents the prediction point to  {\textbar}   {\textbar} the distance  {\textbar} and  {\textbar} the ratio of the distance; {\textbar} 3.3, then connecting the limb of common joint node; forming a complete human body 2D skeleton characteristic f2D, finally inputting the 2D skeleton sequence into a neural network to obtain the 3D skeleton sequence f3D, for the whole segment of video, the final 3D skeleton sequence is: F3D = [f3D1, f3D2, ..., f3DN]. {\textbar}   {\textbar} For the whole answer process, there are front video {VFront}, side video Vside, and the answer operation sequence A = (a1, a2, ..., {aK}), ai represents the i-th answer of the time stamp, K is the total number of answer. according to the answer time stamp, the whole answer flow is divided into K time periods; for each time period, the video frame corresponding to {VFront} and Vside can form an image sequence; correspondingly, extracting from the video frame to obtain the corresponding eye movement attention vector Fg, micro expression Fexp, an action feature vector F3D; {\textbar}   {\textbar} for the time i, the intelligent analysis module to obtain the three different vectors fg i (9-d), fexp i (22-d), f3D i (75-d) and the test of the current answer condition i spliced together, can obtain the vector representing the time tester behaviour characteristic; for a fragment, it can obtain the current time of the behaviour characteristic xi = [fg i, fexp i, f3D i, i] (1-d), thereby, for the whole section test, can obtain the 107 dimensional behaviour characteristic vector sequence X = (x0, x1, x2, ..., {xN}), wherein x0 is a fixed initial vector. {\textbar}   {\textbar} in the multimodal information fusion model, abnormal behaviour detection module is composed of 12 layers of encoder, each encoder comprises an attention layer and a forward feedback layer (Vaswani et al., 2017), in the attention layer, for the input x, calculating by dot product-product attention mechanism, obtaining the vector group Z representing the influence weight of each sequence unit to the current unit: {\textbar}   {\textbar} wherein Q, K, V are the hidden variables in the attention mechanism,  {\textbar}   {\textbar} is the square root of vector dimension in vector group K; for multi-head attention model, multiple groups of independent Q, K, V hidden variables are needed to generate multiple vector groups (Z1, Z2, ..., {ZT}), T is the total number of the vector group, so as to obtain more abundant model expression capability, combining all vector groups with weighted summation to obtain output Zfinal of multi-head attention: {\textbar} Zfinal=Concat (Z1, Z2, ..., {ZT}) Wo {\textbar}   {\textbar} the forward feedback layer is composed of 2 layers of full connection layer, responsible for further processing the output of the attention layer; In addition, the attention layer and the forward feedback layer are added with residual error, so as to prevent the number of the encoder is more, in the reverse propagation process, the gradient disappears; {\textbar}   {\textbar} output vector group is marked as Y = (y0, y1, y2, ..., {yN}), yi belongs to {RL}, wherein the two-dimensional vector y0 is the output corresponding to x0, representing the vector representation of the whole time segment, inputting y0 into the classifier in the form of the full connection layer, obtaining the classification result of whether the segment is abnormal. {\textbar}   {\textbar} The beneficial effects of the present invention are mainly shown in the following: 1, the system can provide auxiliary reference, by artificial intelligence can improve the working efficiency, making more accurate and individualized treatment solution for the patient; 2. to the patient, through artificial intelligence can quickly finish each inspection, obtaining more accurate diagnosis and treatment suggestion; 3. The artificial intelligence can try to simulate the medical expert diagnosis and treatment thinking and reasoning process, giving a more reliable auxiliary reference intermediate result. {\textbar}   {\textbar} Description of pictures {\textbar}   {\textbar} {FIG}. 1 is a schematic diagram of a child {ADHD} screening evaluation system. {\textbar}   {\textbar} {FIG}. 2 is a flow chart of the eye movement attention feature vector calculation unit. {\textbar}   {\textbar} {FIG}. 3 is a flow chart of the expression feature vector calculation unit. {\textbar}   {\textbar} {FIG}. 4 is a flow chart of the limb action feature vector calculation unit. {\textbar}   {\textbar} Specific implementation examples {\textbar}   {\textbar} The present invention will be further described below with reference to the drawings. {\textbar}   {\textbar} Referring to {FIG}. 1 to {FIG}. 4, a children {ADHD} screening evaluation system based on multi-mode deep learning technology, comprising: {\textbar}   {\textbar} a meter testing module for collecting and evaluating the behavioral performance and relative ability of each aspect of the child by the {ADHD} diagnosis psychology meter; The traditional paper questionnaire method has patient filling trouble, the later data finishing process is repeated and fussy, data storage and analysis is not easy. Therefore, we have developed a full set of micro-credit small program to replace the traditional paper questionnaire; the tester only needs to scan the two-dimensional code by the mobile phone to fill; the test result can be automatically integrated into the final generated intelligent auxiliary diagnosis report for doctor reference; {\textbar}   {\textbar} software and hardware cooperative module for collecting three kinds of execution function test, and developing the corresponding test software to make the diagnosis children finish the related task; the hardware module comprises a multi-camera group and a synchronous control system; it can record the eye movement attention in the task test process, expression and body posture information; the later period can be further intelligent analysis; {\textbar}   {\textbar} an intelligent analysis module, for intelligently processing the multimedia information collected in the software and hardware cooperative module; using computer vision technology to perform eye movement attention; analysis of expression and posture, tracking and identifying, and converting into the next machine learning compatible homogeneous vector representation, at the same time, also recording and tracking the mouse movement of the test personnel, clicking, keyboard input and so on, can be fused with the multimedia information analysis. {\textbar}   {\textbar} multi-mode information fusion model, using time sequence multi-mode information fusion model {BERT} (Devlin et al., 2018), the same quality vector obtained in a certain time segment combined with other test result for pre-training, finally generating model can judge whether the patient has abnormal behaviour in the time period, and the type and occurrence frequency of the abnormal behaviour as important reference basis for final auxiliary diagnosis, replacing the subjective observation and description completely dependent on the doctor experience level in the traditional diagnosis. {\textbar}   {\textbar} {FIG}. 1 describes the relationship between the camera and the tested person, the 1 \# camera behind the computer display screen for shooting the front image of the tester, collecting the eye movement and expression change information of the tester. 2, 3 \# binocular depth camera module located at the side of the test person can be used for shooting the whole body of the tester; collecting the three-dimensional body posture information of the tester. {\textbar}   {\textbar} Three psychology tests commonly used in the {ADHD} clinical diagnosis are required to be completed by the tester during the shooting period: Stroop test, Wisconsin card classification test and expression recognition test. the three tests respectively attention to the patient, inhibiting cognitive interference, abstract thinking and cognitive transfer, emotion and social and other cognitive function to evaluate, Stroop test mainly through word meaning and font color conflict to evaluate the ability of the tester for inhibiting cognitive interference; Weisconsin card classification test mainly by changing color, shape, number of test rules to evaluate the cognitive transfer ability of the tester; The expression test mainly classifies the expression of the human face picture to evaluate the social cognitive ability of the tester. {\textbar}   {\textbar} integrating the three execution function test into a set of task test software; the whole set of task completion time is substantially controlled at 20 {\textasciitilde} 30 minutes. In addition to the implementation of the function, the professional software designer and child psychology professionals interact software interaction; interface design provides guidance opinion; the tested children can successfully finish the design task in the predetermined time in the test. {\textbar}   {\textbar} In the process of the three tests, the test software can interact with the camera module, when the tester starts testing, software will start the camera module to start recording, recording the eye, expression and posture of the tester video information, for intelligent analysis module analyzing and extracting key features. when the test is finished, the test software will stop the recording work of the camera module synchronously. at the same time, the test software can integrate and count the measurement index, and record the key time node of the answer operation and the mouse keyboard action of the tested personnel; these forms the data base of the subsequent multi-mode fusion mechanism. {\textbar}   {\textbar} The camera module mainly collects two types of video information: 1) the camera facing the face of the tester mainly focuses attention of the eye movement (attention focus) and facial muscle action (abnormal expression) of the tester; 2) the lateral binocular depth camera mainly uses three-dimensional visual perception technology to extract human body skeleton position of each time, performing attitude analysis. {\textbar}   {\textbar} the intelligent analysis module comprises eye movement attention feature vector calculation unit, expression feature vector calculation unit and the limb action feature vector calculation unit; {\textbar}   {\textbar} the eye movement attention feature vector calculation unit, input is the collected front video {VFront} and camera calibration matrix Cr, output is generated eye movement attention feature vector Fg, comprising the following steps: {\textbar}   {\textbar} 1.1 pupil position calculation: firstly confirming the face position by algorithm based on {HOG}; the detection of the face key point is realized by continuous condition neural field ({CCNF}) model frame, so as to calculate the pupil position in the plane; then, using the {EPnP} algorithm, the detected human face and the average standard 3 D face model F is aligned, calculating the camera coordinate system lower head of the rotating matrix Rr and translation vector tr, the output of the step is the eye space position er=tr + eh; {\textbar}   {\textbar} 1.2 sight direction calculation, the sight direction characteristic can be represented as a two-dimensional vector g comprising yaw angle (yaw) and pitch angle (pitch), the yaw angle is the included angle of the sight direction and the vertical plane; the pitch angle is the included angle between the sight direction and the horizontal plane; {\textbar}   {\textbar} In order to obtain a line-of-sight vector, the eye image is subjected to normalization processing: multiplying the original image by the inverse matrix of the camera projection matrix  {\textbar}   {\textbar} converting into the head pose in the three-dimensional space; then multiplying the head original posture by the transformation matrix M to fix the eye position, at last, multiplying the normalized eye posture by a standard camera projection matrix Cn, obtaining the normalized eye two-dimensional image e; in order to calculate the sight vector, converting the normalized rotation matrix Rn=M Rr into a two-dimensional rotation vector h, inputting the obtained 2 D head posture information h and the single-channel grey eye image e into the convolutional neural network model, outputting the sight direction characteristic vector, the feature vector is a two-dimensional vector g including yaw angle and pitch angle; {\textbar} 1.3 screen position conversion: by means of external calibration, can determine the space position of the plane of the screen; according to the sight direction feature vector g and the eye position er can calculate the intersection point of the sight and the screen plane, namely the line falling point ps on the screen, and then obtaining the eye attention area r according to the screen structure; {\textbar}   {\textbar} 1.4, combining the pupil position, the sight direction and the screen attention to obtain the final eye movement attention feature vector, representing Fg = [er, g, r]. {\textbar}   {\textbar} the expression characteristic vector calculation unit, through the 22 Facial Action Coding System (Hammet, 2011) description of facial movement unit and action to describe the expression change of the tester, specifically, using a combined Region of Intesti ({ROI}), Multi-label Learning, and {optimalLSTM}-based temporalst; the structure of the micro-expression for detecting the expression characteristic calculation input is collected front video {VFront}, output is generated {AU} probability sequence expression Fexp, comprising the following steps: {\textbar}   {\textbar} 2.1 firstly need to identify the face key feature point set, then according to the position {PL} of the key feature point to obtain the position {PAU} of the corresponding muscle associated with the expression motion unit, on this basis, it can construct {ROIcropping} ({ROI}) based on {VGGNet} Nets), by cutting out the network 12 layer to obtain the feature map, thereby obtaining the corresponding characteristic representation of each {AU}, the all feature vector splicing to obtain the whole vector {FAU}; {\textbar}   {\textbar} 2.2 because the input form of the expression recognition task is video data, through the expression state of the previous time is more accurate, more smoothly predicting the expression state of the current time; using one multi-layer {LSTM} structure to process the time-ordered expression characteristic vector; finishing multi-task binary classification problem of multiple {AU}; obtaining expression characteristic sequence expression Fexp based on {AU} characteristic activation probability. {\textbar}   {\textbar} the limb action characteristic vector calculation unit, input is the collected side video Vside, output is generated 3D framework sequence F3D, comprising the following steps: {\textbar}   {\textbar} 3.1 confidence map and {PAF} calculation: for the picture input, firstly extracting picture feature F by 10 layers of {VGG}-19, then inputting the F into two multi-stage {CNN}, one network determines the position of the human closing node by means of confidence map, and the other network determines limb direction by Part Affinity Fields ({PAF}) ; finally obtaining the confidence map S = (S1, S2, ..., {SJ}) and {PAF} L = (L1, L2, ..., {LC}), wherein J, C respectively represents the type number of the node and the limb; {\textbar}   {\textbar} 3.2: node matching optimization: obtaining the position of the node according to the confidence map,  {\textbar}   {\textbar} represents the m-th of the j-th gateway node, calculating the node group through L  {\textbar} Confidence  {\textbar} wherein p is the interpolation function between two points: {\textbar}   {\textbar} wherein u represents the prediction point to  {\textbar}   {\textbar} the distance  {\textbar} and  {\textbar} the ratio of the distance; {\textbar} 3.3, then connecting the limb of common joint node; forming a complete human body 2D skeleton characteristic f2D, finally inputting the 2D skeleton sequence into a neural network to obtain the 3D skeleton sequence f3D, for the whole segment of video, the final 3D skeleton sequence is: F3D = [f3D1, f3D2, ..., f3DN]. {\textbar}   {\textbar} For the whole answer process, there are front video {VFront}, side video Vside, and the answer operation sequence A = (a1, a2, ..., {aK}), ai represents the i-th answer of the time stamp, K is the total number of answer. according to the answer time stamp, the whole answer flow is divided into K time periods; for each time period, the video frame corresponding to {VFront} and Vside can form an image sequence; correspondingly, extracting from the video frame to obtain the corresponding eye movement attention vector Fg, micro expression Fexp, an action feature vector F3D; {\textbar}   {\textbar} for the time i, the intelligent analysis module to obtain the three different vectors fg i (9-d), fexp i (22-d), f3D i (75-d) and the test of the current answer condition i spliced together, can obtain the vector representing the time tester behaviour characteristic; for a fragment, it can obtain the current time of the behaviour characteristic xi = [fg i, fexp i, f3D i, i] (1-d), thereby, for the whole section test, can obtain the 107 dimensional behaviour characteristic vector sequence X = (x0, x1, x2, ..., {xN}), wherein x0 is a fixed initial vector. {\textbar}   {\textbar} in the multimodal information fusion model, abnormal behaviour detection module is composed of 12 layers of encoder, each encoder comprises an attention layer and a forward feedback layer (Vaswani et al., 2017), in the attention layer, for the input x, calculating by dot product-product attention mechanism, obtaining the vector group Z representing the influence weight of each sequence unit to the current unit: {\textbar}   {\textbar} wherein Q, K, V are the hidden variables in the attention mechanism,  {\textbar}   {\textbar} is the square root of vector dimension in vector group K; for multi-head attention model, multiple groups of independent Q, K, V hidden variables are needed to generate multiple vector groups (Z1, Z2, ..., {ZT}), T is the total number of the vector group, so as to obtain more abundant model expression capability, combining all vector groups with weighted summation to obtain output Zfinal of multi-head attention: {\textbar} Zfinal=Concat (Z1, Z2, ..., {ZT}) Wo {\textbar}   {\textbar} the forward feedback layer is composed of 2 layers of full connection layer, responsible for further processing the output of the attention layer; In addition, the attention layer and the forward feedback layer are added with residual error, so as to prevent the number of the encoder is more, in the reverse propagation process, the gradient disappears; {\textbar}   {\textbar} output vector group is marked as Y = (y0, y1, y2, ..., {yN}), yi belongs to {RL}, wherein the two-dimensional vector y0 is the output corresponding to x0, representing the vector representation of the whole time segment, inputting y0 into the classifier in the form of the full connection layer, obtaining the classification result of whether the segment is abnormal. {\textbar}   {\textbar} before receiving the execution function test, the tester will receive a series of {ADHD} diagnosis common psychological test table test, the intelligence of the tester, emotion, social ability and so on for preliminary evaluation. The main purpose of the teacher feedback quantity table is to primarily evaluate the daily behaviour function of the patient, as one of the diagnosis of the doctor. and intelligence, emotion evaluation mainly is to know the state of the patient when performing the function test, excluding the intellectual impairment, short term emotion abnormal interference factor, combining the intelligent analysis result to obtain more accurate diagnosis conclusion. The specific evaluation quantity table module name and test content are shown in Table 1. {\textbar}   {\textbar} Table 1 {\textbar}   {\textbar} the doctor in the diagnosis {ADHD} using the Conners, {WFIRS}-P and {SNAP}-{IV} three quantity table into the form of micro-credit small program for children parents and teachers filling, combined measuring result, executing the function test result, and the eye attention, the expression and action multi-mode information after the abnormal behaviour recognition result, can automatically generate a standard specification, objective quantization of interpretable {ADHD} evaluation report. {\textbar}   {\textbar} The solution of the embodiment, the cost is low, the service life is long, the occupied space is small, the operation process is convenient and fast, the requirement of the operator is very low. {\textbar}   {\textbar} The content of the embodiment of the present specification is only enumerated in the implementation form of the concept, and is only used for illustrative purposes. The protection scope of the present invention should not be considered to be limited to the specific forms set forth in the present embodiment, and the protection scope of the present invention is also the equivalent technical means of those skilled in the art to conceive in accordance with the inventive concept.
Issue: {CN}111528859A},
}

@patent{geigenmuller_etal20,
	location = {{US}},
	title = {Metabolic markers of attention deficit hyperactivity disorder metabolic markers of attention deficit hyperactivity disorder metabolic markers of attention deficit hyperactivity disorder},
	url = {https://www.derwentinnovation.com/tip-innovation/recordView.do?hideHighlightPanel=true&idType=uid/recordid&datasource=T3&databaseIds=PATENT&category=PAT&recordKeys=US20200188335A120200618&TYPE=RECORDVIEW&fromExternalLink=true&fromLocation=external&isDAJImageAllowed=false},
	abstract = {Disclosed herein are methods for treating subjects having {ADHD} identifiable by levels of 3-{IS} in blood.
Disclosed herein are methods for treating subjects having {ADHD} identifiable by levels of 3-{IS} in blood.
Disclosed herein are methods for treating subjects having {ADHD} identifiable by levels of 3-{IS} in blood.},
	type = {patentus},
	number = {20200188335A1},
	author = {Geigenmuller, Ute and Damian, Doris and Pacula, Maciej and {DePristo}, Mark A.},
	urldate = {2019-12-13},
	date = {2020-06-18},
	note = {Edition: A61K0031165 {\textbar} A61K0031137 {\textbar} A61K0031138 {\textbar} A61K00314168 {\textbar} A61K00314458 {\textbar} A61K003155 {\textbar} G01N003353 {CPC}  - A61K0031165 {\textbar} A61K0031137 {\textbar} A61K0031138 {\textbar} A61K00314168 {\textbar} A61K00314458 {\textbar} A61K003155 {\textbar} G01N00335308 {\textbar} G01N2800305 {\textbar} G01N280052 {EP}; {US} {US}
Issue: {US}20200188335A1
Number Of Volumes: 001001 What is claimed: {\textbar}   {\textbar} 1 {\textbar} . A method for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the method comprising the steps of:  {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level; and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} 2 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the individual is independently suspected of having or is independently observed to have atypical development, said independent suspicion or observation having been made prior to the identifying step. {\textbar} 3 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , comprising identifying, by the processor of the computing device, the existence of {ADHD} in the individual as opposed to non-{ADHD}. {\textbar} 4 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , comprising identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. {\textbar} 5 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , comprising identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar} 6 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the sample is a blood sample. {\textbar} 7 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the sample comprises plasma. {\textbar} 8 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the sample comprises white blood cells. {\textbar} 9 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. {\textbar} 10 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). {\textbar} 11 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the individual is male. {\textbar} 12 {\textbar} . A system for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the system comprising:  {\textbar} a diagnostics kit comprising testing instruments for measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; and {\textbar}   {\textbar} a non-transitory computer-readable medium having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to:  {\textbar}   {\textbar} optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determine at least one of: (i) the existence of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level; and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} 13 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the diagnostics kit is an in vitro diagnostics kit. {\textbar} 14 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the individual is independently suspected of having or is independently observed to have (e.g., by a medical practitioner) atypical development. {\textbar} 15 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the instructions cause the processor to identify the existence of {ADHD} in the individual as opposed to non-{ADHD}. {\textbar} 16 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. {\textbar} 17 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar} 18 {\textbar} - {\textbar} 24 {\textbar} . (canceled) {\textbar} 25 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the method further comprises  {\textbar} administering therapy to the individual that has been determined to have {ADHD}. {\textbar}   {\textbar} 26 {\textbar} . The method of  {\textbar} claim 25 {\textbar} , wherein the therapy is behavioral therapy or a therapeutic substance. {\textbar} 27 {\textbar} - {\textbar} 33 {\textbar} . (canceled) {\textbar} 34 {\textbar} . A method for determining a condition for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least one condition comprises attention deficit hyperactivity disorder ({ADHD}), the method comprising the steps of:  {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference between the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to the non-existence of {ADHD}, wherein the non-existence of {ADHD} comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level; and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition indicative of atypical development and exclusive of {ADHD}, wherein the at least one other condition does not comprise {ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. What is claimed: {\textbar}   {\textbar} 1 {\textbar} . A method for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the method comprising the steps of:  {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level; and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} 2 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the individual is independently suspected of having or is independently observed to have atypical development, said independent suspicion or observation having been made prior to the identifying step. {\textbar} 3 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , comprising identifying, by the processor of the computing device, the existence of {ADHD} in the individual as opposed to non-{ADHD}. {\textbar} 4 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , comprising identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. {\textbar} 5 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , comprising identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar} 6 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the sample is a blood sample. {\textbar} 7 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the sample comprises plasma. {\textbar} 8 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the sample comprises white blood cells. {\textbar} 9 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. {\textbar} 10 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). {\textbar} 11 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the individual is male. {\textbar} 12 {\textbar} . A system for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the system comprising:  {\textbar} a diagnostics kit comprising testing instruments for measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; and {\textbar}   {\textbar} a non-transitory computer-readable medium having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to:  {\textbar}   {\textbar} optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determine at least one of: (i) the existence of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level; and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} 13 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the diagnostics kit is an in vitro diagnostics kit. {\textbar} 14 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the individual is independently suspected of having or is independently observed to have (e.g., by a medical practitioner) atypical development. {\textbar} 15 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the instructions cause the processor to identify the existence of {ADHD} in the individual as opposed to non-{ADHD}. {\textbar} 16 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. {\textbar} 17 {\textbar} . The system of  {\textbar} claim 12 {\textbar} , wherein the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar} 18 {\textbar} - {\textbar} 24 {\textbar} . (canceled) {\textbar} 25 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the method further comprises  {\textbar} administering therapy to the individual that has been determined to have {ADHD}. {\textbar}   {\textbar} 26 {\textbar} . The method of  {\textbar} claim 25 {\textbar} , wherein the therapy is behavioral therapy or a therapeutic substance. {\textbar} 27 {\textbar} - {\textbar} 33 {\textbar} . (canceled) {\textbar} 34 {\textbar} . A method for determining a condition for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least one condition comprises attention deficit hyperactivity disorder ({ADHD}), the method comprising the steps of:  {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference between the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to the non-existence of {ADHD}, wherein the non-existence of {ADHD} comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level; and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition indicative of atypical development and exclusive of {ADHD}, wherein the at least one other condition does not comprise {ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. 1 {\textbar} . A method for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the method comprising the steps of:  {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level; and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. 1 {\textbar} . A method for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the method comprising the steps of:  {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level; and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {CROSS} {REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar}   {\textbar} This patent application claims the benefit of U.S. Provisional Patent Application No. 62/115,101, filed Feb. 11, 2015, the entirety of which is incorporated herein by reference. {\textbar}   {\textbar} {FIELD} {OF} {THE} {INVENTION} {\textbar}   {\textbar} This invention relates generally to metabolic markers of Attention Deficit Hyperactivity Disorder ({ADHD}) individuals. {\textbar}   {\textbar} {BACKGROUND} {\textbar}   {\textbar} Attention Deficit Hyperactivity Disorder ({ADHD}) is a disorder characterized by inattention and/or difficulty staying focused as well as hyperactivity and/or difficulty in control of one's behavior. {ADHD} typically presents early in life (i.e. during childhood). Presently, diagnosis is typically based upon a combination of self, family and/or teacher/caretaker reports of behaviors combined with observations and input from physicians and other licensed health-care practitioners. {\textbar}   {\textbar} {SUMMARY} {\textbar}   {\textbar} In some embodiments, the invention provides methods for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the method comprising the steps of: {\textbar}   {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development, said independent suspicion or observation having been made prior to the identifying step. {\textbar}   {\textbar} In some embodiments, the methods comprise identifying, by the processor of the computing device, the existence of {ADHD} in the individual as opposed to non-{ADHD}. In some embodiments, the methods comprise identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. In some embodiments, the methods comprise identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. {\textbar}   {\textbar} In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). In some embodiments, the individual is male. {\textbar}   {\textbar} In some embodiments, the invention provides systems for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the system comprising: {\textbar}   {\textbar} a diagnostics kit comprising testing instruments for measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; and {\textbar}   {\textbar} a non-transitory computer-readable medium having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to: {\textbar}   {\textbar} optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determine at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the diagnostics kit is an in vitro diagnostics kit. In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development. {\textbar}   {\textbar} In some embodiments, the instructions cause the processor to identify the existence of {ADHD} in the individual as opposed to non-{ADHD} (e.g., distinguish between {ADHD} and non-{ADHD}). In some embodiments, the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. In some embodiments, the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). In some embodiments, the individual is male. {\textbar}   {\textbar} In some embodiments, the invention provides non-transitory computer-readable media having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to: {\textbar}   {\textbar} optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determine at least one of: {\textbar}   {\textbar} (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and {\textbar}   {\textbar} (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the invention provides methods of treating an individual suspected of having or observed as having atypical development, the method comprising the steps of: {\textbar}   {\textbar} obtaining a biological sample from the individual; {\textbar}   {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in the biological sample; {\textbar}   {\textbar} optionally, identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; {\textbar}   {\textbar} determining the existence of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and {\textbar}   {\textbar} administering therapy to the individual for {ADHD}. {\textbar}   {\textbar} In some embodiments, the therapy is behavioral therapy. In some embodiments, the therapy comprises administration of a therapeutic substance. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is male. {\textbar}   {\textbar} In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development, said independent suspicion or observation having been made prior to the identifying step. {\textbar}   {\textbar} In some embodiments, the invention provides methods for determining a condition for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least one condition comprises attention deficit hyperactivity disorder ({ADHD}), the method comprising the steps of: {\textbar}   {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to the non-existence of {ADHD}, wherein the non-existence of {ADHD} comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition indicative of atypical development and exclusive of {ADHD}, wherein the at least one other condition does not comprise {ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the invention provides methods of treating a subject for attention deficit hyperactivity disorder, comprising administering to the subject a composition comprising methylphenidate, dextroamphetamine, dextroamphetamine-amphetamine, lisdexamfetamine, atomoxetine, bupropion, desipramine, clonidine, or guanfacine, wherein a blood sample from the subject has previously been identified as having an elevated level of 3-Indoxyl Sulfate (3-{IS}) compared to a reference. {\textbar}   {\textbar} In some embodiments, the elevated level of 3-{IS} is greater than 14 μM. In some embodiments, the elevated level of 3-{IS} is greater than 457 μg/L. In some embodiments, the level of 3-{IS} is measured by mass spectrometry. {\textbar}   {\textbar} In some embodiments, the subject is 5 years old or less. In some embodiments, the subject is 3 years old or less. In some embodiments, the subject is 2 years old or less. {\textbar}   {\textbar} In some embodiments, the invention provides methods of identifying a subject for treatment with a therapy for attention deficit hyperactivity disorder, comprising: {\textbar}   {\textbar} obtaining a blood sample from the subject; {\textbar}   {\textbar} measuring 3-Indoxyl sulfate (3-{IS}) level in the sample by mass spectrometry; and {\textbar}   {\textbar} identifying the sample as having a 3-{IS} level that is higher than a reference level. {\textbar}   {\textbar} In some embodiments, the treatment is a behavioral therapy. In some embodiments, the treatment is selected from the group consisting of methylphenidate, dextroamphetamine, dextroamphetamine-amphetamine, lisdexamfetamine, atomoxetine, bupropion, desipramine, clonidine, guanfacine, and combinations thereof. {\textbar}   {\textbar} In some embodiments, the reference level of 3-{IS} is 14 μM. In some embodiments, the reference level of 3-{IS} is 457 μg/L. {\textbar}   {\textbar} In some embodiments, the 3-{IS} level in the sample is at least 1 fold higher than the reference level. In some embodiments, the 3-{IS} level in the sample is at least 1.5 higher than the reference level. In some embodiments, the 3-{IS} level in the sample is at least 2 fold higher than the reference level. In some embodiments, the 3-{IS} level in the sample is at least 2.5 fold higher than the reference level. In some embodiments, the 3-{IS} level in the subject is at least 3 fold higher than the reference level. In some embodiments, the 3-{IS} level in the sample is at least 4 fold higher than the reference level. {\textbar}   {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWING} {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  shows normalized density levels of 3-Indoxyl sulfate (3-{IS}) in plasma from a group of subjects previously diagnosed as having {ADHD} or not having {ADHD}. {\textbar} {DETAILED} {DESCRIPTION} {\textbar}   {\textbar} Methods and systems are presented herein to distinguish individuals with Attention Deficit Hyperactivity Disorder ({ADHD}) from those without Attention Deficit Hyperactivity Disorder (non-{ADHD}) based at least in part on level of 3-Indoxyl sulfate (3-{IS}) in a biological sample taken from an individual. In certain embodiments, other metabolites, biochemical markers, and/or biophysical markers can also be used when distinguishing {ADHD} from non-{ADHD}. {\textbar}   {\textbar} It is found that determining the level of 3-{IS} in a biological sample (e.g., plasma) is useful in providing an objective method of diagnosing and/or identifying a risk factor for {ADHD} as distinguished from non-{ADHD}. {\textbar}   {\textbar} 3-Indoxyl Sulfate (3-{IS}) {\textbar}   {\textbar} 3-Indoxyl sulfate, also known as Indoxyl sulfate, is a dietary protein metabolite and a metabolite of the common amino acid tryptophan. 3-{IS} is a circulating uremic toxin stimulating glomerular sclerosis and interstitial fibrosis. In plasma, 3-{IS} is a protein-bound uremic solute that induces endothelial dysfunction by inhibiting endothelial proliferation and migration in vitro. Some studies suggest that 3-{IS} is also involved in oxidative stress. In hemodialyzed patients, serum levels of 3-{IS} are associated with levels of pentosidine, a marker of carbonyl and oxidative stress. In vitro, Indoxyl sulfate has been shown to increase reactive oxygen species ({ROS}) production in tubular cells, and increase {NAD}(P)H oxidase activity in endothelial cells. 3-{IS} is also associated with a decrease in levels of the active antioxidant glutathione in cells. {\textbar}   {\textbar} Concentrations of 3-{IS} in the blood of adults has been reported to be on average approximately 2.49 to 14 μM. (See, e.g., Duranton F et al., (2012) J Am Soc Nephrol. July; 23(7):1258-70. Epub 2012 May 24, reporting 2.49+/−1.36 μM in a normal population of 18 years and older males and females; and Geigy Scientific Tables, 8th Rev edition, pp. 165-177. Edited by C. Lentner, West Cadwell, N.J.: Medical education Div., Ciba-Geigy Corp., Basel, Switzerland, reporting 14.0+/−4.2 μM in a normal population of 18 years and older males; the disclosure of each of which pertaining to Indoxyl sulfate incorporated herein by reference). {\textbar}   {\textbar} In a pediatric population, blood levels of normal subjects (i.e., without {ADHD}) have been reported to be approximately 457.5+/−228.5 μg/L (see Umino et al.,  {\textbar}   {\textbar} Pediatrics International {\textbar}  (2010) 52:257-261, incorporated herein by reference in its entirety. {\textbar} In some embodiments a reference blood concentration of 3-{IS} in normal subjects (without {ADHD}) is from about 2.5 μM to about 14.0 μM. In some embodiments a reference blood concentration of 3-{IS} in normal subject is about 2.5 μM. In some embodiments, a reference blood concentration of 3-{IS} in normal subjects is about 14.0 μM. In some embodiments, a reference blood concentration of 3-{IS} in normal subjects (i.e., without {ADHD}) is from about 229 μg/L to about 686 μg/L. In some embodiments, a reference blood concentration of 3-{IS} in normal subjects (i.e., without {ADHD}) is about 457.5 μg/L. {\textbar}   {\textbar} Treatment of Attention Deficit Hyperactivity Disorder ({ADHD}) {\textbar}   {\textbar} Standard treatments for {ADHD} in children include medications, education, training and counseling. Currently, stimulant drugs (psychostimulants) are commonly prescribed medications for {ADHD}. Stimulants appear to boost and balance brain levels of levels of neurotransmitters and help improve the signs and symptoms of inattention and hyperactivity. Examples include methylphenidate ({CONCERTA}, {METADATE}, {RITALIN}), dextroamphetamine ({DEXEDRINE}), dextroamphetamine-amphetamine ({ADDERALL} {XR}) and lisdexamfetamine ({VYVANSE}). Stimulant drugs are available in short-acting and long-acting forms. {\textbar}   {\textbar} Other medications used to treat {ADHD} include atomoxetine ({STRATERRA}) and antidepressants such as bupropion ({WELLBUTRIN}, others) and desipramine ({NORPRAMIN}). Clonidine ({CATAPRES}) and guanfacine ({INTUNIV}, {TENEX}) have also been shown to be effective. Atomoxetine and antidepressants may take several weeks before they take full effect. {\textbar}   {\textbar} Children with {ADHD} often benefit from behavior therapy and counseling, which may be provided by a psychiatrist, psychologist, social worker or other mental health care professional. Some children with {ADHD} may also have other conditions such as anxiety disorder or depression. In these cases, counseling may help both {ADHD} and the coexisting problem. Examples of therapy include: behavioral therapy, psychotherapy, social skills training, and family therapy. {\textbar}   {\textbar} In one aspect, the invention is directed to a method for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the method comprising the steps of: measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; optionally, identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determining, by the processor, at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development, said independent suspicion or observation having been made prior to the identifying step. In some embodiments, the method comprises identifying, by the processor of the computing device, the existence of {ADHD} in the individual as opposed to non-{ADHD}. {\textbar}   {\textbar} In some embodiments, the method comprises identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition. In some embodiments, the method comprises identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. In some embodiments, the sample comprises cerebrospinal fluid. In some embodiments, the sample comprises urine. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). {\textbar}   {\textbar} In some embodiments, the individual is male. {\textbar}   {\textbar} In another aspect, the invention is directed to a system for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the system comprising: a diagnostics kit comprising testing instruments for measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; and a non-transitory computer-readable medium having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to: {\textbar}   {\textbar} optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determine at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the diagnostics kit is an in vitro diagnostics kit. In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development. {\textbar}   {\textbar} In some embodiments, the instructions cause the processor to identify the existence of {ADHD} in the individual as opposed to non-{ADHD} (e.g., distinguish between {ADHD} and non-{ADHD}). In some embodiments, the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. In some embodiments, the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. In some embodiments, the sample comprises cerebrospinal fluid. In some embodiments, the sample comprises urine. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). {\textbar}   {\textbar} In some embodiments, the individual is male. {\textbar}   {\textbar} In another aspect, the invention is directed to a non-transitory computer-readable medium having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to: optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determine at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In another aspect, the invention is directed to a method of treating an individual suspected of having or observed as having atypical development, the method comprising the steps of: obtaining a biological sample from the individual; measuring a level of 3-Indoxyl Sulfate (3-{IS}) in the biological sample; optionally, identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determining the existence of {ADHD} in the individual as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and administering therapy to the individual for {ADHD}. {\textbar}   {\textbar} In some embodiments, the therapy is behavioral therapy. In some embodiments, the therapy comprises administration of a therapeutic substance. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. In some embodiments, the sample comprises cerebrospinal fluid. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). {\textbar}   {\textbar} In some embodiments, the individual is male. {\textbar}   {\textbar} In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development, said independent suspicion or observation having been made prior to the identifying step. {\textbar}   {\textbar} In another aspect, the invention is directed to a method of determining a condition for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least one condition comprises attention deficit hyperactivity disorder ({ADHD}), the method comprising the steps of: measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to the nonexistence of {ADHD}, wherein the non-existence of {ADHD} comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition indicative of atypical development, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} Methods and systems are presented herein to distinguish a child with attention deficit hyperactivity disorder ({ADHD}) from those with non-attention deficit hyperactivity disorder (non-{ADHD}) based at least in part on the measured 3-{IS} level in a biological sample of the child. {\textbar}   {\textbar} {EXAMPLES} {\textbar}   {\textbar} This study used blood samples from subjects in the {SynapDx} Autism Spectrum Disorder Gene Expression Analysis ({STORY}) study. The {STORY} study was performed in accordance with current {ICH} guidelines on Good Clinical Practice ({GCP}), and applicable regulatory requirements. {GCP} is an international ethical and scientific quality standard for designing, conducting, recording, and reporting studies that involve the participation of human subjects. Compliance with this standard provides public assurance that the rights, safety, and wellbeing of study subjects are protected, consistent with the principles that have originated in the Declaration of Helsinki and that the clinical study data are credible. {\textbar}   {\textbar} Results are based on 800 samples from the {STORY} study. The sample set included 30 (24 males/6 females) known samples from subjects diagnosed with {ADHD} out of a total number of 800 samples. Machine learning results, using a subset of metabolites, yielded {AUCs} of 0.60 (matched by age, ethnicity and gender), and 0.73 (all samples). {ADHD} diagnosis can be based on {DSM} diagnostic criteria. Blood was collected in {EDTA} tubes, and plasma was prepared by centrifuging the tubes. The plasma was then frozen and shipped to a laboratory for analysis. At the laboratory, {MeOH} extraction of the samples was conducted, and the extracts were analyzed by an {LC}/{MS} method. An example of this method can be found in Evans A M et al,  {\textbar}   {\textbar} Anal. Chem {\textbar} . (2009) 81(16):6656-6667, the entirety of which is herein incorporated by reference. {\textbar} {FIG}. 1 {\textbar}   {\textbar}  shows the distributions of normalized (to all tested samples) amounts of 3-Indoxyl Sulfate (3-{IS}) in the plasma of children with {ADHD} or of children with non-{ADHD}. The plot shows log transformed values. Twenty-three percent of subjects with known {ADHD} were also co-diagnosed with Autism Spectrum Disorder ({ASD}). Examples of methods and systems for determining risk of {ASD} can be found in {US} Application Numbers filed Sep. 22, 2014 and Ser. No. 14/633,558, filed Feb. 27, 2015, the entireties of each of which are herein incorporated by reference. {\textbar} In view of the structure, functions and apparatus of the systems and methods described here, in some implementations, a systems, methods, and apparatus for distinguishing between or among at least two conditions (e.g., {ADHD} and non-{ADHD}) for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development are provided. Having described certain implementations of methods, systems, and apparatus herein, it will now become apparent to one of skill in the art that other implementations incorporating the concepts of the disclosure may be used. Therefore, the disclosure should not be limited to certain implementations, but rather should be limited only by the spirit and scope of the following claims. {CROSS} {REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar}   {\textbar} This patent application claims the benefit of U.S. Provisional Patent Application No. 62/115,101, filed Feb. 11, 2015, the entirety of which is incorporated herein by reference. {\textbar}   {\textbar} {FIELD} {OF} {THE} {INVENTION} {\textbar}   {\textbar} This invention relates generally to metabolic markers of Attention Deficit Hyperactivity Disorder ({ADHD}) individuals. {\textbar}   {\textbar} {BACKGROUND} {\textbar}   {\textbar} Attention Deficit Hyperactivity Disorder ({ADHD}) is a disorder characterized by inattention and/or difficulty staying focused as well as hyperactivity and/or difficulty in control of one's behavior. {ADHD} typically presents early in life (i.e. during childhood). Presently, diagnosis is typically based upon a combination of self, family and/or teacher/caretaker reports of behaviors combined with observations and input from physicians and other licensed health-care practitioners. {\textbar}   {\textbar} {SUMMARY} {\textbar}   {\textbar} In some embodiments, the invention provides methods for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the method comprising the steps of: {\textbar}   {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development, said independent suspicion or observation having been made prior to the identifying step. {\textbar}   {\textbar} In some embodiments, the methods comprise identifying, by the processor of the computing device, the existence of {ADHD} in the individual as opposed to non-{ADHD}. In some embodiments, the methods comprise identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. In some embodiments, the methods comprise identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. {\textbar}   {\textbar} In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). In some embodiments, the individual is male. {\textbar}   {\textbar} In some embodiments, the invention provides systems for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the system comprising: {\textbar}   {\textbar} a diagnostics kit comprising testing instruments for measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; and {\textbar}   {\textbar} a non-transitory computer-readable medium having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to: {\textbar}   {\textbar} optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determine at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the diagnostics kit is an in vitro diagnostics kit. In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development. {\textbar}   {\textbar} In some embodiments, the instructions cause the processor to identify the existence of {ADHD} in the individual as opposed to non-{ADHD} (e.g., distinguish between {ADHD} and non-{ADHD}). In some embodiments, the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. In some embodiments, the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). In some embodiments, the individual is male. {\textbar}   {\textbar} In some embodiments, the invention provides non-transitory computer-readable media having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to: {\textbar}   {\textbar} optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determine at least one of: {\textbar}   {\textbar} (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and {\textbar}   {\textbar} (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the invention provides methods of treating an individual suspected of having or observed as having atypical development, the method comprising the steps of: {\textbar}   {\textbar} obtaining a biological sample from the individual; {\textbar}   {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in the biological sample; {\textbar}   {\textbar} optionally, identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; {\textbar}   {\textbar} determining the existence of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and {\textbar}   {\textbar} administering therapy to the individual for {ADHD}. {\textbar}   {\textbar} In some embodiments, the therapy is behavioral therapy. In some embodiments, the therapy comprises administration of a therapeutic substance. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is male. {\textbar}   {\textbar} In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development, said independent suspicion or observation having been made prior to the identifying step. {\textbar}   {\textbar} In some embodiments, the invention provides methods for determining a condition for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least one condition comprises attention deficit hyperactivity disorder ({ADHD}), the method comprising the steps of: {\textbar}   {\textbar} measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; {\textbar}   {\textbar} optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and {\textbar}   {\textbar} determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to the non-existence of {ADHD}, wherein the non-existence of {ADHD} comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition indicative of atypical development and exclusive of {ADHD}, wherein the at least one other condition does not comprise {ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the invention provides methods of treating a subject for attention deficit hyperactivity disorder, comprising administering to the subject a composition comprising methylphenidate, dextroamphetamine, dextroamphetamine-amphetamine, lisdexamfetamine, atomoxetine, bupropion, desipramine, clonidine, or guanfacine, wherein a blood sample from the subject has previously been identified as having an elevated level of 3-Indoxyl Sulfate (3-{IS}) compared to a reference. {\textbar}   {\textbar} In some embodiments, the elevated level of 3-{IS} is greater than 14 μM. In some embodiments, the elevated level of 3-{IS} is greater than 457 μg/L. In some embodiments, the level of 3-{IS} is measured by mass spectrometry. {\textbar}   {\textbar} In some embodiments, the subject is 5 years old or less. In some embodiments, the subject is 3 years old or less. In some embodiments, the subject is 2 years old or less. {\textbar}   {\textbar} In some embodiments, the invention provides methods of identifying a subject for treatment with a therapy for attention deficit hyperactivity disorder, comprising: {\textbar}   {\textbar} obtaining a blood sample from the subject; {\textbar}   {\textbar} measuring 3-Indoxyl sulfate (3-{IS}) level in the sample by mass spectrometry; and {\textbar}   {\textbar} identifying the sample as having a 3-{IS} level that is higher than a reference level. {\textbar}   {\textbar} In some embodiments, the treatment is a behavioral therapy. In some embodiments, the treatment is selected from the group consisting of methylphenidate, dextroamphetamine, dextroamphetamine-amphetamine, lisdexamfetamine, atomoxetine, bupropion, desipramine, clonidine, guanfacine, and combinations thereof. {\textbar}   {\textbar} In some embodiments, the reference level of 3-{IS} is 14 μM. In some embodiments, the reference level of 3-{IS} is 457 μg/L. {\textbar}   {\textbar} In some embodiments, the 3-{IS} level in the sample is at least 1 fold higher than the reference level. In some embodiments, the 3-{IS} level in the sample is at least 1.5 higher than the reference level. In some embodiments, the 3-{IS} level in the sample is at least 2 fold higher than the reference level. In some embodiments, the 3-{IS} level in the sample is at least 2.5 fold higher than the reference level. In some embodiments, the 3-{IS} level in the subject is at least 3 fold higher than the reference level. In some embodiments, the 3-{IS} level in the sample is at least 4 fold higher than the reference level. {\textbar}   {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWING} {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  shows normalized density levels of 3-Indoxyl sulfate (3-{IS}) in plasma from a group of subjects previously diagnosed as having {ADHD} or not having {ADHD}. {\textbar} {DETAILED} {DESCRIPTION} {\textbar}   {\textbar} Methods and systems are presented herein to distinguish individuals with Attention Deficit Hyperactivity Disorder ({ADHD}) from those without Attention Deficit Hyperactivity Disorder (non-{ADHD}) based at least in part on level of 3-Indoxyl sulfate (3-{IS}) in a biological sample taken from an individual. In certain embodiments, other metabolites, biochemical markers, and/or biophysical markers can also be used when distinguishing {ADHD} from non-{ADHD}. {\textbar}   {\textbar} It is found that determining the level of 3-{IS} in a biological sample (e.g., plasma) is useful in providing an objective method of diagnosing and/or identifying a risk factor for {ADHD} as distinguished from non-{ADHD}. {\textbar}   {\textbar} 3-Indoxyl Sulfate (3-{IS}) {\textbar}   {\textbar} 3-Indoxyl sulfate, also known as Indoxyl sulfate, is a dietary protein metabolite and a metabolite of the common amino acid tryptophan. 3-{IS} is a circulating uremic toxin stimulating glomerular sclerosis and interstitial fibrosis. In plasma, 3-{IS} is a protein-bound uremic solute that induces endothelial dysfunction by inhibiting endothelial proliferation and migration in vitro. Some studies suggest that 3-{IS} is also involved in oxidative stress. In hemodialyzed patients, serum levels of 3-{IS} are associated with levels of pentosidine, a marker of carbonyl and oxidative stress. In vitro, Indoxyl sulfate has been shown to increase reactive oxygen species ({ROS}) production in tubular cells, and increase {NAD}(P)H oxidase activity in endothelial cells. 3-{IS} is also associated with a decrease in levels of the active antioxidant glutathione in cells. {\textbar}   {\textbar} Concentrations of 3-{IS} in the blood of adults has been reported to be on average approximately 2.49 to 14 μM. (See, e.g., Duranton F et al., (2012) J Am Soc Nephrol. July; 23(7):1258-70. Epub 2012 May 24, reporting 2.49+/−1.36 μM in a normal population of 18 years and older males and females; and Geigy Scientific Tables, 8th Rev edition, pp. 165-177. Edited by C. Lentner, West Cadwell, N.J.: Medical education Div., Ciba-Geigy Corp., Basel, Switzerland, reporting 14.0+/−4.2 μM in a normal population of 18 years and older males; the disclosure of each of which pertaining to Indoxyl sulfate incorporated herein by reference). {\textbar}   {\textbar} In a pediatric population, blood levels of normal subjects (i.e., without {ADHD}) have been reported to be approximately 457.5+/−228.5 μg/L (see Umino et al.,  {\textbar}   {\textbar} Pediatrics International {\textbar}  (2010) 52:257-261, incorporated herein by reference in its entirety. {\textbar} In some embodiments a reference blood concentration of 3-{IS} in normal subjects (without {ADHD}) is from about 2.5 μM to about 14.0 μM. In some embodiments a reference blood concentration of 3-{IS} in normal subject is about 2.5 μM. In some embodiments, a reference blood concentration of 3-{IS} in normal subjects is about 14.0 μM. In some embodiments, a reference blood concentration of 3-{IS} in normal subjects (i.e., without {ADHD}) is from about 229 μg/L to about 686 μg/L. In some embodiments, a reference blood concentration of 3-{IS} in normal subjects (i.e., without {ADHD}) is about 457.5 μg/L. {\textbar}   {\textbar} Treatment of Attention Deficit Hyperactivity Disorder ({ADHD}) {\textbar}   {\textbar} Standard treatments for {ADHD} in children include medications, education, training and counseling. Currently, stimulant drugs (psychostimulants) are commonly prescribed medications for {ADHD}. Stimulants appear to boost and balance brain levels of levels of neurotransmitters and help improve the signs and symptoms of inattention and hyperactivity. Examples include methylphenidate ({CONCERTA}, {METADATE}, {RITALIN}), dextroamphetamine ({DEXEDRINE}), dextroamphetamine-amphetamine ({ADDERALL} {XR}) and lisdexamfetamine ({VYVANSE}). Stimulant drugs are available in short-acting and long-acting forms. {\textbar}   {\textbar} Other medications used to treat {ADHD} include atomoxetine ({STRATERRA}) and antidepressants such as bupropion ({WELLBUTRIN}, others) and desipramine ({NORPRAMIN}). Clonidine ({CATAPRES}) and guanfacine ({INTUNIV}, {TENEX}) have also been shown to be effective. Atomoxetine and antidepressants may take several weeks before they take full effect. {\textbar}   {\textbar} Children with {ADHD} often benefit from behavior therapy and counseling, which may be provided by a psychiatrist, psychologist, social worker or other mental health care professional. Some children with {ADHD} may also have other conditions such as anxiety disorder or depression. In these cases, counseling may help both {ADHD} and the coexisting problem. Examples of therapy include: behavioral therapy, psychotherapy, social skills training, and family therapy. {\textbar}   {\textbar} In one aspect, the invention is directed to a method for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the method comprising the steps of: measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; optionally, identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determining, by the processor, at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development, said independent suspicion or observation having been made prior to the identifying step. In some embodiments, the method comprises identifying, by the processor of the computing device, the existence of {ADHD} in the individual as opposed to non-{ADHD}. {\textbar}   {\textbar} In some embodiments, the method comprises identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition. In some embodiments, the method comprises identifying, by the processor of the computing device, a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. In some embodiments, the sample comprises cerebrospinal fluid. In some embodiments, the sample comprises urine. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). {\textbar}   {\textbar} In some embodiments, the individual is male. {\textbar}   {\textbar} In another aspect, the invention is directed to a system for distinguishing between or among at least two conditions for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least two conditions comprise attention deficit hyperactivity disorder ({ADHD}) and non-attention deficit hyperactivity disorder (non-{ADHD}), the system comprising: a diagnostics kit comprising testing instruments for measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; and a non-transitory computer-readable medium having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to: {\textbar}   {\textbar} optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determine at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In some embodiments, the diagnostics kit is an in vitro diagnostics kit. In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development. {\textbar}   {\textbar} In some embodiments, the instructions cause the processor to identify the existence of {ADHD} in the individual as opposed to non-{ADHD} (e.g., distinguish between {ADHD} and non-{ADHD}). In some embodiments, the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}. In some embodiments, the instructions cause the processor to identify a risk score quantifying the likelihood the individual has {ADHD} as opposed to non-{ADHD}. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. In some embodiments, the sample comprises cerebrospinal fluid. In some embodiments, the sample comprises urine. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). {\textbar}   {\textbar} In some embodiments, the individual is male. {\textbar}   {\textbar} In another aspect, the invention is directed to a non-transitory computer-readable medium having instructions stored thereon, wherein the instructions, when executed by a processor, cause the processor to: optionally, identify a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determine at least one of: (i) the existence (or non-existence) of {ADHD} in the individual as opposed to at least one other condition exclusive of {ADHD}, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has (or does not have) {ADHD} as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}, based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} In another aspect, the invention is directed to a method of treating an individual suspected of having or observed as having atypical development, the method comprising the steps of: obtaining a biological sample from the individual; measuring a level of 3-Indoxyl Sulfate (3-{IS}) in the biological sample; optionally, identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determining the existence of {ADHD} in the individual as opposed to at least one other condition, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and administering therapy to the individual for {ADHD}. {\textbar}   {\textbar} In some embodiments, the therapy is behavioral therapy. In some embodiments, the therapy comprises administration of a therapeutic substance. {\textbar}   {\textbar} In some embodiments, the sample is a blood sample. In some embodiments, the sample comprises plasma. In some embodiments, the sample comprises white blood cells. In some embodiments, the sample comprises cerebrospinal fluid. {\textbar}   {\textbar} In some embodiments, the individual has been identified by a medical practitioner as displaying atypical behavior prior to the identifying step. In some embodiments, the individual is five years old or less (e.g., three years old or less, 24 months old or less, or 20 months old or less). {\textbar}   {\textbar} In some embodiments, the individual is male. {\textbar}   {\textbar} In some embodiments, the individual is independently suspected of having (e.g., by a medical practitioner) or is independently observed to have (e.g., by a medical practitioner) atypical development, said independent suspicion or observation having been made prior to the identifying step. {\textbar}   {\textbar} In another aspect, the invention is directed to a method of determining a condition for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development, wherein the at least one condition comprises attention deficit hyperactivity disorder ({ADHD}), the method comprising the steps of: measuring a level of 3-Indoxyl Sulfate (3-{IS}) in a biological sample obtained from the individual; optionally identifying, by a processor of a computing device, a difference (e.g., an absolute difference or a relative difference) between (or ratio of) the measured 3-{IS} level and a predetermined control level; and determining, by the processor, at least one of: (i) the existence of {ADHD} in the individual as opposed to the nonexistence of {ADHD}, wherein the non-existence of {ADHD} comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level (e.g., distinguishing between {ADHD} and non-{ADHD} in the individual based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level); and (ii) a likelihood the individual has {ADHD} as opposed to at least one other condition indicative of atypical development, wherein the at least one other condition comprises non-{ADHD}, said identifying based at least in part on the measured 3-{IS} level and/or the difference between the measured 3-{IS} level and the predetermined control level. {\textbar}   {\textbar} Methods and systems are presented herein to distinguish a child with attention deficit hyperactivity disorder ({ADHD}) from those with non-attention deficit hyperactivity disorder (non-{ADHD}) based at least in part on the measured 3-{IS} level in a biological sample of the child. {\textbar}   {\textbar} {EXAMPLES} {\textbar}   {\textbar} This study used blood samples from subjects in the {SynapDx} Autism Spectrum Disorder Gene Expression Analysis ({STORY}) study. The {STORY} study was performed in accordance with current {ICH} guidelines on Good Clinical Practice ({GCP}), and applicable regulatory requirements. {GCP} is an international ethical and scientific quality standard for designing, conducting, recording, and reporting studies that involve the participation of human subjects. Compliance with this standard provides public assurance that the rights, safety, and wellbeing of study subjects are protected, consistent with the principles that have originated in the Declaration of Helsinki and that the clinical study data are credible. {\textbar}   {\textbar} Results are based on 800 samples from the {STORY} study. The sample set included 30 (24 males/6 females) known samples from subjects diagnosed with {ADHD} out of a total number of 800 samples. Machine learning results, using a subset of metabolites, yielded {AUCs} of 0.60 (matched by age, ethnicity and gender), and 0.73 (all samples). {ADHD} diagnosis can be based on {DSM} diagnostic criteria. Blood was collected in {EDTA} tubes, and plasma was prepared by centrifuging the tubes. The plasma was then frozen and shipped to a laboratory for analysis. At the laboratory, {MeOH} extraction of the samples was conducted, and the extracts were analyzed by an {LC}/{MS} method. An example of this method can be found in Evans A M et al,  {\textbar}   {\textbar} Anal. Chem {\textbar} . (2009) 81(16):6656-6667, the entirety of which is herein incorporated by reference. {\textbar} {FIG}. 1 {\textbar}   {\textbar}  shows the distributions of normalized (to all tested samples) amounts of 3-Indoxyl Sulfate (3-{IS}) in the plasma of children with {ADHD} or of children with non-{ADHD}. The plot shows log transformed values. Twenty-three percent of subjects with known {ADHD} were also co-diagnosed with Autism Spectrum Disorder ({ASD}). Examples of methods and systems for determining risk of {ASD} can be found in {US} Application Numbers filed Sep. 22, 2014 and Ser. No. 14/633,558, filed Feb. 27, 2015, the entireties of each of which are herein incorporated by reference. {\textbar} In view of the structure, functions and apparatus of the systems and methods described here, in some implementations, a systems, methods, and apparatus for distinguishing between or among at least two conditions (e.g., {ADHD} and non-{ADHD}) for diagnosis and/or risk assessment of an individual suspected of having or observed as having atypical development are provided. Having described certain implementations of methods, systems, and apparatus herein, it will now become apparent to one of skill in the art that other implementations incorporating the concepts of the disclosure may be used. Therefore, the disclosure should not be limited to certain implementations, but rather should be limited only by the spirit and scope of the following claims.},
}

@patent{siekmeier_etal22b,
	location = {{US}},
	title = {Method of increasing cognitive function with glutamate receptor agonist},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {In some embodiments, a method of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject is provided. Treating a subject with an glutamate receptor agonist can include identifying the subject as an glutamate receptor agonist responder. The method can further include obtaining an electroencephalogram ({EEG}) signals from the subject. The method can further include measuring one or more {EEG} metrics, thereby identifying the subject as a glutamate receptor agonist. Further provided non-transitory processor-readable medium storing code with instructions for identify glutamate receptor agonist responders
In some embodiments, a method of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject is provided. Treating a subject with an glutamate receptor agonist can include identifying the subject as an glutamate receptor agonist responder. The method can further include obtaining an electroencephalogram ({EEG}) signals from the subject. The method can further include measuring one or more {EEG} metrics, thereby identifying the subject as a glutamate receptor agonist. Further provided non-transitory processor-readable medium storing code with instructions for identify glutamate receptor agonist responders
In some embodiments, a method of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject is provided. Treating a subject with an glutamate receptor agonist can include identifying the subject as an glutamate receptor agonist responder. The method can further include obtaining an electroencephalogram ({EEG}) signals from the subject. The method can further include measuring one or more {EEG} metrics, thereby identifying the subject as a glutamate receptor agonist. Further provided non-transitory processor-readable medium storing code with instructions for identify glutamate receptor agonist responders},
	type = {patent},
	author = {Siekmeier, Peter J. and Lowen, Steven B. and Coyle, Joseph T.},
	urldate = {2022-03-03},
	date = {2022-10-06},
	note = {Edition: A61B000500 {\textbar} A61B0005372 {\textbar} A61N000136 {\textbar} A61N0001372 {\textbar} G16H005020 {CPC} - A61N000137247 {\textbar} A61B0005372 {\textbar} A61B00057264 {\textbar} A61B00057267 {\textbar} A61B00057282 {\textbar} A61N000136 {\textbar} A61N000136082 {\textbar} A61N000137282 {\textbar} G16H002010 {\textbar} G16H005020 {EP}; {US} {US} What is claimed is: {\textbar} {\textbar} 1 {\textbar} . A method of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject, comprising administering an effective amount of a glutamate receptor agonist. {\textbar} 2 {\textbar} . The method of {\textbar} claim 1 {\textbar} , wherein the cognitive function is selected from the group consisting of working memory, reasoning/problem solving, and attention/vigilance. {\textbar} 3 {\textbar} . The method of {\textbar} claim 1 {\textbar} or {\textbar} claim 2 {\textbar} , wherein the subject is a human. {\textbar} 4 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 3 {\textbar} , wherein the subject is a healthy subject. {\textbar} 5 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 3 {\textbar} , wherein the subject suffers from or is at risk for a disease or disorder associated with decreased cognitive function. {\textbar} 6 {\textbar} . The method of {\textbar} claim 5 {\textbar} , wherein the disease or disorder associated with decreased cognitive function is selected from the group consisting of dementia, Alzheimer's disease, {MAJOR} depression, bipolar depression, post-traumatic stress disorder ({PTSD}), panic disorder, generalized anxiety disorder ({GAD}), attention-deficit hyperactivity disorder ({ADHD}), Parkinson's disease, schizophrenia, an autism spectrum disorder ({ASD}), obsessive compulsive disorder ({OCD}) or intellectual disability. {\textbar} 7 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 6 {\textbar} , wherein the glutamate receptor agonist is a group {II} metabotropic glutamate receptor ({mGluR}2/3) agonist. {\textbar} 8 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 7 {\textbar} , wherein the glutamate receptor agonist is pomaglumetad or a pharmaceutically acceptable salt thereof. {\textbar} 9 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 7 {\textbar} , wherein the glutamate receptor agonist is pomaglumetad methionil or a pharmaceutically acceptable salt thereof {\textbar} 10 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 9 {\textbar} , wherein the effective amount of the glutamate receptor agonist is between about 10 mg and 120 mg. {\textbar} 11 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 9 {\textbar} , wherein the effective amount of the glutamate receptor agonist is between about 20 mg and 80 mg. {\textbar} 12 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 11 {\textbar} , wherein the effective amount of the glutamate receptor agonist is administered twice daily ({BID}). {\textbar} 13 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 11 {\textbar} , wherein the effective amount of the glutamate receptor agonist is administered once daily ({QD}). {\textbar} 14 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 13 {\textbar} , further comprising identifying the subject as a glutamate receptor agonist responder by: {\textbar} obtaining or having obtained electroencephalogram ({EEG}) signals from the subject, and {\textbar} {\textbar} measuring or having measuring one or more {EEG} metrics, thereby identifying the subject as glutamate receptor agonist; and {\textbar} {\textbar} if the subject is a glutamate receptor agonist responder, then administering the glutamate receptor agonist. {\textbar} {\textbar} 15 {\textbar} . The method of {\textbar} claim 14 {\textbar} , wherein the measuring is performed pre-treatment. {\textbar} 16 {\textbar} . The method of any one of {\textbar} claims 14 {\textbar} - {\textbar} 15 {\textbar} , wherein the one or more {EEG} metrics comprise one or more electrophysiological behaviors at one or more brain locations. {\textbar} 17 {\textbar} . The method of any one of {\textbar} claims 14 {\textbar} - {\textbar} 16 {\textbar} , wherein the one or more {EEG} metrics comprise one or more electrophysiological behaviors at one or more brain locations under sensory stimulation of the subject. {\textbar} 18 {\textbar} . The method of {\textbar} claim 17 {\textbar} , wherein the sensory stimulation is a photic stimulation, an electrical stimulation, a magnetic stimulation, haptic stimulation, or an acoustic stimulation. {\textbar} 19 {\textbar} . The method of {\textbar} claim 17 {\textbar} or {\textbar} claim 18 {\textbar} , wherein the electrophysiological behavior under sensory stimulation is selected from: {\textbar} Predetermined {\textbar} {\textbar} Brain Location {\textbar} {\textbar} {EEG} Metric {\textbar} Frequency {\textbar} center frontal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} left temporal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} right central {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} center parietal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} right parietal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} right rear temporal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} left occipital {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} right occipital {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} left temporal {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform {\textbar} {\textbar} left rear temporal {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform {\textbar} {\textbar} left parietal {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform {\textbar} {\textbar} center parietal {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform {\textbar} {\textbar} left occipital {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform. {\textbar} {\textbar} 20 {\textbar} {\textbar} . The method of any one of {\textbar} claims 14 {\textbar} - {\textbar} 16 {\textbar} , wherein the one or more {EEG} metrics comprise one or more electrophysiological behaviors in resting state at one or more brain locations, the electrophysiological behavior at the brain location selected from: {\textbar} Predetermined {\textbar} {\textbar} Brain Location {\textbar} {\textbar} {EEG} Metric {\textbar} Frequency {\textbar} left frontal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} center frontal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} right frontal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} left central {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} right frontal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} left temporal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} right parietal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} right rear temporal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} left temporal {\textbar} {\textbar} Frequency domain {\textbar} beta (22 Hz) {\textbar} transform {\textbar} {\textbar} right central {\textbar} {\textbar} Frequency domain {\textbar} beta (16-25 Hz) {\textbar} transform. {\textbar} {\textbar} 21 {\textbar} {\textbar} . The method of any one of {\textbar} claims 14 {\textbar} - {\textbar} 20 {\textbar} , wherein each clinical treatment outcome from the plurality of clinical treatment outcomes is classified as responsive and non-responsive based on a threshold value or a receiver operating characteristic ({ROC}) curve. {\textbar} 22 {\textbar} . The method of any one of {\textbar} claims 14 {\textbar} - {\textbar} 21 {\textbar} , wherein the identifying step is performed by a non-transitory processor-readable medium storing code representing instructions to be executed by a processor, the code comprising code to cause the processor to: {\textbar} receive the {EEG} signals recorded from the one or more brain locations of the subject; {\textbar} {\textbar} transform the {EEG} signals into the one or more {EEG} metrics; and {\textbar} {\textbar} execute a model configured to receive the {EEG} metrics and identify the subject as a glutamate receptor agonist responder. {\textbar} {\textbar} 23 {\textbar} . The method of {\textbar} claim 22 {\textbar} , wherein the model is a machine learning model, the non-transitory processor-readable medium further comprising code to: {\textbar} train the machine learning model based on a training set including a plurality of {EEG} metrics and a plurality of clinical treatment outcomes associated with the plurality of {EEG} metrics. {\textbar} {\textbar} 24 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 23 {\textbar} , wherein the glutamate receptor agonist increases working memory performance. {\textbar} 25 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 23 {\textbar} , wherein the glutamate receptor agonist increases attention-vigilance. {\textbar} 26 {\textbar} . The method of any one of {\textbar} claims 1 {\textbar} - {\textbar} 23 {\textbar} , wherein the glutamate receptor agonist increases reasoning-problem solving. {\textbar} 27 {\textbar} . A non-transitory processor-readable medium storing code representing instructions to be executed by a processor, the code comprising code to cause the processor to: {\textbar} receive electroencephalogram ({EEG}) signals recorded from one or more brain locations of the subject; {\textbar} {\textbar} transform the {EEG} signals into one or more {EEG} metrics; and {\textbar} {\textbar} execute a model configured to receive the one or more {EEG} metrics and identify the subject as a glutamate receptor agonist responder based on the one or more {EEG} metrics. {\textbar} {\textbar} 28 {\textbar} . The non-transitory processor-readable medium of {\textbar} claim 27 {\textbar} , wherein when administered a glutamate receptor agonist the glutamate receptor agonist increases cognitive function {\textbar} 29 {\textbar} . The non-transitory processor-readable medium of {\textbar} claim 28 {\textbar} , wherein the cognitive function is selected from the group consisting of working memory, reasoning/problem solving, and attention/vigilance. {\textbar} 30 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 29 {\textbar} , wherein the subject is a human. {\textbar} 31 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 30 {\textbar} , wherein the subject is a healthy subject. {\textbar} 31 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 30 {\textbar} , wherein the subject suffers from or is at risk for a disease or disorder associated with decreased cognitive function. {\textbar} 32 {\textbar} . The non-transitory processor-readable medium of {\textbar} claim 31 {\textbar} , wherein the disease or disorder associated with decreased cognitive function is selected from the group consisting of the disease or disorder associated with decreased cognitive function is dementia, Alzheimer's disease, {MAJOR} depression, bipolar depression, post-traumatic stress disorder ({PTSD}), panic disorder, generalized anxiety disorder ({GAD}), attention-deficit hyperactivity disorder ({ADHD}), Parkinson's disease, schizophrenia, an autism spectrum disorder ({ASD}), obsessive compulsive disorder ({OCD}), or intellectual disability. {\textbar} 33 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 32 {\textbar} , wherein the glutamate receptor agonist is a group {II} metabotropic glutamate receptor ({mGluR}2/3) agonist. {\textbar} 34 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 33 {\textbar} , wherein the glutamate receptor agonist is pomaglumetad or a pharmaceutically acceptable salt thereof. {\textbar} 35 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 33 {\textbar} , wherein the glutamate receptor agonist is pomaglumetad methionil or a pharmaceutically acceptable salt thereof. {\textbar} 36 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 35 {\textbar} , wherein an {EEG} associated with the {EEG} signals is recorded pre-treatment. {\textbar} 37 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 36 {\textbar} , wherein the one or more {EEG} metrics include a power law exponent. {\textbar} 38 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 37 {\textbar} , further comprising code to: {\textbar} record the {EEG} signals from the subject. {\textbar} {\textbar} 39 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 38 {\textbar} , further comprising code to: {\textbar} remove, before the {EEG} signals are transformed, measurement artifacts from the {EEG} signals, the measurement artifacts including periods in which the subject moves and periods in which the subject blink eyes; and {\textbar} {\textbar} perform, before the {EEG} signals are transformed, independent component analysis ({ICA}) to decompose and denoise the {EGG} signals. {\textbar} {\textbar} 39 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 38 {\textbar} , wherein recording the {EEG} signals is at resting state. {\textbar} 40 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 38 {\textbar} , wherein recording the {EEG} signals is when exposed to sensory stimulation. {\textbar} 41 {\textbar} . The non-transitory processor-readable medium of {\textbar} claim 40 {\textbar} , wherein the stimulation is a photic stimulation. {\textbar} 42 {\textbar} . The non-transitory processor-readable medium of {\textbar} claim 41 {\textbar} , wherein the stimulation is an electrical stimulation, a magnetic stimulation, a haptic stimulation, or an acoustic stimulation. {\textbar} 43 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 42 {\textbar} , wherein the model is a machine learning model, the non-transitory processor-readable medium further comprising code to: {\textbar} train the machine learning model based on a training set including a plurality of {EEG} metrics and a plurality of clinical treatment outcomes associated with the plurality of {EEG} metrics, the plurality of {EEG} metrics including the one or more {EEG} metrics. {\textbar} {\textbar} 44 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 43 {\textbar} , wherein each clinical treatment outcome from the plurality of clinical treatment outcomes is classified as responsive and non-responsive based on a threshold value or a receiver operating characteristic ({ROC}) curve. {\textbar} 45 {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 44 {\textbar} wherein, the electrophysiological behavior under sensory stimulation is selected from: {\textbar} Predetermined {\textbar} {\textbar} Brain Location {\textbar} {\textbar} {EEG} Metric {\textbar} Frequency {\textbar} center frontal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} left temporal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} right central {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} center parietal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} right parietal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} right rear temporal {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} left occipital {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} right occipital {\textbar} {\textbar} Frequency domain {\textbar} low gamma (30 Hz) {\textbar} transform {\textbar} {\textbar} left temporal {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform {\textbar} {\textbar} left rear temporal {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform {\textbar} {\textbar} left parietal {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform {\textbar} {\textbar} center parietal {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform {\textbar} {\textbar} left occipital {\textbar} {\textbar} Frequency domain {\textbar} low beta (15 Hz) {\textbar} transform. {\textbar} {\textbar} 46 {\textbar} {\textbar} . The non-transitory processor-readable medium of any one of {\textbar} claims 27 {\textbar} - {\textbar} 45 {\textbar} , wherein the one or more {EEG} metrics comprise one or more electrophysiological behaviors in resting state at one or more brain locations, the electrophysiological behavior at the brain location selected from: {\textbar} Predetermined {\textbar} {\textbar} Brain Location {\textbar} {\textbar} {EEG} Metric {\textbar} Frequency {\textbar} left frontal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} center frontal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} right frontal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} left central {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} right frontal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} left temporal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} right parietal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} right rear temporal {\textbar} {\textbar} power law exponent {\textbar} — {\textbar} left temporal {\textbar} {\textbar} Frequency domain {\textbar} beta (22 Hz) {\textbar} transform {\textbar} {\textbar} right central {\textbar} {\textbar} Frequency domain {\textbar} beta (16-25 Hz) {\textbar} transform. {\textbar} {\textbar} 1 {\textbar} . A method of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject, comprising administering an effective amount of a glutamate receptor agonist. 1 {\textbar} . A method of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject, comprising administering an effective amount of a glutamate receptor agonist. {CROSS}-{REFERENCES} {TO} {RELATED} {APPLICATIONS} {\textbar} {\textbar} This application is based on, claims priority to U.S. Provisional Application Ser. No. 62/895,081, filed Sept. 3, 2019, and entitled “{EEG} Biomarkers,” the disclosure of which is incorporated by reference herein in its entirety. {\textbar} {\textbar} {TECHNICAL} {FIELD} {\textbar} {\textbar} The present disclosure relates to the field of treatment for cogitative function {\textbar} {\textbar} {BACKGROUND} {\textbar} {\textbar} There is a need in the art for treatments that increase cognitive function, including working memory, reasoning/problem solving, and attention/vigilance. {\textbar} {\textbar} {SUMMARY} {\textbar} {\textbar} Pre-treatment analysis of electroencephalogram ({EEG}) data of subjects subsequently administered a glutamate receptor agonist indicates that treatment with a glutamate receptor agonist increases cognitive function in human subjects. Moreover, analysis of {EEG} data identifies subsets of subjects in which glutamate receptor agonist has an especially strong effect on cognitive function. {\textbar} {\textbar} Accordingly, provided herein is, in various embodiments, a method of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject, comprising administering an effective amount of a glutamate receptor agonist. The subject may be a healthy subject or may suffer from or be at risk for a mental disorder. {\textbar} {\textbar} Further provided are, in various embodiments, a non-transitory processor-readable medium storing code representing instructions to be executed by a processor, the code comprising code to cause the processor to receive electroencephalogram ({EEG}) signals recorded from one or more brain locations of the subject; transform the {EEG} signals into one or more {EEG} metrics; and execute a model configured to receive the one or more {EEG} metrics and identify the subject as a glutamate receptor agonist responder based on the one or more {EEG} metrics. {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a schematic description of a treatment-response prediction device, according to an embodiment. {\textbar} {FIG}. 2 {\textbar} {\textbar} is a flowchart illustrating a method of treatment-response prediction, according to an embodiment. {\textbar} {FIG}. 3 {\textbar} {\textbar} is a flowchart illustrating a method of treatment-response prediction, according to an embodiment. {\textbar} {FIG}. 4 {\textbar} {\textbar} shows a montage for {EEG} recording. {\textbar} {FIG}. 5 {\textbar} {\textbar} illustrates determining the power law exponent ({PLE}) of an {EEG} signal. {\textbar} {FIG}. 6 {\textbar} {\textbar} shows a correlation between pre-treatment low-gamma (30 Hz) activity and treatment response based on {MCCB} attention-vigilance domain score. Subjects received photic stimulation at 30 Hz. Coloring indicates correlation coefficient, r, with scale shown at right. Selected r and p values shown in Table 1A. {\textbar} {FIG}. 7 {\textbar} {\textbar} shows a correlation between pre-treatment low-beta (15 Hz) activity and treatment response based on {MCCB} reasoning-problems solving domain score. Subjects received photic stimulation at 15 Hz. Coloring indicates correlation coefficient, r, with scale shown at right. Selected r and p values shown in Table 1A. {\textbar} {FIG}. 8 {\textbar} {\textbar} shows a correlation between pre-treatment power law exponent and treatment response based on {MCCB} working memory domain score. {EEG} readings were taken in resting state. Coloring indicates correlation coefficient, r, with scale shown at right. Selected r values and significance shown in Table 1B. {\textbar} {FIG}. 9 {\textbar} {\textbar} shows a receiver operator curve ({ROC}) for effect shown in {\textbar} {FIG}. 8 {\textbar} , at {EEG} lead C3. Sensitivity=0.750, specificity=0.897 (area under the curve [{AUC}]=0.809, p=0.039). {\textbar} {DETAILED} {DESCRIPTION} {\textbar} {\textbar} Non-limiting examples of various aspects and variations of the embodiments are described herein and illustrated in the accompanying drawings. {\textbar} {\textbar} In one aspect, the disclosure provides methods of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject, comprising administering an effective amount of a glutamate receptor agonist. {\textbar} {\textbar} The method may include identifying the subject as a glutamate receptor agonist responder by obtaining or having obtained electroencephalogram ({EEG}) signals from the subject. They include measuring or having measuring one or more {EEG} metrics, thereby identifying the subject as a glutamate receptor agonist responder, and if the subject is a glutamate receptor agonist responder, then administering the glutamate receptor agonist. {\textbar} {\textbar} In another aspect, one or more embodiments described herein generally relate to apparatus, methods, and systems for dynamically processing structured and semi-structured data, and in particular, apparatus, methods, and systems that use a model (e.g. a neural network model) to efficiently and reliably predict an outcome based on the structured and semi-structured-data. Apparatus, methods and systems of treatment-response prediction are disclosed. In some embodiments, treatment-response can be used to process, for example, {EEG} signals in form of time series, stationary data, non-stationary-data, linear data, non-linear data, and/or the like. {\textbar} {\textbar} Described herein are treatment-response prediction apparatuses and methods that predict treatment response based on {EEG} signals collected from a subject. By enabling identification of a subject as an glutamate receptor agonist responder, prior to treatment, the methods described herein may avoid unnecessary adverse events and side effects of treatment. Moreover, the methods described herein may increase the response rate to the glutamate receptor agonist. In particular embodiments, the methods described herein enable safe and effective use of the pomaglumetad, pomaglumetad methionil or a pharmaceutically acceptable salt thereof in the treatment of psychiatric disorders (e.g., psychotic disorders). In some embodiments, individual {EEG} metrics predictive of glutamate receptor agonist responder status are disclosed. In some embodiments, responder prediction is improved by training a machine-learning model on multiple {EEG} metrics. {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a schematic description of a treatment-response prediction device {\textbar} 110 {\textbar} , according to an embodiment. The treatment-response prediction device {\textbar} 110 {\textbar} can identify a subject as an glutamate receptor agonist responder, prior to treatment. The treatment-response prediction device {\textbar} 110 {\textbar} can be also configured to execute a model (e.g., an artificial intelligence model) that predicts a treatment response based on {EEG} signals collected for a subject. The set of {EEG} signals are analyzed by the treatment-response prediction device {\textbar} 110 {\textbar} to generate {EEG} metrics. The treatment-response prediction device {\textbar} 110 {\textbar} can optionally be coupled to a server compute device {\textbar} 160 {\textbar} , a clinician programmer device {\textbar} 170 {\textbar} , and/or a subject compute device {\textbar} 180 {\textbar} via a network {\textbar} 150 {\textbar} . The treatment-response prediction device {\textbar} 110 {\textbar} , clinician programmer device {\textbar} 170 {\textbar} , and/or a subject compute device {\textbar} 180 {\textbar} each can be a hardware-based computing device and/or a multimedia device, such as, for example, a computer, a desktop, a laptop, a smartphone, a tablet, a wearable device, and/or the like. {\textbar} The treatment-response prediction device {\textbar} {\textbar} 110 {\textbar} includes a memory {\textbar} 111 {\textbar} , a communication interface {\textbar} 112 {\textbar} , and a processor {\textbar} 113 {\textbar} . The treatment-response prediction device {\textbar} 110 {\textbar} can receive data including {EEG} signals from an {EEG} machine (not shown) that records activities of a subject's brain. In some instances, the activities of the subject's brain can be/include electrical activities and the activities can be recorded as {EEG} signals by a set of electrodes connected to the {EEG} machine that may be operatively coupled to the treatment-response prediction device {\textbar} 110 {\textbar} . The {EEG} machine can transmit the set of {EEG} signals to the treatment-response prediction device {\textbar} 110 {\textbar} . The {EEG} signals can be recorded in the memory {\textbar} 111 {\textbar} and analyzed by the processor {\textbar} 113 {\textbar} for treating a subject with a glutamate receptor agonist. {\textbar} The network {\textbar} {\textbar} 150 {\textbar} can be a digital telecommunication network of servers and/or compute devices. The servers and/or compute device on the network can be connected via one or more wired or wireless communication networks (not shown) to share resources such as, for example, data storage and/or computing power. The wired or wireless communication networks between servers and/or compute devices of the network {\textbar} 150 {\textbar} can include one or more communication channels, for example, a radio frequency ({RF}) communication channel(s), an extremely low frequency ({ELF}) communication channel(s), an ultra-low frequency ({ULF}) communication channel(s), a low frequency ({LF}) communication channel(s), a medium frequency ({MF}) communication channel(s), an ultra-high frequency ({UHF}) communication channel(s), an extremely high frequency ({EHF}) communication channel(s), a fiber optic commination channel(s), an electronic communication channel(s), a satellite communication channel(s), and/or the like. The network {\textbar} 150 {\textbar} can be, for example, the Internet, an intranet, a local area network ({LAN}), a wide area network ({WAN}), a metropolitan area network ({MAN}), a worldwide interoperability for microwave access network ({WiMAX}®), a virtual network, any other suitable communication system and/or a combination of such networks. {\textbar} The server compute device {\textbar} {\textbar} 160 {\textbar} can be/include compute device mediums specialized for data storage purposes and/or computing purposes that can include, for example, a network of electronic memories, a network of magnetic memories, a server(s), a blade server(s), a storage area network(s), a network attached storage(s), deep learning computing servers, deep learning storage servers, and/or the like. Each server device {\textbar} 160 {\textbar} can include a memory (not shown), a communication interface (not shown) and/or a processor (not shown). The communication interface can receive/transmit data from/to the prediction device {\textbar} 110 {\textbar} via the network {\textbar} 150 {\textbar} , the memory can store the data, and the processor can analyze the data. In some instances, the server compute device {\textbar} 160 {\textbar} can be a biobank server that stores the data for a long period of time (e.g. 2 years, 5 years, 10 years, 100 years, and/or the like). {\textbar} The clinician compute device {\textbar} {\textbar} 170 {\textbar} and/or the subject compute device {\textbar} 180 {\textbar} can be/include compute devices operatively coupled and configured to transmit and/or receive data and/or analytical models to the treatment-response prediction device {\textbar} 110 {\textbar} . A user of subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can use the treatment-response prediction device {\textbar} 110 {\textbar} (partially or fully) for selecting a treatment and/or a treatment-response prediction. In some instances, the subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can be/include, for example, a personal computer, a laptop, a smartphone, a custom personal assistant device, and/or the like, each including a memory (not shown), a communication interface (not shown) and/or a processor (not shown). The processor of the subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can include a hardware based integrated circuit ({IC}) or any other suitable processing device configured to run and/or execute a set of instructions or code. The memory of the subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can include a hardware based charge storage electronic device or any other suitable data storage medium configured to store data for long term or batch processing of the data by the processor. The communication interface of the subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can include a hardware based device configured to receive/transmit electric signals, electromagnetic signals, and/or optical signals. {\textbar} The memory {\textbar} {\textbar} 111 {\textbar} of the treatment-response prediction device {\textbar} 110 {\textbar} can be, for example, a memory buffer, a random access memory ({RAM}), a read-only memory ({ROM}), a hard drive, a flash drive, a secure digital ({SD}) memory card, a compact disk ({CD}), an external hard drive, an erasable programmable read-only memory ({EPROM}), an embedded multi-time programmable ({MTP}) memory, an embedded multi-media card ({eMMC}), a universal flash storage ({UFS}) device, and/or the like. The memory {\textbar} 111 {\textbar} can store, for example, one or more software modules and/or code that includes instructions to cause the processor {\textbar} 113 {\textbar} to execute one or more processes or functions (e.g., a signal analyzer {\textbar} 114 {\textbar} , a data preprocessor {\textbar} 115 {\textbar} , a predictor model {\textbar} 116 {\textbar} , and/or the like). {\textbar} The memory {\textbar} {\textbar} 111 {\textbar} can store a set of files associated with (e.g., generated by executing) the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} . The set of files associated with the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} can include data generated by the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} during the operation of the treatment-response prediction device {\textbar} 110 {\textbar} . In some instances, the predictor model {\textbar} 116 {\textbar} can be/include a machine learning model. The machine learning model can store temporary variables, return memory addresses, variables, a graph of the machine learning model (e.g., a set of arithmetic operations or a representation of the set of arithmetic operations used by the machine learning model), the graph's metadata, assets (e.g., external files), electronic signatures (e.g., specifying a type of the machine learning model being exported, and the input/output arrays and/or tensors), and/or the like, in the memory {\textbar} 111 {\textbar} . {\textbar} The communication interface {\textbar} {\textbar} 112 {\textbar} of the treatment-response prediction device {\textbar} 110 {\textbar} can include a software component (e.g., executed by processor {\textbar} 113 {\textbar} ) and/or a hardware component of the treatment-response prediction {\textbar} 110 {\textbar} to facilitate data communication between the treatment-response prediction {\textbar} 110 {\textbar} and external devices (e.g., the server compute device {\textbar} 160 {\textbar} , the clinician platform {\textbar} 170 {\textbar} , the subject compute device {\textbar} 180 {\textbar} , and/or the like) or internal components of the treatment-response prediction {\textbar} 110 {\textbar} (e.g., the memory {\textbar} 111 {\textbar} , the processor {\textbar} 113 {\textbar} ). The communication interface {\textbar} 112 {\textbar} is operatively coupled to and used by the processor {\textbar} 113 {\textbar} and/or the memory {\textbar} 111 {\textbar} . The communication interface {\textbar} 112 {\textbar} can be, for example, a network interface card ({NIC}), a Wi-Fi™ module, a Bluetooth® module, an optical communication module, and/or any other suitable wired and/or wireless communication interface. In some instances, the communication interface {\textbar} 112 {\textbar} can facilitate receiving or transmitting data via the network {\textbar} 150 {\textbar} . More specifically, in some implementations, the communication interface {\textbar} 112 {\textbar} can facilitate receiving or transmitting data containing {EEG} signals, models, and/or the like through the network {\textbar} 150 {\textbar} from/to the server compute device {\textbar} 160 {\textbar} , the clinician platform {\textbar} 170 {\textbar} , the subject compute device {\textbar} 180 {\textbar} , and/or the like, each of which are communicatively coupled to the treatment-response prediction {\textbar} 110 {\textbar} via the network {\textbar} 150 {\textbar} . In some instances, the communication interface {\textbar} 112 {\textbar} can facilitate receiving or transmitting data from the {EEG} machine. {\textbar} The processor {\textbar} {\textbar} 113 {\textbar} can be, for example, a hardware based integrated circuit ({IC}) or any other suitable processing device configured to run or execute a set of instructions or a set of code. For example, the processor {\textbar} 113 {\textbar} can include a general purpose processor, a central processing unit ({CPU}), an accelerated processing unit ({APU}), an application specific integrated circuit ({ASIC}), a field programmable gate array ({FPGA}), a programmable logic array ({PLA}), a complex programmable logic device ({CPLD}), a programmable logic controller ({PLC}), a graphics processing unit ({GPU}), a neural network processor ({NNP}), and/or the like. The processor {\textbar} 113 {\textbar} can be operatively coupled to the memory {\textbar} 111 {\textbar} through a system bus (for example, address bus, data bus, and/or control bus, not shown). {\textbar} The processor {\textbar} {\textbar} 113 {\textbar} includes a signal analyzer {\textbar} 114 {\textbar} , a data preprocessor {\textbar} 115 {\textbar} , and a predictor model {\textbar} 116 {\textbar} . Each of the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} can include software stored in the memory {\textbar} 111 {\textbar} and executed by the processor {\textbar} 113 {\textbar} . For example, a code to cause the signal analyzer {\textbar} 114 {\textbar} to fetch/process the high dimensional and high volume data can be stored in the memory {\textbar} 111 {\textbar} and executed by the processor {\textbar} 113 {\textbar} . Alternatively, each of the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} can be a hardware-based device. For example, a process to predictor model {\textbar} 116 {\textbar} to predict a clinical outcome can be implemented on an individual integrated circuit chip (e.g., an {ASIC}). {\textbar} The signal analyzer {\textbar} {\textbar} 114 {\textbar} can receive the {EEG} signals and perform signal analysis on the {EEG} signal. In some instances, the signal analyzer can perform a Fourier analysis (e.g., used for stationary signals) and/or wavelet analysis (e.g., used for non-stationary signals) to transform the {EEG} signals from time domain to frequency domain. The transformed {EEG} signals can be further analyzed by the signal analyzer {\textbar} 114 {\textbar} to extract significant frequency components of the {EEG} signals. Fourier analysis of an {EEG} signal produces a power spectrum that includes an indication of which frequencies are present in the {EEG} signals, and relative strength (or power) of the frequencies. Known power spectrum analysis of {EEG} or magnetoencephalographic ({MEG}) signals has not revealed particular frequency peaks that robustly differentiates schizophrenic subjects from controls. {\textbar} The signal analyzer {\textbar} {\textbar} 114 {\textbar} can further generate {EEG} metrics. In some instances, the {EEG} metrics can include an index that is based on a ratio of an {EEG} signal power at a first frequency to the {EEG} signal power at a second frequency (e.g., a ratio of power at 20 Hz/power at 40 Hz power). The first and/or the second frequencies can be picked from a frequency band or multiple frequency bands. In some instances, the {EEG} metrics can include a power law exponent (also referred to as ‘1/f noise’ or ‘fractal exponent’) of the {EEG} signals. A power spectrum of {EEG} signals (at resting state or under stimulation), when viewed in the frequency domain (that is, with frequency of oscillation plotted on the x-axis and power on the y-axis), may be approximated by a straight line, when viewed on a log-log plot (see {\textbar} {FIG}. 5 {\textbar} ). Mathematically, the power spectrum can be expressed as log (P)=k−βlog (f), or equivalently, P αf (=1/fβ), where P represents power, f represents frequency, −β represents the slope of the fitted line, and k represents a constant. The power law exponent, β, is constant (“scale invariant” or “fractal” behavior) regardless of the resolution at which it is calculated (see inset of {\textbar} {FIG}. 5 {\textbar} ). Steeper slopes of the power law exponent may reveal a higher degree of “structure” or “memory” in underlying brain interactions. {\textbar} Oscillatory activity at a number of frequencies and brain locations can be observed in human brain. The {EEG} signals recorded by the {EEG} machine can be collected for the frequencies and the brain locations. The brain locations can be based on an {EEG} electrode map. The frequencies can be in the delta band (1-3 cycles per second [Hz]), the theta band (4-7 Hz), the alpha band (8-12 Hz), the beta band (12-30 Hz), the gamma band (40-80 Hz), and/or the like. {\textbar} {\textbar} The data preprocessor {\textbar} {\textbar} 115 {\textbar} can be used to receive the data (e.g., including analyzed signals by the signal analyzer {\textbar} 114 {\textbar} ) and further prepare the data for processing by the predictor model {\textbar} 116 {\textbar} . In some implantations, the data preprocessor {\textbar} 115 {\textbar} can normalize the data, perform feature extraction, dimension reduction, and/or the like. In some instances, normalizing the data may involve amplitude matching, frequency matching, file format (e.g., txt format, {CSV} format, and/or the like) adjustment, data format (e.g., comma separated, semicolon separated, etc.) adjustment, and/or the like. {\textbar} In some instances, the data preprocessor {\textbar} {\textbar} 115 {\textbar} can be configured to receive a set of signals, convert a format of the set of signals, remove measurement artifacts (e.g., generated due to eye blinks or scalp muscle movements of a subject from whom the set of signals are taken from), and/or filter the set of signals (e.g., to reduce noise in the set of (denoise) signals). Also, the data preprocessor {\textbar} 115 {\textbar} can be configured to perform an independent component analyses ({ICA}) to decompose the set of signals into functionally and spatially separated signals. {\textbar} The predictor model {\textbar} {\textbar} 116 {\textbar} (also referred to as ‘the model’) can be/include a machine learning model, as described in further details herein. The predictor model {\textbar} 116 {\textbar} may include a feed-forward machine learning model, a convolutional neural network ({CNN}), a graph neural network ({GNN}), an auto encoder, a transformer neural network, a logistic regression model, a Naive Bayes classifier, a support vector machine ({SVM}), a random forest, a decision tree, an extreme gradient boosting ({XGBoost}) model, and/or the like. The predictor model {\textbar} 116 {\textbar} can be configured to include a set of model parameters including a set of weights, a set of biases, and/or a set of activation functions that, once trained, may be executed to generate a prediction of clinical outcome (e.g., responder, non-responder, 20\% responder, 99\% responder, a response score, and/or the like) of the {EEG} signals. For example the predictor model {\textbar} 116 {\textbar} can be configured to predict glutamate receptor agonist treatment responders. {\textbar} In some embodiments, the clinical outcome can be categorized as “responder” vs. “non-responder”. Such categorization can be defined in multiple ways including: {\textbar} {\textbar} Based on percentage improvement, averaged across all items of the {MCCB} cognitive battery. {\textbar} Based on percentage improvement, averaged across all items of the positive symptom scale. {\textbar} Based on percentage improvement, averaged across all items of the negative symptom scale. {\textbar} Based on an average of (i), (ii), and (iii) above, as well as percentage change in Clinical Global Impression Severity Scale ({CGI}-S). {\textbar} In all the above cases, percentage improvement from baseline will be taken as the outcome measure. “Response” can be defined using a number of different cutoffs (e.g., improvement of 20\%, 30\%, 40\%, 50\% and 60\%). {\textbar} {\textbar} In one example, the predictor model 116 can be/include a feed forward neural network or a deep learning model that includes an input layer, an output layer, and multiple hidden layers (e.g., 5 layers, 10 layers, 20 layers, 50 layers, 100 layers, 200 layers, etc.). The multiple hidden layers may include normalization layers, fully connected layers, activation layers, convolutional layers, recurrent layers, and/or any other layers that are suitable for representing a correlation between the {EEG} signals and the clinical outcome, each score representing an energy term. {\textbar} {\textbar} In one example, the predictor model {\textbar} {\textbar} 116 {\textbar} can be an {XGBoost} model that includes a set of hyper-parameters such as, for example, a number of boost rounds that defines the number of boosting rounds or trees in the {XGBoost} model, maximum depth that defines a maximum number of permitted nodes from a root of a tree of the {XGBoost} model to a leaf of the tree, and/or the like. The {XGBoost} model may include a set of trees, a set of nodes, a set of weights, a set of biases, and other parameters useful for describing the {XGBoost} model. {\textbar} In some implementations, the predictor model {\textbar} {\textbar} 116 {\textbar} can be configured to iteratively receive {EEG} signals and/or {EEG} metrics and generate an output predicting the clinical outcome (e.g., a binary response in which 1 represents responder and 0 represents non-responder). The {EEG} signals and/or {EEG} metrics can be associated with one clinical outcome. True clinical outcomes can be compared to outputs from the predictor model {\textbar} 116 {\textbar} using an optimization model and an objective function (also referred to as ‘cost function’) to generate a training loss value. The objective function may include, for example, a mean square error, a mean absolute error, a mean absolute percentage error, a logcosh, a categorical cross entropy, and/or the like. The set of model parameters of the predictor model {\textbar} 116 {\textbar} can be modified in multiple iterations and the first objective function can be executed at each iteration until the training loss value converges to a first predetermined training threshold (e.g. 80\%, 85\%, 90\%, 97\%, etc.). {\textbar} In some embodiments, the predictor model {\textbar} {\textbar} 116 {\textbar} can integrate the {EEG} metrics and/or {EEG} signals to generate a composite score that identifies the subject as an glutamate receptor agonist responder. In some instances, the composite score can be a normalized range of 0 to 100. A threshold within the normalized range can be set to determine whether a subset of {EEG} metric and/or {EEG} signals of a subject can identify the subject as an glutamate receptor agonist responder. {\textbar} {FIG}. 2 {\textbar} {\textbar} is a flowchart illustrating a method {\textbar} 200 {\textbar} of treatment-response prediction, according to an embodiment. The method {\textbar} 200 {\textbar} can be performed by a treatment-response prediction device (such as the treatment-response prediction device as shown and described with respect to {\textbar} {FIG}. 1 {\textbar} ). The method {\textbar} 200 {\textbar} can include receiving {\textbar} 201 {\textbar} electroencephalogram ({EEG}) signals recorded from one or more brain locations of the subject. The method {\textbar} 200 {\textbar} can further include transforming {\textbar} 202 {\textbar} the {EEG} signals into a set of {EEG} metrics. The {EEG} metrics can include electrophysiological behaviors under stimulation or in rest at a set of brain locations. The stimulation can include a photic stimulation, an electrical stimulation, a magnetic stimulation, haptic stimulation, and/or an acoustic stimulation. The method {\textbar} 200 {\textbar} can further include executing {\textbar} 203 {\textbar} a model to receive the set of {EEG} metrics and identify the subject as an glutamate receptor agonist responder based on the set of {EEG} metrics. In some implementations, the model is a machine leaning model. {\textbar} {FIG}. 3 {\textbar} {\textbar} is a flowchart illustrating a method {\textbar} 300 {\textbar} of treatment-response prediction, according to an embodiment. The method {\textbar} 300 {\textbar} can be performed by a treatment-response prediction device (such as the treatment-response prediction device as shown and described with respect to {\textbar} {FIG}. 1 {\textbar} ). The method {\textbar} 300 {\textbar} can include receiving {\textbar} 301 {\textbar} electroencephalogram ({EEG}) signals for a set of electrodes. The method {\textbar} 300 {\textbar} can further include determining {\textbar} 302 {\textbar} peak frequencies among the frequencies, power in one or more frequency range (also termed a power band) (e.g., delta band, 1-4 Hz; gamma band (30-80 Hz)), and/or fractal exponents (power law exponent) of the {EEG} signals. The method {\textbar} 300 {\textbar} can further include determining {\textbar} 303 {\textbar} a set of indices based on the peak frequencies, power in one or more frequency ranges, and/or the fractal exponents of the {EEG} signals. {\textbar} The method {\textbar} {\textbar} 300 {\textbar} can further include identifying {\textbar} 304 {\textbar} l a set of {EEG} metrics that have statistical significance (can be calculated and represented by p-value as shown in Table 1A and Table 1B) in a set of clinical treatment outcomes. Each {EEG} metric can be identified/generated based on (a) power at a particular frequency band (e.g., the delta band, the beta band, the gamma band, and/or the like), (b) a ratio of the power of two different frequency bands (eg, a first power at the beta band/a second power at the gamma band), (c) the power law exponent, (d) power of the {EEG} signal at the driven frequency (i.e., stimulation frequency), and/or (e) the ratio of the powers at two different driven frequencies. In some instances, a principal component analysis ({PCA}) can be carried out to arrive at a set of principal components ({PCs}) that included 75\% variance of independent variables (e.g., pre-treatment {EEG} indexes) from the {EEG} metric. In some instances, a multivariate analysis of covariance ({MANCOVA}) can be carried out with all clinical outcomes as dependent variables, and independent factors of (i) treatment class, indicating treatment with pomaglumetad vs. placebo; (ii) principal components ({PC}); and (iii) interaction between (i) and (ii). This determines whether or not there was a relationship between any principal component and any clinical response and, more importantly, if there was a significant interaction—which would indicate a difference between treated and non-treated subjects. A significance level of p{\textless}0.05 can be used. {\textbar} In some instances, for {PCs} that showed significant interactions above, an analysis of covariance ({ANCOVA}) can be conducted to determine whether there was a significant relationship (e.g., p{\textless}0.05) between the {PC} and any number of clinical outcome measures, for treated subjects. For those clinical outcome measures identified in step above, correlation between that outcome measure and the independent variables (e.g., a particular {EEG} index at a particular {EEG} electrode) for that sub-analysis can be determined. All predictor variables that showed a correlation with the outcome measure at a significance level of p{\textless}0.05 can be considered for analysis. These can be ranked from lowest (most significant) to highest, and the relationship(s) showing the highest level of significance for each sub-analysis can be examined in more details by constructing a topographic cortical map including electrode-level correlation and significance levels for that independent variable-dependent variable pair. {\textbar} {\textbar} The method {\textbar} {\textbar} 300 {\textbar} can further include training {\textbar} 305 {\textbar} a machine learning model based on the set of {EEG} metrics and the set of clinical treatment outcomes, each {EEG} metrics from the set of {EEG} metrics being associated with a clinical treatment outcome from the set of clinical treatment outcomes. The method {\textbar} 300 {\textbar} can further include executing {\textbar} 306 {\textbar} , after the training, the machine learning model to generate a clinical treatment outcome based on a {EEG} metric. {\textbar} In one aspect, the disclosure provides methods of treating a subject with a glutamate receptor agonist. The methods include identifying the subject as a glutamate receptor agonist responder by obtaining or having obtained a electroencephalogram ({EEG}) signals from the subject. They include measuring or having measuring one or more {EEG} metrics, thereby identifying the subject as an glutamate receptor agonist responder, and if the subject is an glutamate receptor agonist responder, then administering the glutamate receptor agonist. {\textbar} {\textbar} As used herein, the term “subject” refers to a human subject suffering from or at risk for a psychiatric disorder. The subject presents one or more symptoms of a mental disorder. Illustrative psychiatric disorders are described in the Diagnostic and Statistical Manual of Mental Disorders ({DSM}-5) (5 {\textbar} {\textbar} th {\textbar} ed.) (2013), which is incorporated by reference for the purpose of defining mental disorders and symptoms by which subjects can be identified as suffering from or at risk for a mental disorder. In some embodiments, the mental disorder is schizophrenia spectrum or other psychotic disorder. {\textbar} The term “effective amount” refers to the amount or dose of a glutamate receptor agonist, or pharmaceutically acceptable salt, upon which single or multiple dose administration to a patient, provides the desired treatment and/or increasing in cognitive function. {\textbar} {\textbar} According to the methods of the disclosure, a subject may be identified as a likely responder to a glutamate receptor agonist. Other factors, including symptoms of the mental disorder, may be considered by the treating physician or other healthcare worker. The methods of the disclosure are not limited to schizophrenia spectrum or other psychotic disorders, as it will be understood that glutamate receptor agonist may be used to treat other disorders. Without being bound by theory, it is believed that the {EEG} metrics disclosed herein are predictive of response due the correlation between {EEG} signals and the underlying biochemistry of the human brain. Features of the brain physiology underlying responsiveness to treatment in psychotic subjects may extend to other disorders, including neurodevelopment disorders, bipolar and related disorders, depressive disorders, anxiety disorders, and others. {\textbar} {\textbar} Given the observed prediction of response to treatment in particular clinical domains (attention-vigilance, reasoning-problem solving, and working memory), the methods of the disclosure may be applied to mental disorders that affect these clinical domains, including but not limited to schizophrenia spectrum and other psychotic disorders. {\textbar} {\textbar} Glutamate receptor agonists have to date failed to achieve the clinical utility expected from preclinical studies. The methods of the disclosure, with associated computational methods and apparatuses, provide for successful treatment with glutamate receptor agonists that otherwise could not be safe and effective. {\textbar} {\textbar} Illustrative glutamate receptor agonists include D-serine, {CTP}-692 (deuterated D-serine), {SAGE}-718 (positive allosteric modulator [{PAM}] at the {NMDA} receptor). sarcosine ({GlyT}-1 inhibitor; also increases glycine), {LY}379268, eglumegad, pomaglumetad ({LY}2140023), and pomaglumetad methionil, or pharmaceutically acceptable salts thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is D-serine or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is {CTP}-692 or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is {SAGE}-718 or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is a {GlyT}-1 inhibitor or a pharmaceutically acceptable salt thereof. In some embodiments, the glutamate receptor agonist is a Bitopertin, {PF}-3463275,{GSK}1018921, Org25935, {AMG}747, {SSR}504734, {SSR}103800, {DCCCyB}, R231857, R213129. {ASP}2535, or a derivative of any of the foregoing, or a pharmaceutically acceptable salt thereof. The chemical structures of these molecules are provided below: {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is sarcosine or a pharmaceutically acceptable salt thereof. Sarcosine is a {GlyT}-1 inhibitor; it also increases glycine. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is {LY}379268 or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is eglumegad or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is pomaglumetad or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is pomaglumetad methionil or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} Pomaglumetad is an amino acid analog drug that acts as a highly selective agonist for the metabotropic glutamate receptor group {II} subtypes {mGluR}2 and {mGluR}3. Human studies investigating therapeutic use of pomaglumetad have focused on the prodrug pomaglumetad methionil, since pomaglumetad exhibits low oral absorption and bioavailability in humans. The dosage of pomaglumetad methionil given to subjects has varied by clinical trial, though dosages have typically ranged between 10 mg and 40 mg twice daily ({BID}). In an early phase {II} monotherapy trial, the dosage shown to be efficacious was 40 mg {BID}. Later trials investigating the use of pomaglumetad methionil as an adjuvant to the glutamate receptor agonist medications already used by subjects participating in the study utilized a lower dose of 20 mg {BID}. If treatment was well tolerated after a week at this target dose, the dose was increased to 40 mg {BID}. However, if the 20 mg dose was not well tolerated, the dose was decreased to 10 mg. {\textbar} {\textbar} Clinical studies of pomaglumetad methionil were halted because the glutamate receptor agonist was not significantly more efficacious than the placebo as determined with {PANS} S total scores. The apparatuses and methods of the present disclosure relate to the surprising discovery that {EEG} metrics, alone or combined using machine learning-based models, can select subjects that respond to glutamate receptor agonist (e.g., pomaglumetad methionil) therapy and/or can predict clinical outcome based on the {EEG} metrics. {\textbar} {\textbar} Depending on the specific conditions being treated, such agents may be formulated into liquid (e.g., solutions, suspensions, or emulsions) or solid dosage forms (capsules or tablets) and administered systemically or locally. The agents may be delivered, for example, in a timed-, controlled, or sustained-slow release form as is known to those skilled in the art. Techniques for formulation and administration may be found in Remington: The Science and Practice of Pharmacy (20 {\textbar} {\textbar} th {\textbar} ed.) Lippincott, Williams \& Wilkins (2000). Suitable routes may include oral, buccal, by inhalation spray, sublingual, rectal, transdermal, vaginal, transmucosal, nasal or intestinal administration; parenteral delivery, including intramuscular, subcutaneous, intramedullary injections, as well as intrathecal, direct intraventricular, intravenous, intra-articullar, intra-sternal, intra-synovial, intra-hepatic, intralesional, intracranial, intraperitoneal, intranasal, or intraocular injections or other modes of delivery. In some embodiments, the pharmaceutical composition is administered orally. In some embodiments, the pharmaceutical composition is administered intravenously. In some embodiments, the pharmaceutical composition is administered intramuscularly. In some embodiments, the pharmaceutical composition is administered intrathecally. In some embodiments, the pharmaceutical composition is administered subcutaneously. {\textbar} The pharmaceutical composition or combination of the present invention can be in a unit dosage form (e.g., tablet, capsule, caplet or particulate), wherein the appropriate dosage of the active ingredient may vary depending upon a variety of factors, such as, for example, the age, weight, sex, the route of administration or salt employed. {\textbar} {\textbar} In general, the presently disclosed methods of treatment result in a decrease in the severity of a disease or condition in a subject. The term “decrease” is meant to inhibit, suppress, attenuate, diminish, arrest, or stabilize a symptom of a disease or condition. {\textbar} {\textbar} The term “treat” “treating” “treatment” or “therapy”, as used herein, means obtaining beneficial or desired results, for example, clinical results. Beneficial or desired results can include, but are not limited to, alleviation of one or more symptoms of mental disorder. One aspect of the treatment is, for example, that said treatment should have a minimal adverse effect on the subject, e.g., it should have a high level of safety. The term “alleviation”, for example in reference to a symptom of a condition, as used herein, refers to reducing at least one of the frequency and amplitude of a symptom of a condition in a subject. In one embodiment, the term “method for the treatment”, as used herein, refers to “method to treat.” {\textbar} {\textbar} In some embodiments of the methods of the disclosure, the glutamate receptor agonist is administered in an amount effective to cause the desired therapeutic effect (i.e., in a therapeutically effective amount). {\textbar} {\textbar} The term “antipsychotic”, as used herein, refers to a neuroleptic drug used to treat a psychotic disorder, such as schizophrenia. In one embodiment, the antipsychotic is, for example, selected from the group comprising a typical antipsychotic and an atypical antipsychotic. In another embodiment, the antipsychotic is a typical antipsychotic. In yet another embodiment, the antipsychotic is an atypical antipsychotic. {\textbar} {\textbar} The term “typical antipsychotic”, as used herein, refers to a first-generation antipsychotic, for example selected from the group comprising a butyrophenone (e.g., haloperidol), a diphenylbutylpiperidine (e.g., pimozide), a phenothiazine (e.g., chlorpromazine, fluphenazine, perphenazine, prochlorperazine, trifluoperazine), and a thioxanthene (e.g., thiothixene). In one embodiment, the typical antipsychotic is selected from the group comprising haloperidol, pimozide, chlorpromazine, fluphenazine, perphenazine, prochlorperazine, trifluoperazine, and thiothixene; or salts thereof. {\textbar} {\textbar} The term “atypical antipsychotic”, as used herein, refers to a second-generation antipsychotic, for example selected from the group comprising a benzamide (e.g., sultopride), a benzisoxazole/benzisothiazole (e.g., lurasidone, paliperidone, risperidone), a phenylpiperazine/quinolinone (e.g., aripiprazole, brexpiprazole, cariprazine) a tricyclic (e.g., clozapine, olanzapine, quetiapine, asenapine, zotepine). In one embodiment, the atypical antipsychotic is selected from the group comprising sultopride, lurasidone, paliperidone, risperidone, brexpiprazole, cariprazine, clozapine, olanzapine, quetiapine, asenapine and zotepine; or salts thereof {\textbar} {\textbar} Definitions of specific clinical domains of cognition and standard tests in humans to evaluate these are well known in the art.Test batteries developed for schizophrenia—e.g., the {MATRICS} (National Institute for Mental Health's Measurement and Treatment Research to Improve Cognition in Schizophrenia) Consensus, Cognitive Battey (“{MCCB}”)—may be used. (Nuechterlein et al., Am J Psychiatry 165(2):203-213 (2008).) The {MCCB} has 7 subdomains: speed of processing, attention/vigilance, working memory, verbal learning, visual learning, reasoning and problem solving, and social cognition. In embodiments of the present disclosure, increasing memory/cognition in response to administration of a glutamate receptor agonist may be evaluated using one or more of the criteria below (listed in recommended order): {\textbar} {\textbar} The {MATRICS} Consensus Cognitive Battery {\textbar} {\textbar} Test {\textbar} {\textbar} Domain {\textbar} Trail Making Test, Part A {\textbar} {\textbar} Speed of processing {\textbar} Brief Assessment of Cognition in {\textbar} {\textbar} Speed of processing {\textbar} Schizophrenia, symbol coding {\textbar} {\textbar} subtest {\textbar} {\textbar} Hopkins Verbal Learning Test- {\textbar} {\textbar} Verbal learning {\textbar} Revised, immediate recall (three {\textbar} {\textbar} learning trials only) {\textbar} {\textbar} Wechsler Memory Scale, 3rd ed., {\textbar} {\textbar} Working memory {\textbar} spatial span subtest {\textbar} {\textbar} (nonverbal) {\textbar} Letter-Number Span test {\textbar} {\textbar} Working memory (verbal) {\textbar} Neuropsychological Assessment {\textbar} {\textbar} Reasoning and problem {\textbar} Battery, mazes subtest {\textbar} {\textbar} solving {\textbar} Brief Visuospatial Memory Test- {\textbar} {\textbar} Visual learning {\textbar} Revised {\textbar} {\textbar} Category fluency test, animal {\textbar} {\textbar} Speed of processing {\textbar} naming {\textbar} {\textbar} Mayer-Salovey-Caruso Emotional {\textbar} {\textbar} Social cognition {\textbar} Intelligence Test, managing {\textbar} {\textbar} emotions branch {\textbar} {\textbar} Continuous Performance Test, {\textbar} {\textbar} Attention/vigilance {\textbar} Identical Pairs version {\textbar} {\textbar} Further known in the art is that mouse and rat experimental tasks map onto the {MCCB} battery as a “preclinical {MATRICS}”. In embodiments of the present disclosure, effectiveness of a glutamate receptor agonist in improving cognitive function may be evaluated pre-clinically with the following sven rodent tasks: 5-choice serial reaction task (for attention/vigilance), olfactory discrimination (for speed of processing), attentional set-shifting (for reasoning/problem solving), novel object recognition test (for visual learning/memory), radial arm maze (for working memory-spatial), odor span task (for working memory-non spatial), and social interaction task (for social cognition). {\textbar} {\textbar} In some embodiments, the subject suffers from or is at risk for a disease or disorder associated with decreased cognitive function. In some embodiments, the disease or disorder associated with decreased cognitive function is dementia, Alzheimer's disease, {MAJOR} depression, bipolar depression, post-traumatic stress disorder ({PTSD}), panic disorder, generalized anxiety disorder ({GAD}), attention-deficit hyperactivity disorder ({ADHD}), Parkinson's disease, schizophrenia, an autism spectrum disorder ({ASD}), or obsessive compulsive disorder ({OCD}). In some embodiments, the subject suffers from intellectual disability, including but not limited to intellectual disability caused by Down Syndrome or Fragile X syndrome. {\textbar} {\textbar} {EXAMPLES} {\textbar} {\textbar} The following specific examples are illustrative and do not limit the scope of the invention as claimed. {\textbar} {\textbar} {METHODS} {\textbar} {\textbar} Preprocessing {\textbar} {\textbar} After receiving the data, the format of the data can be converted (e.g., change of file format). The data can be further processed to remove measurement artifacts (e.g., due to eye blinks or scalp muscle movements), and filter it. In addition or alternatively, independent component analyses ({ICA}) can be performed. {ICA} is a process that allows one to decompose the recorded {EEG} data into functionally and spatially separated signals (Onton et al. (2006) {\textbar} {\textbar} Neurosci Biobehav Rev {\textbar} 30(6):808-822.); this can also serve to denoise the signals. The analytic techniques that follow can be applied to the filtered, artifact-free data, as well as the estimated sources as revealed by {ICA}. {\textbar} Power Spectrum Analysis {\textbar} {\textbar} Oscillatory activity at a number of different frequencies has been observed in human brain. These are conventionally divided into the slow frequency ranges of delta (1-3 cycles per second [Hz]) and theta (4-7 Hz); the intermediate frequencies, alpha (8-12 Hz) and beta (12-30 Hz); and the gamma band (40-80 Hz). {\textbar} {\textbar} Fourier analysis of an {EEG} signal produces a so-called power spectrum—that is, an indication of which frequencies are present, and their relative strength (or power). To our knowledge, this power spectrum analysis has never successfully been used to predict medication response, or to subcategorize schizophrenic subjects. {\textbar} {\textbar} In some instances, wavelet analysis can be used to analyze the {EEG} signal. The wavelet analysis is a methodology that provides similar information, but uses a rolling time window to determine frequencies present. This is particularly well suited for sets of shorter ({\textless}10 sec) data segments that can result after artifact removal. {\textbar} {\textbar} Power-Law Behavior {\textbar} {\textbar} The power spectrum of resting state {EEG} signals, when viewed in the frequency domain (that is, with frequency of oscillation on the x-axis and power on the y-axis), forms roughly a straight line, when viewed on a log-log plot; see {FIG}.5 (from Miller et al. (2019) {PLoS} Comput Biol 5(12): e1000609) {\textbar} {\textbar} Mathematically, this can be expressed as log (P)=k−βlog (f), or equivalently, P αf−β1/fβ), where P=power, f=frequency, −β is the slope of the fitted line, and k is a constant. This phenomenon is known by various terms, such as a “power law” spectrum or “1/f noise”. It is often referred to as “scale invariant” or “fractal” behavior (Lowen and Teich, 2005), as the power law exponent, β, is constant regardless of the resolution at which it is calculated. {\textbar} {\textbar} Treatment Response {\textbar} {\textbar} Response to treatment is determined by calculating change from baseline in key clinical outcome measures, as follows: {\textbar} {\textbar} Positive and Negative Symptom Scale ({PANS} S). Correlations are made up of the Positive subscale (which ranges from 7 to 49), the Negative subscale (7 to 49) the general psychopathology subscale (16 to 112), and the {PANNS} total score (30 to 210). {\textbar} {\textbar} Clinical Global Impression Severity Scale ({CGI}-S). This measures overall severity of subjects' symptoms and ranges from 1 to 7. {\textbar} {\textbar} 16-Item Negative Symptoms Assessment ({NSA}-16). Total score, ranging from 16 to 96, is used. {\textbar} {\textbar} Measurement and Treatment Research to Improve Cognition in Schizophrenia Consensus Cognitive Battery ({MCCB}). This assesses cognitive functioning in 7 domains (speed of processing, working memory, verbal leaning, visual learning, reasoning and problem solving, attention/vigilance, and social cognition). {\textbar} {\textbar} Personal and Social Performance ({PSP}) scale. Total score, which ranges to 100 and assesses four domains of functioning, is used. {\textbar} {\textbar} Example 1 {\textbar} {\textbar} Pomaglumetad methionil ({LY}-2140023, or “poma”) is an experimental glutamate receptor agonist which is an agonist at metabotropic ({mGluR}2/3) glutamate receptors, and has no known effects on dopamine receptors. Multiple phase {II} and {III} clinical trials suggested that while this agent may not be effective for subjects with schizophrenia as a whole, there may be particular subgroups for whom it is uniquely helpful. Our objective was to develop novel {EEG} biomarkers to identify subjects who are more likely to show a positive response to treatment with poma. Furthermore, we examined additional {EEG} measures—e.g., response to photic stimulation, magnitude of power law exponent ({PLE})—that, to our knowledge, have not been used in prior predictive studies. {\textbar} {\textbar} Methods {\textbar} {\textbar} This study used data from clinical trials {NCT}00845026 (N=117) and {NCT}01052103 (N=196), which studied male and female subjects with schizophrenia treated with poma vs. antipsychotic agent standard of care. {EEG} recordings were taken in the pre-treatment period using a standard 19-lead montage ( {\textbar} {\textbar} {FIG}. 4 {\textbar} ), both in the resting state and when subjects were exposed to photic stimulation (flashing light), at frequencies ranging from 1 to 30 Hz. We subjected resting {EEG} data to known power spectrum analysis to determine strength of activity in the delta (1-4 Hz), theta (4-7 Hz), alpha (8-13 Hz), beta (13-30 Hz), and gamma (30-80 Hz) frequency bands. We calculated only power at the stimulated frequency and, for recordings in the resting state, the power law exponent ({PLE}; also known as the “fractal exponent”). The power spectrum of resting state {EEG} signals, when viewed in the frequency domain—that is, with power graphed as a function of oscillatory frequency—often forms a roughly straight line when viewed on a log-log plot; the slope of the fitted line is the {PLE} (see {\textbar} {FIG}. 5 {\textbar} for example). We calculated all predictive measures for each {EEG} electrode. {\textbar} Response to poma treatment was operationalized as percentage change from baseline to trial endpoint on several clinical outcome measures, including the Positive and Negative Symptom Scale ({PANSS}), and the {MATRICS} Consensus Cognitive Battery ({MCCB}) and its seven individual cognitive domain scales. We performed statistical analysis to determine whether there was a significant relationship between any of our calculated {EEG} metrics in the pre-treatment condition and treatment outcomes. The positive symptom of the {PANNSS} can include delusions, conceptual disorganization, hallucinations, excitement, grandiosity, suspiciousness/persecution, hostility, and/or the like. The negative symptom of the {PANNSS} can include blunted affect, emotional withdrawal, poor rapport, passive/apathetic social withdrawal, difficulty in abstract thinking, lack of spontaneity and flow of conversation, stereotyped thinking, and/or the like. {\textbar} {\textbar} Results {\textbar} {\textbar} Surprisingly, we identified a number of pre-treatment {EEG} metrics that correlated with clinical outcomes and predict response to treatment with poma (Table 1A and Table 1B). {\textbar} {\textbar} {TABLE} 1A {\textbar} {\textbar} Photic Stimulation {\textbar} {\textbar} {EEG} {\textbar} {\textbar} Lead {\textbar} {\textbar} Brain Location {\textbar} Electrophys Behavior {\textbar} Clinical Domain {\textbar} {FIG}. {\textbar} r {\textbar} p-value {\textbar} 1 {\textbar} {\textbar} Fz {\textbar} center frontal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.319 {\textbar} 0.000042 {\textbar} 2 {\textbar} {\textbar} T3 {\textbar} left temporal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.339 {\textbar} 0.000013 {\textbar} 3 {\textbar} {\textbar} C4 {\textbar} right central {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.313 {\textbar} 0.000060 {\textbar} 4 {\textbar} {\textbar} Pz {\textbar} center parietal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.370 {\textbar} 0.000002 {\textbar} 5 {\textbar} {\textbar} P4 {\textbar} right parietal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.374 {\textbar} 0.000001 {\textbar} 6 {\textbar} {\textbar} T6 {\textbar} right rear temporal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.385 {\textbar} 0.000001 {\textbar} 7 {\textbar} {\textbar} O1 {\textbar} left occipital {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.342 {\textbar} 0.000010 {\textbar} 8 {\textbar} {\textbar} O2 {\textbar} right occipital {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.361 {\textbar} 0.000003 {\textbar} 9 {\textbar} {\textbar} T3 {\textbar} left temporal {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 6 {\textbar} 0.196 {\textbar} 0.024550 {\textbar} 10 {\textbar} {\textbar} T5 {\textbar} left rear temporal {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 7 {\textbar} 0.244 {\textbar} 0.004932 {\textbar} 11 {\textbar} {\textbar} P3 {\textbar} left parietal {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 7 {\textbar} 0.217 {\textbar} 0.012777 {\textbar} 12 {\textbar} {\textbar} Pz {\textbar} center parietal {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 7 {\textbar} 0.181 {\textbar} 0.038468 {\textbar} 13 {\textbar} {\textbar} O1 {\textbar} left occipital {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 7 {\textbar} 0.210 {\textbar} 0.016154 {\textbar} {TABLE} 1B {\textbar} {\textbar} Resting State {\textbar} {\textbar} {EEG} {\textbar} {\textbar} Lead {\textbar} {\textbar} Brain Location {\textbar} Electrophys Behavior {\textbar} Clinical Domain {\textbar} {FIG}. {\textbar} r {\textbar} p-value {\textbar} 14 {\textbar} {\textbar} F3 {\textbar} left frontal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.275 {\textbar} 0.000996 {\textbar} 15 {\textbar} {\textbar} Fz {\textbar} center frontal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.253 {\textbar} 0.002556 {\textbar} 16 {\textbar} {\textbar} F4 {\textbar} right frontal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.309 {\textbar} 0.000204 {\textbar} 17 {\textbar} {\textbar} C3 {\textbar} left central {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.288 {\textbar} 0.000558 {\textbar} 18 {\textbar} {\textbar} C4 {\textbar} right frontal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.261 {\textbar} 0.001837 {\textbar} 19 {\textbar} {\textbar} T5 {\textbar} left temporal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.266 {\textbar} 0.001462 {\textbar} 20 {\textbar} {\textbar} P4 {\textbar} right parietal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.299 {\textbar} 0.000330 {\textbar} 21 {\textbar} {\textbar} T6 {\textbar} right rear temporal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.297 {\textbar} 0.000372 {\textbar} 22 {\textbar} {\textbar} T3 {\textbar} left temporal {\textbar} beta (22 Hz) {\textbar} attention-vigilance {\textbar} — {\textbar} 0.222 {\textbar} 0.003470 {\textbar} 23 {\textbar} {\textbar} C4 {\textbar} right central {\textbar} beta (16-25 Hz) {\textbar} reasoning-problem solving {\textbar} — {\textbar} 0.198 {\textbar} 0.020872 {\textbar} For example: (1) In the 30 Hz photically stimulated condition, there was a positive correlation between pre-treatment low gamma (30 Hz) activity in {EEG} lead T6 and post-treatment improvement in cognition, as measured by the attention-vigilance domain score of the {MCCB} (r=0.385, p=0.000001) (line 6 of Table 1A). Correlation coefficients ranged from 0.34 to 0.39 with similar levels of significance at other occipital and inferior leads ( {\textbar} {\textbar} {FIG}. 6 {\textbar} ). (2) In the 15 Hz photically stimulated condition, there was a positive correlation between pre-treatment low beta (15 Hz) activity at {EEG} lead T5 and post-treatment improvement in cognition, as measured by the reasoning-problem solving domain score of the {MCCB} (r=0.244, p=0.004932) (line 10 of Table 1A). Correlation coefficients ranged from 0.19 to 0.24, with similar significance levels, in other left tempo-parietal leads ( {\textbar} {FIG}. 7 {\textbar} ). (3) For left central electrode C3, there was a positive correlation between pre-treatment {PLE} and improvement in the working memory ({WM}) domain score of the {MCCB} (r=0.288, p=0.000558) (line 17 of Table 1B). Correlation coefficients of 0.25 to 0.31, with similar significance levels, were seen at other fronto-central leads ( {\textbar} {FIG}. 8 {\textbar} ). {\textbar} Taking this effect (pre-treatment {PLE} at left central electrode C3) as an example and using improvement in {WM} performance of 50\% as the definition of treatment response, receiver operator curve ({ROC}) analysis revealed that {PLE} at lead C3 could identify poma responders with a sensitivity of 0.750 and a specificity of 0.897 ({AUC}=0.809, p=0.039) ( {\textbar} {\textbar} {FIG}. 9 {\textbar} ). In all, 23 lead-level relationships were judged to have relatively high effect size and robust statistical significance, and thus potential clinical utility (Table 1A and Table 1B). Notably, all response variables that we identified involved improvement in cognitive functioning, rather than positive or negative symptoms or other measures of psychopathology. The positive {EEG} predictors did not occur in one particular cortical area. {\textbar} In sum, this data demonstrates there are subject subgroup(s) which shows unique benefit in terms of cognitive improvement, and that may be characterized by particular {EEG} “spectral fingerprints.” {\textbar} {\textbar} Example 2 {\textbar} {\textbar} We have identified individual {EEG}-based pre-treatment metrics that serve as a priori biomarkers of treatment outcome. The methodology described here could be applied to other psychoactive medications, beyond poma, and for a variety of conditions aside from schizophrenia, as these also may result in unique patterns of {EEG} activity in responders vs. non-responders that may be difficult to appreciate with known methods alone. In treatment settings, the ability to pinpoint likely medication responders, and therefore decrease time and resources devoted to pharmacologic trial and error would have clear value. Also, markers of the kind we have developed could be used to enrich subject samples for clinical trials, potentially resulting in smaller studies and shorter trials, and overall lower drug development costs. {\textbar} {\textbar} Example 3 {\textbar} {\textbar} The particular brain phenotype that is uniquely responsive to poma is characterized by a combination of the effects described in Examples 1 and 2. We have developed an artificial intelligence ({AI}) approach using deep learning artificial neural nets ({ANNs}) to identify such patterns. This methodology is well-suited to complex, non-linear, pattern recognition tasks with multiple inputs. The resultant “composite biomarker” takes into account all of the effects identified, and is a more robust predictor than any one singly. {\textbar} {\textbar} We propose to create a deep neural network consisting of four layers: an input layer of 23 nodes, each corresponding to one of the biomarkers of Table 1; two hidden layers—hidden layer one consisting of 33 nodes and the hidden layer two consisting of 7 nodes—and an output layer consisting of one node, representing “responder” when active, and “non-responder” when inactive. The model can be a four layer model and number of nodes in the first and second hidden layers layer can be: {\textbar} {\textbar} √\{square root over ((m+2)N)\}+2√\{square root over (N/(m+2))\} and m√\{square root over (N/(m+2))\} {\textbar} {\textbar} nodes, respectively, where m is the number of output neurons, and N is the number of samples to be learned. The transfer function to be used will be the so-called rectified linear unit ({ReLU}), (f(z)=max(z, 0)). {\textbar} {\textbar} Achieving optimal network architecture (e.g., number of layers, number of nodes per layer) can be approached as an optimization challenge. A number of different methodologies have been suggested to address this problem (Thomas and Suhner, 2015), such as the “evolutionary approach”, “constructive approach” or the “pruning approach” (which the method we have chosen to use). According to this approach, one begins with an oversized network. In the course of training, it may become clear that particular parameters are not being utilized (e.g., some connection weights go to zero or near-zero); these are then eliminated. While this approach can result in very effective networks, a downside is that this process can be computationally demanding. Given the 72 processor computer cluster that our lab owns, and that will be used to run these models, this is not a major consideration. If the pruning approach fails to produce adequate results, other model-construction approaches can be used: this is necessarily a trial-and-error process. {\textbar} {\textbar} Example 4 {\textbar} {\textbar} Our analysis (detailed in Examples 1-3, above) indicated that there are subgroups of patients that show significant improvement in cognitive function in measures of working memory, reasoning/problem solving, and attention/vigilance when given pomaglumetad methionil, and our methodology allows one to identify such subgroups. Significantly, the novel metrics we have developed which point to these functional subgroups make sense from neurocognitive standpoint. Because of this apparent preferential effect of pomaglumetad methionil, we propose a novel usage for this drug: as a nootropic, or memory enhancing, agent in normal (not psychiatrically ill) subjects. {\textbar} {\textbar} Pre-clinical studies of glutamate receptor agonists as agents that increase cognitive function are performed using pomaglumetad methionil ({LY}-2140023, or “poma”) as representative of the class as a whole. Results are extended to other agents by testing them in the same or similar animal models. Animal models used include those described in Dahhan et al. Front. Behay. Neurosci., 14 (2019) doi:10.3389/fnbeh.2019.00048 which is incorporated by reference herein. {\textbar} {\textbar} Testing of pomaglumetad methionil and other glutamate receptor agonists includes the following: {\textbar} {\textbar} Morris Water Task. This test is used to evaluate learning and memory in rodents. The apparatus consists of a water-filled pool with a hidden escape platform beneath the surface of the water. When the animal is released into the water, it seeks the platform to escape from the water. Spatial memory is separately assessed in a probe trial without the platform. {\textbar} {\textbar} Y Maze. This test to assesses spatial learning and memory. The spontaneous alteration test is used to assess hippocampal damage, quantify the cognitive deficits in transgenic mice, and evaluate the effects of drugs on cognition. The recognition memory test is used to test memory functions in mice. {\textbar} {\textbar} Radial Arm Maze. This test assesses reference memory and working memory. Animals are placed on the central platform of the radial arm maze and allowed to explore the maze for reinforcers (baits) placed at the end of each arm. Failure to visit the arms of the maze containing the reward is regarded as reference memory error. Failure to reenter the arms is regarded as a working memory error. {\textbar} {\textbar} Novel Object Recognition ({NOR})Task. The test evaluates the effect of drug candidates on short-term memory, intermediate-term memory, and long-term memory. It measures the amount of time for which animals must retain memory of the sample objects placed during the recognition phase before the test phase when one of the familiar objects is replaced by a novel one. {\textbar} {\textbar} Fear Conditioning Test. This test assesses associative fear learning and memory and may be used to evaluate a drug compounds' ability to reverse drug-induced deficits in memory. {\textbar} {\textbar} Passive Avoidance Test. This test is fear-motivated test to assess long-term memory based on negative reinforcement. Memory performance is assessed by recording the latency to escape from the white compartment. {\textbar} {\textbar} Elevated Plus Maze. This test is used to assess drugs affecting learning and memory. It uses transfer latency ({TL}) as a parameter for acquisition and retention of memory process. {\textbar} {\textbar} Example 5 {\textbar} {\textbar} Clinical studies of glutamate receptor agonists as agents that increase cognitive function are performed using pomaglumetad methionil ({LY}-2140023, or “poma”) as representative of the class as a whole. Clinical trial endpoints may include: {\textbar} {\textbar} Clinical Global Impression Severity Scale ({CGI}-S). Clinical Global Impression Severity Scale ({CGI}-S). This measures overall severity of patients' symptoms, and ranges from 1 to 7. {\textbar} {\textbar} 16-Item Negative Symptoms Assessment ({NSA}-16). Total score, ranging from 16 to 96, will be used. {\textbar} {\textbar} Measurement and Treatment Research to Improve Cognition in Schizophrenia Consensus Cognitive Battery ({MCCB}). This assesses cognitive functioning in 7 domains (speed of processing, working memory, verbal leaning, visual learning, reasoning and problem solving, attention/vigilance, and social cognition) {\textbar} {\textbar} Dose escalation studies are performed to identify effective amounts of the glutamate receptor agonist for each candidate agonist. {CROSS}-{REFERENCES} {TO} {RELATED} {APPLICATIONS} {\textbar} {\textbar} This application is based on, claims priority to U.S. Provisional Application Ser. No. 62/895,081, filed Sept. 3, 2019, and entitled “{EEG} Biomarkers,” the disclosure of which is incorporated by reference herein in its entirety. {\textbar} {\textbar} {TECHNICAL} {FIELD} {\textbar} {\textbar} The present disclosure relates to the field of treatment for cogitative function {\textbar} {\textbar} {BACKGROUND} {\textbar} {\textbar} There is a need in the art for treatments that increase cognitive function, including working memory, reasoning/problem solving, and attention/vigilance. {\textbar} {\textbar} {SUMMARY} {\textbar} {\textbar} Pre-treatment analysis of electroencephalogram ({EEG}) data of subjects subsequently administered a glutamate receptor agonist indicates that treatment with a glutamate receptor agonist increases cognitive function in human subjects. Moreover, analysis of {EEG} data identifies subsets of subjects in which glutamate receptor agonist has an especially strong effect on cognitive function. {\textbar} {\textbar} Accordingly, provided herein is, in various embodiments, a method of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject, comprising administering an effective amount of a glutamate receptor agonist. The subject may be a healthy subject or may suffer from or be at risk for a mental disorder. {\textbar} {\textbar} Further provided are, in various embodiments, a non-transitory processor-readable medium storing code representing instructions to be executed by a processor, the code comprising code to cause the processor to receive electroencephalogram ({EEG}) signals recorded from one or more brain locations of the subject; transform the {EEG} signals into one or more {EEG} metrics; and execute a model configured to receive the one or more {EEG} metrics and identify the subject as a glutamate receptor agonist responder based on the one or more {EEG} metrics. {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a schematic description of a treatment-response prediction device, according to an embodiment. {\textbar} {FIG}. 2 {\textbar} {\textbar} is a flowchart illustrating a method of treatment-response prediction, according to an embodiment. {\textbar} {FIG}. 3 {\textbar} {\textbar} is a flowchart illustrating a method of treatment-response prediction, according to an embodiment. {\textbar} {FIG}. 4 {\textbar} {\textbar} shows a montage for {EEG} recording. {\textbar} {FIG}. 5 {\textbar} {\textbar} illustrates determining the power law exponent ({PLE}) of an {EEG} signal. {\textbar} {FIG}. 6 {\textbar} {\textbar} shows a correlation between pre-treatment low-gamma (30 Hz) activity and treatment response based on {MCCB} attention-vigilance domain score. Subjects received photic stimulation at 30 Hz. Coloring indicates correlation coefficient, r, with scale shown at right. Selected r and p values shown in Table 1A. {\textbar} {FIG}. 7 {\textbar} {\textbar} shows a correlation between pre-treatment low-beta (15 Hz) activity and treatment response based on {MCCB} reasoning-problems solving domain score. Subjects received photic stimulation at 15 Hz. Coloring indicates correlation coefficient, r, with scale shown at right. Selected r and p values shown in Table 1A. {\textbar} {FIG}. 8 {\textbar} {\textbar} shows a correlation between pre-treatment power law exponent and treatment response based on {MCCB} working memory domain score. {EEG} readings were taken in resting state. Coloring indicates correlation coefficient, r, with scale shown at right. Selected r values and significance shown in Table 1B. {\textbar} {FIG}. 9 {\textbar} {\textbar} shows a receiver operator curve ({ROC}) for effect shown in {\textbar} {FIG}. 8 {\textbar} , at {EEG} lead C3. Sensitivity=0.750, specificity=0.897 (area under the curve [{AUC}]=0.809, p=0.039). {\textbar} {DETAILED} {DESCRIPTION} {\textbar} {\textbar} Non-limiting examples of various aspects and variations of the embodiments are described herein and illustrated in the accompanying drawings. {\textbar} {\textbar} In one aspect, the disclosure provides methods of increasing cognitive function and/or treating a disease or disorder associated with decreased cognitive function in a subject, comprising administering an effective amount of a glutamate receptor agonist. {\textbar} {\textbar} The method may include identifying the subject as a glutamate receptor agonist responder by obtaining or having obtained electroencephalogram ({EEG}) signals from the subject. They include measuring or having measuring one or more {EEG} metrics, thereby identifying the subject as a glutamate receptor agonist responder, and if the subject is a glutamate receptor agonist responder, then administering the glutamate receptor agonist. {\textbar} {\textbar} In another aspect, one or more embodiments described herein generally relate to apparatus, methods, and systems for dynamically processing structured and semi-structured data, and in particular, apparatus, methods, and systems that use a model (e.g. a neural network model) to efficiently and reliably predict an outcome based on the structured and semi-structured-data. Apparatus, methods and systems of treatment-response prediction are disclosed. In some embodiments, treatment-response can be used to process, for example, {EEG} signals in form of time series, stationary data, non-stationary-data, linear data, non-linear data, and/or the like. {\textbar} {\textbar} Described herein are treatment-response prediction apparatuses and methods that predict treatment response based on {EEG} signals collected from a subject. By enabling identification of a subject as an glutamate receptor agonist responder, prior to treatment, the methods described herein may avoid unnecessary adverse events and side effects of treatment. Moreover, the methods described herein may increase the response rate to the glutamate receptor agonist. In particular embodiments, the methods described herein enable safe and effective use of the pomaglumetad, pomaglumetad methionil or a pharmaceutically acceptable salt thereof in the treatment of psychiatric disorders (e.g., psychotic disorders). In some embodiments, individual {EEG} metrics predictive of glutamate receptor agonist responder status are disclosed. In some embodiments, responder prediction is improved by training a machine-learning model on multiple {EEG} metrics. {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a schematic description of a treatment-response prediction device {\textbar} 110 {\textbar} , according to an embodiment. The treatment-response prediction device {\textbar} 110 {\textbar} can identify a subject as an glutamate receptor agonist responder, prior to treatment. The treatment-response prediction device {\textbar} 110 {\textbar} can be also configured to execute a model (e.g., an artificial intelligence model) that predicts a treatment response based on {EEG} signals collected for a subject. The set of {EEG} signals are analyzed by the treatment-response prediction device {\textbar} 110 {\textbar} to generate {EEG} metrics. The treatment-response prediction device {\textbar} 110 {\textbar} can optionally be coupled to a server compute device {\textbar} 160 {\textbar} , a clinician programmer device {\textbar} 170 {\textbar} , and/or a subject compute device {\textbar} 180 {\textbar} via a network {\textbar} 150 {\textbar} . The treatment-response prediction device {\textbar} 110 {\textbar} , clinician programmer device {\textbar} 170 {\textbar} , and/or a subject compute device {\textbar} 180 {\textbar} each can be a hardware-based computing device and/or a multimedia device, such as, for example, a computer, a desktop, a laptop, a smartphone, a tablet, a wearable device, and/or the like. {\textbar} The treatment-response prediction device {\textbar} {\textbar} 110 {\textbar} includes a memory {\textbar} 111 {\textbar} , a communication interface {\textbar} 112 {\textbar} , and a processor {\textbar} 113 {\textbar} . The treatment-response prediction device {\textbar} 110 {\textbar} can receive data including {EEG} signals from an {EEG} machine (not shown) that records activities of a subject's brain. In some instances, the activities of the subject's brain can be/include electrical activities and the activities can be recorded as {EEG} signals by a set of electrodes connected to the {EEG} machine that may be operatively coupled to the treatment-response prediction device {\textbar} 110 {\textbar} . The {EEG} machine can transmit the set of {EEG} signals to the treatment-response prediction device {\textbar} 110 {\textbar} . The {EEG} signals can be recorded in the memory {\textbar} 111 {\textbar} and analyzed by the processor {\textbar} 113 {\textbar} for treating a subject with a glutamate receptor agonist. {\textbar} The network {\textbar} {\textbar} 150 {\textbar} can be a digital telecommunication network of servers and/or compute devices. The servers and/or compute device on the network can be connected via one or more wired or wireless communication networks (not shown) to share resources such as, for example, data storage and/or computing power. The wired or wireless communication networks between servers and/or compute devices of the network {\textbar} 150 {\textbar} can include one or more communication channels, for example, a radio frequency ({RF}) communication channel(s), an extremely low frequency ({ELF}) communication channel(s), an ultra-low frequency ({ULF}) communication channel(s), a low frequency ({LF}) communication channel(s), a medium frequency ({MF}) communication channel(s), an ultra-high frequency ({UHF}) communication channel(s), an extremely high frequency ({EHF}) communication channel(s), a fiber optic commination channel(s), an electronic communication channel(s), a satellite communication channel(s), and/or the like. The network {\textbar} 150 {\textbar} can be, for example, the Internet, an intranet, a local area network ({LAN}), a wide area network ({WAN}), a metropolitan area network ({MAN}), a worldwide interoperability for microwave access network ({WiMAX}®), a virtual network, any other suitable communication system and/or a combination of such networks. {\textbar} The server compute device {\textbar} {\textbar} 160 {\textbar} can be/include compute device mediums specialized for data storage purposes and/or computing purposes that can include, for example, a network of electronic memories, a network of magnetic memories, a server(s), a blade server(s), a storage area network(s), a network attached storage(s), deep learning computing servers, deep learning storage servers, and/or the like. Each server device {\textbar} 160 {\textbar} can include a memory (not shown), a communication interface (not shown) and/or a processor (not shown). The communication interface can receive/transmit data from/to the prediction device {\textbar} 110 {\textbar} via the network {\textbar} 150 {\textbar} , the memory can store the data, and the processor can analyze the data. In some instances, the server compute device {\textbar} 160 {\textbar} can be a biobank server that stores the data for a long period of time (e.g. 2 years, 5 years, 10 years, 100 years, and/or the like). {\textbar} The clinician compute device {\textbar} {\textbar} 170 {\textbar} and/or the subject compute device {\textbar} 180 {\textbar} can be/include compute devices operatively coupled and configured to transmit and/or receive data and/or analytical models to the treatment-response prediction device {\textbar} 110 {\textbar} . A user of subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can use the treatment-response prediction device {\textbar} 110 {\textbar} (partially or fully) for selecting a treatment and/or a treatment-response prediction. In some instances, the subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can be/include, for example, a personal computer, a laptop, a smartphone, a custom personal assistant device, and/or the like, each including a memory (not shown), a communication interface (not shown) and/or a processor (not shown). The processor of the subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can include a hardware based integrated circuit ({IC}) or any other suitable processing device configured to run and/or execute a set of instructions or code. The memory of the subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can include a hardware based charge storage electronic device or any other suitable data storage medium configured to store data for long term or batch processing of the data by the processor. The communication interface of the subject compute device {\textbar} 180 {\textbar} and/or the clinician compute device {\textbar} 170 {\textbar} can include a hardware based device configured to receive/transmit electric signals, electromagnetic signals, and/or optical signals. {\textbar} The memory {\textbar} {\textbar} 111 {\textbar} of the treatment-response prediction device {\textbar} 110 {\textbar} can be, for example, a memory buffer, a random access memory ({RAM}), a read-only memory ({ROM}), a hard drive, a flash drive, a secure digital ({SD}) memory card, a compact disk ({CD}), an external hard drive, an erasable programmable read-only memory ({EPROM}), an embedded multi-time programmable ({MTP}) memory, an embedded multi-media card ({eMMC}), a universal flash storage ({UFS}) device, and/or the like. The memory {\textbar} 111 {\textbar} can store, for example, one or more software modules and/or code that includes instructions to cause the processor {\textbar} 113 {\textbar} to execute one or more processes or functions (e.g., a signal analyzer {\textbar} 114 {\textbar} , a data preprocessor {\textbar} 115 {\textbar} , a predictor model {\textbar} 116 {\textbar} , and/or the like). {\textbar} The memory {\textbar} {\textbar} 111 {\textbar} can store a set of files associated with (e.g., generated by executing) the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} . The set of files associated with the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} can include data generated by the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} during the operation of the treatment-response prediction device {\textbar} 110 {\textbar} . In some instances, the predictor model {\textbar} 116 {\textbar} can be/include a machine learning model. The machine learning model can store temporary variables, return memory addresses, variables, a graph of the machine learning model (e.g., a set of arithmetic operations or a representation of the set of arithmetic operations used by the machine learning model), the graph's metadata, assets (e.g., external files), electronic signatures (e.g., specifying a type of the machine learning model being exported, and the input/output arrays and/or tensors), and/or the like, in the memory {\textbar} 111 {\textbar} . {\textbar} The communication interface {\textbar} {\textbar} 112 {\textbar} of the treatment-response prediction device {\textbar} 110 {\textbar} can include a software component (e.g., executed by processor {\textbar} 113 {\textbar} ) and/or a hardware component of the treatment-response prediction {\textbar} 110 {\textbar} to facilitate data communication between the treatment-response prediction {\textbar} 110 {\textbar} and external devices (e.g., the server compute device {\textbar} 160 {\textbar} , the clinician platform {\textbar} 170 {\textbar} , the subject compute device {\textbar} 180 {\textbar} , and/or the like) or internal components of the treatment-response prediction {\textbar} 110 {\textbar} (e.g., the memory {\textbar} 111 {\textbar} , the processor {\textbar} 113 {\textbar} ). The communication interface {\textbar} 112 {\textbar} is operatively coupled to and used by the processor {\textbar} 113 {\textbar} and/or the memory {\textbar} 111 {\textbar} . The communication interface {\textbar} 112 {\textbar} can be, for example, a network interface card ({NIC}), a Wi-Fi™ module, a Bluetooth® module, an optical communication module, and/or any other suitable wired and/or wireless communication interface. In some instances, the communication interface {\textbar} 112 {\textbar} can facilitate receiving or transmitting data via the network {\textbar} 150 {\textbar} . More specifically, in some implementations, the communication interface {\textbar} 112 {\textbar} can facilitate receiving or transmitting data containing {EEG} signals, models, and/or the like through the network {\textbar} 150 {\textbar} from/to the server compute device {\textbar} 160 {\textbar} , the clinician platform {\textbar} 170 {\textbar} , the subject compute device {\textbar} 180 {\textbar} , and/or the like, each of which are communicatively coupled to the treatment-response prediction {\textbar} 110 {\textbar} via the network {\textbar} 150 {\textbar} . In some instances, the communication interface {\textbar} 112 {\textbar} can facilitate receiving or transmitting data from the {EEG} machine. {\textbar} The processor {\textbar} {\textbar} 113 {\textbar} can be, for example, a hardware based integrated circuit ({IC}) or any other suitable processing device configured to run or execute a set of instructions or a set of code. For example, the processor {\textbar} 113 {\textbar} can include a general purpose processor, a central processing unit ({CPU}), an accelerated processing unit ({APU}), an application specific integrated circuit ({ASIC}), a field programmable gate array ({FPGA}), a programmable logic array ({PLA}), a complex programmable logic device ({CPLD}), a programmable logic controller ({PLC}), a graphics processing unit ({GPU}), a neural network processor ({NNP}), and/or the like. The processor {\textbar} 113 {\textbar} can be operatively coupled to the memory {\textbar} 111 {\textbar} through a system bus (for example, address bus, data bus, and/or control bus, not shown). {\textbar} The processor {\textbar} {\textbar} 113 {\textbar} includes a signal analyzer {\textbar} 114 {\textbar} , a data preprocessor {\textbar} 115 {\textbar} , and a predictor model {\textbar} 116 {\textbar} . Each of the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} can include software stored in the memory {\textbar} 111 {\textbar} and executed by the processor {\textbar} 113 {\textbar} . For example, a code to cause the signal analyzer {\textbar} 114 {\textbar} to fetch/process the high dimensional and high volume data can be stored in the memory {\textbar} 111 {\textbar} and executed by the processor {\textbar} 113 {\textbar} . Alternatively, each of the signal analyzer {\textbar} 114 {\textbar} , the data preprocessor {\textbar} 115 {\textbar} , and/or the predictor model {\textbar} 116 {\textbar} can be a hardware-based device. For example, a process to predictor model {\textbar} 116 {\textbar} to predict a clinical outcome can be implemented on an individual integrated circuit chip (e.g., an {ASIC}). {\textbar} The signal analyzer {\textbar} {\textbar} 114 {\textbar} can receive the {EEG} signals and perform signal analysis on the {EEG} signal. In some instances, the signal analyzer can perform a Fourier analysis (e.g., used for stationary signals) and/or wavelet analysis (e.g., used for non-stationary signals) to transform the {EEG} signals from time domain to frequency domain. The transformed {EEG} signals can be further analyzed by the signal analyzer {\textbar} 114 {\textbar} to extract significant frequency components of the {EEG} signals. Fourier analysis of an {EEG} signal produces a power spectrum that includes an indication of which frequencies are present in the {EEG} signals, and relative strength (or power) of the frequencies. Known power spectrum analysis of {EEG} or magnetoencephalographic ({MEG}) signals has not revealed particular frequency peaks that robustly differentiates schizophrenic subjects from controls. {\textbar} The signal analyzer {\textbar} {\textbar} 114 {\textbar} can further generate {EEG} metrics. In some instances, the {EEG} metrics can include an index that is based on a ratio of an {EEG} signal power at a first frequency to the {EEG} signal power at a second frequency (e.g., a ratio of power at 20 Hz/power at 40 Hz power). The first and/or the second frequencies can be picked from a frequency band or multiple frequency bands. In some instances, the {EEG} metrics can include a power law exponent (also referred to as ‘1/f noise’ or ‘fractal exponent’) of the {EEG} signals. A power spectrum of {EEG} signals (at resting state or under stimulation), when viewed in the frequency domain (that is, with frequency of oscillation plotted on the x-axis and power on the y-axis), may be approximated by a straight line, when viewed on a log-log plot (see {\textbar} {FIG}. 5 {\textbar} ). Mathematically, the power spectrum can be expressed as log (P)=k−βlog (f), or equivalently, P αf (=1/fβ), where P represents power, f represents frequency, −β represents the slope of the fitted line, and k represents a constant. The power law exponent, β, is constant (“scale invariant” or “fractal” behavior) regardless of the resolution at which it is calculated (see inset of {\textbar} {FIG}. 5 {\textbar} ). Steeper slopes of the power law exponent may reveal a higher degree of “structure” or “memory” in underlying brain interactions. {\textbar} Oscillatory activity at a number of frequencies and brain locations can be observed in human brain. The {EEG} signals recorded by the {EEG} machine can be collected for the frequencies and the brain locations. The brain locations can be based on an {EEG} electrode map. The frequencies can be in the delta band (1-3 cycles per second [Hz]), the theta band (4-7 Hz), the alpha band (8-12 Hz), the beta band (12-30 Hz), the gamma band (40-80 Hz), and/or the like. {\textbar} {\textbar} The data preprocessor {\textbar} {\textbar} 115 {\textbar} can be used to receive the data (e.g., including analyzed signals by the signal analyzer {\textbar} 114 {\textbar} ) and further prepare the data for processing by the predictor model {\textbar} 116 {\textbar} . In some implantations, the data preprocessor {\textbar} 115 {\textbar} can normalize the data, perform feature extraction, dimension reduction, and/or the like. In some instances, normalizing the data may involve amplitude matching, frequency matching, file format (e.g., txt format, {CSV} format, and/or the like) adjustment, data format (e.g., comma separated, semicolon separated, etc.) adjustment, and/or the like. {\textbar} In some instances, the data preprocessor {\textbar} {\textbar} 115 {\textbar} can be configured to receive a set of signals, convert a format of the set of signals, remove measurement artifacts (e.g., generated due to eye blinks or scalp muscle movements of a subject from whom the set of signals are taken from), and/or filter the set of signals (e.g., to reduce noise in the set of (denoise) signals). Also, the data preprocessor {\textbar} 115 {\textbar} can be configured to perform an independent component analyses ({ICA}) to decompose the set of signals into functionally and spatially separated signals. {\textbar} The predictor model {\textbar} {\textbar} 116 {\textbar} (also referred to as ‘the model’) can be/include a machine learning model, as described in further details herein. The predictor model {\textbar} 116 {\textbar} may include a feed-forward machine learning model, a convolutional neural network ({CNN}), a graph neural network ({GNN}), an auto encoder, a transformer neural network, a logistic regression model, a Naive Bayes classifier, a support vector machine ({SVM}), a random forest, a decision tree, an extreme gradient boosting ({XGBoost}) model, and/or the like. The predictor model {\textbar} 116 {\textbar} can be configured to include a set of model parameters including a set of weights, a set of biases, and/or a set of activation functions that, once trained, may be executed to generate a prediction of clinical outcome (e.g., responder, non-responder, 20\% responder, 99\% responder, a response score, and/or the like) of the {EEG} signals. For example the predictor model {\textbar} 116 {\textbar} can be configured to predict glutamate receptor agonist treatment responders. {\textbar} In some embodiments, the clinical outcome can be categorized as “responder” vs. “non-responder”. Such categorization can be defined in multiple ways including: {\textbar} {\textbar} Based on percentage improvement, averaged across all items of the {MCCB} cognitive battery. {\textbar} Based on percentage improvement, averaged across all items of the positive symptom scale. {\textbar} Based on percentage improvement, averaged across all items of the negative symptom scale. {\textbar} Based on an average of (i), (ii), and (iii) above, as well as percentage change in Clinical Global Impression Severity Scale ({CGI}-S). {\textbar} In all the above cases, percentage improvement from baseline will be taken as the outcome measure. “Response” can be defined using a number of different cutoffs (e.g., improvement of 20\%, 30\%, 40\%, 50\% and 60\%). {\textbar} {\textbar} In one example, the predictor model 116 can be/include a feed forward neural network or a deep learning model that includes an input layer, an output layer, and multiple hidden layers (e.g., 5 layers, 10 layers, 20 layers, 50 layers, 100 layers, 200 layers, etc.). The multiple hidden layers may include normalization layers, fully connected layers, activation layers, convolutional layers, recurrent layers, and/or any other layers that are suitable for representing a correlation between the {EEG} signals and the clinical outcome, each score representing an energy term. {\textbar} {\textbar} In one example, the predictor model {\textbar} {\textbar} 116 {\textbar} can be an {XGBoost} model that includes a set of hyper-parameters such as, for example, a number of boost rounds that defines the number of boosting rounds or trees in the {XGBoost} model, maximum depth that defines a maximum number of permitted nodes from a root of a tree of the {XGBoost} model to a leaf of the tree, and/or the like. The {XGBoost} model may include a set of trees, a set of nodes, a set of weights, a set of biases, and other parameters useful for describing the {XGBoost} model. {\textbar} In some implementations, the predictor model {\textbar} {\textbar} 116 {\textbar} can be configured to iteratively receive {EEG} signals and/or {EEG} metrics and generate an output predicting the clinical outcome (e.g., a binary response in which 1 represents responder and 0 represents non-responder). The {EEG} signals and/or {EEG} metrics can be associated with one clinical outcome. True clinical outcomes can be compared to outputs from the predictor model {\textbar} 116 {\textbar} using an optimization model and an objective function (also referred to as ‘cost function’) to generate a training loss value. The objective function may include, for example, a mean square error, a mean absolute error, a mean absolute percentage error, a logcosh, a categorical cross entropy, and/or the like. The set of model parameters of the predictor model {\textbar} 116 {\textbar} can be modified in multiple iterations and the first objective function can be executed at each iteration until the training loss value converges to a first predetermined training threshold (e.g. 80\%, 85\%, 90\%, 97\%, etc.). {\textbar} In some embodiments, the predictor model {\textbar} {\textbar} 116 {\textbar} can integrate the {EEG} metrics and/or {EEG} signals to generate a composite score that identifies the subject as an glutamate receptor agonist responder. In some instances, the composite score can be a normalized range of 0 to 100. A threshold within the normalized range can be set to determine whether a subset of {EEG} metric and/or {EEG} signals of a subject can identify the subject as an glutamate receptor agonist responder. {\textbar} {FIG}. 2 {\textbar} {\textbar} is a flowchart illustrating a method {\textbar} 200 {\textbar} of treatment-response prediction, according to an embodiment. The method {\textbar} 200 {\textbar} can be performed by a treatment-response prediction device (such as the treatment-response prediction device as shown and described with respect to {\textbar} {FIG}. 1 {\textbar} ). The method {\textbar} 200 {\textbar} can include receiving {\textbar} 201 {\textbar} electroencephalogram ({EEG}) signals recorded from one or more brain locations of the subject. The method {\textbar} 200 {\textbar} can further include transforming {\textbar} 202 {\textbar} the {EEG} signals into a set of {EEG} metrics. The {EEG} metrics can include electrophysiological behaviors under stimulation or in rest at a set of brain locations. The stimulation can include a photic stimulation, an electrical stimulation, a magnetic stimulation, haptic stimulation, and/or an acoustic stimulation. The method {\textbar} 200 {\textbar} can further include executing {\textbar} 203 {\textbar} a model to receive the set of {EEG} metrics and identify the subject as an glutamate receptor agonist responder based on the set of {EEG} metrics. In some implementations, the model is a machine leaning model. {\textbar} {FIG}. 3 {\textbar} {\textbar} is a flowchart illustrating a method {\textbar} 300 {\textbar} of treatment-response prediction, according to an embodiment. The method {\textbar} 300 {\textbar} can be performed by a treatment-response prediction device (such as the treatment-response prediction device as shown and described with respect to {\textbar} {FIG}. 1 {\textbar} ). The method {\textbar} 300 {\textbar} can include receiving {\textbar} 301 {\textbar} electroencephalogram ({EEG}) signals for a set of electrodes. The method {\textbar} 300 {\textbar} can further include determining {\textbar} 302 {\textbar} peak frequencies among the frequencies, power in one or more frequency range (also termed a power band) (e.g., delta band, 1-4 Hz; gamma band (30-80 Hz)), and/or fractal exponents (power law exponent) of the {EEG} signals. The method {\textbar} 300 {\textbar} can further include determining {\textbar} 303 {\textbar} a set of indices based on the peak frequencies, power in one or more frequency ranges, and/or the fractal exponents of the {EEG} signals. {\textbar} The method {\textbar} {\textbar} 300 {\textbar} can further include identifying {\textbar} 304 {\textbar} l a set of {EEG} metrics that have statistical significance (can be calculated and represented by p-value as shown in Table 1A and Table 1B) in a set of clinical treatment outcomes. Each {EEG} metric can be identified/generated based on (a) power at a particular frequency band (e.g., the delta band, the beta band, the gamma band, and/or the like), (b) a ratio of the power of two different frequency bands (eg, a first power at the beta band/a second power at the gamma band), (c) the power law exponent, (d) power of the {EEG} signal at the driven frequency (i.e., stimulation frequency), and/or (e) the ratio of the powers at two different driven frequencies. In some instances, a principal component analysis ({PCA}) can be carried out to arrive at a set of principal components ({PCs}) that included 75\% variance of independent variables (e.g., pre-treatment {EEG} indexes) from the {EEG} metric. In some instances, a multivariate analysis of covariance ({MANCOVA}) can be carried out with all clinical outcomes as dependent variables, and independent factors of (i) treatment class, indicating treatment with pomaglumetad vs. placebo; (ii) principal components ({PC}); and (iii) interaction between (i) and (ii). This determines whether or not there was a relationship between any principal component and any clinical response and, more importantly, if there was a significant interaction—which would indicate a difference between treated and non-treated subjects. A significance level of p{\textless}0.05 can be used. {\textbar} In some instances, for {PCs} that showed significant interactions above, an analysis of covariance ({ANCOVA}) can be conducted to determine whether there was a significant relationship (e.g., p{\textless}0.05) between the {PC} and any number of clinical outcome measures, for treated subjects. For those clinical outcome measures identified in step above, correlation between that outcome measure and the independent variables (e.g., a particular {EEG} index at a particular {EEG} electrode) for that sub-analysis can be determined. All predictor variables that showed a correlation with the outcome measure at a significance level of p{\textless}0.05 can be considered for analysis. These can be ranked from lowest (most significant) to highest, and the relationship(s) showing the highest level of significance for each sub-analysis can be examined in more details by constructing a topographic cortical map including electrode-level correlation and significance levels for that independent variable-dependent variable pair. {\textbar} {\textbar} The method {\textbar} {\textbar} 300 {\textbar} can further include training {\textbar} 305 {\textbar} a machine learning model based on the set of {EEG} metrics and the set of clinical treatment outcomes, each {EEG} metrics from the set of {EEG} metrics being associated with a clinical treatment outcome from the set of clinical treatment outcomes. The method {\textbar} 300 {\textbar} can further include executing {\textbar} 306 {\textbar} , after the training, the machine learning model to generate a clinical treatment outcome based on a {EEG} metric. {\textbar} In one aspect, the disclosure provides methods of treating a subject with a glutamate receptor agonist. The methods include identifying the subject as a glutamate receptor agonist responder by obtaining or having obtained a electroencephalogram ({EEG}) signals from the subject. They include measuring or having measuring one or more {EEG} metrics, thereby identifying the subject as an glutamate receptor agonist responder, and if the subject is an glutamate receptor agonist responder, then administering the glutamate receptor agonist. {\textbar} {\textbar} As used herein, the term “subject” refers to a human subject suffering from or at risk for a psychiatric disorder. The subject presents one or more symptoms of a mental disorder. Illustrative psychiatric disorders are described in the Diagnostic and Statistical Manual of Mental Disorders ({DSM}-5) (5 {\textbar} {\textbar} th {\textbar} ed.) (2013), which is incorporated by reference for the purpose of defining mental disorders and symptoms by which subjects can be identified as suffering from or at risk for a mental disorder. In some embodiments, the mental disorder is schizophrenia spectrum or other psychotic disorder. {\textbar} The term “effective amount” refers to the amount or dose of a glutamate receptor agonist, or pharmaceutically acceptable salt, upon which single or multiple dose administration to a patient, provides the desired treatment and/or increasing in cognitive function. {\textbar} {\textbar} According to the methods of the disclosure, a subject may be identified as a likely responder to a glutamate receptor agonist. Other factors, including symptoms of the mental disorder, may be considered by the treating physician or other healthcare worker. The methods of the disclosure are not limited to schizophrenia spectrum or other psychotic disorders, as it will be understood that glutamate receptor agonist may be used to treat other disorders. Without being bound by theory, it is believed that the {EEG} metrics disclosed herein are predictive of response due the correlation between {EEG} signals and the underlying biochemistry of the human brain. Features of the brain physiology underlying responsiveness to treatment in psychotic subjects may extend to other disorders, including neurodevelopment disorders, bipolar and related disorders, depressive disorders, anxiety disorders, and others. {\textbar} {\textbar} Given the observed prediction of response to treatment in particular clinical domains (attention-vigilance, reasoning-problem solving, and working memory), the methods of the disclosure may be applied to mental disorders that affect these clinical domains, including but not limited to schizophrenia spectrum and other psychotic disorders. {\textbar} {\textbar} Glutamate receptor agonists have to date failed to achieve the clinical utility expected from preclinical studies. The methods of the disclosure, with associated computational methods and apparatuses, provide for successful treatment with glutamate receptor agonists that otherwise could not be safe and effective. {\textbar} {\textbar} Illustrative glutamate receptor agonists include D-serine, {CTP}-692 (deuterated D-serine), {SAGE}-718 (positive allosteric modulator [{PAM}] at the {NMDA} receptor). sarcosine ({GlyT}-1 inhibitor; also increases glycine), {LY}379268, eglumegad, pomaglumetad ({LY}2140023), and pomaglumetad methionil, or pharmaceutically acceptable salts thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is D-serine or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is {CTP}-692 or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is {SAGE}-718 or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is a {GlyT}-1 inhibitor or a pharmaceutically acceptable salt thereof. In some embodiments, the glutamate receptor agonist is a Bitopertin, {PF}-3463275,{GSK}1018921, Org25935, {AMG}747, {SSR}504734, {SSR}103800, {DCCCyB}, R231857, R213129. {ASP}2535, or a derivative of any of the foregoing, or a pharmaceutically acceptable salt thereof. The chemical structures of these molecules are provided below: {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is sarcosine or a pharmaceutically acceptable salt thereof. Sarcosine is a {GlyT}-1 inhibitor; it also increases glycine. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is {LY}379268 or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is eglumegad or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is pomaglumetad or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} In some embodiments, the glutamate receptor agonist is pomaglumetad methionil or a pharmaceutically acceptable salt thereof. {\textbar} {\textbar} Pomaglumetad is an amino acid analog drug that acts as a highly selective agonist for the metabotropic glutamate receptor group {II} subtypes {mGluR}2 and {mGluR}3. Human studies investigating therapeutic use of pomaglumetad have focused on the prodrug pomaglumetad methionil, since pomaglumetad exhibits low oral absorption and bioavailability in humans. The dosage of pomaglumetad methionil given to subjects has varied by clinical trial, though dosages have typically ranged between 10 mg and 40 mg twice daily ({BID}). In an early phase {II} monotherapy trial, the dosage shown to be efficacious was 40 mg {BID}. Later trials investigating the use of pomaglumetad methionil as an adjuvant to the glutamate receptor agonist medications already used by subjects participating in the study utilized a lower dose of 20 mg {BID}. If treatment was well tolerated after a week at this target dose, the dose was increased to 40 mg {BID}. However, if the 20 mg dose was not well tolerated, the dose was decreased to 10 mg. {\textbar} {\textbar} Clinical studies of pomaglumetad methionil were halted because the glutamate receptor agonist was not significantly more efficacious than the placebo as determined with {PANS} S total scores. The apparatuses and methods of the present disclosure relate to the surprising discovery that {EEG} metrics, alone or combined using machine learning-based models, can select subjects that respond to glutamate receptor agonist (e.g., pomaglumetad methionil) therapy and/or can predict clinical outcome based on the {EEG} metrics. {\textbar} {\textbar} Depending on the specific conditions being treated, such agents may be formulated into liquid (e.g., solutions, suspensions, or emulsions) or solid dosage forms (capsules or tablets) and administered systemically or locally. The agents may be delivered, for example, in a timed-, controlled, or sustained-slow release form as is known to those skilled in the art. Techniques for formulation and administration may be found in Remington: The Science and Practice of Pharmacy (20 {\textbar} {\textbar} th {\textbar} ed.) Lippincott, Williams \& Wilkins (2000). Suitable routes may include oral, buccal, by inhalation spray, sublingual, rectal, transdermal, vaginal, transmucosal, nasal or intestinal administration; parenteral delivery, including intramuscular, subcutaneous, intramedullary injections, as well as intrathecal, direct intraventricular, intravenous, intra-articullar, intra-sternal, intra-synovial, intra-hepatic, intralesional, intracranial, intraperitoneal, intranasal, or intraocular injections or other modes of delivery. In some embodiments, the pharmaceutical composition is administered orally. In some embodiments, the pharmaceutical composition is administered intravenously. In some embodiments, the pharmaceutical composition is administered intramuscularly. In some embodiments, the pharmaceutical composition is administered intrathecally. In some embodiments, the pharmaceutical composition is administered subcutaneously. {\textbar} The pharmaceutical composition or combination of the present invention can be in a unit dosage form (e.g., tablet, capsule, caplet or particulate), wherein the appropriate dosage of the active ingredient may vary depending upon a variety of factors, such as, for example, the age, weight, sex, the route of administration or salt employed. {\textbar} {\textbar} In general, the presently disclosed methods of treatment result in a decrease in the severity of a disease or condition in a subject. The term “decrease” is meant to inhibit, suppress, attenuate, diminish, arrest, or stabilize a symptom of a disease or condition. {\textbar} {\textbar} The term “treat” “treating” “treatment” or “therapy”, as used herein, means obtaining beneficial or desired results, for example, clinical results. Beneficial or desired results can include, but are not limited to, alleviation of one or more symptoms of mental disorder. One aspect of the treatment is, for example, that said treatment should have a minimal adverse effect on the subject, e.g., it should have a high level of safety. The term “alleviation”, for example in reference to a symptom of a condition, as used herein, refers to reducing at least one of the frequency and amplitude of a symptom of a condition in a subject. In one embodiment, the term “method for the treatment”, as used herein, refers to “method to treat.” {\textbar} {\textbar} In some embodiments of the methods of the disclosure, the glutamate receptor agonist is administered in an amount effective to cause the desired therapeutic effect (i.e., in a therapeutically effective amount). {\textbar} {\textbar} The term “antipsychotic”, as used herein, refers to a neuroleptic drug used to treat a psychotic disorder, such as schizophrenia. In one embodiment, the antipsychotic is, for example, selected from the group comprising a typical antipsychotic and an atypical antipsychotic. In another embodiment, the antipsychotic is a typical antipsychotic. In yet another embodiment, the antipsychotic is an atypical antipsychotic. {\textbar} {\textbar} The term “typical antipsychotic”, as used herein, refers to a first-generation antipsychotic, for example selected from the group comprising a butyrophenone (e.g., haloperidol), a diphenylbutylpiperidine (e.g., pimozide), a phenothiazine (e.g., chlorpromazine, fluphenazine, perphenazine, prochlorperazine, trifluoperazine), and a thioxanthene (e.g., thiothixene). In one embodiment, the typical antipsychotic is selected from the group comprising haloperidol, pimozide, chlorpromazine, fluphenazine, perphenazine, prochlorperazine, trifluoperazine, and thiothixene; or salts thereof. {\textbar} {\textbar} The term “atypical antipsychotic”, as used herein, refers to a second-generation antipsychotic, for example selected from the group comprising a benzamide (e.g., sultopride), a benzisoxazole/benzisothiazole (e.g., lurasidone, paliperidone, risperidone), a phenylpiperazine/quinolinone (e.g., aripiprazole, brexpiprazole, cariprazine) a tricyclic (e.g., clozapine, olanzapine, quetiapine, asenapine, zotepine). In one embodiment, the atypical antipsychotic is selected from the group comprising sultopride, lurasidone, paliperidone, risperidone, brexpiprazole, cariprazine, clozapine, olanzapine, quetiapine, asenapine and zotepine; or salts thereof {\textbar} {\textbar} Definitions of specific clinical domains of cognition and standard tests in humans to evaluate these are well known in the art.Test batteries developed for schizophrenia—e.g., the {MATRICS} (National Institute for Mental Health's Measurement and Treatment Research to Improve Cognition in Schizophrenia) Consensus, Cognitive Battey (“{MCCB}”)—may be used. (Nuechterlein et al., Am J Psychiatry 165(2):203-213 (2008).) The {MCCB} has 7 subdomains: speed of processing, attention/vigilance, working memory, verbal learning, visual learning, reasoning and problem solving, and social cognition. In embodiments of the present disclosure, increasing memory/cognition in response to administration of a glutamate receptor agonist may be evaluated using one or more of the criteria below (listed in recommended order): {\textbar} {\textbar} The {MATRICS} Consensus Cognitive Battery {\textbar} {\textbar} Test {\textbar} {\textbar} Domain {\textbar} Trail Making Test, Part A {\textbar} {\textbar} Speed of processing {\textbar} Brief Assessment of Cognition in {\textbar} {\textbar} Speed of processing {\textbar} Schizophrenia, symbol coding {\textbar} {\textbar} subtest {\textbar} {\textbar} Hopkins Verbal Learning Test- {\textbar} {\textbar} Verbal learning {\textbar} Revised, immediate recall (three {\textbar} {\textbar} learning trials only) {\textbar} {\textbar} Wechsler Memory Scale, 3rd ed., {\textbar} {\textbar} Working memory {\textbar} spatial span subtest {\textbar} {\textbar} (nonverbal) {\textbar} Letter-Number Span test {\textbar} {\textbar} Working memory (verbal) {\textbar} Neuropsychological Assessment {\textbar} {\textbar} Reasoning and problem {\textbar} Battery, mazes subtest {\textbar} {\textbar} solving {\textbar} Brief Visuospatial Memory Test- {\textbar} {\textbar} Visual learning {\textbar} Revised {\textbar} {\textbar} Category fluency test, animal {\textbar} {\textbar} Speed of processing {\textbar} naming {\textbar} {\textbar} Mayer-Salovey-Caruso Emotional {\textbar} {\textbar} Social cognition {\textbar} Intelligence Test, managing {\textbar} {\textbar} emotions branch {\textbar} {\textbar} Continuous Performance Test, {\textbar} {\textbar} Attention/vigilance {\textbar} Identical Pairs version {\textbar} {\textbar} Further known in the art is that mouse and rat experimental tasks map onto the {MCCB} battery as a “preclinical {MATRICS}”. In embodiments of the present disclosure, effectiveness of a glutamate receptor agonist in improving cognitive function may be evaluated pre-clinically with the following sven rodent tasks: 5-choice serial reaction task (for attention/vigilance), olfactory discrimination (for speed of processing), attentional set-shifting (for reasoning/problem solving), novel object recognition test (for visual learning/memory), radial arm maze (for working memory-spatial), odor span task (for working memory-non spatial), and social interaction task (for social cognition). {\textbar} {\textbar} In some embodiments, the subject suffers from or is at risk for a disease or disorder associated with decreased cognitive function. In some embodiments, the disease or disorder associated with decreased cognitive function is dementia, Alzheimer's disease, {MAJOR} depression, bipolar depression, post-traumatic stress disorder ({PTSD}), panic disorder, generalized anxiety disorder ({GAD}), attention-deficit hyperactivity disorder ({ADHD}), Parkinson's disease, schizophrenia, an autism spectrum disorder ({ASD}), or obsessive compulsive disorder ({OCD}). In some embodiments, the subject suffers from intellectual disability, including but not limited to intellectual disability caused by Down Syndrome or Fragile X syndrome. {\textbar} {\textbar} {EXAMPLES} {\textbar} {\textbar} The following specific examples are illustrative and do not limit the scope of the invention as claimed. {\textbar} {\textbar} {METHODS} {\textbar} {\textbar} Preprocessing {\textbar} {\textbar} After receiving the data, the format of the data can be converted (e.g., change of file format). The data can be further processed to remove measurement artifacts (e.g., due to eye blinks or scalp muscle movements), and filter it. In addition or alternatively, independent component analyses ({ICA}) can be performed. {ICA} is a process that allows one to decompose the recorded {EEG} data into functionally and spatially separated signals (Onton et al. (2006) {\textbar} {\textbar} Neurosci Biobehav Rev {\textbar} 30(6):808-822.); this can also serve to denoise the signals. The analytic techniques that follow can be applied to the filtered, artifact-free data, as well as the estimated sources as revealed by {ICA}. {\textbar} Power Spectrum Analysis {\textbar} {\textbar} Oscillatory activity at a number of different frequencies has been observed in human brain. These are conventionally divided into the slow frequency ranges of delta (1-3 cycles per second [Hz]) and theta (4-7 Hz); the intermediate frequencies, alpha (8-12 Hz) and beta (12-30 Hz); and the gamma band (40-80 Hz). {\textbar} {\textbar} Fourier analysis of an {EEG} signal produces a so-called power spectrum—that is, an indication of which frequencies are present, and their relative strength (or power). To our knowledge, this power spectrum analysis has never successfully been used to predict medication response, or to subcategorize schizophrenic subjects. {\textbar} {\textbar} In some instances, wavelet analysis can be used to analyze the {EEG} signal. The wavelet analysis is a methodology that provides similar information, but uses a rolling time window to determine frequencies present. This is particularly well suited for sets of shorter ({\textless}10 sec) data segments that can result after artifact removal. {\textbar} {\textbar} Power-Law Behavior {\textbar} {\textbar} The power spectrum of resting state {EEG} signals, when viewed in the frequency domain (that is, with frequency of oscillation on the x-axis and power on the y-axis), forms roughly a straight line, when viewed on a log-log plot; see {FIG}.5 (from Miller et al. (2019) {PLoS} Comput Biol 5(12): e1000609) {\textbar} {\textbar} Mathematically, this can be expressed as log (P)=k−βlog (f), or equivalently, P αf−β1/fβ), where P=power, f=frequency, −β is the slope of the fitted line, and k is a constant. This phenomenon is known by various terms, such as a “power law” spectrum or “1/f noise”. It is often referred to as “scale invariant” or “fractal” behavior (Lowen and Teich, 2005), as the power law exponent, β, is constant regardless of the resolution at which it is calculated. {\textbar} {\textbar} Treatment Response {\textbar} {\textbar} Response to treatment is determined by calculating change from baseline in key clinical outcome measures, as follows: {\textbar} {\textbar} Positive and Negative Symptom Scale ({PANS} S). Correlations are made up of the Positive subscale (which ranges from 7 to 49), the Negative subscale (7 to 49) the general psychopathology subscale (16 to 112), and the {PANNS} total score (30 to 210). {\textbar} {\textbar} Clinical Global Impression Severity Scale ({CGI}-S). This measures overall severity of subjects' symptoms and ranges from 1 to 7. {\textbar} {\textbar} 16-Item Negative Symptoms Assessment ({NSA}-16). Total score, ranging from 16 to 96, is used. {\textbar} {\textbar} Measurement and Treatment Research to Improve Cognition in Schizophrenia Consensus Cognitive Battery ({MCCB}). This assesses cognitive functioning in 7 domains (speed of processing, working memory, verbal leaning, visual learning, reasoning and problem solving, attention/vigilance, and social cognition). {\textbar} {\textbar} Personal and Social Performance ({PSP}) scale. Total score, which ranges to 100 and assesses four domains of functioning, is used. {\textbar} {\textbar} Example 1 {\textbar} {\textbar} Pomaglumetad methionil ({LY}-2140023, or “poma”) is an experimental glutamate receptor agonist which is an agonist at metabotropic ({mGluR}2/3) glutamate receptors, and has no known effects on dopamine receptors. Multiple phase {II} and {III} clinical trials suggested that while this agent may not be effective for subjects with schizophrenia as a whole, there may be particular subgroups for whom it is uniquely helpful. Our objective was to develop novel {EEG} biomarkers to identify subjects who are more likely to show a positive response to treatment with poma. Furthermore, we examined additional {EEG} measures—e.g., response to photic stimulation, magnitude of power law exponent ({PLE})—that, to our knowledge, have not been used in prior predictive studies. {\textbar} {\textbar} Methods {\textbar} {\textbar} This study used data from clinical trials {NCT}00845026 (N=117) and {NCT}01052103 (N=196), which studied male and female subjects with schizophrenia treated with poma vs. antipsychotic agent standard of care. {EEG} recordings were taken in the pre-treatment period using a standard 19-lead montage ( {\textbar} {\textbar} {FIG}. 4 {\textbar} ), both in the resting state and when subjects were exposed to photic stimulation (flashing light), at frequencies ranging from 1 to 30 Hz. We subjected resting {EEG} data to known power spectrum analysis to determine strength of activity in the delta (1-4 Hz), theta (4-7 Hz), alpha (8-13 Hz), beta (13-30 Hz), and gamma (30-80 Hz) frequency bands. We calculated only power at the stimulated frequency and, for recordings in the resting state, the power law exponent ({PLE}; also known as the “fractal exponent”). The power spectrum of resting state {EEG} signals, when viewed in the frequency domain—that is, with power graphed as a function of oscillatory frequency—often forms a roughly straight line when viewed on a log-log plot; the slope of the fitted line is the {PLE} (see {\textbar} {FIG}. 5 {\textbar} for example). We calculated all predictive measures for each {EEG} electrode. {\textbar} Response to poma treatment was operationalized as percentage change from baseline to trial endpoint on several clinical outcome measures, including the Positive and Negative Symptom Scale ({PANSS}), and the {MATRICS} Consensus Cognitive Battery ({MCCB}) and its seven individual cognitive domain scales. We performed statistical analysis to determine whether there was a significant relationship between any of our calculated {EEG} metrics in the pre-treatment condition and treatment outcomes. The positive symptom of the {PANNSS} can include delusions, conceptual disorganization, hallucinations, excitement, grandiosity, suspiciousness/persecution, hostility, and/or the like. The negative symptom of the {PANNSS} can include blunted affect, emotional withdrawal, poor rapport, passive/apathetic social withdrawal, difficulty in abstract thinking, lack of spontaneity and flow of conversation, stereotyped thinking, and/or the like. {\textbar} {\textbar} Results {\textbar} {\textbar} Surprisingly, we identified a number of pre-treatment {EEG} metrics that correlated with clinical outcomes and predict response to treatment with poma (Table 1A and Table 1B). {\textbar} {\textbar} {TABLE} 1A {\textbar} {\textbar} Photic Stimulation {\textbar} {\textbar} {EEG} {\textbar} {\textbar} Lead {\textbar} {\textbar} Brain Location {\textbar} Electrophys Behavior {\textbar} Clinical Domain {\textbar} {FIG}. {\textbar} r {\textbar} p-value {\textbar} 1 {\textbar} {\textbar} Fz {\textbar} center frontal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.319 {\textbar} 0.000042 {\textbar} 2 {\textbar} {\textbar} T3 {\textbar} left temporal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.339 {\textbar} 0.000013 {\textbar} 3 {\textbar} {\textbar} C4 {\textbar} right central {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.313 {\textbar} 0.000060 {\textbar} 4 {\textbar} {\textbar} Pz {\textbar} center parietal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.370 {\textbar} 0.000002 {\textbar} 5 {\textbar} {\textbar} P4 {\textbar} right parietal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.374 {\textbar} 0.000001 {\textbar} 6 {\textbar} {\textbar} T6 {\textbar} right rear temporal {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.385 {\textbar} 0.000001 {\textbar} 7 {\textbar} {\textbar} O1 {\textbar} left occipital {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.342 {\textbar} 0.000010 {\textbar} 8 {\textbar} {\textbar} O2 {\textbar} right occipital {\textbar} low gamma (30 Hz) {\textbar} attention-vigilance {\textbar} 6 {\textbar} 0.361 {\textbar} 0.000003 {\textbar} 9 {\textbar} {\textbar} T3 {\textbar} left temporal {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 6 {\textbar} 0.196 {\textbar} 0.024550 {\textbar} 10 {\textbar} {\textbar} T5 {\textbar} left rear temporal {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 7 {\textbar} 0.244 {\textbar} 0.004932 {\textbar} 11 {\textbar} {\textbar} P3 {\textbar} left parietal {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 7 {\textbar} 0.217 {\textbar} 0.012777 {\textbar} 12 {\textbar} {\textbar} Pz {\textbar} center parietal {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 7 {\textbar} 0.181 {\textbar} 0.038468 {\textbar} 13 {\textbar} {\textbar} O1 {\textbar} left occipital {\textbar} low beta (15 Hz) {\textbar} reasoning-problem solving {\textbar} 7 {\textbar} 0.210 {\textbar} 0.016154 {\textbar} {TABLE} 1B {\textbar} {\textbar} Resting State {\textbar} {\textbar} {EEG} {\textbar} {\textbar} Lead {\textbar} {\textbar} Brain Location {\textbar} Electrophys Behavior {\textbar} Clinical Domain {\textbar} {FIG}. {\textbar} r {\textbar} p-value {\textbar} 14 {\textbar} {\textbar} F3 {\textbar} left frontal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.275 {\textbar} 0.000996 {\textbar} 15 {\textbar} {\textbar} Fz {\textbar} center frontal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.253 {\textbar} 0.002556 {\textbar} 16 {\textbar} {\textbar} F4 {\textbar} right frontal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.309 {\textbar} 0.000204 {\textbar} 17 {\textbar} {\textbar} C3 {\textbar} left central {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.288 {\textbar} 0.000558 {\textbar} 18 {\textbar} {\textbar} C4 {\textbar} right frontal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.261 {\textbar} 0.001837 {\textbar} 19 {\textbar} {\textbar} T5 {\textbar} left temporal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.266 {\textbar} 0.001462 {\textbar} 20 {\textbar} {\textbar} P4 {\textbar} right parietal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.299 {\textbar} 0.000330 {\textbar} 21 {\textbar} {\textbar} T6 {\textbar} right rear temporal {\textbar} power law exponent {\textbar} working memory {\textbar} 8 {\textbar} 0.297 {\textbar} 0.000372 {\textbar} 22 {\textbar} {\textbar} T3 {\textbar} left temporal {\textbar} beta (22 Hz) {\textbar} attention-vigilance {\textbar} — {\textbar} 0.222 {\textbar} 0.003470 {\textbar} 23 {\textbar} {\textbar} C4 {\textbar} right central {\textbar} beta (16-25 Hz) {\textbar} reasoning-problem solving {\textbar} — {\textbar} 0.198 {\textbar} 0.020872 {\textbar} For example: (1) In the 30 Hz photically stimulated condition, there was a positive correlation between pre-treatment low gamma (30 Hz) activity in {EEG} lead T6 and post-treatment improvement in cognition, as measured by the attention-vigilance domain score of the {MCCB} (r=0.385, p=0.000001) (line 6 of Table 1A). Correlation coefficients ranged from 0.34 to 0.39 with similar levels of significance at other occipital and inferior leads ( {\textbar} {\textbar} {FIG}. 6 {\textbar} ). (2) In the 15 Hz photically stimulated condition, there was a positive correlation between pre-treatment low beta (15 Hz) activity at {EEG} lead T5 and post-treatment improvement in cognition, as measured by the reasoning-problem solving domain score of the {MCCB} (r=0.244, p=0.004932) (line 10 of Table 1A). Correlation coefficients ranged from 0.19 to 0.24, with similar significance levels, in other left tempo-parietal leads ( {\textbar} {FIG}. 7 {\textbar} ). (3) For left central electrode C3, there was a positive correlation between pre-treatment {PLE} and improvement in the working memory ({WM}) domain score of the {MCCB} (r=0.288, p=0.000558) (line 17 of Table 1B). Correlation coefficients of 0.25 to 0.31, with similar significance levels, were seen at other fronto-central leads ( {\textbar} {FIG}. 8 {\textbar} ). {\textbar} Taking this effect (pre-treatment {PLE} at left central electrode C3) as an example and using improvement in {WM} performance of 50\% as the definition of treatment response, receiver operator curve ({ROC}) analysis revealed that {PLE} at lead C3 could identify poma responders with a sensitivity of 0.750 and a specificity of 0.897 ({AUC}=0.809, p=0.039) ( {\textbar} {\textbar} {FIG}. 9 {\textbar} ). In all, 23 lead-level relationships were judged to have relatively high effect size and robust statistical significance, and thus potential clinical utility (Table 1A and Table 1B). Notably, all response variables that we identified involved improvement in cognitive functioning, rather than positive or negative symptoms or other measures of psychopathology. The positive {EEG} predictors did not occur in one particular cortical area. {\textbar} In sum, this data demonstrates there are subject subgroup(s) which shows unique benefit in terms of cognitive improvement, and that may be characterized by particular {EEG} “spectral fingerprints.” {\textbar} {\textbar} Example 2 {\textbar} {\textbar} We have identified individual {EEG}-based pre-treatment metrics that serve as a priori biomarkers of treatment outcome. The methodology described here could be applied to other psychoactive medications, beyond poma, and for a variety of conditions aside from schizophrenia, as these also may result in unique patterns of {EEG} activity in responders vs. non-responders that may be difficult to appreciate with known methods alone. In treatment settings, the ability to pinpoint likely medication responders, and therefore decrease time and resources devoted to pharmacologic trial and error would have clear value. Also, markers of the kind we have developed could be used to enrich subject samples for clinical trials, potentially resulting in smaller studies and shorter trials, and overall lower drug development costs. {\textbar} {\textbar} Example 3 {\textbar} {\textbar} The particular brain phenotype that is uniquely responsive to poma is characterized by a combination of the effects described in Examples 1 and 2. We have developed an artificial intelligence ({AI}) approach using deep learning artificial neural nets ({ANNs}) to identify such patterns. This methodology is well-suited to complex, non-linear, pattern recognition tasks with multiple inputs. The resultant “composite biomarker” takes into account all of the effects identified, and is a more robust predictor than any one singly. {\textbar} {\textbar} We propose to create a deep neural network consisting of four layers: an input layer of 23 nodes, each corresponding to one of the biomarkers of Table 1; two hidden layers—hidden layer one consisting of 33 nodes and the hidden layer two consisting of 7 nodes—and an output layer consisting of one node, representing “responder” when active, and “non-responder” when inactive. The model can be a four layer model and number of nodes in the first and second hidden layers layer can be: {\textbar} {\textbar} √\{square root over ((m+2)N)\}+2√\{square root over (N/(m+2))\} and m√\{square root over (N/(m+2))\} {\textbar} {\textbar} nodes, respectively, where m is the number of output neurons, and N is the number of samples to be learned. The transfer function to be used will be the so-called rectified linear unit ({ReLU}), (f(z)=max(z, 0)). {\textbar} {\textbar} Achieving optimal network architecture (e.g., number of layers, number of nodes per layer) can be approached as an optimization challenge. A number of different methodologies have been suggested to address this problem (Thomas and Suhner, 2015), such as the “evolutionary approach”, “constructive approach” or the “pruning approach” (which the method we have chosen to use). According to this approach, one begins with an oversized network. In the course of training, it may become clear that particular parameters are not being utilized (e.g., some connection weights go to zero or near-zero); these are then eliminated. While this approach can result in very effective networks, a downside is that this process can be computationally demanding. Given the 72 processor computer cluster that our lab owns, and that will be used to run these models, this is not a major consideration. If the pruning approach fails to produce adequate results, other model-construction approaches can be used: this is necessarily a trial-and-error process. {\textbar} {\textbar} Example 4 {\textbar} {\textbar} Our analysis (detailed in Examples 1-3, above) indicated that there are subgroups of patients that show significant improvement in cognitive function in measures of working memory, reasoning/problem solving, and attention/vigilance when given pomaglumetad methionil, and our methodology allows one to identify such subgroups. Significantly, the novel metrics we have developed which point to these functional subgroups make sense from neurocognitive standpoint. Because of this apparent preferential effect of pomaglumetad methionil, we propose a novel usage for this drug: as a nootropic, or memory enhancing, agent in normal (not psychiatrically ill) subjects. {\textbar} {\textbar} Pre-clinical studies of glutamate receptor agonists as agents that increase cognitive function are performed using pomaglumetad methionil ({LY}-2140023, or “poma”) as representative of the class as a whole. Results are extended to other agents by testing them in the same or similar animal models. Animal models used include those described in Dahhan et al. Front. Behay. Neurosci., 14 (2019) doi:10.3389/fnbeh.2019.00048 which is incorporated by reference herein. {\textbar} {\textbar} Testing of pomaglumetad methionil and other glutamate receptor agonists includes the following: {\textbar} {\textbar} Morris Water Task. This test is used to evaluate learning and memory in rodents. The apparatus consists of a water-filled pool with a hidden escape platform beneath the surface of the water. When the animal is released into the water, it seeks the platform to escape from the water. Spatial memory is separately assessed in a probe trial without the platform. {\textbar} {\textbar} Y Maze. This test to assesses spatial learning and memory. The spontaneous alteration test is used to assess hippocampal damage, quantify the cognitive deficits in transgenic mice, and evaluate the effects of drugs on cognition. The recognition memory test is used to test memory functions in mice. {\textbar} {\textbar} Radial Arm Maze. This test assesses reference memory and working memory. Animals are placed on the central platform of the radial arm maze and allowed to explore the maze for reinforcers (baits) placed at the end of each arm. Failure to visit the arms of the maze containing the reward is regarded as reference memory error. Failure to reenter the arms is regarded as a working memory error. {\textbar} {\textbar} Novel Object Recognition ({NOR})Task. The test evaluates the effect of drug candidates on short-term memory, intermediate-term memory, and long-term memory. It measures the amount of time for which animals must retain memory of the sample objects placed during the recognition phase before the test phase when one of the familiar objects is replaced by a novel one. {\textbar} {\textbar} Fear Conditioning Test. This test assesses associative fear learning and memory and may be used to evaluate a drug compounds' ability to reverse drug-induced deficits in memory. {\textbar} {\textbar} Passive Avoidance Test. This test is fear-motivated test to assess long-term memory based on negative reinforcement. Memory performance is assessed by recording the latency to escape from the white compartment. {\textbar} {\textbar} Elevated Plus Maze. This test is used to assess drugs affecting learning and memory. It uses transfer latency ({TL}) as a parameter for acquisition and retention of memory process. {\textbar} {\textbar} Example 5 {\textbar} {\textbar} Clinical studies of glutamate receptor agonists as agents that increase cognitive function are performed using pomaglumetad methionil ({LY}-2140023, or “poma”) as representative of the class as a whole. Clinical trial endpoints may include: {\textbar} {\textbar} Clinical Global Impression Severity Scale ({CGI}-S). Clinical Global Impression Severity Scale ({CGI}-S). This measures overall severity of patients' symptoms, and ranges from 1 to 7. {\textbar} {\textbar} 16-Item Negative Symptoms Assessment ({NSA}-16). Total score, ranging from 16 to 96, will be used. {\textbar} {\textbar} Measurement and Treatment Research to Improve Cognition in Schizophrenia Consensus Cognitive Battery ({MCCB}). This assesses cognitive functioning in 7 domains (speed of processing, working memory, verbal leaning, visual learning, reasoning and problem solving, attention/vigilance, and social cognition) {\textbar} {\textbar} Dose escalation studies are performed to identify effective amounts of the glutamate receptor agonist for each candidate agonist.
Issue: {US}20220313170A1},
}

@patent{kenyon_etal18,
	location = {{CN}},
	title = {Alertness prediction system and method},
	url = {https://www.derwentinnovation.com/tip-innovation/recordView.do?hideHighlightPanel=true&idType=uid/recordid&datasource=T3&databaseIds=PATENT&category=PAT&recordKeys=CN108697391A_20181023&TYPE=RECORDVIEW&fromExternalLink=true&fromLocation=external&isDAJImageAllowed=false},
	abstract = {The invention relates to alertness device for use in such a wearable device of the predicted bio-mathematical model, the model by collecting from the individual data to be monitored to generate the alertness level to more accurately estimate to improve the current fatigue and alertness prediction model. the bio-mathematical model can be a double process algorithm sleep-wake state and circadian rhythm. by using motion recorded measured values to improve the accuracy of sleep and wakefulness estimation in combination with far end skin and ambient light and heart rate measurements, sleep-awake state of the model can be improved. circadian rhythm model by using the distal end of skin, heart rate and body movement recording data to improve prediction and estimation of fatigue. sleep-wake state and circadian rhythm can be connected with additional objective and subjective measurements and information from the user are combined, to further improve accuracy of the estimation of alertness. {\textbar}   {\textbar} An alertness prediction bio-mathematical model for use in devices such as a wearable device that improves upon previous models of predicting fatigue and alertness by gathering data from the individual being monitored to create a more accurate estimation of alertness levels. The bio-mathematical model may be a two- process algorithm which incorporates a sleep-wake homeostasis aspect and a circadian rhythm aspect. The sleep-wake homeostasis aspect of the model is improved by using actigraphy measures in conjunction with distal skin, ambient light and heart rate measures to improve the accuracy of the sleep and wake estimations. The circadian rhythm model aspect improves fatigue prediction and estimation by using distal skin, heart rate and actigraphy data. The sleep-wake homeostasis and circadian rhythm aspects may also be combined with additional objective and subjective measures as well as information from a user to Improve the accuracy of the alertness estimation even further. {\textbar}   {\textbar} 本发明涉及一种用于在例如可穿戴设备的设备中使用的警觉性预测生物‑数学模型，该模型通过收集来自被监控的个人的数据以产生对警觉性水平更加准确的估计来改善现有的疲劳和警觉性预测模型。该生物‑数学模型可以是包含睡眠‑清醒稳态方面和昼夜节律方面的双进程算法。通过与远端皮肤、环境光线和心率测量值结合地使用体动记录测量值来改善睡眠和清醒估计的准确性，该模型的睡眠‑清醒稳态方面得到改善。昼夜节律模型方面通过使用远端皮肤、心率和体动记录数据来改善疲劳预测和估计。睡眠‑清醒稳态和昼夜节律方面还可与额外的客观和主观测量值以及来自使用者的信息相结合，以更进一步改善警觉性估计的准确性。
本发明涉及一种用于在例如可穿戴设备的设备中使用的警觉性预测生物‑数学模型，该模型通过收集来自被监控的个人的数据以产生对警觉性水平更加准确的估计来改善现有的疲劳和警觉性预测模型。该生物‑数学模型可以是包含睡眠‑清醒稳态方面和昼夜节律方面的双进程算法。通过与远端皮肤、环境光线和心率测量值结合地使用体动记录测量值来改善睡眠和清醒估计的准确性，该模型的睡眠‑清醒稳态方面得到改善。昼夜节律模型方面通过使用远端皮肤、心率和体动记录数据来改善疲劳预测和估计。睡眠‑清醒稳态和昼夜节律方面还可与额外的客观和主观测量值以及来自使用者的信息相结合，以更进一步改善警觉性估计的准确性。
The invention relates to alertness device for use in such a wearable device of the predicted bio-mathematical model, the model by collecting from the individual data to be monitored to generate the alertness level to more accurately estimate to improve the current fatigue and alertness prediction model. the bio-mathematical model can be a double process algorithm sleep-wake state and circadian rhythm. by using motion recorded measured values to improve the accuracy of sleep and wakefulness estimation in combination with far end skin and ambient light and heart rate measurements, sleep-awake state of the model can be improved. circadian rhythm model by using the distal end of skin, heart rate and body movement recording data to improve prediction and estimation of fatigue. sleep-wake state and circadian rhythm can be connected with additional objective and subjective measurements and information from the user are combined, to further improve accuracy of the estimation of alertness.},
	type = {patent},
	number = {{CN}108697391A},
	author = {Kenyon, Matt and Payne-Rogers, Colin and Jones, Josh},
	urldate = {2017-02-17},
	date = {2018-10-23},
	note = {Edition: A61B000516 {\textbar} A61B000500 {\textbar} A61B000501 {\textbar} A61B00050205 {\textbar} A61B000511 {CPC}  - A61B00054857 {\textbar} A61B00050022 {\textbar} A61B000501 {\textbar} A61B00050205 {\textbar} A61B000502055 {\textbar} A61B000511 {\textbar} A61B0005165 {\textbar} A61B000518 {\textbar} A61B00054809 {\textbar} A61B00057267 {\textbar} A61B00057275 {\textbar} A61B00057278 {\textbar} A61B00057282 {\textbar} G16H002000 {\textbar} G16H004063 {\textbar} G16H005020 {\textbar} G16H005030 {\textbar} G16H005050 {\textbar} A61B000502438 {\textbar} A61B00051118 {\textbar} A61B25600242 {EP}; {KR}; {US} 1.一种可穿戴设备，用于监控和预测个人的警觉性，所述可穿戴设备包括： {\textbar} 一个或更多个被配置为获得关于所述个人的信息信号的传感器，所述传感器包括以下 {\textbar}   {\textbar}  中的至少一种： {\textbar}   {\textbar} 被配置为产生所述个人的运动数据和/或身体姿势数据的运动传感器， {\textbar}   {\textbar} 被配置为产生所述个人的远端皮肤温度数据的温度传感器， {\textbar}   {\textbar} 和 {\textbar}   {\textbar} 被配置为产生所述个人的心率数据的心率监控器； {\textbar}   {\textbar} 存储器，该存储器被配置为存储： {\textbar}   {\textbar} 缺省昼夜节律，被配置为用从关于所述个人的所述信息信号得出的数据来进行精细化 {\textbar}   {\textbar}  以生成所述个人的估计的昼夜节律， {\textbar}   {\textbar} 生物-数学模型，被配置为生成所述个人的疲劳分数； {\textbar}   {\textbar} 处理器，该处理器联接到所述一个或更多个传感器和所述存储器并被配置为： {\textbar}   {\textbar} 接收关于所述个人的信息信号，所述信息信号包括运动数据、姿势数据、远端皮肤温度 {\textbar}   {\textbar}  数据或心率数据中的至少一种， {\textbar}   {\textbar} 通过引入关于所述个人的信息信号以精细化所述缺省昼夜节律，来估计所述个人的昼 {\textbar}   {\textbar}  夜节律， {\textbar}   {\textbar} 从关于所述个人的信息信号和所估计的昼夜节律中提取特征， {\textbar}   {\textbar} 对所提取的特征应用至少一种模式识别算法或机器学习算法， {\textbar}   {\textbar} 使用该至少一种模式识别算法或机器学习算法来从所提取的特征中提取至少一个系 {\textbar}   {\textbar}  数， {\textbar}   {\textbar} 对提取的所述至少一个系数应用生物-数学模型，以及 {\textbar}   {\textbar} 使用所述生物-数学模型由提取的所述至少一个系数生成所述个人的疲劳分数；以及 {\textbar}   {\textbar} 支承件，该支承件被配置为在所述个人身上支承所述一个或更多个传感器、所述存储 {\textbar}   {\textbar}  器和所述处理器。 {\textbar}   {\textbar} 2.如权利要求1所述的可穿戴设备，其中，所述生物-数学模型是一种双进程算法，该双 {\textbar}  进程算法被配置为使用睡眠-清醒稳态评估和所估计的昼夜节律来预测所述个人的警觉性 {\textbar}   {\textbar}  水平，并且其中，所述处理器还被配置为： {\textbar}   {\textbar} 使用所述运动数据和/或身体姿势数据来进行体动记录确定， {\textbar}   {\textbar} 基于所述体动记录确定，使用所述双进程算法来评估所述个人的睡眠-清醒稳态，包括 {\textbar}   {\textbar}  睡眠和清醒时期，以及 {\textbar}   {\textbar} 根据所述双进程算法，将所述睡眠-清醒稳态评估和所估计的昼夜节律结合到所述个 {\textbar}   {\textbar}  人的疲劳分数的生成中。 {\textbar}   {\textbar} 3.如权利要求2所述的可穿戴设备，其中，所述处理器还被配置为： {\textbar} 使用所述远端皮肤温度数据或所述心率数据中的至少一种来精细化所述体动记录确 {\textbar}   {\textbar}  定，以及 {\textbar}   {\textbar} 进而基于经过精细化的体动记录确定，评估所述个人的睡眠-清醒稳态。 {\textbar}   {\textbar} 4.如权利要求1所述的可穿戴设备，其中，所述至少一个系数包括昼夜节律系数(Φ)、 {\textbar}  清醒/睡眠系数(T)、昼夜节律加权系数或清醒/睡眠加权系数中的至少一个。 {\textbar}   {\textbar} 5.如权利要求1所述的可穿戴设备，其中，所述处理器还被配置为： {\textbar} 通过使用信号处理技术来处理关于所述个人的所述信息信号； {\textbar}   {\textbar} 将经过处理的信息信号引入到对所述个人的昼夜节律的估计中；以及 {\textbar}   {\textbar} 将经过处理的信息信号引入到对所述特征的提取中。 {\textbar}   {\textbar} 6.如权利要求1所述的可穿戴设备，其中，所述处理器还被配置为： {\textbar} 获得关于所述个人的运动和/或姿势的信息信号； {\textbar}   {\textbar} 使用关于所述个人的运动的信息信号来确定所述个人的体动记录数据； {\textbar}   {\textbar} 对所述体动记录数据应用所述生物-数学模型，其中，所述生物-数学模型选自清醒生 {\textbar}   {\textbar}  物-数学子模型和睡眠生物-数学子模型中的一个；以及 {\textbar}   {\textbar} 将所述体动记录数据引入到所述个人的疲劳分数的生成中。 {\textbar}   {\textbar} 7.如权利要求6所述的可穿戴设备，其中，所述处理器还被配置为使用关于所述个人的 {\textbar}  远端皮肤温度或所述个人的心率的信息信号中的至少一个来精细化所述体动记录数据。 {\textbar}   {\textbar} 8.如权利要求1所述的可穿戴设备，其中，所提取的特征包括以下中的一个或更多个： {\textbar}  指示所述个人的昼夜节律的形状的标记；关于所述个人在工作日和空闲日的睡眠习惯的信 {\textbar}   {\textbar}  息；以及，关于所述个人的一般性医疗信息。 {\textbar}   {\textbar} 9.如权利要求1所述的可穿戴设备，其中，所述处理器还被配置为在关于所述个人的个 {\textbar}  人参数被输入所述可穿戴设备时将所述个人参数引入到对所述特征的提取中。 {\textbar}   {\textbar} 10.如权利要求1所述的可穿戴设备，其中，所述处理器还被配置为： {\textbar} 识别关于所述个人的所述信息信号中的原始昼夜节律数据； {\textbar}   {\textbar} 识别所述原始昼夜节律数据中的由非昼夜节律事件导致的非昼夜节律数据； {\textbar}   {\textbar} 从所述原始昼夜节律数据中去除所述非昼夜节律数据以获得经过精细化的昼夜节律 {\textbar}   {\textbar}  数据；以及 {\textbar}   {\textbar} 将所述经过精细化的昼夜节律数据引入到对所述个人的昼夜节律的估计中。 {\textbar}   {\textbar} 11.如权利要求1所述的可穿戴设备，其中，所述可穿戴设备的所述传感器被配置为收 {\textbar}  集关于所述个人的环境的环境信息信号，所述环境信息信号包括环境光线水平数据或环境 {\textbar}   {\textbar}  温度数据中的至少一种，并且其中，所述处理器还被配置为将所述环境信息信号引入到对 {\textbar}   {\textbar}  所述昼夜节律的估计中。 {\textbar}   {\textbar} 12.如权利要求11所述的可穿戴设备，其中： {\textbar} 所述设备的所述传感器还包括环境光线传感器，所述环境光线传感器被配置为由所述 {\textbar}   {\textbar}  个人周围的环境光线产生环境光线数据； {\textbar}   {\textbar} 所述处理器联接到所述环境光线传感器； {\textbar}   {\textbar} 并且其中，所述处理器还被配置为通过引入所述环境光线数据用所述生物-数学模型 {\textbar}   {\textbar}  来精细化所述昼夜节律估计。 {\textbar}   {\textbar} 13.如权利要求11所述的可穿戴设备，其中，所述温度传感器还被配置为由所述个人周 {\textbar}  围的环境温度产生环境温度数据，并且其中，所述处理器还被配置为通过引入所述环境温 {\textbar}   {\textbar}  度数据用所述生物-数学模型来精细化所述昼夜节律估计。 {\textbar}   {\textbar} 14.一种用于生成个人的疲劳分数的方法，该方法包括： {\textbar} 用可穿戴设备的传感器获得关于所述个人的信息信号，所述信息信号包括运动、姿势、 {\textbar}   {\textbar}  远端皮肤温度或心率中的至少一种； {\textbar}   {\textbar} 用所述可穿戴设备的处理器来由关于所述个人的所述信息信号估计所述个人的昼夜 {\textbar}   {\textbar}  节律； {\textbar}   {\textbar} 用所述处理器从关于所述个人的所述信息信号和所估计的昼夜节律提取特征； {\textbar}   {\textbar} 用所述处理器对所提取的特征应用至少一个模式识别算法或机器学习算法； {\textbar}   {\textbar} 用所述处理器并用所述至少一个模式识别算法或机器学习算法，从所提取的特征提取 {\textbar}   {\textbar}  至少一个系数； {\textbar}   {\textbar} 用所述处理器对所提取的系数应用生物-数学模型；以及 {\textbar}   {\textbar} 用所述处理器并用所述生物-数学模型，由所提取的系数生成所述个人的疲劳分数。 {\textbar}   {\textbar} 15.如权利要求14所述的方法，其中，所述方法还包括： {\textbar} 用所述处理器，通过使用信号处理技术，处理关于所述个人的所述信息信号； {\textbar}   {\textbar} 用所述处理器，将经过处理的信息信号引入到对所述个人的昼夜节律的估计中；以及 {\textbar}   {\textbar} 用所述处理器，将经过处理的信息信号引入到对所述特征的提取中。 {\textbar}   {\textbar} 16.如权利要求14所述的方法，其中，所述可穿戴设备的所述传感器被配置为： {\textbar} 收集关于所述个人的环境的环境信息信号，所述环境信息信号包括环境光线水平或环 {\textbar}   {\textbar}  境温度中的至少一种；以及 {\textbar}   {\textbar} 用所述处理器，将所述环境信息信号引入到对所述个人的昼夜节律的估计中。 {\textbar}   {\textbar} 17.如权利要求14所述的方法，其中，所述方法还包括： {\textbar} 用所述处理器，识别关于所述个人的所述信息信号中的原始昼夜节律数据； {\textbar}   {\textbar} 用所述处理器，识别所述原始昼夜节律数据中的由非昼夜节律事件导致的非昼夜节律 {\textbar}   {\textbar}  数据； {\textbar}   {\textbar} 用所述处理器，从所述原始昼夜节律数据中去除所述非昼夜节律数据，以获得经过精 {\textbar}   {\textbar}  细化的昼夜节律数据；以及 {\textbar}   {\textbar} 用所述处理器，将经过精细化的昼夜节律数据引入到对所述个人的昼夜节律的估计 {\textbar}   {\textbar}  中。 {\textbar}   {\textbar} 18.如权利要求14所述的方法，其中，所述方法还包括： {\textbar} 将关于所述个人的个人参数输入到所述可穿戴设备；以及 {\textbar}   {\textbar} 用所述处理器，将所述个人参数引入到对所述特征的提取中。 {\textbar}   {\textbar} 19.如权利要求14所述的方法，其中，所述至少一个系数包括昼夜节律系数、清醒/睡眠 {\textbar}  系数、昼夜节律加权系数或清醒/睡眠加权系数中的至少一个。 {\textbar}   {\textbar} 20.如权利要求14所述的方法，其中，所述方法还包括： {\textbar} 用所述可穿戴设备的运动传感器，获得关于所述个人的运动/或姿势的信息信号； {\textbar}   {\textbar} 用所述处理器，使用关于所述个人的运动的所述信息信号确定所述个人的体动记录数 {\textbar}   {\textbar}  据； {\textbar}   {\textbar} 用所述处理器，对所述体动记录数据应用所述生物-数学模型， {\textbar}   {\textbar} 其中，所述生物-数学模型选自清醒生物-数学子模型和睡眠生物-数学子模型中的一 {\textbar}   {\textbar}  个；以及 {\textbar}   {\textbar} 用所述处理器，将所述体动记录数据引入到所述个人的疲劳分数的生成中。 {\textbar}   {\textbar} 21.如权利要求20所述的方法，其中，所述方法还包括： {\textbar} 用所述处理器，使用关于所述个人的远端皮肤温度或所述个人的心率的信息信号中的 {\textbar}   {\textbar}  至少一个来精细化所述体动记录数据。 {\textbar}   {\textbar} 22.如权利要求20所述的方法，其中，所述方法还包括： {\textbar} 用所述处理器并用所述体动记录数据，确定所述个人是清醒还是在睡觉。 {\textbar}   {\textbar} 23.如权利要求22所述的方法，其中，所述方法还包括： {\textbar} 当所述处理器确定所述个人清醒时，用所述处理器选择所述清醒生物-数学子模型。 {\textbar}   {\textbar} 24.如权利要求22所述的方法，其中，所述方法还包括： {\textbar} 当所述处理器确定所述个人在睡觉时，用所述处理器选择所述睡眠生物-数学子模型。 {\textbar}   {\textbar} 25.如权利要求14所述的方法，其中，所提取的特征包括以下中的一个或更多个：指示 {\textbar}  所述个人的昼夜节律的形状的标记；关于所述个人在工作日和空闲日的睡眠习惯的信息； {\textbar}   {\textbar}  以及，关于所述个人的一般性医疗信息。 1. A wearable device for alertness monitoring and predicting individual, the wearable device comprising: one or more configured to obtain sensor information about the signal of the individual, at least one said sensor comprises of the following: is configured to generate movement data of the individual and/or body posture data of the motion sensor is configured to generate a far end skin temperature data of the individual temperature sensor, and is configured to generate a heart rate monitor of heart rate data of the person; a memory, the memory being configured to store default circadian rhythm, is configured to be used from the information signal about the personal data to carry out fine to generate estimates of the individual circadian, bio-mathematical model, configured to generate the personal fatigue score, a processor, the processor coupled to the one or more sensors and the memory and configured to: receive information about the signal of the individual, the information signal comprises the movement data. gesture data, distal end skin temperature data or heart rate data from at least one of, by introducing the information signal about the individual to refine the default circadian rhythm, to estimate the circadian rhythm of the individual, from the information signal about the individual and the estimated rhythm extraction features, the extracted characteristic using at least one pattern recognition algorithm or machine learning algorithm, using the at least one pattern recognition algorithm or machine learning algorithm from the extracted feature extracted from at least one coefficient. the extracted said at least one coefficient bio-mathematical model, and using the mathematical model of the extracted at least one coefficient generating fatigue scores of the individual, and a support member, the support member is configured to support the one or more sensors on the individual body, the memory and the processor. {\textbar} 2. The wearable device according to claim 1, wherein the bio-mathematical model is a double process algorithm, the double process algorithm is configured to use the sleep-wake state estimation and the estimated rhythm to predict alertness level of the individual, and wherein the processor is further configured to use the motion data and/or body posture data to record the motion is determined based on the movement record is determined using the dual process algorithm to evaluate the sleep-wake state of the individual. a sleep and awake period, and according to the process algorithm, the sleep-awake state estimation and the estimated rhythm generated by combining the fatigue score of the individual. {\textbar} 3. The method according to claim 2, the wearable device, wherein the processor is further configured to use the skin temperature data of at least one of the distal end or the heart rate data refinement of the motion recording determination, and further based on the refinement of the motion recording determination, evaluating sleep-wake state of the individual. {\textbar} 4. The wearable device according to claim 1, wherein the at least one coefficient comprises circadian rhythm coefficient (Φ), awake/sleep coefficient (T), circadian rhythm weighting coefficient or awake/sleep weighting coefficient in the at least one. {\textbar} 5. The wearable device according to claim 1, wherein the processor is further configured by using signal processing techniques to process the information signal about the person, the processed information signal into an estimate of the circadian rhythm of the individual, and the information signal which has been processed into the extraction of the features. {\textbar} 6. The wearable device according to claim 1, wherein the processor is further configured to: obtain motion about the personal and/or posture information signal using the information signal related to the movement of the individual to determine the movement record data of the individual; applying the bio-mathematical model of the movement record data, wherein said bio-mathematical model is selected from awake-to-digital sub-model and sleep-to-digital sub-model in one, and the movement record data into the generated to fatigue scores of the individual. {\textbar} 7. The method according to claim 6, the wearable device, wherein the processor is further configured to at least one of the heart about the distal end of the individual skin temperature or the personal information signal refinement in the movement record data. {\textbar} 8. The wearable device according to claim 1, wherein the extracted features comprise one or more of the following: indicating circadian rhythm of the individual shape of the mark regarding the personal day and idle sleep habit information, and general medical information about the person. {\textbar} 9. The wearable device according to claim 1, wherein the processor is further configured to, with respect to personal parameters of the person is input to the wearable device the personal parameters into the extraction of the features. {\textbar} 10. The wearable device according to claim 1, wherein the processor is further configured to: identify the original rhythm data of the information signal with respect to the individual; identifying the original rhythm data of non circadian rhythm data caused by non-circadian rhythm event from the original rhythm data obtained by removing the non circadian rhythm data refinement of the rhythm data, and the refinement of the circadian rhythm data into the estimate of the circadian rhythm of the individual. {\textbar} 11. The wearable device according to claim 1, wherein the sensor of the wearable device is configured to collect environmental information signal related to the environment of the individual, the environment information signal comprises an ambient light level data or environment temperature data from at least one of, and, wherein the processor is further configured to transmit the environment information signal into the estimate of the circadian rhythm. {\textbar} 12. The wearable device according to claim 11, wherein the sensor of said device further comprises an ambient light sensor, the ambient light sensor is configured to generate ambient light data from ambient light around the personal, the processor coupled to the ambient light sensor, and wherein the processor is further configured to pass into the ambient light data with said bio-mathematical model to refine the estimate the circadian rhythm. {\textbar} 13. The wearable device according to claim 11, wherein the temperature sensor is further configured to be driven by the ambient temperature of the individual generated around ambient temperature data, and wherein the processor is further configured to pass into the environmental temperature data to fine the circadian rhythm for the bio-mathematical model estimate. {\textbar} 14. A method for generating personal fatigue scores of the method, the method comprising: a sensor of the wearable device for obtaining signal information about the individual, the information signal comprises the movement, posture, distal end at least one skin temperature or heart rate, the processor of the wearable device by said information signal about the personal estimate the circadian rhythm of the individual, with the processor from the information about the individual signal and the estimated rhythm extracting characteristic; using the processor to the extracted feature application at least one pattern recognition algorithm or machine learning algorithm, using the processor and the at least one pattern recognition algorithm or machine learning algorithm, extracting at least one coefficient from the extracted feature, using the processor the extracted coefficient bio-mathematical model, and using said processor and said bio-mathematical model, by the extracted coefficient generating fatigue score of the individual. {\textbar} 15. The method according to claim 14, wherein the method further comprises: using the processor, by using signal processing techniques, processing with respect to the information signal of the person, using the processor, the processed information signal into an estimate of the circadian rhythm of the individual, and using the processor, the processed information signal is brought to the extraction of the features. {\textbar} 16. The method according to claim 14, wherein the sensor of the wearable device is configured to collect environmental information signal related to the environment of the person, the environment information signal comprises ambient light levels or ambient temperature of at least one, and using the processor, converting the environment information signal into an estimate of the circadian rhythm of the individual. {\textbar} 17. The method according to claim 14, wherein the method further comprises: using the processor, identify the original rhythm data of the information signal with respect to the individual, using the processor. identifying non circadian rhythm data in the original rhythm data caused by non-circadian rhythm event; removing the non circadian rhythm by the processor, data from the original rhythm data, to obtain a refined circadian rhythm data, and using said processor; the refined circadian rhythm data into the estimate of the circadian rhythm of the individual. {\textbar} 18. The method according to claim 14, wherein the method further comprises: the personal parameters about the individual input to the wearable device, and using the processor, the personal parameters into the extraction of the features. {\textbar} 19. The method according to claim 14, wherein the at least one coefficient comprises circadian rhythm coefficients, awake/sleep, circadian rhythm weighting coefficients or awake/sleep weighting coefficient in the at least one. {\textbar} 20. The method according to claim 14, wherein the method further comprises: using a motion sensor of the wearable device to obtain the information signal related to movement and/or posture of the person, using the processor; the information signal using the motion of the person determining the movement record data of the person, the processor applying the bio-mathematical model of the movement record data, wherein said bio-mathematical model selected from awake one bio-digital sub-model and sleep-to-digital sub-model; and using the processor, generated in the movement record data to fatigue score of the individual. {\textbar} 21. The method according to claim 20, wherein the method further comprises: at least one of the processor, using heart rate about the distal end of the individual skin temperature or the personal information signal refinement in the movement record data. {\textbar} 22. The method according to claim 20, wherein the method further comprises: using the processor and the motion record data for determining the individual is awake or sleeping. {\textbar} 23. The method according to claim 22, wherein the method further comprises: when the processor determines the individual is awake, the processor selects the number of awake-sub-model. {\textbar} 24. The method according to claim 22, wherein the method further comprises: when the processor determines that the individual when sleeping with the processor selecting the sleep-to-digital sub-model. {\textbar} 25. The method according to claim 14, wherein the extracted features comprise one or more of the following: indication mark of the shape of circadian rhythm of the individual regarding the individual day and idle sleep habit information, and general medical information about the person. 1.一种可穿戴设备，用于监控和预测个人的警觉性，所述可穿戴设备包括： {\textbar} 一个或更多个被配置为获得关于所述个人的信息信号的传感器，所述传感器包括以下 {\textbar}   {\textbar}  中的至少一种： {\textbar}   {\textbar} 被配置为产生所述个人的运动数据和/或身体姿势数据的运动传感器， {\textbar}   {\textbar} 被配置为产生所述个人的远端皮肤温度数据的温度传感器， {\textbar}   {\textbar} 和 {\textbar}   {\textbar} 被配置为产生所述个人的心率数据的心率监控器； {\textbar}   {\textbar} 存储器，该存储器被配置为存储： {\textbar}   {\textbar} 缺省昼夜节律，被配置为用从关于所述个人的所述信息信号得出的数据来进行精细化 {\textbar}   {\textbar}  以生成所述个人的估计的昼夜节律， {\textbar}   {\textbar} 生物-数学模型，被配置为生成所述个人的疲劳分数； {\textbar}   {\textbar} 处理器，该处理器联接到所述一个或更多个传感器和所述存储器并被配置为： {\textbar}   {\textbar} 接收关于所述个人的信息信号，所述信息信号包括运动数据、姿势数据、远端皮肤温度 {\textbar}   {\textbar}  数据或心率数据中的至少一种， {\textbar}   {\textbar} 通过引入关于所述个人的信息信号以精细化所述缺省昼夜节律，来估计所述个人的昼 {\textbar}   {\textbar}  夜节律， {\textbar}   {\textbar} 从关于所述个人的信息信号和所估计的昼夜节律中提取特征， {\textbar}   {\textbar} 对所提取的特征应用至少一种模式识别算法或机器学习算法， {\textbar}   {\textbar} 使用该至少一种模式识别算法或机器学习算法来从所提取的特征中提取至少一个系 {\textbar}   {\textbar}  数， {\textbar}   {\textbar} 对提取的所述至少一个系数应用生物-数学模型，以及 {\textbar}   {\textbar} 使用所述生物-数学模型由提取的所述至少一个系数生成所述个人的疲劳分数；以及 {\textbar}   {\textbar} 支承件，该支承件被配置为在所述个人身上支承所述一个或更多个传感器、所述存储 {\textbar}   {\textbar}  器和所述处理器。 1. A wearable device for alertness monitoring and predicting individual, the wearable device comprising: one or more configured to obtain sensor information about the signal of the individual, at least one said sensor comprises of the following: is configured to generate movement data of the individual and/or body posture data of the motion sensor is configured to generate a far end skin temperature data of the individual temperature sensor, and is configured to generate a heart rate monitor of heart rate data of the person; a memory, the memory being configured to store default circadian rhythm, is configured to be used from the information signal about the personal data to carry out fine to generate estimates of the individual circadian, bio-mathematical model, configured to generate the personal fatigue score, a processor, the processor coupled to the one or more sensors and the memory and configured to: receive information about the signal of the individual, the information signal comprises the movement data. gesture data, distal end skin temperature data or heart rate data from at least one of, by introducing the information signal about the individual to refine the default circadian rhythm, to estimate the circadian rhythm of the individual, from the information signal about the individual and the estimated rhythm extraction features, the extracted characteristic using at least one pattern recognition algorithm or machine learning algorithm, using the at least one pattern recognition algorithm or machine learning algorithm from the extracted feature extracted from at least one coefficient. the extracted said at least one coefficient bio-mathematical model, and using the mathematical model of the extracted at least one coefficient generating fatigue scores of the individual, and a support member, the support member is configured to support the one or more sensors on the individual body, the memory and the processor. 警觉性预测系统和方法 {\textbar}   {\textbar} 对相关申请的交叉引用 {\textbar}   {\textbar} 本申请要求题为“警觉性预测算法”、于2016年2月18日提交的、序列号为62/296, {\textbar}   {\textbar}  800的美国临时申请(Atty.Doc.No.{TVC}-141USP)和题为“警觉性预测系统和方法”、于2016 {\textbar}   {\textbar}  年12月12日提交的、序列号为62/432,977的美国临时申请(Atty.Doc.No.{TVC}-141USP1)的 {\textbar}   {\textbar}  优先权，这些申请每个的内容通过引用完全包括在本说明书中。 {\textbar}   {\textbar} 背景技术 {\textbar}   {\textbar} 个人警觉性的不受控制的下降是一个日益令人担忧的问题，在某些领域的后果正 {\textbar}   {\textbar}  在接近泛滥的程度。例如，估计每天有25万名驾驶员在驾驶时睡着。严重和致命的卡车、公 {\textbar}   {\textbar}  交车、火车和机动车事故正在以令人惊恐的频率发生。制造工厂中的许多受伤和事故与疲 {\textbar}   {\textbar}  劳有关。监控警觉性的目的在于防止发生这些和其它紧急情况，而不是事后处理。例如，在 {\textbar}   {\textbar}  驾驶时已经睡着之后再叫醒就已经太迟了。 {\textbar}   {\textbar} 过去，用于预测或估计个人警觉性的算法基于经常称作的双进程模型。该双进程 {\textbar}   {\textbar}  模型由昼夜节律进程和睡眠-清醒稳态模型组成。该模型的昼夜节律方面通常仅基于一标 {\textbar}   {\textbar}  准时间周期(例如：23-25小时)。另一方面，睡眠-清醒稳态模型则通常仅基于体动记录仪的 {\textbar}   {\textbar}  确定结果。 {\textbar}   {\textbar} 双进程算法模型的当前形式的一个缺陷在于，该形式基于从小样本集合收集的数 {\textbar}   {\textbar}  据来概括其对警觉性的预测。该算法无法对其拟用于的个人进行个性化设置。 {\textbar}   {\textbar} 发明内容 {\textbar}   {\textbar} 本发明的各方面旨在通过收集来自于被监控的个人的数据以产生对该个人的警 {\textbar}   {\textbar}  觉性水平更准确的估计来改善现有的疲劳和警觉性水平预测模型。可在可穿戴设备中引入 {\textbar}   {\textbar}  一算法或生物-数学模型，以便基于主观和客观测量值的组合来检测、预测和/或估计个人 {\textbar}   {\textbar}  的警觉性。 {\textbar}   {\textbar} 根据本发明一个方面的一个算法性生物-数学模型涉及包含睡眠-清醒稳态确定 {\textbar}   {\textbar}  和昼夜节律估计的双进程算法。可通过在远端皮肤、环境光线和心率测量值以外还使用体 {\textbar}   {\textbar}  动记录测量值来改善该模型的睡眠-清醒稳态方面，从而改善对于该个人的睡眠和清醒确 {\textbar}   {\textbar}  定的准确性。可通过将远端皮肤、心率和体动记录数据相结合来改善疲劳预测和估计的昼 {\textbar}   {\textbar}  夜节律模型。该昼夜节律估计产生更加准确的模型，该模型能够捕捉使用者的警觉性水平 {\textbar}   {\textbar}  在下午中段的下降和在傍晚的提升。睡眠-清醒稳态和昼夜节律模型也可与额外的客观和 {\textbar}   {\textbar}  主观测量值以及由使用者提供的信息相结合，以更进一步改善估计的准确性。 {\textbar}   {\textbar} 根据本发明一些方面的其它生物-数学模型可使用各种度量来生成预测个人的警 {\textbar}   {\textbar}  觉性的疲劳分数。在本说明书中描述的生物-数学模型和包含这些生物-数学模型的设备、 {\textbar}   {\textbar}  系统和方法可在关注个人的警觉性的情境中使用。生物-数学模型可作为应用存在于独立 {\textbar}   {\textbar}  设备(例如可穿戴设备)上或另一软件环境中。所关注的度量中的某些或全部可被收集并提 {\textbar}   {\textbar}  供给生物-数学模型以产生与个人的警觉性水平关联的输出。 {\textbar}   {\textbar} 现有的用于估计或预测个人的警觉性水平的系统和算法模型可用个人样本集合 {\textbar}   {\textbar}  来训练，包含不多的昼夜节律估计反馈或不包含昼夜节律估计反馈。这会产生个人的实际 {\textbar}   {\textbar}  昼夜节律的非常不准确的模型，并由于简单且概括性的正弦形而经常漏掉对已知的昼夜节 {\textbar}   {\textbar}  律事件(例如下午中段的困倦和傍晚的清醒)的预测。然而，在本说明书中描述的创造性设 {\textbar}   {\textbar}  备、系统和生物-数学模型随着模型根据个人的昼夜节律进行调整而持续改善其准确性。所 {\textbar}   {\textbar}  提出的模型可对个人个性化，而其它系统则是对数据样本集合的概括。 {\textbar}   {\textbar} 附图说明 {\textbar}   {\textbar} 以下详细说明，当结合附图阅读时，可最好地理解本发明，在附图中相似元件具有 {\textbar}   {\textbar}  相同的附图标记。当存在多个类似元件时，可能给该多个类似元件配上一个附图标记数字， {\textbar}   {\textbar}  并用小写字母指示表示特定元件。当同时提及这些元件或提及这些元件中的非特定的一个 {\textbar}   {\textbar}  或更多个时，可能会省略该小写字母指示。在此强调，根据惯例，附图的各个特征不是按比 {\textbar}   {\textbar}  例绘制的。相反地，为了显示清楚，各个特征的尺寸是随意放大或缩小的。附图中包括以下 {\textbar}   {\textbar}  图： {\textbar}   {\textbar} 图1是根据本发明一些方面的可穿戴设备的框图； {\textbar}   {\textbar} 图2是描绘根据本发明一些方面的个人昼夜节律与睡眠-清醒稳态(稳态睡眠欲 {\textbar}   {\textbar}  望)的相互作用的图； {\textbar}   {\textbar} 图3是描绘根据本发明一些方面的个人昼夜节律中的示例性事件或特征的图； {\textbar}   {\textbar} 图4是根据本发明一些方面的与外部设备通讯的包括本文所述可穿戴设备的系统 {\textbar}   {\textbar}  的框图； {\textbar}   {\textbar} 图5是根据本发明一些方面的预测使用者的警觉性的步骤的流程图； {\textbar}   {\textbar} 图6是根据本发明一些方面的用于实施图5的概念的示例性方法的流程图； {\textbar}   {\textbar} 图7是来自根据本发明一些方面的生物-数学模型的警觉性预测输出结果的图； {\textbar}   {\textbar} 图8是根据本发明一些方面的用于估计疲劳的示例性方法的流程图； {\textbar}   {\textbar} 图9A是可在图8的方法中提取的第一系数的图； {\textbar}   {\textbar} 图9B是可在图8的方法中提取的第二系数的图； {\textbar}   {\textbar} 图9C是可在图8的方法中提取的第三系数的图； {\textbar}   {\textbar} 图9D是可在图8的方法中提取的第四系数的图。 {\textbar}   {\textbar} 具体实施方式 {\textbar}   {\textbar} 本发明的一些方面提供一种可穿戴设备，该可穿戴设备具有使用各种度量来预测 {\textbar}   {\textbar}  个人的疲劳水平的生物-数学模型。某些方面涉及一种双进程算法(这是一种生物-数学模 {\textbar}   {\textbar}  型)，该算法通过使用准确的体动记录测量值和对个人的昼夜节律的估计来预测警觉性水 {\textbar}   {\textbar}  平。该可穿戴设备还可连接到其它系统(例如：智能手机应用或其它“智能”设备)或与其通 {\textbar}   {\textbar}  讯。体动记录和昼夜节律估计两者都可通过使用对个人的运动、身体姿势、心率和远端皮肤 {\textbar}   {\textbar}  温度的测量来实现。可通过添加在本说明书中更详细说明的额外的客观和主观测量值来进 {\textbar}   {\textbar}  一步改善生物-数学模型对警觉性的预测的准确性。由于闭环反馈并通过持续学习和监控， {\textbar}   {\textbar}  生物-数学模型能够进行改善。 {\textbar}   {\textbar} 图1描绘了可穿戴设备100，该可穿戴设备用于监控个人疲劳和给例如穿戴该设备 {\textbar}   {\textbar}  100的个人和/或其它个体提供对该个人的警觉性水平的预测。在美国专利申请14/848,771 {\textbar}   {\textbar}  中描述了一种合适的可穿戴设备。所示出的可穿戴设备100被实现成带子102，该带子可例 {\textbar}   {\textbar}  如放置在个人的手腕上。带子102支承至少一个运动传感器104和至少一个用于监控所述个 {\textbar}   {\textbar}  人的生物度量的生物度量传感器模块105。生物度量传感器模块105可包括皮肤温度传感器 {\textbar}   {\textbar}  105a或心率监控器105b中的至少一种。本领域技术人员由本说明书的说明将理解与本发明 {\textbar}   {\textbar}  一起使用的合适的运动传感器104和生物度量传感器模块105。 {\textbar}   {\textbar} 运动传感器104可包括一个或更多个回转仪和/或加速度计以跟踪(线性、角度等 {\textbar}   {\textbar}  的)运动。被监控或跟踪的运动可包括使用者的规定运动、使用者在规定运动之外的其它运 {\textbar}   {\textbar}  动、使用者的相对运动、或由使用者环境造成的运动(例如来自卡车发动机的振动等)。在测 {\textbar}   {\textbar}  量运动之外，运动传感器104还可用于估计使用者的身体姿势(例如：坐着、站着、躺着)。 {\textbar}   {\textbar} 用于跟踪运动和/或身体姿势的技术是通过加速度计和/或回转仪实现的。市场上 {\textbar}   {\textbar}  存在众多小型低功率回转仪。回转仪通常使用压电传感器或其它形式的微电子运动传感器 {\textbar}   {\textbar}  ({MEMS})。例如，{SGS}-Thompson Microelectronics(st.com)有一系列基于{MEMS的回转仪}，这 {\textbar}   {\textbar}  些回转仪以低功率工作、测量所有三个运动轴、提供数字输出，其中所述数字输出可直接供 {\textbar}   {\textbar}  给到微处理器中，并具有低噪音阈值和低回转仪偏移，从而允许这些回转仪以高的精确性 {\textbar}   {\textbar}  和可重复性测量细微的运动。L3G3200D是工作电压范围为2.4V至3.6V的合适的设备，其相 {\textbar}   {\textbar}  当适于电池工作，在通常工作中仅消耗6.1mA，工作范围为-40至+85摄氏度，包括嵌入的温 {\textbar}   {\textbar}  度传感器，并具有温度和运动角速度两者的数字输出，对于角速度具有直至16位的精确性。 {\textbar}   {\textbar} 可使用线性加速度计，作为{MEMS回转仪的替代选择}。如在文献“Tilt Sensing  {\textbar}   {\textbar}  Using a Three-Axis Acccelerometer”.Mark Pedley.Freescale  {\textbar}   {\textbar}  Semiconductor.Document Number {AN}3461.Revision 6,3/2013中所述(该文献通过引用完 {\textbar}   {\textbar}  全包括在本说明书中)，{MEMS线性加速度计由于对重力场和线性加速度做出响应}，因此当设 {\textbar}   {\textbar}  置在三轴配置中时，能够计算偏航角、俯仰角、翻滚角的旋转变化。 {\textbar}   {\textbar} 生物度量传感器模块105可包括一个或更多个传感器以测量使用者的一个或更多 {\textbar}   {\textbar}  个生物标记。可根据本发明的一些方面测量的生物标记包括但不限于：皮肤温度和心脏相 {\textbar}   {\textbar}  关的度量，包括心率。生物度量传感器模块105可用于对使用者的各种生物标记进行持续 {\textbar}   {\textbar}  和/或周期性的被动测量，例如频率为每分钟测量一次。在某些实施例中，生物度量传感器 {\textbar}   {\textbar}  模块105可以是上位的，并可包括生物度量传感器和非生物度量传感器(例如：环境光线传 {\textbar}   {\textbar}  感器107)两者。在一个实施例中，生物度量传感器模块105可作为单元集成在设备100中。在 {\textbar}   {\textbar}  另一实施例中，生物度量传感器模块105可包括数个分布在设备100中或遍及设备100的构 {\textbar}   {\textbar}  件。 {\textbar}   {\textbar} 生物度量传感器模块105可包括皮肤温度传感器105a和心率传感器105b，例如 {\textbar}   {\textbar}  Karlsson Robotics的脉搏率传感器。皮肤温度传感器105a可用于测量可穿戴设备100位置 {\textbar}   {\textbar}  处的使用者皮肤温度。Silicon Labs制造包括脉搏率传感器/心率传感器以及血氧饱和度 {\textbar}   {\textbar}  (血液中的氧气饱和度)的集成电路芯片。然而，尽管这些类型的系统在确定目前该系统是 {\textbar}   {\textbar}  否正被穿戴着时可能是有利的，但是如果设计目的在于保持电池寿命，则根据某些方面可 {\textbar}   {\textbar}  仅使用温度传感器。例如，可省掉使用发光二极管和传感器来测量氧气饱和度并具有高电 {\textbar}   {\textbar}  流消耗的血氧饱和度传感器。 {\textbar}   {\textbar} 生物度量传感器模块105也可用于检测使用者的各种生物标记(包括心脏相关的 {\textbar}   {\textbar}  度量和皮肤温度)随着时间推移发生的变化。可通过用生物度量传感器模块105中的所述一 {\textbar}   {\textbar}  个或更多个传感器对使用者进行持续和周期性被动客观测量来检测该变化。 {\textbar}   {\textbar} 根据本发明的一些方面，可穿戴设备100被实现成舒适的类似于手表的腕带。然 {\textbar}   {\textbar}  而，设备100附接到前臂、围绕肘部穿戴或附接到实际上任何身体部位也是能够工作的。而 {\textbar}   {\textbar}  且，设备100可集成到例如手套的服饰物品或将其保持在使用者身上的其它装置中。根据本 {\textbar}   {\textbar}  发明一些方面的设备100的设计使其穿戴起来不妨碍操作员，从而有助于确保操作员穿戴 {\textbar}   {\textbar}  该设备。为此，生物度量传感器模块105可用于检测可穿戴设备100(例如：基于指示该设备 {\textbar}   {\textbar}  目前贴着使用者皮肤的温度测量值)是否正被穿戴着。例如，温度传感器和/或心率传感器 {\textbar}   {\textbar}  可用于该目的。生物度量传感器模块105的其它生物度量传感器可用于该目的。运动传感器 {\textbar}   {\textbar}  104和任何被监控的运动也可用于确定使用者是否正穿戴着设备100。 {\textbar}   {\textbar} 可穿戴设备100具有存储用于预测个人的警觉性或疲劳水平的生物-数学模型的 {\textbar}   {\textbar}  存储器110。该生物-数学模型可以是包含睡眠-清醒稳态确定和昼夜节律估计的双进程算 {\textbar}   {\textbar}  法。睡眠-清醒稳态反映个人的睡眠需求或欲望。睡眠-清醒稳态确定(或稳态睡眠欲望)可 {\textbar}   {\textbar}  由例如以下因子组成：距离使用者上一次睡眠的时间(睡眠负债)、使用者上一次睡眠时段 {\textbar}   {\textbar}  的长度和使用者上一次睡眠时段期间的睡眠质量。确定使用者何时实际清醒或睡眠是使用 {\textbar}   {\textbar}  称作“体动记录”的方法来实现的。除了远端皮肤、环境光线和心率测量值以外，所述模型的 {\textbar}   {\textbar}  睡眠-清醒稳态方面还使用由运动传感器104检测的运动得出的准确的体动记录测量值，来 {\textbar}   {\textbar}  改善对于个人的睡眠和清醒确定的准确性。该模型还包括通过组合远端皮肤、心率和体动 {\textbar}   {\textbar}  记录数据得出的疲劳预测和估计的昼夜节律模型方面。该昼夜节律估计能够捕捉使用者的 {\textbar}   {\textbar}  警觉性水平在下午中段的下降和傍晚的提升。 {\textbar}   {\textbar} 存储器110还存储由大众人口的样本得出的对昼夜节律的概括性缺省估计。该概 {\textbar}   {\textbar}  括性缺省估计假设大约24小时的昼夜节律周期。当个人第一次戴上设备100时，设备100对 {\textbar}   {\textbar}  该个人应用概括性缺省估计。然而，随着时间推移，设备100基于在闭环系统中对该个人的 {\textbar}   {\textbar}  各种持续和被动的测量值通过应用所存储的生物-数学模型来调整概括性缺省估计以反映 {\textbar}   {\textbar}  该个人的实际昼夜节律。测量值可包括运动、皮肤温度和心率。个人的个人昼夜节律实际上 {\textbar}   {\textbar}  可在例如23.5到25小时之间变化，偏离概括性缺省估计。由此，概括性缺省估计被配置为根 {\textbar}   {\textbar}  据对个人的实际昼夜节律的估计来调整，由此在应用生物-数学模型之后使对于个人的警 {\textbar}   {\textbar}  觉性预测个性化。例如，在个人穿戴设备100两天后可对该个人的概括性缺省估计进行调 {\textbar}   {\textbar}  整，两天期间的测量值指示概括性缺省估计不足以反映该个人的实际昼夜节律。 {\textbar}   {\textbar} 处理器108联接到运动传感器104和生物度量传感器模块105。处理器108可以是可 {\textbar}   {\textbar}  编程微处理器。处理器108还联接到用于存储和获取数据的存储器110。处理器108可执行指 {\textbar}   {\textbar}  令或应用存储在存储器110中的生物-数学模型来提供本文描述的可穿戴设备100的功能 {\textbar}   {\textbar}  性。处理器108也可将从运动传感器104和生物度量传感器模块105获取的数据存储在存储 {\textbar}   {\textbar}  器110中，并从存储器110获取存储的数据用于处理。存储器110可以是常规存储器，例如静 {\textbar}   {\textbar}  态随机存取存储器({RAM})。处理器108可以是常规微处理器，例如低能耗嵌入式处理器。可使 {\textbar}   {\textbar}  用可再编程微处理器设备，其允许固件升级。一个合适的处理器108{是Altera} {MAX}7000A，其 {\textbar}   {\textbar}  在3.3V下工作(该工作电压范围与合适的回转仪兼容)。 {\textbar}   {\textbar} 处理器108也可联接到用于监控定时的和/或规划的事件的时钟112和用于传输信 {\textbar}   {\textbar}  号到远程位置和/或接收来自远程位置的信号的收发器114。时钟112可以是能够测量时间 {\textbar}   {\textbar}  (例如单位为例如毫秒、微妙等的时间分数)的集成电路时钟。收发器114可以是例如蓝牙收 {\textbar}   {\textbar}  发器，例如用于使可穿戴设备100能够在通知情况下通知远程信息处理设备、远程计算机系 {\textbar}   {\textbar}  统、计算机应用和/或智能手机应用。可穿戴设备100的构件可由电池116来供能。电池116可 {\textbar}   {\textbar}  以是例如锂离子电池的充电电池。 {\textbar}   {\textbar} 处理器108可监控来自运动传感器104和生物度量传感器模块105的温度和运动输 {\textbar}   {\textbar}  出，以确定该设备是否正贴着皮肤被穿戴着。来自运动传感器104的运动输出可被处理器 {\textbar}   {\textbar}  108用于监控可穿戴设备100的运动。处理器108可被配置为关注速度在0dps至2000dps(度/ {\textbar}   {\textbar}  秒)的范围内的角度运动。该范围的下限去除了由于振动导致的小角度偏移，该范围的上限 {\textbar}   {\textbar}  去除了例如来自转弯卡车的大幅度径向运动。操作员的响应时间以及记录的温度和时间可 {\textbar}   {\textbar}  存储在存储器110中，以使得例如在没有可用的远程信息处理系统来通讯的情况下，调度员 {\textbar}   {\textbar}  能够在之后的一个时间点验证该设备之前被正确地穿戴着。 {\textbar}   {\textbar} 设备100额外地可包括环境光线检测器107。环境光线检测器107可用于检测使用 {\textbar}   {\textbar}  者在光线下的暴露程度。在光线下的暴露程度可影响个人的昼夜节律并调整个人的生物 {\textbar}   {\textbar}  钟。这可使得个人的昼夜节律偏移。生物-数学模型可将由环境光线检测器107获得的信息 {\textbar}   {\textbar}  包含到对个人昼夜节律响应于个人在光线下的暴露程度的未来变化的预测中。环境光线检 {\textbar}   {\textbar}  测器107可被配置为确定使用者在蓝色波长光线下的暴露程度，这些蓝色波长光线对于个 {\textbar}   {\textbar}  人的昼夜节律可能会有更大的影响。处理器108也可联接到环境光线检测器107。处理器108 {\textbar}   {\textbar}  可监控并处理由运动传感器104、生物度量传感器模块105和环境光线检测器107测量到的 {\textbar}   {\textbar}  输出。 {\textbar}   {\textbar} 处理器108也可监控来自于运动传感器104和生物度量传感器模块105的温度、心 {\textbar}   {\textbar}  率和运动输出，以使用存储在存储器110中的生物-数学模型，通过将运动测量值包含到体 {\textbar}   {\textbar}  动记录确定中来评估个人的睡眠-清醒稳态，该稳态包括个人的睡眠和清醒时期。 {\textbar}   {\textbar} 对距离使用者上一次睡眠的时间和睡眠时间的检测可由处理器108通过对指示使 {\textbar}   {\textbar}  用者不运动(这指示睡眠时间)的体动记录运动数据的分析并结合例如心率和皮肤温度的 {\textbar}   {\textbar}  生物标记来确定。处理器可使用远端皮肤温度和心率的测量值来调整和/或确认体动记录 {\textbar}   {\textbar}  的确定结果。例如，处理器108可(通过模式识别或其它技术)将远端皮肤温度测量值应用到 {\textbar}   {\textbar}  体动记录确定中，以确认个人在睡觉还是清醒的。这可通过阈值(关注与基准数据的偏差) {\textbar}   {\textbar}  或通过皮肤温度在一定时期内上升的模式来实现。已经证实远端皮肤温度的上升与个人在 {\textbar}   {\textbar}  睡觉这一事实有关联，远端皮肤温度的下降与个人清醒这一事实有关联。 {\textbar}   {\textbar} 此外，处理器108可将来自于环境光线传感器107的环境光线测量值作为额外输入 {\textbar}   {\textbar}  应用到体动记录睡眠或清醒确定中，例如在确定个人是在睡觉还是清醒不容易的情况下。 {\textbar}   {\textbar}  例如，如果不容易确定该人是在睡觉还是清醒，但存在大量环境光线，则体动记录输出可以 {\textbar}   {\textbar}  是该个人处于清醒状态的预测。相反地，光线缺乏可能指示该个人在睡觉。 {\textbar}   {\textbar} 处理器108也可将身体姿势和心率的确定应用到体动记录确定中以确认和/或调 {\textbar}   {\textbar}  整体动记录确定结果。可以以与环境光线类似的方式来使用身体姿势，这是因为身体姿势 {\textbar}   {\textbar}  可提供关于使用者是在睡觉还是清醒的额外指示。例如，使用者站着或坐着比躺着的在睡 {\textbar}   {\textbar}  觉的可能性更小。与皮肤温度类似地，心率具有指示个人是在睡觉还是清醒的模式。处理器 {\textbar}   {\textbar}  108可使用该额外输入来更好地改善体动记录的睡眠/清醒预测的准确性，以改善睡眠-清 {\textbar}   {\textbar}  醒稳态评估。 {\textbar}   {\textbar} 处理器108还估计个人的昼夜节律。见图2。处理器108可处理至少一个生物标记 {\textbar}   {\textbar}  (例如皮肤温度或心率)的初始测量值，以估计使用者的个人昼夜节律。所导致的经过处理 {\textbar}   {\textbar}  的数据可例如如图2中那样绘制成图，处理器108可识别或提取与个人昼夜节律中特定位置 {\textbar}   {\textbar}  关联的特征或事件。使用者全天的警觉性可以与使用者昼夜节律中的使用者位置高度关 {\textbar}   {\textbar}  联。估计使用者昼夜节律的能力可提供对给定日期中任一点时使用者警觉性的准确预测。 {\textbar}   {\textbar} 一种用于估计使用者个人昼夜节律的生物标记是使用者的远端皮肤温度。使用者 {\textbar}   {\textbar}  的远端皮肤温度与使用者的核心体温关联。核心体温遵循使用者的昼夜节律，核心体温由 {\textbar}   {\textbar}  于遵循使用者昼夜节律，会在清醒时间期间上升，并在通常的睡眠时间期间下降。使用者的 {\textbar}   {\textbar}  警觉性水平因此也会随着昼夜节律变化。由于使用者的身体通过经由身体的四肢发散热量 {\textbar}   {\textbar}  来调节核心体温，因此当核心身体热量下降时，四肢的温度升高。因此，通过使远端皮肤温 {\textbar}   {\textbar}  度与核心体温关联(该核心体温遵循使用者的昼夜节律)，使用者远端皮肤温度的测量值可 {\textbar}   {\textbar}  用于准确地估计使用者的个人昼夜节律。这提供了使用者警觉性水平模型。 {\textbar}   {\textbar} 远端皮肤温度也可与使用者的褪黑激素水平关联。使用者的内源性褪黑激素水平 {\textbar}   {\textbar}  是对使用者在个人昼夜节律中的位置的可靠且准确的指示，因此是对使用者的警觉性水平 {\textbar}   {\textbar}  的指示。褪黑激素通常在减弱的警觉性时间期间(例如：夜晚睡眠之前的时期)升高，并通常 {\textbar}   {\textbar}  在提高的警觉性时间期间下降。皮肤温度一般与褪黑激素水平关联，这是因为当褪黑激素 {\textbar}   {\textbar}  水平上升时，使用者的皮肤温度也与使用者昼夜节律相关地升高。由此，皮肤温度也可用作 {\textbar}   {\textbar}  用于确定使用者当前褪黑激素水平、并因此确定由使用者在个人昼夜节律中的位置决定的 {\textbar}   {\textbar}  使用者当前警觉性水平的关联性代替参数。 {\textbar}   {\textbar} 用于估计使用者个人昼夜节律和/或褪黑激素水平的个人远端皮肤温度的初始测 {\textbar}   {\textbar}  量可在使用者身体上的多个位置处(包括脚、胳膊、手腕和手)进行。可被包含到处理器108 {\textbar}   {\textbar}  对使用者的个人昼夜节律和/或褪黑激素水平的估计中的生物标记的其它初始测量可包括 {\textbar}   {\textbar}  但不限于心脏相关的度量，例如心率。 {\textbar}   {\textbar} 估计使用者个人昼夜节律的一个例子可开始于使用者在身体的远端位置(例如手 {\textbar}   {\textbar}  腕)处穿戴可穿戴设备100一测试时期。该测试时期可具有两天或更多天的长度。活动皮肤 {\textbar}   {\textbar}  温度可由温度传感器105a按照每分钟一次的频率在至少两天的时期内测量。基于由远端皮 {\textbar}   {\textbar}  肤温度测量值得出的数据，处理器108可估计使用者的个人昼夜节律。在测试期间对生物标 {\textbar}   {\textbar}  记的其它初始测量值也可用于估计使用者的昼夜节律。 {\textbar}   {\textbar} 通过在一个时期内收集个人远端皮肤温度和/或其心率的测量值而使处理器108 {\textbar}   {\textbar}  能够估计昼夜节律。处理器108生成由远端皮肤温度和心率的测量值得出的数据点。处理器 {\textbar}   {\textbar}  108也可包含个人运动的测量值以精细化数据点。数据点代表个人实际昼夜节律内的时间 {\textbar}   {\textbar}  点，处理器108可通过将这些数据点在时间上累积成发展变化来用这些数据点估计个人的 {\textbar}   {\textbar}  整体昼夜节律。处理器108还将这些数据点用于调整存储在存储器110中的概括性缺省估 {\textbar}   {\textbar}  计，以更好地反映该个人的实际昼夜节律。处理器108可应用模式识别和/或机器学习技术 {\textbar}   {\textbar}  来实现该调整，以使得昼夜节律的确定对于该个人而言是个性化的。 {\textbar}   {\textbar} 个人的昼夜节律通常不会天天极大地变化。然而，个人活动可能会每天变化。这些 {\textbar}   {\textbar}  活动会“掩盖”对通常稳定的个人昼夜节律的指示。由于远端皮肤温度和/或心率受其他外 {\textbar}   {\textbar}  界“掩盖性”事件(例如行走、睡眠等)影响，因此处理器108可能会需要应用额外的信号处理 {\textbar}   {\textbar}  技术来将皮肤温度或心率数据与这些“掩盖性”非昼夜节律事件分离(即“解除掩盖”)。处理 {\textbar}   {\textbar}  器108应用“解除掩盖”算法来从暗含的皮肤温度和心率数据(即原始昼夜节律数据)去除 {\textbar}   {\textbar}  “掩盖性事件”，以提供对昼夜节律的准确预测。例如，周期性地起立行走(例如从一个办公 {\textbar}   {\textbar}  室到另一个办公室)的人的掩盖性事件不在每天的同一确切时间发生。这意味着可用所采 {\textbar}   {\textbar}  用的信号处理技术来检查在多天期间在每天同一时间点(例如每天中午12点5分)收集的数 {\textbar}   {\textbar}  据点，其中所述技术能够去除无关的“掩盖性”因素，而保留暗含的一致信号。这用在多天期 {\textbar}   {\textbar}  间在给定的24小时内的多个点取平均的技术实施起来最容易；然而，可使用额外的信号处 {\textbar}   {\textbar}  理技术，例如滤波。类似地，该同一原理可应用到心率测量值，心率测量值类似地受昼夜节 {\textbar}   {\textbar}  律影响但由于掩盖性效应在过去是不可用的。 {\textbar}   {\textbar} 在对远端皮肤温度测量值和心率测量值“解除掩盖”过程中考虑的变量包括身体 {\textbar}   {\textbar}  姿势和个人的活动，这些是可能会扭曲暗含的来自皮肤温度和心率的昼夜节律信号的“掩 {\textbar}   {\textbar}  盖性事件”。例如，在其中观察昼夜节律信号的典型环境是实验室环境，在该环境中使用者 {\textbar}   {\textbar}  以固定的姿势躺在床上，少进食，不运动。“解除掩盖”是去除在这样的受控环境之外发生的 {\textbar}   {\textbar}  事件的影响的过程。例如，个人可能会进行慢跑。当发生该事件时，由于个人开始出汗，个人 {\textbar}   {\textbar}  的远端皮肤温度下降。而且，由于身体活动，个人的心率上升。因此通常失去暗含的昼夜节 {\textbar}   {\textbar}  律信号。然而，处理器108应用“解除掩盖”算法，该算法能够通过引入保存在存储器的特定 {\textbar}   {\textbar}  时期的历史信息和情况信息而在存在这些掩盖性效应的情况下保留暗含的昼夜节律信号。 {\textbar}   {\textbar}  如果设备100和处理器108知道个人正在跑步，则处理器108可确定正在接收的数据是不良 {\textbar}   {\textbar}  数据并可丢弃，或其意义在通过生物-数学模型确定实际警觉性时可被减小。 {\textbar}   {\textbar} 在一个优选实施例中，昼夜节律估计还通过与每个数据点关联的质量因子的概念 {\textbar}   {\textbar}  而被改善。如果可获知关于数据捕捉时情况(例如使用者是否在行走或在睡觉)的额外信 {\textbar}   {\textbar}  息，则可给予该数据点一质量因子。例如，如果当捕捉数据点时，使用者正在行走，则可将该 {\textbar}   {\textbar}  数据点视为是低质量数据点，反之，如果当捕捉数据点时，使用者已经坐了一段时间，则可 {\textbar}   {\textbar}  将该数据点视为高质量数据点。使用该质量因子概念，由于数据点不是全都被同等地处理， {\textbar}   {\textbar}  因此可改善昼夜节律的准确性。处理器108可通过对数天期间的特定时期的给定数据点取 {\textbar}   {\textbar}  平均而“解除掩盖”或将质量因子应用到数据点中的皮肤温度或心率数据。例如，如果在给 {\textbar}   {\textbar}  定日正好在中午12点5分收集远端皮肤温度，个人可能会正在跑着去赶公交车，导致给予该 {\textbar}   {\textbar}  数据点一低质量因子。第二天，在中午12点5分会收集额外的数据点。这次，使用者正在坐在 {\textbar}   {\textbar}  椅子上，因此该数据点会是高质量数据点。通过对这些数据点应用加权平均，处理器108可 {\textbar}   {\textbar}  获得更加准确的“解除掩盖”的远端皮肤温度或心率。 {\textbar}   {\textbar} 处理器108将质量因子用作加权平均的系数，该系数用于合并数天的一天中给定 {\textbar}   {\textbar}  点的昼夜节律数据的价值。例如，处理器108可采用星期二中午12点5分和星期三中午12点5 {\textbar}   {\textbar}  分的数据点。星期二评估为0.1的质量因子，而星期三具有0.9的质量因子。所导致的加权平 {\textbar}   {\textbar}  均将由处理器计算为(0.1*星期二\_数据+0.9*星期三\_数据)。因为处理器108不将所有数据 {\textbar}   {\textbar}  点作为同等数值来处理，因此这提供了比简单地对数天期间的数据取平均更好的估计结 {\textbar}   {\textbar}  果。 {\textbar}   {\textbar} 另外，处理器108可通过引入皮肤温度和/或心率趋势来估计昼夜节律的实际时间 {\textbar}   {\textbar}  周期(对于通常的个人，该实际时间周期并不刚好是24小时)。通过赋予皮肤温度和/或心率 {\textbar}   {\textbar}  数据一质量因子和/或对其“解除掩盖”，处理器108则可使数据标准化并假设昼夜节律是相 {\textbar}   {\textbar}  位偏移和关联的模式。而且，可通过标准化的远端皮肤温度数据的急剧升高来预测褪黑激 {\textbar}   {\textbar}  素水平，褪黑激素水平可被用作昼夜节律系数(相位Φ)偏移和个人昼夜节律的周期T的一 {\textbar}   {\textbar}  个标记。 {\textbar}   {\textbar} 处理器108也可将睡眠-清醒稳态确定和根据生物-数学模型的实际昼夜节律估计 {\textbar}   {\textbar}  进行结合，以获得对个人的警觉性的预测。这导致更加准确且个性化的个人警觉性预测。睡 {\textbar}   {\textbar}  眠-清醒稳态和昼夜节律在个人体内协同工作以产生个人的时刻变化的警觉性。见图3。然 {\textbar}   {\textbar}  后可通过生物-数学模型将昼夜节律与睡眠稳态信息进行结合以产生对警觉性的整体估 {\textbar}   {\textbar}  计。生物-数学模型的每个输入都可使用模式识别和/或机器学习技术来进行组合。这些技 {\textbar}   {\textbar}  术中的某些包括对各部分进行加权。生物-数学模型的加权部分可被静态或动态地限定。例 {\textbar}   {\textbar}  如，给予昼夜节律的权重是基于处理器108所收集的数据的估计的质量的。 {\textbar}   {\textbar} 图4描绘了一个系统400，该系统包括根据本发明一些方面的可穿戴设备100。可穿 {\textbar}   {\textbar}  戴设备100可与例如智能设备450和/或外部计算设备460通讯。智能设备450可以是例如智 {\textbar}   {\textbar}  能手机的移动设备。外部计算设备460可以是个人计算机或类似设备。由可穿戴设备100收 {\textbar}   {\textbar}  集的数据可以被传送给智能设备450和/或外部计算设备460。智能设备450和/或外部计算 {\textbar}   {\textbar}  设备460也可将其它信息传送给可穿戴设备100。 {\textbar}   {\textbar} 智能设备450和/或外部计算设备460可具有能够显示、存储和/或进一步处理从可 {\textbar}   {\textbar}  穿戴设备100接收的数据的应用或其它软件模块。例如，智能设备450可具有一软件应用，该 {\textbar}   {\textbar}  软件应用显示由从可穿戴设备100接收并由智能设备450存储的数据得出的个人警觉性预 {\textbar}   {\textbar}  测或疲劳分数随时间变化的图。智能设备450和/或计算设备460也可用于在从可穿戴设备 {\textbar}   {\textbar}  100接收的数据预测个人疲劳的情况下警告该个人。另外，智能设备450和/或计算设备460 {\textbar}   {\textbar}  可与数据云470通讯和交换数据。由此，由智能设备450和/或计算设备460接收的数据可传 {\textbar}   {\textbar}  输到云470进行存储，智能设备450和/或计算设备460可例如获取存储在云470中的数据以 {\textbar}   {\textbar}  生成个人疲劳相关数据随时间变化的图。此外，第三方(例如管理员或调度员)可以能够通 {\textbar}   {\textbar}  过智能设备450和/或计算设备460查看关于个人疲劳或警觉性的信息。 {\textbar}   {\textbar} 图5描绘了根据本发明一些方面的用于预测个人警觉性的步骤。首先，在步骤500 {\textbar}   {\textbar}  时，处理器108可获得或接收由运动传感器产生的运动数据、由温度传感器产生的远端皮肤 {\textbar}   {\textbar}  温度数据和/或由心率监测器产生的心率数据。运动传感器、温度传感器和心率监测器中的 {\textbar}   {\textbar}  每个都可与由个人穿戴的可穿戴设备100关联。运动传感器也可在步骤500a产生关于个人 {\textbar}   {\textbar}  身体姿势的数据或关于个人进行的运动类型的数据，这些数据也可被处理器108获得。步骤 {\textbar}   {\textbar}  500a也可包括处理器108获得或接收由环境光线传感器产生的环境光线数据。 {\textbar}   {\textbar} 在步骤500b时，处理器可处理远端皮肤温度数据和/或心率数据以根据生物-数学 {\textbar}   {\textbar}  模型指示来精细化数据，该生物-数学模型可存储在可穿戴设备100的存储器中。处理器108 {\textbar}   {\textbar}  可应用信号处理技术(包括例如低通滤波和移动平均)来实现对皮肤温度数据和心率数据 {\textbar}   {\textbar}  的处理。这样的处理/滤波从远端皮肤温度数据信号和/或心率数据信号中去除“噪音”以产 {\textbar}   {\textbar}  生更加干净、更加准确的信号。 {\textbar}   {\textbar} 在步骤500c时，处理器可根据生物-数学模型基于关于个人身体姿势和由个人进 {\textbar}   {\textbar}  行的运动的类型中的至少一个赋予皮肤温度数据和/或心率数据一质量因子。 {\textbar}   {\textbar} 在步骤500d，处理器可在皮肤温度数据和/或心率数据(即原始昼夜节律数据)中 {\textbar}   {\textbar}  识别昼夜节律和非昼夜节律数据，并去除非昼夜节律数据以获得精细化的昼夜节律数据 {\textbar}   {\textbar}  (即对昼夜节律数据“解除掩盖”)。昼夜节律数据被定义为由昼夜节律事件得出的数据，而 {\textbar}   {\textbar}  非昼夜节律数据是由非昼夜节律事件得出的数据。处理器可使用模式识别和/或机器学习 {\textbar}   {\textbar}  技术去除非昼夜节律数据。处理器108也可检测精细化/解除掩盖的昼夜节律数据中的局部 {\textbar}   {\textbar}  最大值事件和局部最小值事件，以识别潜在的个人疲劳风险时间。 {\textbar}   {\textbar} 在步骤510时，处理器108可使用其从运动传感器接收的运动数据进行体动记录确 {\textbar}   {\textbar}  定。处理器108然后可在步骤510a时使用远端皮肤温度或心率数据中的至少一个来精细化 {\textbar}   {\textbar}  体动记录确定结果，以进行更准确的体动记录确定。 {\textbar}   {\textbar} 处理器108然后可在步骤520时使用体动记录确定结果来评估个人的睡眠-清醒稳 {\textbar}   {\textbar}  态生物-数学模型，包括个人的睡眠和清醒时期。该评估可反复发生。处理器可要么使用原 {\textbar}   {\textbar}  始体动记录确定结果要么使用精细化的体动记录确定结果来评估个人的睡眠-清醒稳态。 {\textbar}   {\textbar}  此外，处理器108可引入关于个人身体姿势的数据以精细化睡眠-清醒稳态评估结果。处理 {\textbar}   {\textbar}  器也可通过引入环境光线数据来精细化个人睡眠-清醒稳态评估结果。 {\textbar}   {\textbar} 在步骤530时，处理器108可使用皮肤温度数据或心率数据中的至少一种来计算数 {\textbar}   {\textbar}  据点。处理器108可引入来自步骤500b的经过处理的皮肤温度和/或心率数据或未经处理的 {\textbar}   {\textbar}  数据来计算数据点。此外，处理器108可将赋予来自步骤500c的皮肤温度数据和/或心率数 {\textbar}   {\textbar}  据的质量因子包含到数据点的计算中。处理器108还可引入去除或未去除非昼夜节律数据 {\textbar}   {\textbar}  的皮肤温度数据和/或心率数据来计算数据点。 {\textbar}   {\textbar} 在步骤540时，处理器108可生成估计的个人昼夜节律。这可反复发生。处理器108 {\textbar}   {\textbar}  可通过使用经过处理的数据点来生成估计的昼夜节律，以精细化存储在可穿戴设备的存储 {\textbar}   {\textbar}  器中的缺省昼夜节律。缺省昼夜节律可由大众人口的样本得出，缺省昼夜节律可假设大约 {\textbar}   {\textbar}  24小时的昼夜节律周期。此外，处理器108可通过引入环境光线数据来精细化估计的昼夜节 {\textbar}   {\textbar}  律。 {\textbar}   {\textbar} 处理器108还可在步骤540a时估计个人的昼夜节律系数(当前相位Φ)、个人的清 {\textbar}   {\textbar}  醒/睡眠系数、个人的昼夜节律周期T、个人的睡眠开始时间，和/或个人的褪黑激素分泌起 {\textbar}   {\textbar}  点(melatonin onset)。每个人都可能会具有不同的昼夜节律系数/相位(Φ)偏移，这意味 {\textbar}   {\textbar}  着每个人的昼夜节律周期T可能会在不同时间开始。睡眠开始时间可通过例如识别解除掩 {\textbar}   {\textbar}  盖的个人远端皮肤温度中的低点来确定，在该低点之后，解除掩盖的远端皮肤温度上升(例 {\textbar}   {\textbar}  如上升35％)。低点与个人的高警觉性水平关联，而从低点上升35％指示褪黑激素分泌起 {\textbar}   {\textbar}  点。褪黑激素分泌起点进而可用作个人昼夜节律周期T起始时间的一个标记。 {\textbar}   {\textbar} 在步骤550时，个人可将客观和主观参数输入到设备100中。个人还可将主观和客 {\textbar}   {\textbar}  观参数输入到智能设备450和/或外部计算设备460上，使得这些参数可被传送到可穿戴设 {\textbar}   {\textbar}  备100并被其使用。可输入的参数包括但不限于如由美国专利申请14/848,771详细说明的 {\textbar}   {\textbar}  规定运动、关于个人医疗历史的数据、对没有获得足够睡眠的后果的敏感性、来自个人回答 {\textbar}   {\textbar}  的问卷的数据、和个人对自己的警觉性水平的主观评估。 {\textbar}   {\textbar} 在步骤560时，处理器108可将睡眠-清醒稳态评估和通过生物-数学模型估计的昼 {\textbar}   {\textbar}  夜节律相结合来预测个人的警觉性水平或生成疲劳预测。处理器108可引入主观和客观参 {\textbar}   {\textbar}  数以进一步精细化对个人的疲劳的预测。可以使用模式识别或机器学习技术以非线性的方 {\textbar}   {\textbar}  式对这些参数加权，以将其引入到对根据生物-数学模型的预测的精细化中。处理器108还 {\textbar}   {\textbar}  可使用所估计的昼夜节律系数/相位Φ、昼夜节律周期T、清醒/睡眠系数、睡眠开始时间、 {\textbar}   {\textbar}  和/或褪黑激素分泌起点，以预测个人的警觉性。当根据生物-数学模型进行预测时，处理器 {\textbar}   {\textbar}  108还可引入精细化或未精细化的睡眠-清醒稳态评估和/或精细化或未精细化的所估计的 {\textbar}   {\textbar}  昼夜节律。处理器108还可通过使用所检测到的局部最大值事件和局部最小值事件来精细 {\textbar}   {\textbar}  化对个人的警觉性的预测。对警觉性的预测结果可在之后由可穿戴设备100传送到外部计 {\textbar}   {\textbar}  算设备460和/或智能设备450，用于显示、存储和/或进一步处理。 {\textbar}   {\textbar} 图6描绘了一个示例性的用于实施根据图5的概念的方法600的步骤。首先，在步骤 {\textbar}   {\textbar}  602时，可获得关于个人的运动、远端皮肤温度和心率的数据。可穿戴设备100或可穿戴设备 {\textbar}   {\textbar}  的处理器108可获得作为来自运动传感器104、温度传感器105a和/或心率监控器105b的信 {\textbar}   {\textbar}  号的该数据。可穿戴设备100或处理器108还可从运动传感器104接收指示个人的身体姿势 {\textbar}   {\textbar}  的信号。 {\textbar}   {\textbar} 在步骤604时，从温度传感器105a和心率监控器105b接收的信号可由处理器108处 {\textbar}   {\textbar}  理，以根据生物-数学模型的指示来清理数据，该生物-数学模型对于该示例性方法600而言 {\textbar}   {\textbar}  是双进程算法。处理器108可应用低通滤波和移动平均值来改善对皮肤温度和心率数据的 {\textbar}   {\textbar}  信号处理。 {\textbar}   {\textbar} 在步骤606时，皮肤温度和心率数据可根据双进程算法被“解除掩盖”，以便从暗含 {\textbar}   {\textbar}  的个人的远端皮肤温度和心率的测得的数据信号中去除由非昼夜节律事件导致的遮掩性 {\textbar}   {\textbar}  信号。这些事件包括但不限于睡眠、身体活动、和某些身体姿势。关于昼夜节律的暗含的信 {\textbar}   {\textbar}  号可例如通过对数天的数据一起取平均值来被“解除掩盖”。被“解除掩盖”的数据(包括皮 {\textbar}   {\textbar}  肤温度、心率数据)然后可被用于生成个人的实际昼夜节律的数据点。还可在步骤606时基 {\textbar}   {\textbar}  于所检测到的由个人进行的运动的类型来赋予皮肤温度和/或心率数据一质量因子。 {\textbar}   {\textbar} 在步骤608时，使用双进程算法的特征提取方面来从所测得并“解除掩盖”的信号 {\textbar}   {\textbar}  中提取有意义的事件或与昼夜节律相关的特征。这些有意义的事件或特征可包括远端皮肤 {\textbar}   {\textbar}  温度的缓慢升高，该缓慢升高遵循个人的昼夜节律，并指示正在下降的警觉性水平。而且， {\textbar}   {\textbar}  远端温度的突然升高可指示警觉性水平的突然变化。可使用机器学习和/或模式识别技术 {\textbar}   {\textbar}  来提取事件和/或模式。该算法可使用数个常用函数来进行特征提取，包括峰值检测算法、 {\textbar}   {\textbar}  点间插值法、余弦函数。 {\textbar}   {\textbar} 在步骤610时，可由被“解除掩盖”的数据来确定睡眠开始时间，该睡眠开始时间然 {\textbar}   {\textbar}  后可被用于估计当前相位/昼夜节律系数Φ，即个人在其昼夜节律周期T中的位置。每个人 {\textbar}   {\textbar}  都可具有不同的相位(Φ)偏移，这意味着每个人的昼夜节律周期T可能会起始于不同时间。 {\textbar}   {\textbar}  可通过识别昼夜节律中的的低点来确定睡眠开始时间，这些低点之后发生例如35％的昼夜 {\textbar}   {\textbar}  节律升高。低点与个人的高警觉性水平关联，而从低点起的35％升高指示褪黑激素分泌起 {\textbar}   {\textbar}  点。褪黑激素分泌起点进而可用作对于个人的昼夜节律周期T的起始时间的标记。 {\textbar}   {\textbar} 在步骤612时，可检测被“解除掩盖”的皮肤温度数据和/或心率数据中的局部最大 {\textbar}   {\textbar}  值和最小值点或事件，并将其识别成给定个人的潜在疲劳风险时间。这些检测到的事件可 {\textbar}   {\textbar}  与升高的睡意水平关联。例如，大约在下午2点到4点时间范围的皮肤温度的升高可被识别 {\textbar}   {\textbar}  成警觉性下降，这经常在下午中段时间观察到。 {\textbar}   {\textbar} 在步骤614时，可使用来自个人的体动记录数据来确定个人的睡眠和清醒时期和 {\textbar}   {\textbar}  所得到的用于双进程算法模型的个人的睡眠-清醒稳态。这可仅使用所检测到的由个人进 {\textbar}   {\textbar}  行的运动来确定。然而，可引入其它测量值(例如心率、远端皮肤温度和环境光线暴露程 {\textbar}   {\textbar}  度)，以使得对个人的睡眠和活动时期的确定更加准确。 {\textbar}   {\textbar} 在步骤616时，个人可将其它主观和客观参数输入到设备100中。个人还可将主观 {\textbar}   {\textbar}  和客观参数输入到智能设备450和/或外部计算设备460上，使得这些参数可被传送给可穿 {\textbar}   {\textbar}  戴设备100并被其使用。这些参数可用于进一步精细化对个人的警觉性的预测。可输入的参 {\textbar}   {\textbar}  数包括但不限于如由美国专利申请14/848771详细描述的规定运动、关于个人的医疗历史 {\textbar}   {\textbar}  的数据、对于没有获得足够睡眠的后果的敏感性、来自个人回答的问卷的数据、和个人对自 {\textbar}   {\textbar}  己的警觉性水平的主观评估。可使用模式识别或机器学习技术以非线性的方式对这些参数 {\textbar}   {\textbar}  进行加权，以将其引入到对双进程算法模型的精细化中。 {\textbar}   {\textbar} 在步骤618时，将来自昼夜节律方面的输入(包括从数据点得出的周期T、相位/昼 {\textbar}   {\textbar}  夜节律系数Φ、事件特征和褪黑激素分泌起点)与双进程算法的睡眠-清醒稳态方面的输入 {\textbar}   {\textbar}  相结合，以产生预测个人的警觉性水平的表现度量(performance metric)。使用模式识别 {\textbar}   {\textbar}  技术和/或机器学习技术来对算法的每个输入进行结合。这些技术中的某些可包括对算法 {\textbar}   {\textbar}  的各部分加权。例如，赋予算法模型的昼夜节律方面的权重是基于所收集的数据的估计质 {\textbar}   {\textbar}  量的。可使用从步骤616得出的输入(即其它客观和主观参数)来进一步精细化该警觉性水 {\textbar}   {\textbar}  平预测。这些客观和主观参数还可在被引入到个人警觉性预测中之前被加权。 {\textbar}   {\textbar} 图7描绘了由生物-数学模型得出的在24小时期间对个人的警觉性预测输出。虚线 {\textbar}   {\textbar}  代表按从0到10的度量来衡量的个人的警觉性风险，其中10代表最高的疲劳风险并用作疲 {\textbar}   {\textbar}  劳风险基准线。该图显示了个人的警觉性预测在整个24小时期间随着时间的变化。该图还 {\textbar}   {\textbar}  显示了个人的睡眠时期，并描绘了对该个人的警觉性预测结果，这些预测结果指示低、中和 {\textbar}   {\textbar}  高疲劳风险。 {\textbar}   {\textbar} 图8描绘出根据本发明一些方面的用于估计穿戴者/个人的疲劳的方法800的步 {\textbar}   {\textbar}  骤。方法800的步骤中的一个或更多个可省掉和/或重复和/或按可不同于在本说明书中披 {\textbar}   {\textbar}  露的顺序(包括同时)实现，而不超出本发明的范围和精神。 {\textbar}   {\textbar} 在步骤802时，获得传感器数据。传感器数据可包括关于穿戴者的信息，例如运动、 {\textbar}   {\textbar}  位置、远端皮肤温度、和/或心率。而且，传感器数据可包括环境状况，例如环境光线水平和/ {\textbar}   {\textbar}  或温度。可穿戴设备100或可穿戴设备的处理器108可获得作为来自例如运动传感器104、温 {\textbar}   {\textbar}  度传感器105a、心率监控器105b和/或光线传感器的传感器数据。 {\textbar}   {\textbar} 在步骤804时，进行信号处理。例如，从温度传感器105a和心率监控器105b接收的 {\textbar}   {\textbar}  信号可由处理器108处理，以按在本说明书中描述的生物-数学模型要求来清理数据。处理 {\textbar}   {\textbar}  器108可例如应用低通滤波和移动平均值来改善皮肤温度和心率数据的信号的质量。 {\textbar}   {\textbar} 在步骤806时，根据接收到并经过处理的信号来估计昼夜节律。处理器108可识别 {\textbar}   {\textbar}  皮肤温度数据和/或心率数据(即原始昼夜节律数据)中的昼夜节律数据和非昼夜节律数 {\textbar}   {\textbar}  据，并去除非昼夜节律数据以获得精细化的昼夜节律数据(即对昼夜节律数据进行“解除掩 {\textbar}   {\textbar}  盖”)。处理器108可使用模式识别和/或机器学习技术来去除非昼夜节律数据。 {\textbar}   {\textbar} 在步骤808时，获得个人参数。个人参数可包括主观和/或客观参数。个人参数可包 {\textbar}   {\textbar}  括但不限于关于个人的医疗历史的数据、对没有获得足够睡眠的后果的敏感性、进行规定 {\textbar}   {\textbar}  运动的能力、来自个人回答的问卷的数据，和个人对自己的警觉性水平的主观评估。个人参 {\textbar}   {\textbar}  数可通过例如设备100或智能设备450和/或外部计算设备460的使用者输入从穿戴者接收， {\textbar}   {\textbar}  使得这些参数可被传送到可穿戴设备100并被其使用。这些参数可用于进一步精细化对个 {\textbar}   {\textbar}  人的警觉性的预测。 {\textbar}   {\textbar} 在步骤810时，从所接收到的并经过处理的信号、所估计的昼夜节律和所获得的个 {\textbar}   {\textbar}  人参数提取特征。所提取的特征可包括指示昼夜节律的形状的标记，例如局部昼夜节律高 {\textbar}   {\textbar}  点和低点(例如“午餐之后的下降”)；关于使用者在工作日和空闲日的睡眠习惯，例如入睡 {\textbar}   {\textbar}  时间、睡眠惯性、昼夜节律低点、昼夜节律偏好(早上活跃vs.晚间活跃的个人)、习惯的睡眠 {\textbar}   {\textbar}  机会和位置(相位)、平均睡眠时间、和小睡习惯；一般性医疗信息，例如年龄、性别、{BMI等}。 {\textbar}   {\textbar}  在一个实施例中，所提取的特征是：(1)在工作日中：醒来的时间，使用闹钟，精力下降时间， {\textbar}   {\textbar}  就寝时间，睡眠中间时间(mid-sleep time)，睡眠时长，入睡时间；(2)在空闲日中：醒来的 {\textbar}   {\textbar}  时间，精力下降时间，就寝时间，睡眠中间时间，睡眠时长，入睡时间；(3)年龄；(4)性别；(5) {\textbar}   {\textbar}  {BMI}；和/或(6)修正的睡眠中间相位信息。可通过简单的取平均值、在转换数据之前和之后 {\textbar}   {\textbar}  (在信号中)检测峰值和谷值(通过微分、积分、相位偏移等)、代数组合、基于映射函数的转 {\textbar}   {\textbar}  换、将数据转换到频域等来提取特征。 {\textbar}   {\textbar} 在步骤812时，对所提取的特征应用一个或更多个模式识别和/或机器学习算法， {\textbar}   {\textbar}  以确定如何能够将所提取的特征用于确定系数。处理器108可应用模式识别和/或机器学习 {\textbar}   {\textbar}  技术来使得昼夜节律因子对于个人是个性化的和/或对各因子进行加权。可静态或动态地 {\textbar}   {\textbar}  限定算法模型的被加权的部分。模式识别和/或机器学习算法可应用峰值检测算法、点间插 {\textbar}   {\textbar}  值和/或余弦函数。在一个实施例中，对所提取的特征应用基于回归的机器学习算法，以确 {\textbar}   {\textbar}  定要在下一个步骤中提取的系数。 {\textbar}   {\textbar} 在步骤814时，例如由处理器108来提取系数。在一个实施例中，提取四个系数。这 {\textbar}   {\textbar}  四个系数可包括昼夜节律系数(相位Φ)、清醒/睡眠系数、昼夜节律加权系数，和清醒/睡眠 {\textbar}   {\textbar}  加权系数。处理器108可通过(应用映射、相位偏移等)转换步骤812的机器学习的输出来提 {\textbar}   {\textbar}  取系数，以使得可将其供给给下述步骤818的生物-数学模型中。 {\textbar}   {\textbar} 在步骤816时，确定体动记录数据。处理器108可使用从运动传感器接收到的经过 {\textbar}   {\textbar}  处理的运动数据来进行体动记录确定。处理器108然后可使用远端皮肤温度和/或心率数据 {\textbar}   {\textbar}  中的至少一种来精细化体动记录确定，以进行更准确的体动记录确定，例如：该个人是醒着 {\textbar}   {\textbar}  还是在睡觉，该个人是坐着还是在移动等。 {\textbar}   {\textbar} 在步骤818时，例如由处理器108来对所提取的系数和确定的体动记录数据应用生 {\textbar}   {\textbar}  物-数学模型。在一个实施例中，生物-数学模型包括至少两个子模型，例如当个人清醒时应 {\textbar}   {\textbar}  用的清醒子模型和当个人睡觉时应用的睡眠子模型。个人是清醒还是在睡觉可由处理器 {\textbar}   {\textbar}  108基于体动记录数据来确定，并基于所确定的清醒/睡眠情况来应用合适的模型。 {\textbar}   {\textbar} 在步骤820时，生成疲劳分数。疲劳分数可由处理器108生成。疲劳分数或其指示可 {\textbar}   {\textbar}  呈现给使用者或关心的人(例如雇主)。如果疲劳分数指示高疲劳水平，则可给使用者提供 {\textbar}   {\textbar}  刺激(例如可穿戴设备的振动)。 {\textbar}   {\textbar} 图9A描绘了16个个人的第一系数数值。所描绘的第一系数数值是昼夜节律周期/ {\textbar}   {\textbar}  相位(Φ)数值。系数的最优数值用“o”表示，由昼夜节律周期的系数提取器确定的提取的数 {\textbar}   {\textbar}  值用“x”表示。 {\textbar}   {\textbar} 图9B描绘了16个个人的第二系数数值。所描绘的第二系数数值是清醒/睡眠周期 {\textbar}   {\textbar}  数值。系数的最优数值用“o”表示，由清醒/睡眠周期的系数提取器确定的提取的数值用“x” {\textbar}   {\textbar}  表示。 {\textbar}   {\textbar} 图9C描绘了16个个人的第三系数数值。所描绘的第三系数数值是昼夜节律周期加 {\textbar}   {\textbar}  权数值。系数的最优数值用“o”表示，由昼夜节律周期权重的系数提取器确定的提取的数值 {\textbar}   {\textbar}  用“x”表示。 {\textbar}   {\textbar} 图9D描绘了16个个人的第四系数数值。所描绘的第四系数数值是清醒/睡眠周期 {\textbar}   {\textbar}  加权数值。系数的最优数值用“o”表示，由清醒/睡眠周期权重的系数提取器确定的提取的 {\textbar}   {\textbar}  数值用“x”表示。 {\textbar}   {\textbar} 在图9A至9D中描绘的信息示出，使用根据本发明一些方面的技术提取的特征在个 {\textbar}   {\textbar}  人层面是准确的——能够对个人疲劳进行准确预测。 {\textbar}   {\textbar} 尽管本文参照特定实施例对本发明进行了展示和描述，但是本发明不限于所示出 {\textbar}   {\textbar}  的细节。相反地，在权利要求的等同物的范围内在不偏离本发明的情况下可对各细节进行 {\textbar}   {\textbar}  各种改动。 alertness prediction system and method {\textbar}   {\textbar} the intersection of related application reference {\textbar}   {\textbar} The present invention relates to questions for alertness prediction algorithm ", submitted on February 18, 2016, the sequence number is 62/296, 800 the America temporary application (Atty.Doc.No.{TVC}-141USP) and the question is for alertness prediction system and method ", submitted on December 12, 2016, the sequence number is 62/432, 977 the America temporary application (Atty.Doc.No.{TVC}-141USP1) priority. each of these application content fully included herein by reference in this specification. {\textbar}   {\textbar} background technology {\textbar}   {\textbar} personal alertness without control of drop is a problem increasingly worrying consequences of some field of the approaching degree of flooding. For example, estimated 25 million per day name when driver driving asleep. serious and fatal truck, bus, train and motor vehicle accident is occurring at a frequency of making people panic. many injured and accident of manufacturing plant associated with fatigue. The purpose of monitoring the alertness to prevent these and other emergency situation, but not post-treatment. For example, after already sleeping when driving and then waking it has been too late. {\textbar}   {\textbar} In the past, for predicting or estimating algorithm of personal alertness based on process model called frequently. the double process model process and by circadian sleep-wake steady state models. circadian rhythm of the model generally only based on a standard time period (such as 23-25 hours). On the other hand, sleep-wake is usually only steady-state model based on the determination result of the motion recording instrument. {\textbar}   {\textbar} a defect-process algorithm model of the current form is the form based on the collected data from the small sample set for summarizing the alertness prediction. the algorithm cannot be personal for performing personalized setting to it. {\textbar}   {\textbar} summary of the invention {\textbar}   {\textbar} Aspects of the present invention are intended to by collecting personal data from monitored to produce a more accurate the alertness level of the individual estimation to improve the current fatigue and alertness level prediction model. can be used in the wearable device into an algorithm or bio-mathematical model so as to detect based on a combination of subjective and objective measurements, predicting and/or estimating the alertness of the person. {\textbar}   {\textbar} According to one aspect of the present invention of one algorithm bio-mathematical model relates to sleep-wake state determination and double circadian estimation process algorithm. can be obtained by further using motion recorded measured values to improve the sleeping of the model outside the distal end the skin, ambient light and heart rate measuring value-conscious state so as to improve the sleep and wake of the accuracy of determining the personal. can through the distal end of skin, heart rate and movement record data are combined to improve the fatigue prediction and estimation of the circadian model. estimating the circadian rhythm produces a more accurate model, the model can capture the alertness level of the user in the afternoon the middle section of falling and lifting in the evening. sleep-wake state and circadian rhythm model can also be used with additional objective and subjective measurement values and information provided by the user is combined to further improve the accuracy of the estimation. {\textbar}   {\textbar} fatigue score of alertness can use various metrics to generate predicting some aspect of personal other bio-mathematical model according to the invention. biological-mathematical model described in the specification of and a device, system, and method of the bio-mathematical model can be used in the context of personal interest of alertness. bio-mathematical model can be present as applied to independent device (e.g., a wearable device) or in another software environment. metrics of interest in some or all can be collected and supplied to the bio-mathematical model to generate the alertness level of the person associated with the output. {\textbar}   {\textbar} current for estimating or predicting the alertness level of the personal system and algorithm model set of available personal samples to train, comprises no more of circadian rhythm comprises estimating a feedback or no circadian rhythm estimation feedback. This will generate the actual rhythm of the individual model is not accurate, and the prediction of known circadian rhythm events (such as afternoon sleepiness and evening of awake) because of simply and generally sinusoidal. However, the inventive device, system and described in the specification of the mathematical model to continuously improve the accuracy as the model adjusted according to the circadian rhythm of the individual. The proposed model of the personal individual, and the other system is a summarization of the data sample set. {\textbar}   {\textbar} Description {\textbar}   {\textbar} the following detailed explanation, when reading with reference to the accompanying drawings, can best understand this invention, similar elements have the same reference numerals in the accompanying drawings. When there are a plurality of similar elements, possibly to the plurality of similar elements with one of the accompanying mark number, and lowercase letters for indicating a specific element. when the element or the elements of non specific one or more, may omit the lowercase letter indication. In this enhancement, according to the convention, each characteristic of the accompanying drawings are not drawn to scale. Conversely, in order to display clearly, the size of each feature is optionally amplified or reduced. comprises the following figures: {\textbar}   {\textbar} {FIG}. 1 is a diagram of some aspect of the present invention can be worn device; {\textbar}   {\textbar} {FIG}. 2 is a drawing according to the invention some aspects of personal circadian and sleep-wake sleep) steady state (steady state of the interaction of {FIG}. {\textbar}   {\textbar} {FIG}. 3 is described according to the invention in some aspect of personal circadian rhythm of exemplary event diagram feature; {\textbar}   {\textbar} {FIG}. 4 a communication with external device according to some aspect of the present invention comprises herein the wearable device of the system frame; {\textbar}   {\textbar} {FIG}. 5 a flowchart of a step of predicting user according to some aspects of the present invention of alertness; {\textbar}   {\textbar} {FIG}. 6 a according to some aspect of the present invention for implementing the concept of {FIG}. 5 of an exemplary method of {FIG}. {\textbar}   {\textbar} {FIG}. 7 is from some aspect of the present invention bio-mathematical model of alertness prediction of output result; {\textbar}   {\textbar} {FIG}. 8 for flowchart of exemplary method of estimating fatigue according to some aspect of the present invention; {\textbar}   {\textbar} {FIG}. 9A is a graph of first coefficient can be extracted in the method of {FIG}. 8; {\textbar}   {\textbar} {FIG}. 9B is a graph of the coefficient can be extracted in the method of {FIG}. 8; {\textbar}   {\textbar} {FIG}. 9C is a graph of a third coefficient can be extracted in the method of {FIG}. 8; {\textbar}   {\textbar} {FIG}. 9D can be used in the method of {FIG}. 8 of the extracted picture the fourth coefficient. {\textbar}   {\textbar} Specific implementation methods {\textbar}   {\textbar} Some aspects of the invention provide a wearable device, the wearable device has use various metrics to predict fatigue levels of the individual bio-mathematical model. Certain aspects relates to a double process algorithm (this is a bio-mathematical model), the algorithm by using the accurately estimated motion recording measuring value and circadian-to-person to predict alertness level. The wearable device also can be connected to other system (such as intelligent mobile phone application or other "intelligent" device) or with the communication. motion estimation both recording and circadian rhythm can be used by the movement of an individual, body posture, heart rate and measurement of far end skin temperature is achieved. can be added into this specification an additional objective and subjective measurements of more detailed explanation to further improve bio-mathematical model for alertness prediction accuracy. the closed loop feedback and by continuously learning and monitoring bio-mathematical model can be improved. {\textbar}   {\textbar} {FIG}. 1 depicts a wearable device 100, the wearable device for monitoring personal fatigue and to provide prediction of the alertness level of the individual wearing the personal 100 device and/or other individuals, for example. the American patent application 14/848, 771, describes a suitable wearable device. shown by the wearable device 100 is implemented as a belt 102, the belt can be placed on the wrist of an individual. belt 102 supports at least one motion sensor 104 and at least one sensor module 105 for monitoring biological measuring biological metric of the individual. bio-metric sensor module 105 comprises a skin temperature sensor 105a or in at least one heart rate monitor 105b. those skilled in the art will understand used together with the invention of suitable movement sensor 104 and bio-metric sensor module 105 by the description of this specification. {\textbar}   {\textbar} the motion sensor 104 may include one or more gyroscopes and/or accelerometers to track (linear, angle and so on). the monitoring or tracking of motion may include a motion of the user, user other movement outside of the predetermined movement, the relative movement of the user, or the movement (e.g. vibration from truck engine, etc.) by the user environment. out of the measuring movement, motion sensor 104 can be used for body posture (e.g., sitting, standing, lying) estimation of user. {\textbar}   {\textbar} techniques for tracking motion and/or body posture is realized by an accelerometer and/or a gyroscope. many small low-power gyroscopic exists on the market. a gyroscope using a piezoelectric sensor or other forms of micro-motion sensor ({MEMS}). For example, {SGS} Thompson-Microelectronics (st.com) with a series of {MEMS}-based gyroscope, the gyroscope to low-power operating, measuring all three movement axes, for providing a digital output, wherein the digital output is directly supplied to the microprocessor and having a low noise threshold value and low gyroscope offset, thereby allowing the gyroscope with high precision and repeatability of measuring fine movement. L3G3200D is the working voltage range of 2.4V to 3.6V the proper device, which is very suitable for battery operation, only consumes 6.1mA during a normal operation, the working range is -40 to + 85 centigrade, comprising a temperature sensor is embedded, and having a digital output of temperature and motion angular velocity both for the angular velocity has up to 16 bits of precision. {\textbar}   {\textbar} linear accelerometer may be used, as an alternative selection of {MEMS} gyroscope. The document "-Tilt {SensingUsing} a Three-Axis Acccelerometer". Mark Pedley.{FreescaleSemiconductor}.Document {AN}3461.Revision Number 6, 3 /2013 (this document fully included herein by reference in this specification), {MEMS} linear accelerometer because the gravity field and linear acceleration response, when set in the three-shaft configuration, can calculate the yaw, pitch and roll rotation variation of the angle. {\textbar}   {\textbar} bio-metric sensor module 105 may include one or more sensors to measure the user of one or more biomarker. Some aspects of the invention can be according to measurement of biomarkers including but not limited to skin temperature and heart-related metrics, including heart rate. bio-metric sensor module 105 for each of the biomarkers for passive measurement of the user continuously and/or periodically, such as frequency is measured once per minute. In some embodiments, the bio-metric sensor module 105 can be, and can include a bio-metric sensor and non bio-metric sensor (e.g., an ambient light sensor 107). In one embodiment, the bio-metric sensor module 105 can be integrated in the device 100 as a unit. In another embodiment, the biological metric sensor module 105 may include a plurality of distribution in the device 100 or device 100 of the component. {\textbar}   {\textbar} bio-metric sensor module 105 comprises a skin temperature sensor 105a and the heart rate sensor 105b, a pulse rate sensor such as Karlsson Robotics. a skin temperature sensor 105a can be used for measuring the skin temperature of the user position 100 of the wearable device. Silicon Labs for manufacturing integrated circuit chip comprises pulse sensor/heart rate sensor and a blood oxygen saturation (oxygen saturation in the blood). However, although the systems of the type in determining whether existing the system being worn may be advantageous, but if the design goal is to keep the battery life, then according to some aspects can only use the temperature sensor. for example, it can dispense with using light emitting diode and a sensor for measuring oxygen saturation and has a high current consumption of blood oxygen saturation sensor. {\textbar}   {\textbar} change of various biomarkers (including cardiac-related measurement and skin temperature) bio-metric sensor module 105 also can be used for detecting the user occurs as time goes. obtainable by bio-metric sensor module 105, the one or more sensors to the user continuously and periodically driven objective measurement to detect the change. {\textbar}   {\textbar} According to some aspects of this invention, the wearable device 100 is implemented similar to the watch to comfort of the wristband. However, the device 100 attached to the front arm worn around the elbow or attached to virtually any body part is also can work. The device 100 can be integrated into apparel glove or keep it in the body of the user of the other device. According to some aspects of the present invention the device 100 is designed to make it worn without obstructing the operator so as to ensure the operator wearing the device. Therefore, the bio-metric sensor module 105 can be used for detecting a wearable device 100 (for example, based on the indication the device against the temperature measuring value of the skin of the user) is being worn. For example, a temperature sensor and/or heart rate sensor may be used for this purpose. other bio-metric sensor 105 of the bio-metric sensor module can be used for this purpose. the motion sensor 104 and any monitored movement also can be used to determine whether the user is wearing the device 100. {\textbar}   {\textbar} The wearable device 100 with storage for predicting alertness or fatigue level of the individual bio-mathematical model of memory 110. the bio-mathematical model can be a double process algorithm determining and circadian sleep-awake state estimation. sleep-wake state reflecting the sleep need or desire of the person. sleep-wake state determination (or desire) stable sleep can be by, for example, the following factors: the distance between the user previous sleep time (sleep debt), the sleep quality of a sleep period length and a sleep time of the user on the user. determining when the user actually awake or sleep is called " motion recording method to achieve. in addition to distal end skin, ambient light and heart rate measurements, sleep-awake state of the model further use the exact motion recorded measured values obtained motion detection by the motion sensor 104, to improve sleep and wake the personal determination accuracy. the model further comprises a fatigue prediction by combining distal end skin, heart rate and body movement obtained by recording data and estimating the circadian model. estimating the circadian rhythm can capture the alertness level of the user in the afternoon middle descending and evening of lifting. {\textbar}   {\textbar} memory 110 further stores the circadian rhythm of the summarized default obtained by the sample for mass population estimation. the summarized default estimate hypothesis circadian period of about 24 hours. When the human wearing the device 100 for the first time, the device 100 for the personal application summarizing default estimation. However, based on biological by applying stored in a closed loop system to the individual of various duration and passive measurements of mathematical model to adjust the general default estimate to reflect the actual rhythm of the person as time goes on, device 100. measured value may include a motion, skin temperature and heart rate. personal circadian rhythm of the individual actually can vary between e.g. 23.5 to 25 hours, deviates from general default estimation. the predictive personalized for the alertness of the individual Thus, summarizing default estimation is configured to adjust according to the estimated actual circadian rhythm of the individual, whereby the applied bio-mathematical model. For example, a personal wearable device 100 after two days for summarizing default estimate of the personal to adjust a measured value indicative of two days summarizing default estimate is insufficient to reflect the actual rhythm of the individual. {\textbar}   {\textbar} a processor 108 coupled to the motion sensor 104 and bio-metric sensor module 105. Processor 108 may be a programmable microprocessor. Processor 108 is further coupled to a memory for storing and retrieving data 110. processor 108 executable instruction or an application stored in the memory 110 of bio-mathematical model to provide wearable device described herein 100 functionality. processor 108 can be obtained from the motion sensor 104 and bio-metric sensor module 105 of data stored in the memory 110, and the memory 110 to retrieve the stored data for processing. Memory 110 can be conventional memory, such as a static random access memory ({RAM}). Processor 108 may be a conventional microprocessor, such as a low energy-consumption embedded processor. can use reprogrammable microprocessor equipment, which allows the firmware upgrade. A suitable processor 108 is a Altera {MAX}7000A, which work at 3.3V (the working voltage range compatible with suitable gyroscope). {\textbar}   {\textbar} processor 108 also can be connected to a monitoring timing and/or planning of the event clock 112 and a transceiver for transmitting a signal to a remote location and/or receiving the signal from the remote location 114. clock 112 can be integrated circuit clock capable of measuring time (e.g. time fraction unit such as milliseconds, microseconds, etc.). transceiver 114 may be, for example, a Bluetooth transceiver, for example, the wearable device 100 capable of notifying the remote information processing device under the condition of notification, remote computer system, computer application and/or intelligent mobile phone application. The component wearable device 100 can be powered by battery 116 to energy. battery 116 may be, for example, a lithium ion battery of the charging battery. {\textbar}   {\textbar} processor 108 can monitor the output temperature and movement of the motion sensor 104 and the bio-metric sensor module 105 to determine whether the device is attached to the skin is worn. motion output from the motion sensor 104 can be processor 108 for monitoring the motion of the wearable device 100. processor 108 can be configured to target speed 0dps to 2000dps (per second) angular range of motion. the lower limit of the range is removed due to the small angle offset caused by vibration, the upper limit of the range of largely removing the radial movement such as turning the truck. response time of the operator and the temperature and time of the recording can be stored in the memory 110, so that, for example, communication in the absence of available remote information processing system, the dispatcher can at one time point after the verification before the device is properly worn. {\textbar}   {\textbar} additional device 100 can include ambient light detector 107. the ambient light detector 107 can be used for detecting the user level of exposure under the beam. a level of exposure under the beam can affect the circadian rhythm of an individual and adjusting the clock of the individual. This can make the circadian rhythm of the individual. bio-mathematical model can be obtained by the ambient light detector 107 of the information contained in the personal circadian rhythm in response to personal future change degree of exposed under the light of prediction. the ambient light detector 107 can be configured a level of exposure to determine the user under blue wavelength light, the blue wavelength light for the circadian rhythm of an individual may have greater influence. processor 108 can also be coupled to the ambient light detector 107. processor 108 can monitor and process by the motion sensor 104, a bio-metric sensor module 105 and the ambient light detector 107 to the measured output. {\textbar}   {\textbar} processor 108 is also capable of monitoring from temperature, heart rate and motion output of the motion sensor 104 and the bio-metric sensor module 105 to use stored in the memory 110 of bio-mathematical model by the motion measurement value contained in the moving recording and confirming personal to evaluate sleep-awake state, the steady-state comprises sleep and awake periods of the individual. {\textbar}   {\textbar} motion recording motion data analysis of distance between the user previous sleep time and sleep time detection can not move to by processor 108 by instructing the user (indicating that the sleep time) and combining such as heart rate and skin temperature of the biological marker to determine. The processor may use the measured value of distal end skin temperature and heart rate to adjust and/or determination result of the confirmation record. For example, processor 108 can be identified (through mode or other technologies) skin temperature measuring value of the distal end used in determining body movement recording to confirm the individual is sleeping or awake. This can be achieved by threshold (of interest) or rising to the reference data of the deviation in a certain period by skin temperature mode to realize. have demonstrated that ascending and individual distal end skin temperature in fact associated distal end falling and personal skin temperature of sobering fact associated. {\textbar}   {\textbar} In addition, the processor 108 can be the ambient light sensor from ambient light measurement value of 107 as an additional input to the movable recording sleep or awake determination, for example, determining the individual is sleeping or awake is not easily under the condition. For example, if it is not easy to determine the person is sleeping or awake, but there is a lot of ambient light, motion recording output can be the personal in the awake state prediction. Conversely, light may indicate the individual is sleeping. {\textbar}   {\textbar} processor 108 also can be used to determine body posture and rate determination result to determine and/or adjust the body-motion recorded in the moving recording determination. can be to use body posture in a manner similar to the ambient light, because the body posture can provide additional indication about the user is sleeping or awake. For example, a user standing or sitting sleeping than recumbent less likely. Similarly, heart rate with skin temperature indicating individual is sleeping or awake mode. processor 108 can use the additional inputs to better improve the dynamic recording of sleep/wake prediction accuracy so as to improve the sleep-wake state evaluation. {\textbar}   {\textbar} processor 108 further estimates the circadian rhythm of the individual. See {FIG}. 2. processor 108 can process an initial measurement value of at least one biomarker (such as skin temperature or heart rate) to estimate user personal circadian rhythm. the data processed can be caused by drawing picture as shown in {FIG}. 2, for example, the processor 108 can identify or extract personal circadian rhythm associated with a specific position of the feature or event. all day of alertness of the user can height associated with the user position of the user in circadian rhythm. estimating the circadian rhythm of user capability can provide any accurate prediction of the point user alertness in the given date. {\textbar}   {\textbar} A biomarker for estimating personal circadian rhythm is far end skin temperature of the user. far end skin temperature of the user associated with the core body temperature of the user. circadian core body temperature follows the user, core body temperature follows a circadian rhythm of the user, will rise in awake time period, and the normal sleep time period is reduced. alertness level of the user so it will circadian variation. Because the body of the user by radiating the heat quantity for adjusting the core body temperature via the limbs of the body, when the core body heat is reduced, the temperature rise of limbs. Therefore, the distal end temperature of the skin temperature associated with the core (the core body temperature follows the circadian rhythm of the user), the user distal end measured value of skin temperature may be used for accurately estimating a personal circadian rhythm of the user. This provides a user the alertness level model. {\textbar}   {\textbar} the skin temperature of the distal end can also be used with the melatonin level associated with the user. endogenous melatonin level of user is reliable and accurate indication of the position of the user in the personal circadian rhythm and therefore is an indication of user alertness level. melatonin generally increased during the alertness time of attenuating (e.g.: period of the night before sleep), and typically reduced during the alertness time improved. skin temperature generally associated with melatonin level, this is because when the melatonin level rise, the skin temperature of the user is also increased in connection with user circadian rhythm. Thus, skin temperature can also be used for determining a user current melatonin level and thus determined by the user in a personal circadian position decision of the user current alertness level of relevance instead of parameters. {\textbar}   {\textbar} a plurality of positions for estimating the initial measurement of skin temperature of individual distal end user personal circadian rhythm and/or melatonin level of on the body of the user (including the foot, arm, wrist and hand). can be included other initial measurement of biomarker in the processor 108 of the user personal circadian rhythm and/or melatonin level of estimation may include, but is not limited to cardiac-related metric, such as heart rate. {\textbar}   {\textbar} An example of estimating user personal circadian rhythm can begins by user at the body distal end position (e.g., wrist) wearing the wearable device 100 a test period. The test period may have a length of two or more days. active skin temperature can be measured in a period of at least two days according to frequency of once every minute by the temperature sensor 105a. based on a measured value of the distal end skin temperature data, processor 108 may estimate user personal circadian rhythm. it also can be used for estimating circadian rhythm of the user to other initial measurement value of biomarkers in the test period. {\textbar}   {\textbar} by collecting the measured value of individual distal end, skin temperature and/or heart rate in one time period and the processor 108 can estimate the circadian rhythm. processor 108 generated by distal end skin temperature and heart rate of the measured value of a data point. processor 108 may also comprise a personal movement measuring value to fine points. time data points represent the personal actual circadian rhythm, processor 108 can pass the data point on the time accumulated into development change to these data points for estimating overall circadian rhythm of the individual. processor 108 also point for adjusting the data stored in the memory 110 of the general default estimation, so as to better reflect the actual rhythm of the individual. The processor 108 can use pattern recognition and/or machine learning technique to achieve the adjustment, so that determination of the circadian rhythm for the individual is personalized. {\textbar}   {\textbar} circadian rhythm of the individual generally does not greatly change everyday. However, the personal activity may change every day. These active "covering" an indication of common stable personal circadian rhythm. Because distal end skin temperature and/or heart rate to the other outer covering event (such as walking, sleeping, etc.), the processor 108 may need to use additional signal processing techniques to the skin temperature or heart rate data and these "covered" non-circadian rhythm event (i.e., "release" masking). skin temperature and heart rate data (i.e. the original rhythm data) processor 108 using a release covering algorithm to removed from the dark content of "covered event", to provide accurate prediction of the circadian rhythm. For example, periodically raising the walking (e.g. from one office to another office) of a person covered event is not accurate at the same time every day. This means can be adopted for signal processing technology to check the collected each day the same time point (e.g., noon each day 12 point 5) during several days of data point, wherein the technology can remove irrelevant factors "covering" while retaining consistent signal. The used during several days within 24 hours of a given plurality of point averaging technique to implement most easily, however, the use of additional signal processing techniques, such as filtering. Similarly, the same principle can be applied to heart rate measurements, heart rate measurement value is similarly affected by circadian rhythm but the masking effect is not available in the past. {\textbar}   {\textbar} the distal end skin temperature measurements and heart rate measurements "considered in the process of removing masking variables include body posture and personal activities, which are may twist the circadian signal from skin temperature and heart rate of the dark" covered event ". For example, typical environment wherein observation circadian rhythm signal is a laboratory environment, user lying on the bed in a fixed posture, eating little, does not move in the environment. de-masking is to remove the effect of the event outside the controlled environment of the process. For example, the individual may be jogging. When the event occurs, because the individual begins to sweat, skin temperature of the distal end of the individual is reduced. Furthermore, since the physical activity, heart rate of the individual. Therefore, generally lose the dark-rhythm signal. However, processor 108 de-masking " algorithm, the algorithm can pass into history information and the stored state information of the special period of memory, but in the presence of the masking effect of the circadian signal reserved dark. If the device 100 and processor 108 knows personal is running, then processor 108 may determine that the received data is bad data and can be discarded, or its meaning by bio-mathematical model to determine the actual alertness can be reduced. {\textbar}   {\textbar} In a preferred embodiment, circadian rhythm estimation further through the concept of a quality factor associated with each data point to be improved. if additional information can acquire captured data regarding condition (such as whether the user is walking or sleeping), it can give a quality factor of the data points. For example, if the captured data points when the user is walking, then the data point can be considered to be a low quality data points, otherwise, if the captured data points, the user has been sitting for a period of time, then the data points can be considered as high quality data points. using the quality factor because data points, not all are equally processed so as to improve the accuracy of the circadian rhythm. processor 108 can be given points for several days during specific period averaging "release mask" or applying a quality factor to the skin temperature or heart rate data points. For example, if a given day noon 12 5 collecting the distal end temperature of the skin, the individual may being run with bus, resulting in giving a low quality factor of the data points. the second day at noon 12 point 5 branch collecting additional data points. at this time, the user is sitting on the chair, so the data point will be high quality data points. by applying a weighted average of the data points, the processor 108 can acquire more accurate release covering of far end skin temperature or heart rate. {\textbar}   {\textbar} processor 108 the quality factor as a weighted average of the coefficient, the coefficient is used for combining the several days in a day given point of rhythm data value. For example, processor 108 can use the Tuesday afternoon and Wednesday noon 12 point 5 12 point 5 point. intreweeks evaluation of 0.1 quality factor, and Wednesday has a quality factor of 0.9. weighted average resulting from the calculation is (0.1 * * Wednesday-Tuesday-data + 0.9 data) by a processor. Since the processor 108 does not transmit all data points as the same numerical value processing, thus providing better than simply taking the average of the data period of the estimation result. {\textbar}   {\textbar} In addition, the processor 108 can be introduced into the skin temperature and/or heart rate trend to estimate the actual time period of circadian rhythm (for normal personal, not just the actual time period is 24 hours). by giving the skin temperature and/or heart rate data and/or a quality factor to the relieving concealing, processor 108 can make the data standardization and suppose circadian rhythm is a mode of phase offset and associated. Moreover, it can by a sudden rise of far end standard skin temperature data to predict the melatonin level, melatonin level can be used as marker of circadian rhythm coefficient (phase Φ) and the period T of the personal circadian rhythm. {\textbar}   {\textbar} processor 108, or it can be the sleep-wake state determination and the bio-rhythm estimation mathematical model of actual combination, so as to obtain the predicted alertness to individuals. This results in more accurate and personalized personal alertness predictions. sleep-wake state and circadian rhythm in the personal body cooperate to produce time change of personal alertness. See {FIG}. 3. then can be bio-mathematical model the circadian rhythm and sleep state information are combined to generate the overall estimation of alertness. bio-mathematical model of each input can use pattern recognition and/or machine learning techniques to be combined. some of these technology comprises performing weighting for each part. weighted portions of bio-mathematical model may be static or dynamically defined. For example, administration of circadian rhythm of the weights are based on the collected data processor 108 the estimated quality. {\textbar}   {\textbar} {FIG}. 4 depicts a system 400, the system includes a wearable device 100 of some aspect of the invention. wearable device 100 and, for example, intelligent device 450 and/or the external computing device 460. Intelligent device 450 can be, for example, mobile equipment of the intelligent mobile phone. an external computing device 460 may be a personal computer or similar device. data collection by the wearable device 100 can be communicated to the intelligent device 450 and/or external computing device 460. intelligent device 450 and/or external computing device 460 also other information can be transmitted to the wearable device 100. {\textbar}   {\textbar} intelligent device 450 and/or external computing device 460 can display, store and/or further process data received from the wearable device 100 application or other software module. For example, intelligent device 450 with a software application, the software application to display the data received and stored by the intelligent device 450 obtained from the wearable device 100 personal alertness prediction or fatigue score changes over time of {FIG}. intelligent device 450 and/or computing device 460 can be used for the data received from the wearable device 100 predicted fatigue of the personal alerting the individual. In addition, the intelligent device 450 and/or computing device 460 can be connected to data communication cloud 470 and exchange data. Thus, the intelligent device 450 and/or computing device 460 can transmit the received data to the cloud 470 for storage, the intelligent device 450 and/or computing device 460 may, for example, retrieve the stored data in the cloud 470 to generate personal fatigue-related data along with time change of {FIG}. Furthermore, the third party (e.g., manager or dispatcher) can by intelligent device 450 and/or computing device 460 to view information regarding personal fatigue or alertness. {\textbar}   {\textbar} {FIG}. 5 depicts some aspect of the present invention for predicting alertness of the individual step. far end firstly, when skin temperature data in step 500, the processor 108 can obtain or receive motion data generated by a motion sensor of, produced by the temperature sensor and/or heart rate data generated by a heart rate monitor. each of a motion sensor, a temperature sensor and a heart rate monitor can be worn by the person with the wearable device 100 association. a motion sensor can be applied to the step 500a to generate data about individual body posture or about a motion type of the data, these data can be obtained by the processor 108. step 500a also may include a processor 108 to obtain or receive ambient light generated by the ambient light sensor data. {\textbar}   {\textbar} in step 500b, the processor can process the distal end skin temperature data and/or the heart rate data to bio-mathematical model indicating to refinement data, the bio-mathematical model may be stored in a memory of the wearable device 100. processor 108 can use the signal processing technique (including, for example, low-pass filtering and moving average) to realize the processing of skin temperature data and heart rate data. processing/filtering to remove "noise" from distal end skin temperature data signal and/or heart rate data signal in to generate more and more accurate signal. {\textbar}   {\textbar} in the step 500c, the processor can be bio-mathematical model is based on at least one type of motion by the personal of personal body posture and in skin temperature data and/or the heart rate data a quality factor. {\textbar}   {\textbar} in step 500d, a processor in the skin temperature data and/or the heart rate data (i.e. the original rhythm data) identifying circadian rhythm and non-circadian rhythm data, and removing non circadian rhythm data to obtain a refined circadian rhythm data (namely the circadian rhythm data "the mask"). circadian rhythm data is defined as derived from rhythm event data, and non circadian rhythm data is derived from non-circadian rhythm event data. The processor may use pattern recognition and/or machine learning technique unless circadian rhythm data. processor 108 also can detect the refinement/releasing of rhythm data covering local maxima event in the local minimum event to identify potential risk of personal fatigue time. {\textbar}   {\textbar} in step 510, the processor 108 can use the motion data received from the motion sensor for recording motion determination. processor 108 then can in step 510a when using at least one of a refined body distal end skin temperature or heart rate data in the recording determination result, to perform more accurate body motion recording determination. {\textbar}   {\textbar} processor 108 then can using motion recording determination result when the step 520 personal to evaluate sleep-awake state mathematical model, including sleep and awake periods of the individual. the evaluation can occur repeatedly. the processor can either use the original body movement recording determination result using a refined motion recording determination result personal to evaluate sleep-awake state. In addition, the processor 108 can incorporate data about individual body posture to precise sleep-wake state evaluation result. processor may also by introducing ambient light data to refine personal sleep-wake state evaluation result. {\textbar}   {\textbar} in step 530, the processor 108 can use at least one of a skin temperature data or heart rate data in calculated data points. skin temperature of processor 108 can be introduced from step 500b of the processed and/or heart rate data or processed data to calculate points. In addition, the processor 108 can be a quality factor of skin temperature data from step 500c and/or heart rate data included in the calculation of the data point. processor 108 also can be introduced to remove or not unless the skin temperature data and/or calculated heart rate data of the circadian rhythm data points. {\textbar}   {\textbar} in step 540, the processor 108 can generate an estimate of personal circadian rhythm. This may occur repeatedly. processor 108 can be processed by using data points to generate the estimated rhythm, to refined circadian rhythm of default stored in the memory of the wearable device. default circadian rhythm by mass population sample, can assume a default circadian circadian period of about 24 hours. Furthermore, the processor 108 can by introduced ambient light data to refine the estimated circadian rhythm. {\textbar}   {\textbar} processor 108 also capable of estimating circadian rhythm coefficients of the individual when the step 540a (current phase Φ), the awake/sleep coefficient of personal, circadian period T sleep of the individual personal, start time, and/or melatonin secretion starting point of individual (melatonin onset). each person may have different coefficient/phase of circadian rhythm (Φ) offset, which means that the circadian rhythm period T of each person may start at different time. sleep onset time can be identified by for example releasing a low point of masking personal distal end skin temperature is determined after the low point, the distal end concealing of skin temperature rise (e.g. 35\%). low point and the individual high alertness level correlation, but rises from a low point 35\% indicating melatonin secretion starting point. melatonin secretion starting point and can be used as a marking personal circadian period T starting time. {\textbar}   {\textbar} in step 550, personal objective and subjective parameter can be the input to the device 100. personal it can be subjective and objective parameters input to the intelligent device 450 and/or external computing device 460, so that these parameters can be transmitted to the wearable device 100 and its use. can be input parameters including but not limited to as described in detail by American patent application 14 /848 771 the predetermined movement, the personal medical data about history of treatment, does not obtain sufficient sleep sensitivity of consequences from personal answer data of the questionnaire, and personal subjective evaluation of the alertness level of the user. {\textbar}   {\textbar} in step 560, the processor 108 can sleep-wake state evaluation and by combining the bio-mathematical model estimated the circadian rhythm to predict alertness level or generate fatigue prediction of individual. processor 108 may introduce subjective and objective parameters to further refine the prediction of fatigue to the person. can use pattern recognition or machine learning technique in a nonlinear manner the parameters are weighted to be introduced to bio-mathematical model for predicting the refinement. processor 108 may also use diurnal rhythm of coefficient estimation/phase Φ, the circadian rhythm period T, awake/sleep, sleep start time, and/or melatonin secretion starting point to predict alertness of the person. when according to bio-mathematical model to forecast, processor 108 also may introduce refinement or refinement of the sleep-wake state evaluation and/or refinement or refinement of the circadian rhythm of the estimation. processor 108 also by using a local maximum value and local minimum value event detected by event to refine predicted alertness to the individual. forecasting result of alertness after transmitted to the external computing device 460 and/or intelligent device 450 is a wearable device 100 for display, storage and/or further processing. {\textbar}   {\textbar} {FIG}. 6 depicts an exemplary device for implementing the method of {FIG}. 5 the concept of method 600 step. Firstly, in step 602, obtains information about the motion of the individual, remote data of skin temperature and heart rate. the data to wearable device 100 wearable device processor 108 can be obtained as the movement sensor 104, the temperature sensor 105a and/or a heart rate monitor 105b signal. the wearable device 100 or processor 108 also received from the motion sensor 104 indicating that the personal body posture signal. {\textbar}   {\textbar} in step 604, from the temperature sensor 105a and the heart rate monitor 105b receives a signal, which can be processed by the processor 108, according to the indication of bio-mathematical model to the clean data, the bio-mathematical model for the exemplary method 600 is double-process algorithm. processor 108 capable of applying low-pass filtering and moving average value to improve the signal processing of the skin temperature and heart rate data. {\textbar}   {\textbar} in step 606, skin temperature and heart rate data according to the double process algorithm is "released" masking, so that from the dark containing personal far end skin temperature and heart rate data measured by removing the covering signals caused by non-circadian rhythm event. These events include, but are not limited to sleep, physical activity, and certain body posture. on the circadian rhythm of the dark signal can for example be released covered by taking the average value of several days of data ". data (including skin temperature, heart rate data) is "released" masking of then can be used to generate the actual circadian rhythm of the individual data points. also can in step 606 based on the detected type of movement by the personal to imparting a quality factor to skin temperature and/or heart rate data. {\textbar}   {\textbar} in step 608, feature extraction using double-process algorithm to ' ' deregistration conceal and from the measured signal in extracting meaningful event or circadian rhythm-related features. slowly increasing the meaningful events or characteristics may include the skin temperature of the distal end of the slowly rising follows a circadian rhythm of the individual, and indicating the alertness level is reducing. Moreover, an elevated distal end temperature may indicate a sudden change of alertness level. it can use machine learning and/or pattern recognition technology to extract events and/or mode. The algorithm can use multiple common function to carry out characteristic extraction, comprising a peak detection algorithm, the point interpolation method, a cosine function. {\textbar}   {\textbar} in step 610, can be released by the "masking" of data to determine the sleep start time, the sleep start time then can be used for estimating the current phase/circadian rhythm coefficient Φ, namely personal position in the circadian rhythm period. each person may have a different phase (Φ) offset, which means that the circadian rhythm period T of each person may be started from the different time. can be low point identification in the circadian rhythm to determine sleep onset time, after the point such as 35\% of the circadian rhythm. low point and the individual high alertness level is associated to indicate melatonin secretion starting from 35\% low point. melatonin secretion starting point so as to be used as the mark of the starting time of the circadian period T of the individual. {\textbar}   {\textbar} in step 612, can detect the de-masking of skin temperature data and/or the heart rate data in the local maximum value and the minimum value point or event and time that identifies the potential fatigue risk to a given individual. the detected events can be associated with elevated the drowsiness level. e.g., about a point to an elevated skin temperature of 4 point time range can be identified as reduced alertness on Day 2, which often in afternoon time observed. {\textbar}   {\textbar} in step 614, can use the movement record data from personal to determine sleep and awake periods of individual and personal for double process algorithm model obtained by the sleep-wake state. This can be only determined using the detected movement by the personal. However, introducing other measured value (e.g., heart rate, distal end skin temperature and ambient light exposure degree), so that the determination of sleep and active time-to-person more accurately. {\textbar}   {\textbar} in step 616, the individual can the other subjective and objective parameters input into the device 100. personal it can be subjective and objective parameters input to the intelligent device 450 and/or external computing device 460, so that these parameters can be transmitted to the wearable device 100 and its use. These parameters are useful in further refinement predicted alertness to the individual. can be input parameters including but not limited to as described in detail by American patent application 14 /848771 the predetermined motion, history of data about medical personal, not obtaining sufficient sensitivity of sleep of the consequences, the questionnaire data from the personal answer, and personal subjective evaluation of the alertness level of the user. can use pattern recognition or machine learning technique for weighting these parameters in a linear manner so as to store it into the refinement of the double process algorithm in the model. {\textbar}   {\textbar} in step 618, the input from the circadian rhythm (including derived from data points/circadian rhythm of the period T, the phase coefficient Φ, event and melatonin secretion starting point) and double process algorithm of sleep-wake state of input are combined to generate the alertness level of predictive personal performance metrics (performance metric). using pattern recognition technology and/or machine learning techniques to each input to the algorithm to combine. some of these techniques can include for each partial weighting algorithm. For example, given the weight of circadian aspects of the algorithm model is based on estimating the quality of the collected data. can use input (i.e., other objective and subjective parameters) obtained from step 616 to further refine the alertness level prediction. the objective and subjective parameters can also be introduced before are weighted in the personal alertness predictions. {\textbar}   {\textbar} {FIG}. 7 depicts a mathematical model obtained by biological-during 24 hours for alertness prediction output of the individual. the dotted line represents a risk of personal by alertness measurement of from 0 to 10 to measure, wherein 10 represents the highest risk of fatigue and fatigue risk as reference line. the picture shows the alertness prediction personal throughout the 24 hour period along with the change of time. the image further displays the sleep period of the individual, and depicts the alertness prediction result of the individual, the prediction result indicating low, medium and high fatigue risk. {\textbar}   {\textbar} {FIG}. 8 describes the for step of estimating method of the fatigue of wearer/personal 800 according to some aspect of the present invention. method 800 of step one or more of it can save and/or repeating and/or in terms of order (including time) different from the disclosed in the specification, but not beyond the scope and spirit of the invention. {\textbar}   {\textbar} in the step 802, and obtaining the sensor data. sensor data can include information about the wearer, such as motion, position, distal end skin temperature, and/or heart rate. Furthermore, the sensor data may include environmental conditions, such as ambient light level and/or temperature. The wearable device 100 or processor of the wearable device 108 can be obtained as the example motion sensor 104, a temperature sensor 105a, a heart rate monitor 105b and/or sensor data of the light sensor. {\textbar}   {\textbar} in step 804, carry out signal process. For example, 105a from the temperature sensor and the heart rate monitor 105b receives a signal, which can be processed by the processor 108, by bio-mathematical model in the description of claim to clean data. processor 108 can be used, for example, low-pass filtering and moving average value for improving skin temperature and heart rate data of the quality of the signal. {\textbar}   {\textbar} in step 806, according to the received and processed signals to estimate circadian rhythm. processor 108 can identify skin temperature data and/or heart rate data (i.e. the original rhythm data) circadian rhythm data and non-circadian rhythm data, and removing non circadian rhythm data to obtain a refined circadian rhythm data (i.e. the rhythm data "release" masking). Processor 108 can use pattern recognition and/or machine learning technique to unless circadian rhythm data. {\textbar}   {\textbar} in step 808, obtaining personal parameters. personal parameter may comprise subjective and/or objective parameters. personal parameter may include, but is not limited to data about the medical history of the individual, sensitivity to not obtain sufficient sleep of the consequences of performing a predetermined movement ability of data to personal answer from the questionnaire and the personal subjective evaluation of the alertness level of the user. personal parameters by, for example, device 100 or intelligent device 450 and/or external computing device 460 of user input received from the wearer, such that the parameters can be transmitted to the wearable device 100 and its use. These parameters are useful in further refinement predicted alertness to the individual. {\textbar}   {\textbar} in step 810, from the received and processed signal estimation, circadian rhythm and personal parameters obtained extract features. indicating the rhythm of the extracted characteristics may include the shape of the mark, such as local circadian rhythm high point and low point (such as descent after lunch) regarding the user day and idle sleep habits, such as sleep time, sleep inertia, circadian rhythm point, circadian preference (morning vs. personal active at night), habits of the sleep opportunity and the position (phase), the average sleep time, and the small sleeping habits, general medical information, such as age, gender, {BMI}, and the like. In one embodiment, the extracted character is: (1): in the day time of wake, clock for energy falling time, sleep time, sleep time (mid-disense time), sleep duration, sleep time, (2) the idle timeslots, wake time, energy falling time, sleep time, sleep time, sleep duration, sleep time, (3) age, (4) sex, (5) {BMI}; and/or (6) correction of sleep phase information. can be obtained by simply taking the average, before converting the data and thereafter (signal) detecting peak and valley (by differential, integral, phase shift, etc.), algebraic combination based on the conversion of the mapping function, the data is converted to the frequency domain to extract features. {\textbar}   {\textbar} in step 812, the characteristic to apply one or more pattern recognition and/or machine learning algorithm to the extracted, determining how to the extracted features for determining the coefficient. processor 108 can use pattern recognition and/or machine learning techniques to make circadian factor is personalized to the individual and/or weighting for each factor. can be statically or dynamically defined algorithm model is part of the weight. pattern recognition and/or machine learning algorithm can use the peak detection algorithm, interpolation and/or cosine function. In one embodiment, the extracted feature application machine of regression-based learning algorithm, to determine in the next step the extracted coefficient. {\textbar}   {\textbar} in step 814, the extracted coefficients, for example, by processor 108. In one embodiment, extracting four coefficients. the four coefficients can include circadian rhythm coefficient (phase Φ), the awake/sleep, circadian rhythm weighting coefficients, and the awake/sleep weighting coefficient. processor 108 through the (application mapping, phase shift, etc.) conversion step 812 output to extract the coefficient of machine learning, so that it can be supplied to the following step 818 of bio-mathematical model. {\textbar}   {\textbar} in step 816, determining the body movement recording data. processor 108 can use motion data by processing received from the motion sensor to record the motion determination. at least one of fine recording processor 108 then can use the distal end temperature of the skin and/or the determined heart rate data, to perform more accurate motion recording determination, for example, the individual is awake or sleeping, the person is sitting or moving and so on. {\textbar}   {\textbar} in step 818, such as by the processor 108 to the extracted coefficient and determining the movement record data using bio-mathematical model. In one embodiment, bio-mathematical model comprises at least two sub-models, such as waking sub-model when the personal application and application when people sleep sleep sub-model. the individual is awake or sleeping can be determined based on motion data recorded by processor 108, and based on the determination of awake/sleep condition to apply the proper model. {\textbar}   {\textbar} in step 820, generating the fatigue score. fatigue score can be generated by the processor 108. human (e.g., employer) fatigue scores or the indication can be displayed to the user or of interest. if fatigue score indicates a high fatigue level, it can provide stimulation to the user (such as wearable vibration device). {\textbar}   {\textbar} {FIG}. 9A depicts 16 individual first coefficient value. first coefficient value depicted is value of circadian rhythm period/phase (Φ). optimal value of the coefficient represented by " o ", the extracted value by the coefficient extractor of circadian rhythm period determined represented by " x ". {\textbar}   {\textbar} {FIG}. 9B depicts 16 individual of the second coefficient value. second coefficient value depicted is awake/sleep cycle value. optimal value of the coefficient represented by " o ", numerical coefficient extractor for extracting by the awake/sleep period determined is expressed by " x ". {\textbar}   {\textbar} {FIG}. 9C depicts 16 individual of the third coefficient value. the third coefficient value depicted is circadian rhythm period weighted value. the optimal value of coefficient is expressed by " o ", the value of extraction weight of circadian rhythm period determined by the coefficient extractor represented by " x ". {\textbar}   {\textbar} {FIG}. 9D depicts 16 individual of the fourth coefficient value. the fourth coefficient value depicted is awake/sleep period weighted value. the optimal value of coefficient is expressed by " o ", numerical value extracted by the awake/sleep cycle weight of the determined coefficient extractor represented by " x ". {\textbar}   {\textbar} In {FIG}. 9A to 9D describing the information shown, using features of extracted according to some aspect of the technology of the invention is accurate in personal -- can accurately predict the personal fatigue. {\textbar}   {\textbar} Although described herein with reference to a particular embodiment for showing and describing the present invention, but the present invention is not limited to the shown in details. Conversely, in the range of the equivalent according to the condition of not deviating the invention can make various modifications to each detail.
Issue: {CN}108697391A},
}

@patent{moturu_madan18b,
	location = {{US}},
	title = {Method and system for improving care determination},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {Embodiments of a method and system for improving care determination for care providers in relation to a condition of a user associated with a mobile device can include: collecting a log of use dataset associated with user digital communication behavior at the mobile device; collecting a mobility supplementary dataset corresponding to a mobility-related sensor of the mobile device; determining a medical status analysis for a condition of the user based on at least one of the log of use dataset and the mobility supplementary dataset, the medical status analysis including at least one of a diagnosis and a therapeutic intervention associated with the condition; and promoting the at least one of the diagnosis and the therapeutic intervention to a care provider.
Embodiments of a method and system for improving care determination for care providers in relation to a condition of a user associated with a mobile device can include: collecting a log of use dataset associated with user digital communication behavior at the mobile device; collecting a mobility supplementary dataset corresponding to a mobility-related sensor of the mobile device; determining a medical status analysis for a condition of the user based on at least one of the log of use dataset and the mobility supplementary dataset, the medical status analysis including at least one of a diagnosis and a therapeutic intervention associated with the condition; and promoting the at least one of the diagnosis and the therapeutic intervention to a care provider.
Embodiments of a method and system for improving care determination for care providers in relation to a condition of a user associated with a mobile device can include: collecting a log of use dataset associated with user digital communication behavior at the mobile device; collecting a mobility supplementary dataset corresponding to a mobility-related sensor of the mobile device; determining a medical status analysis for a condition of the user based on at least one of the log of use dataset and the mobility supplementary dataset, the medical status analysis including at least one of a diagnosis and a therapeutic intervention associated with the condition; and promoting the at least one of the diagnosis and the therapeutic intervention to a care provider.},
	type = {patent},
	author = {Moturu, Sai and Madan, Anmol},
	urldate = {2017-11-18},
	date = {2018-07-03},
	note = {Edition: G16H001500 {\textbar} G16H004067 {\textbar} G16H005020 {\textbar} G16H005030 {CPC}  - G16H002010 {\textbar} G16H001500 {\textbar} G16H004020 {\textbar} G16H004067 {\textbar} G16H005020 {\textbar} G16H005030 {\textbar} G16H005050 {\textbar} G16H001020 {EP}; {US} {US} We claim: {\textbar}   {\textbar} 1. A method for improving medical status analysis determination in relation to a user condition of a user associated with a mobile device, the method comprising:  {\textbar} receiving a log of use dataset associated with the user at a mobile application of the mobile device; {\textbar}   {\textbar} receiving a mobility sensor supplementary dataset corresponding to a mobility-related sensor of the mobile device, the mobility sensor supplementary dataset associated with a mobility behavior for the user; {\textbar}   {\textbar} extracting, based on the log of use dataset and the mobility sensor supplementary dataset, a set of medical status features associated with the mobility behavior for the user, wherein the set of medical status features is operable to improve data processing by a processing system for facilitating improved medical status analysis determination; {\textbar}   {\textbar} determining a personalized medical status analysis for the user from a first medical status analysis and a second medical status analysis based on the set of medical status features, wherein the first medical status analysis is configured to be selected based on the set of medical status features indicating a first user characteristic associated with the mobility behavior, and wherein the second medical status analysis is configured to be selected based on the set of medical status features indicating a second user characteristic associated with the mobility behavior; {\textbar}   {\textbar} automatically storing, at a remote computing system, the personalized medical status analysis with a user identifier identifying the user; and {\textbar}   {\textbar} transmitting the personalized medical status analysis to a care provider associated with the user, wherein the personalized medical status analysis is operable to improve care provision associated with the user condition. {\textbar}   {\textbar} 2. The method of  {\textbar} claim 1 {\textbar} , further comprising:  {\textbar} determining a selected a patient subgroup for the user from a first subgroup and a second subgroup based on the mobility sensor supplementary dataset, wherein the first subgroup is configured to be selected based on the mobility sensor supplementary dataset indicating a first mobility behavior shared by the first subgroup, and wherein the second subgroup is configured to be selected based on the mobility sensor supplementary dataset indicating a second mobility behavior shared by the second subgroup; {\textbar}   {\textbar} retrieving a medical status model associated with the selected patient subgroup, wherein determining the personalized medical status analysis comprises determining the personalized medical status analysis based on the medical status model and the set of medical status features. {\textbar}   {\textbar} 3. The method of  {\textbar} claim 1 {\textbar} ,  {\textbar} wherein the mobility-related sensor comprises a {GPS} receiver operable to collect {GPS} satellite data during the time period, {\textbar}   {\textbar} wherein extracting the set of medical status features comprises, extracting, at a remote central processing unit ({CPU}), the set of medical status features based on the {GPS} satellite data and the log of use dataset, wherein the medical status features are operable to improve determination of the personalized medical status analysis by the remote {CPU}, and wherein the personalized medical status analysis is associated with the location of the {GPS} receiver during the time period, and {\textbar}   {\textbar} wherein transmitting the personalized medical status analysis comprises presenting the personalized medical status analysis to the care provider at a care provider mobile device. {\textbar}   {\textbar} 4. The method of  {\textbar} claim 1 {\textbar} , wherein determining the personalized medical status analysis comprises determining a set of medication parameters comprising at least one of a medication type, origin, dosage, instructions, interactions, and predicted results, for a medication intervention for the user condition of the user, and wherein transmitting the personalized medical status analysis comprises transmitting the set of medication parameters to the care provider. {\textbar} 5. The method of  {\textbar} claim 4 {\textbar} , further comprising: facilitating provision of the medication intervention to the user through an automated medication system, based on the personalized medical status analysis and a set of care provider inputs associated with the personalized medical status analysis. {\textbar} 6. The method of  {\textbar} claim 1 {\textbar} , wherein transmitting the personalized medical status analysis comprises presenting the personalized medical status analysis at a care provider interface for a care provider device, and wherein the method further comprises:  {\textbar} after transmitting the personalized medical status analysis to the care provider, collecting, at the care provider interface, a care provider input associated with the personalized medical status; and {\textbar}   {\textbar} updating the medical status analysis based on the care provider input. {\textbar}   {\textbar} 7. The method of  {\textbar} claim 6 {\textbar} , wherein collecting the care provider input comprises collecting a care status for modifying care of the user to a different level of care based on the personalized medical status analysis, and wherein the method further comprises transmitting the updated medical status analysis to an additional care provider based on the care status. {\textbar} 8. The method of  {\textbar} claim 1 {\textbar} , wherein determining the personalized medical status analysis comprises determining a therapy recommendation for improving the user condition comprising at least one of a cardiovascular-related condition, a pain-related condition, a sleep-related condition, a communication-related condition, and a mental condition, and transmitting the personalized medical status analysis comprises transmitting the therapy recommendation to the care provider. {\textbar} 9. The method of  {\textbar} claim 1 {\textbar} , wherein determining the personalized medical status analysis comprises determining an emotion-related issue for the user based on the set of medical status features, and wherein transmitting the personalized medical status analysis comprises transmitting the emotion-related issue to the care provider. {\textbar} 10. A method for improving medical status analysis determination in relation to a user condition of a user associated with a mobile device, the method comprising:  {\textbar} receiving a log of use dataset associated with the user at a mobile application of the mobile device; {\textbar}   {\textbar} receiving a mobility sensor supplementary dataset corresponding to a mobility-related sensor of the mobile device, the mobility sensor supplementary dataset associated with a mobility behavior for the user; {\textbar}   {\textbar} extracting a set of medical status features for the user based on the log of use dataset and the mobility sensor supplementary dataset; {\textbar}   {\textbar} retrieving a medical status model from a plurality of medical status models, the medical status model operable to improve data processing by a processing system for facilitating the improved medical status analysis determination; {\textbar}   {\textbar} determining a personalized medical status analysis for the user from a first medical status analysis and a second medical status analysis based on the set of medical status features and the medical status model, wherein the personalized medical status analysis comprises a medication intervention recommendation, wherein the first medical status analysis is configured to be selected based on the set of medical status features indicating a first user characteristic associated with the mobility behavior of the user, and wherein the second medical status analysis is configured to be selected based on the set of medical status features indicating a second user characteristic associated with the mobility behavior of the user; and {\textbar}   {\textbar} promoting the medication intervention recommendation to a care provider by way of transmitting the personalized medical status analysis to the care provider associated with the user, wherein the medication intervention recommendation is operable to improve care provision associated with the user condition. {\textbar}   {\textbar} 11. The method of  {\textbar} claim 10 {\textbar} , wherein transmitting the personalized medical status analysis comprises transmitting the medication intervention recommendation to the care provider, and wherein the method further comprises:  {\textbar} collecting care provider inputs associated with the medication intervention recommendation; and {\textbar}   {\textbar} updating the medication intervention recommendation based on the care provider inputs. {\textbar}   {\textbar} 12. The method of  {\textbar} claim 10 {\textbar} , wherein receiving the log of use dataset comprises accessing at least one of textual communications, audio communications, visual communications, a survey response dataset, and application usage associated with the mobile application of the mobile device, wherein extracting the set of medical status features comprises determining user symptoms based on the at least one of the survey response dataset, the textual communications, the audio communications, the visual communications, and the application usage, and wherein determining the personalized medical status analysis comprises determining the medication intervention recommendation based on the user symptoms. {\textbar} 13. The method of  {\textbar} claim 10 {\textbar} , further comprising:  {\textbar} wherein determining the personalized the medical status analysis comprises determining the medication intervention recommendation from a first therapy recommendation and a second therapy recommendation based on the medical status features. {\textbar}   {\textbar} 14. The method of  {\textbar} claim 10 {\textbar} , wherein the personalized medical status analysis comprises at least one of: user information associated with the user condition, user information associated with the medication intervention recommendation, a therapeutic intervention recommendation improving resource usage, a therapeutic intervention recommendation improving a relationship with the user, an initiation of communication with the user, and a therapeutic intervention recommendation associated with user interaction with an environment. {\textbar} 15. The method of  {\textbar} claim 10 {\textbar} , wherein determining the personalized medical status analysis comprises determining the medication intervention recommendation for a mental condition comprising at least one of a depression disorder, an anxiety disorder, a bipolar disorder, a psychotic disorder, and a mental health symptom, based on the medical status features. {\textbar} 16. The method of  {\textbar} claim 10 {\textbar} , further comprising:  {\textbar} after provision of a medication intervention corresponding to the medication intervention recommendation, collecting a subsequent log of use dataset associated with the user at the mobile application of the mobile device; {\textbar}   {\textbar} determining effectiveness of the medication intervention based on the subsequent log of use dataset; and {\textbar}   {\textbar} updating the medication intervention recommendation for the user based on the effectiveness of the medication intervention. {\textbar}   {\textbar} 17. The method of  {\textbar} claim 10 {\textbar} , further comprising:  {\textbar} generating a therapy model based on medication intervention data associated with a subgroup of patients sharing a subgroup characteristic, wherein the medication intervention data describes at least one of medication intervention efficacy and medication intervention adherence, {\textbar}   {\textbar} wherein determining the personalized medical status analysis comprises:  {\textbar}   {\textbar} matching the user to the subgroup based on a similarity between the subgroup characteristic and a user characteristic describing the user; and {\textbar}   {\textbar} determining the medication intervention recommendation for the user based on the therapy model and the set of medical status features. {\textbar}   {\textbar} 18. The method of  {\textbar} claim 10 {\textbar} , wherein determining the personalized medical status analysis comprises modifying at least one of a content component, a reasoning component, and a format component for tailoring the personalized medical status analysis to the care provider based on a care provider type corresponding to the care provider. {\textbar} 19. The method of  {\textbar} claim 10 {\textbar} , wherein determining the personalized medical status analysis comprises determining a personalized medical status diagnosis from a first medical status diagnosis and a second medical diagnosis based on the set of medical status features, and wherein transmitting the personalized medical status analysis comprises transmitting the personalized medical status diagnosis to the care provider. We claim: {\textbar}   {\textbar} 1. A method for improving medical status analysis determination in relation to a user condition of a user associated with a mobile device, the method comprising:  {\textbar} receiving a log of use dataset associated with the user at a mobile application of the mobile device; {\textbar}   {\textbar} receiving a mobility sensor supplementary dataset corresponding to a mobility-related sensor of the mobile device, the mobility sensor supplementary dataset associated with a mobility behavior for the user; {\textbar}   {\textbar} extracting, based on the log of use dataset and the mobility sensor supplementary dataset, a set of medical status features associated with the mobility behavior for the user, wherein the set of medical status features is operable to improve data processing by a processing system for facilitating improved medical status analysis determination; {\textbar}   {\textbar} determining a personalized medical status analysis for the user from a first medical status analysis and a second medical status analysis based on the set of medical status features, wherein the first medical status analysis is configured to be selected based on the set of medical status features indicating a first user characteristic associated with the mobility behavior, and wherein the second medical status analysis is configured to be selected based on the set of medical status features indicating a second user characteristic associated with the mobility behavior; {\textbar}   {\textbar} automatically storing, at a remote computing system, the personalized medical status analysis with a user identifier identifying the user; and {\textbar}   {\textbar} transmitting the personalized medical status analysis to a care provider associated with the user, wherein the personalized medical status analysis is operable to improve care provision associated with the user condition. {\textbar}   {\textbar} 2. The method of  {\textbar} claim 1 {\textbar} , further comprising:  {\textbar} determining a selected a patient subgroup for the user from a first subgroup and a second subgroup based on the mobility sensor supplementary dataset, wherein the first subgroup is configured to be selected based on the mobility sensor supplementary dataset indicating a first mobility behavior shared by the first subgroup, and wherein the second subgroup is configured to be selected based on the mobility sensor supplementary dataset indicating a second mobility behavior shared by the second subgroup; {\textbar}   {\textbar} retrieving a medical status model associated with the selected patient subgroup, wherein determining the personalized medical status analysis comprises determining the personalized medical status analysis based on the medical status model and the set of medical status features. {\textbar}   {\textbar} 3. The method of  {\textbar} claim 1 {\textbar} ,  {\textbar} wherein the mobility-related sensor comprises a {GPS} receiver operable to collect {GPS} satellite data during the time period, {\textbar}   {\textbar} wherein extracting the set of medical status features comprises, extracting, at a remote central processing unit ({CPU}), the set of medical status features based on the {GPS} satellite data and the log of use dataset, wherein the medical status features are operable to improve determination of the personalized medical status analysis by the remote {CPU}, and wherein the personalized medical status analysis is associated with the location of the {GPS} receiver during the time period, and {\textbar}   {\textbar} wherein transmitting the personalized medical status analysis comprises presenting the personalized medical status analysis to the care provider at a care provider mobile device. {\textbar}   {\textbar} 4. The method of  {\textbar} claim 1 {\textbar} , wherein determining the personalized medical status analysis comprises determining a set of medication parameters comprising at least one of a medication type, origin, dosage, instructions, interactions, and predicted results, for a medication intervention for the user condition of the user, and wherein transmitting the personalized medical status analysis comprises transmitting the set of medication parameters to the care provider. {\textbar} 5. The method of  {\textbar} claim 4 {\textbar} , further comprising: facilitating provision of the medication intervention to the user through an automated medication system, based on the personalized medical status analysis and a set of care provider inputs associated with the personalized medical status analysis. {\textbar} 6. The method of  {\textbar} claim 1 {\textbar} , wherein transmitting the personalized medical status analysis comprises presenting the personalized medical status analysis at a care provider interface for a care provider device, and wherein the method further comprises:  {\textbar} after transmitting the personalized medical status analysis to the care provider, collecting, at the care provider interface, a care provider input associated with the personalized medical status; and {\textbar}   {\textbar} updating the medical status analysis based on the care provider input. {\textbar}   {\textbar} 7. The method of  {\textbar} claim 6 {\textbar} , wherein collecting the care provider input comprises collecting a care status for modifying care of the user to a different level of care based on the personalized medical status analysis, and wherein the method further comprises transmitting the updated medical status analysis to an additional care provider based on the care status. {\textbar} 8. The method of  {\textbar} claim 1 {\textbar} , wherein determining the personalized medical status analysis comprises determining a therapy recommendation for improving the user condition comprising at least one of a cardiovascular-related condition, a pain-related condition, a sleep-related condition, a communication-related condition, and a mental condition, and transmitting the personalized medical status analysis comprises transmitting the therapy recommendation to the care provider. {\textbar} 9. The method of  {\textbar} claim 1 {\textbar} , wherein determining the personalized medical status analysis comprises determining an emotion-related issue for the user based on the set of medical status features, and wherein transmitting the personalized medical status analysis comprises transmitting the emotion-related issue to the care provider. {\textbar} 10. A method for improving medical status analysis determination in relation to a user condition of a user associated with a mobile device, the method comprising:  {\textbar} receiving a log of use dataset associated with the user at a mobile application of the mobile device; {\textbar}   {\textbar} receiving a mobility sensor supplementary dataset corresponding to a mobility-related sensor of the mobile device, the mobility sensor supplementary dataset associated with a mobility behavior for the user; {\textbar}   {\textbar} extracting a set of medical status features for the user based on the log of use dataset and the mobility sensor supplementary dataset; {\textbar}   {\textbar} retrieving a medical status model from a plurality of medical status models, the medical status model operable to improve data processing by a processing system for facilitating the improved medical status analysis determination; {\textbar}   {\textbar} determining a personalized medical status analysis for the user from a first medical status analysis and a second medical status analysis based on the set of medical status features and the medical status model, wherein the personalized medical status analysis comprises a medication intervention recommendation, wherein the first medical status analysis is configured to be selected based on the set of medical status features indicating a first user characteristic associated with the mobility behavior of the user, and wherein the second medical status analysis is configured to be selected based on the set of medical status features indicating a second user characteristic associated with the mobility behavior of the user; and {\textbar}   {\textbar} promoting the medication intervention recommendation to a care provider by way of transmitting the personalized medical status analysis to the care provider associated with the user, wherein the medication intervention recommendation is operable to improve care provision associated with the user condition. {\textbar}   {\textbar} 11. The method of  {\textbar} claim 10 {\textbar} , wherein transmitting the personalized medical status analysis comprises transmitting the medication intervention recommendation to the care provider, and wherein the method further comprises:  {\textbar} collecting care provider inputs associated with the medication intervention recommendation; and {\textbar}   {\textbar} updating the medication intervention recommendation based on the care provider inputs. {\textbar}   {\textbar} 12. The method of  {\textbar} claim 10 {\textbar} , wherein receiving the log of use dataset comprises accessing at least one of textual communications, audio communications, visual communications, a survey response dataset, and application usage associated with the mobile application of the mobile device, wherein extracting the set of medical status features comprises determining user symptoms based on the at least one of the survey response dataset, the textual communications, the audio communications, the visual communications, and the application usage, and wherein determining the personalized medical status analysis comprises determining the medication intervention recommendation based on the user symptoms. {\textbar} 13. The method of  {\textbar} claim 10 {\textbar} , further comprising:  {\textbar} wherein determining the personalized the medical status analysis comprises determining the medication intervention recommendation from a first therapy recommendation and a second therapy recommendation based on the medical status features. {\textbar}   {\textbar} 14. The method of  {\textbar} claim 10 {\textbar} , wherein the personalized medical status analysis comprises at least one of: user information associated with the user condition, user information associated with the medication intervention recommendation, a therapeutic intervention recommendation improving resource usage, a therapeutic intervention recommendation improving a relationship with the user, an initiation of communication with the user, and a therapeutic intervention recommendation associated with user interaction with an environment. {\textbar} 15. The method of  {\textbar} claim 10 {\textbar} , wherein determining the personalized medical status analysis comprises determining the medication intervention recommendation for a mental condition comprising at least one of a depression disorder, an anxiety disorder, a bipolar disorder, a psychotic disorder, and a mental health symptom, based on the medical status features. {\textbar} 16. The method of  {\textbar} claim 10 {\textbar} , further comprising:  {\textbar} after provision of a medication intervention corresponding to the medication intervention recommendation, collecting a subsequent log of use dataset associated with the user at the mobile application of the mobile device; {\textbar}   {\textbar} determining effectiveness of the medication intervention based on the subsequent log of use dataset; and {\textbar}   {\textbar} updating the medication intervention recommendation for the user based on the effectiveness of the medication intervention. {\textbar}   {\textbar} 17. The method of  {\textbar} claim 10 {\textbar} , further comprising:  {\textbar} generating a therapy model based on medication intervention data associated with a subgroup of patients sharing a subgroup characteristic, wherein the medication intervention data describes at least one of medication intervention efficacy and medication intervention adherence, {\textbar}   {\textbar} wherein determining the personalized medical status analysis comprises:  {\textbar}   {\textbar} matching the user to the subgroup based on a similarity between the subgroup characteristic and a user characteristic describing the user; and {\textbar}   {\textbar} determining the medication intervention recommendation for the user based on the therapy model and the set of medical status features. {\textbar}   {\textbar} 18. The method of  {\textbar} claim 10 {\textbar} , wherein determining the personalized medical status analysis comprises modifying at least one of a content component, a reasoning component, and a format component for tailoring the personalized medical status analysis to the care provider based on a care provider type corresponding to the care provider. {\textbar} 19. The method of  {\textbar} claim 10 {\textbar} , wherein determining the personalized medical status analysis comprises determining a personalized medical status diagnosis from a first medical status diagnosis and a second medical diagnosis based on the set of medical status features, and wherein transmitting the personalized medical status analysis comprises transmitting the personalized medical status diagnosis to the care provider. 1. A method for improving medical status analysis determination in relation to a user condition of a user associated with a mobile device, the method comprising:  {\textbar} receiving a log of use dataset associated with the user at a mobile application of the mobile device; {\textbar}   {\textbar} receiving a mobility sensor supplementary dataset corresponding to a mobility-related sensor of the mobile device, the mobility sensor supplementary dataset associated with a mobility behavior for the user; {\textbar}   {\textbar} extracting, based on the log of use dataset and the mobility sensor supplementary dataset, a set of medical status features associated with the mobility behavior for the user, wherein the set of medical status features is operable to improve data processing by a processing system for facilitating improved medical status analysis determination; {\textbar}   {\textbar} determining a personalized medical status analysis for the user from a first medical status analysis and a second medical status analysis based on the set of medical status features, wherein the first medical status analysis is configured to be selected based on the set of medical status features indicating a first user characteristic associated with the mobility behavior, and wherein the second medical status analysis is configured to be selected based on the set of medical status features indicating a second user characteristic associated with the mobility behavior; {\textbar}   {\textbar} automatically storing, at a remote computing system, the personalized medical status analysis with a user identifier identifying the user; and {\textbar}   {\textbar} transmitting the personalized medical status analysis to a care provider associated with the user, wherein the personalized medical status analysis is operable to improve care provision associated with the user condition. 1. A method for improving medical status analysis determination in relation to a user condition of a user associated with a mobile device, the method comprising:  {\textbar} receiving a log of use dataset associated with the user at a mobile application of the mobile device; {\textbar}   {\textbar} receiving a mobility sensor supplementary dataset corresponding to a mobility-related sensor of the mobile device, the mobility sensor supplementary dataset associated with a mobility behavior for the user; {\textbar}   {\textbar} extracting, based on the log of use dataset and the mobility sensor supplementary dataset, a set of medical status features associated with the mobility behavior for the user, wherein the set of medical status features is operable to improve data processing by a processing system for facilitating improved medical status analysis determination; {\textbar}   {\textbar} determining a personalized medical status analysis for the user from a first medical status analysis and a second medical status analysis based on the set of medical status features, wherein the first medical status analysis is configured to be selected based on the set of medical status features indicating a first user characteristic associated with the mobility behavior, and wherein the second medical status analysis is configured to be selected based on the set of medical status features indicating a second user characteristic associated with the mobility behavior; {\textbar}   {\textbar} automatically storing, at a remote computing system, the personalized medical status analysis with a user identifier identifying the user; and {\textbar}   {\textbar} transmitting the personalized medical status analysis to a care provider associated with the user, wherein the personalized medical status analysis is operable to improve care provision associated with the user condition. {CROSS}-{REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar}   {\textbar} This application is a continuation of U.S. application Ser. No. 15/587,599, filed 5 May 2017, which is a continuation-in-part of U.S. application Ser. No. 13/969,349 filed 16 Aug. 2013, which claims the benefit of U.S. Provisional Application Ser. No. 61/683,867 filed on 16 Aug. 2012 and U.S. Provisional Application Ser. No. 61/683,869 filed on 16 Aug. 2012, which are each incorporated in its entirety herein by this reference. {\textbar}   {\textbar} This application is a continuation of U.S. application Ser. No. 15/587,599, filed 5 May 2017, which claims the benefit of U.S. Provisional Application No. 62/359,600 filed 7 Jul. 2016, and U.S. Provisional Application No. 62/332,897 filed 6 May 2016, each of which are incorporated in their entirety by this reference. {\textbar}   {\textbar} {TECHNICAL} {FIELD} {\textbar}   {\textbar} This invention relates generally to the digital health field, and more specifically to a new and useful system and method of leveraging patient digital communication behavior to provide decision support for care providers. {\textbar}   {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {FIGURES} {\textbar}   {\textbar} {FIGS}. 1A-1C {\textbar}   {\textbar}  are schematic representations of variations of a method for improving care determination; {\textbar} {FIG}. 2 {\textbar}   {\textbar}  is a schematic representation of a variation of a method for improving care determination; {\textbar} {FIG}. 3 {\textbar}   {\textbar}  is a schematic representation of a variation of a method for improving care determination associated with multiple users; {\textbar} {FIG}. 4 {\textbar}   {\textbar}  is a schematic representation of a variation of a method for improving care determination using multiple models; {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a schematic representation of variations of a system; {\textbar} {FIGS}. 6A-6B, 7, 8, 9A-9B {\textbar}   {\textbar}  are examples of patient and/or care provider experiences in variations of a method; {\textbar} {FIG}. 10 {\textbar}   {\textbar}  is a schematic representation of a decision flow for promoting therapeutic interventions according to a variation of a method; {\textbar} {FIGS}. 11-13 {\textbar}   {\textbar}  are schematic representations of examples of presenting medical status analyses; {\textbar} {FIGS}. 14A-14C, 15A-15C, and 16 {\textbar}   {\textbar}  are schematic representations of examples of medical status analyses; and {\textbar} {FIGS}. 17A-17E {\textbar}   {\textbar}  are schematic representations of examples of survey questions according to variations of a method. {\textbar} {DESCRIPTION} {OF} {THE} {PREFERRED} {EMBODIMENTS} {\textbar}   {\textbar} The following description of the preferred embodiments of the invention is not intended to limit the invention to these preferred embodiments, but rather to enable any person skilled in the art to make and use this invention. {\textbar}   {\textbar} 1. Overview. {\textbar}   {\textbar} As shown in  {\textbar}   {\textbar} {FIGS}. 1A-1C and 2-3 {\textbar} , embodiments of a method  {\textbar} 100 {\textbar}  for improving care determination for care providers (e.g., care professionals) in relation to a condition of a user (e.g., patient) associated with a mobile device can include: collecting a log of use dataset associated with user digital communication behavior at the mobile device S {\textbar} 110 {\textbar} ; collecting a mobility supplementary dataset corresponding to a mobility-related sensor of the mobile device S {\textbar} 120 {\textbar} ; determining a medical status analysis for a condition of the user based on at least one of the log of use dataset and the mobility supplementary dataset, the medical status analysis including at least one of a diagnosis and a therapeutic intervention associated with the condition S {\textbar} 130 {\textbar} ; and promoting the at least one of the diagnosis and the therapeutic intervention to a care provider S {\textbar} 140 {\textbar} . The method  {\textbar} 100 {\textbar}  can additionally or alternatively include collecting a care provider dataset (e.g., a care professional dataset) from a care provider S {\textbar} 125 {\textbar} ; assigning the user to a user subgroup S {\textbar} 150 {\textbar} ; and/or any other suitable processes. {\textbar} The method  {\textbar}   {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar}  function to leverage patient digital communication behaviors (e.g., text messaging characteristics, phone calling characteristics, etc.) and/or other behaviors (e.g., mobility behaviors, user-provider interaction behaviors associated with interactions between a user and a care provider, behaviors determined based on user inputs such as survey responses, device event behaviors, etc.) to provide one or more care providers with diagnostic and/or therapeutic intervention information pertaining to the user and/or user condition. As shown in  {\textbar} {FIGS}. 6A-6B, 7-8, and 9A-9B {\textbar} , in variations of the method  {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar} , tools can be provided to care providers for improving accuracy and confidence in diagnostic and/or therapeutic decisions regarding patient treatment, and/or tools can be provided to patients for increasing treatment information transparency and confidence in a care provider's recommended treatments. A care provider can include a primary care physician, but can additionally or alternatively include a psychiatrist, therapist, heath coach, nurse practitioner, guardian, friend, other healthcare professional and/or any other suitable provider of care for one or more users. In variations, the method  {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar}  can additionally or alternatively function to support care determination for characterizing and/or improving user conditions including any one or more of: psychiatric and behavioral disorders (e.g., a psychological disorder; depression; anxiety; bipolar disorder; mania; psychosis; associated symptoms; etc.); communication-related conditions (e.g., expressive language disorder; stuttering; phonological disorder; autism disorder; voice conditions; hearing conditions; eye conditions; etc.); sleep-related conditions (e.g., insomnia, sleep apnea; etc.); cardiovascular-related conditions (e.g., coronary artery disease; high blood pressure; hypertension etc.); rheumatoid-related conditions (e.g., arthritis, etc.); pain-related conditions (e.g., chronic pain; etc.); energy-related conditions (e.g., fatigue; lethargy; etc.) endocrine-related conditions; genetic-related conditions; and/or any other suitable type of conditions. User conditions can include at least one of: symptoms, causes, diseases, disorders, side effects (e.g., from medications; etc.), and/or any other suitable aspects associated with conditions. {\textbar} One or more instances of the method  {\textbar}   {\textbar} 100 {\textbar}  and/or processes described herein can be performed asynchronously (e.g., sequentially), concurrently (e.g., in parallel; concurrently on different threads for parallel computing to improve system processing ability for supporting care providers; etc.), in temporal relation to a trigger event, and/or in any other suitable order at any suitable time and frequency by and/or using one or more instances of the system  {\textbar} 200 {\textbar} , elements, and/or entities described herein. However, the method  {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar}  can be configured in any suitable manner. {\textbar} 2. Benefits. {\textbar}   {\textbar} In specific examples, the method and/or system can confer several benefits over conventional methodologies for diagnosing patient conditions and prescribing effective treatments. First, given the potential time pressures and complex patient conditions present in conventional healthcare, traditional diagnostic and therapy recommendation approaches can require a significant time investment in order for a care provider to feel confident about the accuracy of a given diagnosis and/or treatment recommendation. Second, a care provider and/or other care provider may not possess the requisite training and/or updated knowledge base (e.g., recent research findings) to sufficiently provide treatment (e.g., medication prescription, titration, etc.) to patients with different user conditions. Third, from a patient perspective, sub-optimal treatment can arise from lack of monitoring (e.g., of effectiveness, of patient response to treatments in natural settings before, during, and/or after treatment provision, etc.) and/or patient adherence to treatment, leading to care providers possessing insufficient response information to make an informed decision on how to modify a current treatment based on a patient's response to the current treatment. As patient data spanning extended periods of time (e.g., obtained through continuous monitoring) can be integral for the iterative process of improving a patient's treatment regimen (e.g., recommending an initial treatment, monitoring responses during a titration period, modifying medication based on the response, etc.), there can be a need for a long-term full-stack solution that interfaces with both patient and provider. Examples of the method  {\textbar}   {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar}  can confer technologically-rooted solutions to at least the challenges described above. {\textbar} First, the technology can confer improvements in computer-related technology (e.g., digitally provided care provider support; digitally managed treatment response monitoring and analytics; artificial intelligence; computational modeling of diagnosis and treatment determination; etc.) by facilitating computer performance of functions not previously performable. For example, the technology can improve digitally administered care provider support through providing a full-stack solution leveraging passively collected digital communication data, supplementary data, care provider data, and/or other suitable data that would not exist but for advances in mobile devices (e.g., smartphones) and associated digital communication protocols. In a specific example, the technology can provide a full-stack solution starting from monitoring patient digital communication behaviors and patient status before a patient makes an initial visit to a care provider, to providing care providers with relevant patient medical status analysis in real-time during a user-provider interaction, to monitoring patient response to treatments following a user-provider interaction, to providing further decision support for a care provider in deciding whether to modify aspects of the treatment (e.g., type of medication, medication dosage, etc.). Models and/or approaches to generate such analyses and/or recommendations can be iteratively refined to provide such outputs with improved efficiency and specificity for real-time care provider support (e.g., thereby improving the care determination system). {\textbar}   {\textbar} Second, the technology can confer improvements in computer-related technology through an inventive distribution of functionality across a network including a care determination system (e.g., a remote computing system receiving and analyzing digital communication data, supplementary data, interactions with care providers, across a plurality of users), a plurality of mobile devices (e.g., associated with users possessing a diversity of communication behaviors, user-provider relationships, user conditions, and/or other suitable characteristics changing over time), a treatment system (e.g., operable to present medical status analyses including diagnoses and/or therapeutic interventions to care providers, to users, and/or other suitable entities), and/or other suitable components. For example, the care determination system can include functionality of analyzing digital communication data and/or other data previously unused for determining medical status analyses, such as user digital communication data and mobility supplementary data passively collected throughout a treatment regimen (e.g., enabling treatment evaluation based on continuously collected data for pre- and post-treatment provision periods, etc.); digital communication data derived from a population of patients with varying conditions; and/or other suitable data. {\textbar}   {\textbar} Third, the technology can confer improvements in computer-related technology through computer-implemented rules (e.g., feature engineering rules; user preference rules, such as rules describing permissions for types of data collected and/or usable by the care determination system in generating a medical status analysis shared with a care provider; care provider rules, such as rules describing generation of medical status analyses tailored to a care provider to most efficiently guide the care provider; etc.). The increasing prevalence of user digital communication across a plurality of communication protocols and technologies can translate into a plethora of digital communication data (e.g., for both users and care providers), supplementary data (e.g., mobility data, device event data, survey data, etc.), care provider data, and/or other types of data, giving rise to questions of how to process and analyze the vast array of data. However, the technology can address such challenges by, for example, applying feature engineering rules in generating features (e.g., mobility-communication features associated with digital communication behavior and mobility behavior, such as in relation to the treatment regimen) operable to improve processing speed, accuracy, and/or personalization associated medical status analyses and/or other suitable aspects, thereby improving digitally administered care provider support for facilitating improved understanding of patient status. {\textbar}   {\textbar} Fourth, the technology can leverage specialized computing devices (e.g., mobile computing devices with mobility-related sensors, care provider devices, automatic medication dispensers, biosensors, etc.) in facilitating continuous monitoring of a patient (e.g., tracking patient response to recommended treatments), in motivating patient adherence (e.g., by modifying user device operation to alert and/or prompt the user to abide by a treatment regimen based on diagnostic analyses and/or therapy recommendations generated through the method, to automatically control medication dispensation, etc.), and/or providing relevant medical status analysis to the appropriate entities (e.g., at a computing devices of care provider, of a guardian, of a friend, of a family member, etc.). In an example, the technology can apply non-generalized location sensors (e.g., {GPS} systems) to the novel application of care determination through passive continuous monitoring of a patient throughout a treatment regimen. {\textbar}   {\textbar} Fifth, the technology can improve the technical fields of at least digital communication, computational modeling of user and/or care provider behavior, digital medicine, diagnostic and/or treatment prediction, and/or other relevant fields. For example, the technology can continuously collect and utilize datasets unique to internet-enabled mobile computing devices (e.g., social network usage, text messaging characteristics, application usage, patient response monitoring data facilitated through the mobile computing device, etc.) in order to provide real-time, digitally provided care provider decision support in any user-provider interaction. Such decision support can provide the care provider with confidence in their decisions, as care providers can face patients with complex conditions outside of a care providers comfort zone (e.g., psychological conditions associated with a mental health patient), where the conditions can be worsened by inaptly prescribed medications. Additionally or alternatively, the technology can provide decision support that is based on up-to-date medical research, which can be difficult for a care provider to stay abreast of, thereby aiding a care provider in feeling confident that all potential diagnostic and therapeutic options have been considered. Further, the technology can reduce the time required for a care provider to perform an accurate diagnosis and/or treatment recommendation, which can lead to less care provider stress and better patient care. In another example, the technology can take advantage of such datasets (e.g. patient response data to medication, etc.) to better improve the understanding of mental conditions in the field. In another example, the technology can collect patient digital communication behaviors and/or other suitable behaviors with respect to mobile computing devices, determine correlations between the patient digital communication behaviors and patient medical status (e.g., at high risk of depression, low signs of bipolar disorder, etc.), and present the patient medical status analysis to a care provider in a form tailored to guide the care provider in efficiently and accurately making diagnostic and therapeutic choices for the patient. In a specific example, the technology can provide a care provider with likely diagnoses of a patient, which can aid the care provider in narrowing the number and/or types of diagnostic tests to perform on the patient, thereby leading to faster, cheaper, and more accurate user-provider interactions. {\textbar}   {\textbar} Sixth, the technology can provide technical solutions necessarily rooted in computer technology (e.g., utilizing computer models to extract patient health insights from datasets unique to internet-enabled mobile computing devices, in order to provide real-time decision support to care providers at care provider computing devices; modifying visually perceptible digital elements of medical status analyses to tailor the medical status analyses to improving efficient and accurate digitally administered care provider support; etc.) to overcome issues specifically arising with computer technology (e.g., issues surrounding how to use patient digital communication behavior information to improved diagnostic and therapeutic recommendations for patients; issues surrounding how to improve display of medical status analyses at digital interfaces; etc.). {\textbar}   {\textbar} Seventh, the technology can transform entities (e.g., mobile devices, care determination system, treatment system, users, care providers etc.) into different states or things. In an example, the technology can activate applications executing on user devices and/or care provider devices through providing medical status analyses at the applications. In another example, the technology can provide diagnosis- and therapeutic intervention-support to care providers and/or other suitable digital support, thereby transforming the care provider and the associated care provider devices. In another example, the technology can determine and/or update therapeutic intervention recommendations for improving user conditions, thereby transforming the user condition and the health of the user. {\textbar}   {\textbar} As such, the technology can provide a centralized, full-stack approach to leveraging digital monitoring of, engagement of, and/or treatment of a patient to inform digital administration of care provider support, leading to improved effectiveness and/or efficiency of care delivery, cost savings, and care delivery scalability. The technology can, however, provide any other suitable benefit(s) in the context of using non-generalized computer systems for improving care determination. {\textbar}   {\textbar} 3.1 Method—Collecting Communication Behavior Data. {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 110 {\textbar}  recites: collecting a log of use dataset associated with user digital communication behavior at a mobile device (e.g., mobile communication device). Block S {\textbar} 110 {\textbar}  functions to unobtrusively collect and/or retrieve communication-related data (e.g., indicative of digital communication behaviors, mobile application usage, mobile computing device usage, etc.) upon which diagnostic analysis and/or therapeutic recommendations can be inferred. A user is preferably an individual seeking medical attention and/or an individual with a user condition, but can additionally or alternatively be any suitable entity (e.g., human, animal, etc.) possessing any suitable relationship with a care provider. Patient digital behavior data preferably indicates digital behaviors with correlations to medical status (e.g., medical symptom information, diagnostic information, treatment information, treatment efficacy, patient adherence, etc.), but can additionally or alternatively be indicative of any suitable patient characteristic. Collected patient digital behavior data can include logs of use of native communication applications (e.g., phone calling applications, messaging applications, virtual assistant applications, social networking applications, applications facilitating communication with a care provider, etc.), of medical software applications (e.g., cognitive behavioral therapy applications, patient monitoring applications, biosignal detectors, biosensor software, etc.), and/or any suitable data collectable and/or derived from a device of the patient. As such, Block S {\textbar} 110 {\textbar}  preferably enables collection of one or more of: phone call-related data (e.g., number of sent and/or received calls, call duration, call start and/or end time, location of the user before, during, and/or after a call, and number of and time points of missed or ignored calls); text messaging (e.g., {SMS} text messaging) data (e.g., number of messages sent and/or received, message length associated with a contact of the user, message entry speed, delay between message completion time point and sending time point, message efficiency, message accuracy, time of sent and/or received messages, location of the user when receiving and/or sending a message, media such as images, charts and graphs, audio, video, file, links, emojis, clipart, etc.); data on textual messages sent through other communication venues (e.g., public and/or private textual messages sent to contacts of the user through an online social networking system, reviews of products, services, or businesses through an online ranking and/or review service, status updates, “likes” of content provided through an online social networking system), vocal and textual content (e.g., text and/or voice data that can be used to derive features indicative of negative or positive sentiments; textual and/or audio inputs collected from a user in response to automated textual and/or voice communications; etc.) and/or any other suitable type of data. However, patient digital behavior data can include any suitable information relevant to efficiently and/or accurately providing diagnostic results and/or treatment recommendations for a patient. {\textbar} Patient digital behavior data is preferably recorded at a mobile computing device associated with a user (e.g., a smartphone, tablet, smartwatch, laptop, etc., of a user). Additionally or alternatively, patient digital behavior data can be collected from computing devices associated with a care provider (e.g., patient data inputted by a care provider surveying a patient during a doctor appointment), a guardian (e.g., patient data inputted by a guardian administering a medication regimen to a patient), a third party (e.g., database information concerning electronic health records, patient demographic information, patient behavioral information, patient digital communication data, etc.), and/or other suitable entity. In a variation, collecting patient digital behavior data can be performed continuously in real-time as the patient uses a corresponding mobile computing device. For example, as a patient writes and sends a text message, text messaging characteristics (e.g., content, length, recipient, timestamp, time to write, grammar, etc.) regarding the text message can be recorded and transmitted to a remote server for subsequent analysis. {\textbar}   {\textbar} Communications from the log of use are preferably associated with one or more temporal indicators (e.g., during, before, and/or after the user-provider interactions such as visits; time period associated with a treatment regiment, etc.). The temporal indicators can include at least one of: a time period (e.g., seconds, minutes, hours, days, etc.), an absolute time (e.g., indicated by a timestamp), be specific to a user (e.g., a time period associated with a user's daily activity), be specific to a user condition (e.g., a time period associated with medication provision, etc.), be specific to a care provider (e.g., a time period associated with care provider operating hours; etc.), and/or can include any suitable type of temporal indicator. For example, a log of use can include digital communication behavior data collected during a time period (e.g., prior to a user-provider interaction) in which supplementary datasets are collected, where the time period can additionally or alternatively be associated with collected care provider datasets (e.g., care provider data for therapeutic interventions administered to the user to improve symptoms experienced during the time period; user-provider interactions during the time period; care provider inputs commenting upon the log of use data and/or supplementary data collected during the time period; etc.). In an example, generating patient medical status analysis can be based on patient digital behavior data including mobile computing device usage collected over a period of a first and second month, medical device data collected over the second month, a human coach-patient interaction during the second month, and a survey response received in the first day of the first month. Alternatively, generating medical status analysis can be determined from user data associated with the same temporal indicator (e.g., only using data collected during a specific week of the year). Additionally or alternatively, digital behavior data leveraged in determining medical status analysis can have any suitable temporal relationship. However, log of use datasets, other datasets, and associated time periods can be configured and/or related in any suitable manner. {\textbar}   {\textbar} In a variation, collecting patient digital behavior data can be in response to satisfaction of a condition (e.g., a patient engaging in unexpected or high-risk digital communication behavior, a patient permitting a medical monitoring application to record digital behaviors of the patient, a care provider requesting a medical status update for a patient being monitored, treatment response efficacy below an efficacy threshold, a patient requesting a patient medical report to be transmitted to a care provider, and/or any other suitable condition or criteria). However, Block S {\textbar}   {\textbar} 110 {\textbar}  can be performed in any suitable manner. {\textbar} 3.2 Method—Collecting a Supplementary Dataset. {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 120 {\textbar}  recites: collecting a supplementary dataset characterizing activity of the user (e.g., in association with a time period), which functions to unobtrusively receive non-communication-related data from a user's mobile device and/or other device configured to receive contextual data from the user. Supplementary datasets can include any one or more of: device sensor datasets (e.g., mobility supplementary datasets; etc.); medical device data; survey datasets; application usage datasets (e.g., social networking datasets; treatment provision application datasets); device usage information (e.g., screen usage information, physical movement of the mobile device, etc.), device authentication information (e.g., information associated with authenticated unlocking of the mobile device); third-party data; and/or any suitable mobile computing device data. Social networking characteristics can include quantitative characteristics (e.g., amount of posts, amount of views, degree of using a social networking feature, number of social networking friends, number of professional contacts, etc.), content characteristics (e.g., post content, comment content, media content, profile content, etc.), change in activity (e.g., change in social network activity, change in posts frequency, change in content tone, change in social network relationships, etc.), and/or any other suitable social networking characteristics. Mobile computing device sensor information can include recorded biosignals (e.g., heart rate, blood pressure, {EEG} signals, blood sugar levels, etc.), location information (e.g., {GPS} sensor information), physical activity information (e.g., inertial sensor data including gyroscope data, accelerometer data, etc.), light sensor information (e.g., measuring amount of user light exposure, etc.), and/or any other suitable mobile computing device sensor information. However, mobile computing device usage information can include any other suitable information. {\textbar} In a variation, Block S {\textbar}   {\textbar} 120 {\textbar} , can include collecting a mobility supplementary dataset. For instance, the supplementary dataset can include a mobility supplementary dataset including a log of times when the user has picked up and/or placed the mobile device down, in able to determine when the mobile device was in use. Such data can be used to flag certain time periods as time periods where the user was awake. In variations, Block S {\textbar} 120 {\textbar}  can include receiving a mobility supplementary dataset including location information of the user by way of one or more of: receiving a {GPS} location of the user (e.g., from a {GPS} sensor within the mobile device of the user), estimating the location of the user through triangulation of local cellular towers in communication with the mobile device, identifying a geo-located local Wi-Fi hotspot during a phone call, and in any other suitable manner. In specific examples, mobility supplementary datasets can include one or more of: user location data (e.g., a user located inside their private house when communicating with a care provider about a treatment regimen, etc.), physical activity data (e.g., footstep parameters; heart rate above a threshold amount exceeding an average resting heart rate while communicating with a care provider and/or care determination system; accelerometer and/or gyroscope data; breathing patterns; other cardiovascular and/or physical activity parameters; physical isolation lethargy; etc.), and/or any other suitable data. For example, Block S {\textbar} 120 {\textbar}  can include collecting a mobility supplementary dataset indicating the locations of the user within a predetermined time period of the user taking a medication (e.g., before, during, after taking the medication, etc.) for a treatment regimen. In another example, Block S {\textbar} 120 {\textbar}  can include receiving a mobility supplementary dataset indicating locations at which therapeutic interventions were promoted to the user. However, collecting mobility supplementary datasets can be performed in any suitable manner. {\textbar} In another variation, Block S {\textbar}   {\textbar} 120 {\textbar}  can include collecting a survey dataset (e.g., survey responses from the patient; patient responses to care provider-administered questions and inputted by a care provider; etc.). A presented survey can prompt for information regarding user demographic, behavior, digital communication activity, current medical status, historical medical status, family medical status and/or any suitable user information relevant to providing diagnostic analyses and therapy recommendations. As shown in  {\textbar} {FIGS}. 17A-17E {\textbar} , in specific examples, a digital survey can be presented to a user, asking for information regarding: demographic information (e.g., gender, ethnicity, age, name), medical history (e.g., previous diagnoses, previous treatments), current medical status (e.g., current medications, current symptoms, current conditions), future plans (e.g., health plans, exercise plans, habits, life plans, etc.), mental condition (e.g., mental thoughts, anxiety, stress, mood, emotions, etc.), and/or other suitable information. However, collecting a survey dataset can be performed in any suitable manner. {\textbar} In another variation, Block S {\textbar}   {\textbar} 120 {\textbar}  can include collecting usage data for a therapy provision application executing on a mobile computing device of the patient. Therapy provision applications can include any application suitable for and/or designed for facilitating a therapeutic effect on a user (e.g., through administering a therapeutic intervention; etc.). For example, a therapy provision application can include elements related to cognitive behavioral therapy, acceptance and commitment therapy, anger management, mindfulness, couples therapy, trauma relief therapy, and/or any other suitable elements for aiding in psychological ailments (e.g., helping with mood recognition, dealing with negative emotions, overcoming self-esteem issues, striving for positive emotions, handling stress, etc.). However, collecting therapy provision application data and/or other suitable application data can be performed in any suitable manner. {\textbar} In another variation, Block S {\textbar}   {\textbar} 120 {\textbar}  can include collecting medical device data. Medical device data can be collected from medical devices including any one or more of: a biosensor, a biosignal detector, a mobile computing device executing a medical application, a medication adherence device (e.g., automatic medication dispenser, alert devices, chip-embedded medication), and/or any other suitable medical device. For example, a log of patient usage of an automatic medication dispenser can be used in characterizing patient response to a medication regimen. Additionally or alternatively, the medical device data can be directly used in generating a diagnostic analysis and/or therapy recommendation for the patient. For example, {EEG} readings can be directly used (e.g., in combination with digital communication behaviors) for diagnosing the risk severity of depression in an at-risk individual. However, collecting medical device data can be performed in any suitable manner. {\textbar} In another variation Block S {\textbar}   {\textbar} 120 {\textbar}  can include collecting a device event dataset, such as in a manner analogous to that described in U.S. application Ser. No. 13/969,339 filed on 16 Aug. 2013. However, collecting supplementary data can be performed in any suitable manner. {\textbar} 3.3 Method—Collecting Care Provider Data {\textbar}   {\textbar} The method  {\textbar}   {\textbar} 100 {\textbar}  can additionally or alternatively include Block S {\textbar} 125 {\textbar} , which recites: collecting care provider data (e.g., care professional data), which functions to receive datasets associated with one or more care providers, user conditions (e.g., user-provider interactions relating to the user condition; therapeutic interventions promoted through medical status analyses and/or administered by care providers for the user condition; etc.), and/or other suitable entities. A care provider dataset preferably includes care provider analyses (e.g., regarding components of medical status analyses, regarding the user condition, etc.), survey responses (e.g., responses from care providers to surveys analogous to those described in Block S {\textbar} 140 {\textbar} ), assessments and/or insights regarding user-provider interactions (e.g., communications between one or more users and care providers; in-person communications; textual communications, audio; video; automated communications; communication content; etc.), regarding medical status analyses (e.g., care provider modifications to medical status analyses; care providers' actual diagnosis and/or therapeutic intervention in relation to a medical status analysis' predicted diagnosis and/or therapeutic intervention; care provider inputs associated with medical status analyses, such as comments on diagnoses from medical status analyses; etc.), regarding therapeutic interventions, and/or any other suitable aspects, but can include any suitable data in relation to one or more users. User-provider interactions can be through any one or more of: in-person communication (e.g., a scheduled appointment), digital communication (e.g., text messaging communication), and/or any suitable venue. In another variation, Block S {\textbar} 125 {\textbar}  can include collecting electronic health records (e.g., from retrieving electronic health records generated from data associated with the method  {\textbar} 100 {\textbar} ; from querying third-party databases; from receiving electronic health records and/or associated data from care providers, etc.), which can be subsequently processed (e.g., through natural language processing; extracting features; etc.) for use in other portions of the method  {\textbar} 100 {\textbar}  (e.g., determining medical status analyses and/or therapeutic interventions, etc.). However, collecting and/or processing electronic health records can be performed in any suitable manner. {\textbar} For Block S {\textbar}   {\textbar} 125 {\textbar} , care provider data can be collected through a web interface, an application executing on a mobile device (e.g., a care provider device), and/or any suitable venue. For example, Block S {\textbar} 125 {\textbar}  can include receiving a care provider dataset in response to prompting a care provider to provide a care provider input (e.g., at a web interface displaying user information including a user improvement evaluation, etc.), such as during and/or after a user-provider interaction (e.g., an in-person visit). In another example, Block S {\textbar} 125 {\textbar}  can include receiving care provider data in real-time during a user-provider interaction (e.g., where the care provider data includes care-provider interaction data such as the user's answers to the care provider's questions associated with the user condition; etc.). Additionally or alternatively, receiving a care provider dataset can be performed in any manner analogous to embodiments, variations, and examples described in U.S. application Ser. No. 15/005,923, entitled “Method for Providing Therapy to an Individual” and filed on 25 Jan. 2016, which is herein incorporated in its entirety by this reference. However, Block S {\textbar} 125 {\textbar}  can be performed in any suitable manner. {\textbar} Blocks S {\textbar}   {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar}  preferably include collecting datasets associated with a time period and/or other suitable temporal indicator, where different collected datasets can be: collected during the same time period (e.g., received at the care determination system during the time period; sampled during the time period; etc.); related to datasets collected during the time period (e.g., a care provider dataset including care provider assessments of log of use data collected during the time period; etc.); and/or otherwise associated with temporal indicators. Additionally or alternatively, collecting datasets can include any suitable elements described in U.S. application Ser. No. 13/969,339 filed 16 Aug. 2013, which are incorporated herein in their entirety by this reference. However, collecting patient digital behavior can be performed in one or more of the approaches described above, and/or performed in any other suitable manner. {\textbar} 3.4 Method—Determining a Medical Status Analysis {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  recites: determining a medical status analysis (e.g., care status analysis) for a condition of the user based on at least one of a log of use dataset and a mobility supplementary dataset. Block S {\textbar} 130 {\textbar}  functions determine medically relevant information regarding a user and/or user condition. As shown in  {\textbar} {FIGS}. 11-13 {\textbar} , medical status analyses preferably include a diagnosis and/or therapeutic intervention (e.g., a therapy recommendation; treatment recommendation; etc.). Additionally or alternatively, medical status analyses can include symptom information (e.g., predicted current symptoms, potential future symptoms), supplemental user information (e.g., automatically identified demographic information, behavioral information, familial information, etc.), a supplemental medical status analysis (e.g., drug interactions; reasoning components including the sources of information upon which the medical status analysis is based; references to additional information regarding a generated diagnostic analysis and/or therapy recommendation; etc.); user behaviors determined based on datasets collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} ; options for care providers to provide care provider data; digital behavior data for other patients; correlations between digital behavior data and conditions; reference patient profiles (e.g., digital behavior profiles of patients with known conditions and/or treatment responses, composite patient profiles, manually curated patient profiles, automatically generated patient profiles, and/or any suitable reference patient profile; etc.); general medical information derived from databases and/or other resources (e.g., Diagnostic and Statistical Manual of Mental Disorders, International Statistical Classification of Disease and Related Health Problems, resources from the American Psychiatric Association, the World Health Organization, drug regulation agencies, health insurance companies, pharmaceutical companies, policy organizations, research organizations, educational institutions, etc.); therapeutic interventions prescribed to patients (e.g., prescribed and/or verified as efficacious for patients sharing the condition, patients with shared medical parameters; etc.); and/or any other suitable information. In a variation, determining a medical status analysis can include automatically ranking (e.g., triaging) users from a set of users (e.g., patients associated with a particular care provider; patients sharing a demographic; patients associated with a hospital; patients sharing a condition; etc.) for assigning degrees of urgency for providing care and/or for determining suitable types of therapeutic interventions for different users. For example, the method  {\textbar} 100 {\textbar}  can include identifying a subset of users associated with conditions suitable for treatment through a subset of therapeutic interventions (e.g., therapy, psychiatry, specialized care provider visits, etc.). Ranking users can be based on condition, user response monitoring, therapeutic intervention effectiveness, datasets collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar}  (e.g., user-provider interaction data, electronic health records, survey data, logs of use, mobility supplementary data, etc.), and/or any other suitable criteria. Additionally or alternatively, such criteria can be used in ranking and/or otherwise evaluating care providers (e.g., determining a metric indicative of the degree to which care providers are following best practices, such as determined based on reasoning components, etc.). For example, evaluating care providers can be based on at least one of user-provider interactions, care provider inputs, electronic health records, and/or other suitable criteria. Ranking users and/or care providers can be performed at any suitable time and/or frequency (e.g., updating the triaging of users based on user response monitoring, such as by updating the ranking associated with a user to recommend therapy for the user, etc.). Rankings can additionally or alternatively be used in determining the timing and/or frequency of determining a medical status analysis and/or in other suitable portions of the method  {\textbar} 100 {\textbar}  (e.g., determining therapeutic interventions; promoting medical status analyses; etc.), and/or used for any suitable purpose. However, ranking users and/or care providers can be performed in any suitable manner analogous to U.S. application Ser. No. 15/005,923 filed 25 Jan. 2016, which is herein incorporated in its entirety by this reference. {\textbar} Regarding Block S {\textbar}   {\textbar} 130 {\textbar} , generating medical status analyses is preferably based on datasets collected in Blocks S {\textbar} 1100 {\textbar} -S {\textbar} 125 {\textbar} . In a variation, Block S {\textbar} 130 {\textbar}  can be based on log of use data. For example, the method  {\textbar} 100 {\textbar}  can include identifying correlations between digital communication behavior from a set of users (e.g., population of users) and one or more user conditions (e.g., a correlation between decreased digital communication frequency and severity of depression); determining a medical status analysis for a user based on the correlations and a log of use dataset for the user; promoting a therapeutic intervention according to the medical status analyses; and updating the medical status analysis based on an updated log of use dataset for the user and the correlations (e.g., determining an improvement in depression based on an increase in digital communication frequency for the user in response to the therapeutic intervention; etc.). {\textbar} In another variation, Block S {\textbar}   {\textbar} 130 {\textbar}  can be based on mobility supplementary datasets. For example, the method  {\textbar} 100 {\textbar}  can include: identifying a partial response to a promoted medication dosage (e.g., recommended in a medical status analysis) based on log of use dataset and a mobility supplementary dataset (e.g., indicating, during post-therapeutic intervention periods, an increased amount of digital communications at locations of a greater average distance from the user's household, etc.); and updating the medical status analysis (e.g., increasing the medication dosage) based on the identified partial response. However, determining medical status analyses based on mobility supplementary datasets and/or log of use datasets can be performed in any manner analogous to U.S. application Ser. No. 13/969,349 filed 16 Aug. 2013, which is incorporated in its entirety by this reference. {\textbar} In another variation, Block S {\textbar}   {\textbar} 130 {\textbar}  can be based on interaction data (e.g., collected from log of use data; from care provider data; etc.) for interactions between users and/or care providers. For example, Block S {\textbar} 130 {\textbar}  can be based on interactions between a user and a plurality of care providers. In a specific example, Block S {\textbar} 130 {\textbar}  can include: determining (e.g., updating) a medical status analysis based on user-first care provider interaction data between the user and a first care provider (e.g., verbal communications regarding physical symptoms experienced by the user and associated with the user condition, etc.), and user-second care provider interaction data between the user and a second care provider (e.g., textual communications regarding psychological symptoms experienced by the user and associated with the user condition, etc.). In another example, Block S {\textbar} 130 {\textbar}  can be based on interactions between a care provider and multiple users, such as through personalizing a medical status analysis to a care provider based on interactions between the care provider and their patients (e.g., including therapeutic interventions in a medical status analysis that are commonly recommended by the care provider for a user condition; including summaries of previous interactions between the care provider and patients; including recommended interactions to the care provider based on historic interactions associated with the care provider; leveraging user-provider interactions concerning a first patient in order to provide analogous insights for a second patient of the care provider; etc.). In another example, Block S {\textbar} 130 {\textbar}  can be based on interactions between care providers. In a specific example, Block S {\textbar} 130 {\textbar}  can include: determining a medical status analysis based on first care provider-second care provider interaction data for interactions between care providers (e.g., interaction data associated with a first care provider consulting a second care provider concerning the user and/or user condition, such as interaction data concerning symptoms, diagnoses, therapeutic interventions, and/or other suitable components of medical status analyses). Any suitable format of interactions between care providers and/or users can be facilitated at any suitable time. For example, the method  {\textbar} 100 {\textbar}  can include automatically initiating, during a user-care provider interaction period (e.g., during an initial visit; follow-up visit; digital communication period; etc.), a telemedicine communication through a wireless communicable link between a first care provider device associated with the first care provider, and a second care provider device associated with the second care provider; and collecting the first care provider-second care provider interaction data based on the telemedicine communication (e.g., transcribing the telemedicine communication; analyzing the transcription; etc.). {\textbar} In another variation, Block S {\textbar}   {\textbar} 130 {\textbar}  can be based on one or more user conditions. For example, Block S {\textbar} 130 {\textbar}  can include determining reasoning components (e.g., information sources associated with the user condition) of a medical status analysis based on the condition (e.g., mapping the user condition to a plurality of information sources associated with diagnosis and/or therapeutic interventions for the user condition; determining the medical status analysis based on the information sources; etc.). In another example, Block S {\textbar} 130 {\textbar}  can include modifying a visually perceptible digital element of the medical status analysis based on a user condition (e.g., using colors, fonts, graphics, and/or other suitable format components for highlighting portions of the medical status analysis to optimize care determination by a care provider, such as highlighting user conditions with high risk; highlighting side effects of a promoted therapeutic interventions; etc.), where the visually perceptible digital element can be associated with the reasoning component (e.g., highlighting the primary information sources from which the diagnosis is based, etc.) and be operable to improve display of the care status analysis. Additionally or alternatively, modifying perceptible elements of medical status analyses can be based on any suitable criteria. However, determining medical status analyses based on any suitable data can be performed in any suitable manner. {\textbar} Regarding Block S {\textbar}   {\textbar} 130 {\textbar} , determining a medical status analysis is preferably based on one or more medical status features. Medical status features can include any one or more of: mobility features (e.g., location, physical activity behaviors, inertial sensor data, etc.), user condition features (e.g., diagnostic features; user response to therapeutic interventions; survey response data; etc.), textual features (e.g., word frequency, sentiment, punctuation associated with words present in text messages; length; textual features extracted from transcriptions of phone calls associated with the user; etc.), graphical features (e.g., emojis used in text messages; media posted to social networking sites; media transmitted and/or received through digital messages; associated pixel values; etc.), audio features (e.g., Mel Frequency Cepstral Coefficients extracted from audio captured in telemedicine communications, phone calls; etc.), cross-user features (e.g., average frequency of text messages; average length and/or duration of phone calls and/or text messaging; users participating in a digital communication; etc.), cross-care provider features (e.g., care provider communication features associated with subgroups of care providers, etc.), and/or any other suitable features. {\textbar} Regarding Block S {\textbar}   {\textbar} 130 {\textbar} , determining medical status features is preferably based on applying one or more computer-implemented rules (e.g., a feature engineering rule; a user preference rule; rules operable to improve care determination systems, treatment systems, and/or associated medical status models, etc.), but medical status features can be determined based on any suitable information. In an example, Block S {\textbar} 130 {\textbar}  can include establishing and/or storing computer-implemented rules (e.g., to be used in determining the medical status analysis) based on one or more reasoning components (e.g., third-party information sources; meta-analysis performed on data associated with different portions of the method  {\textbar} 100 {\textbar} , such as user response monitoring data). In another example, Block S {\textbar} 130 {\textbar}  can include obtaining a first feature engineering rule defining a medical status analysis as a function of at least one of log of use data and mobility supplementary data; and generating mobility-communication features (e.g., digital communication frequency and/or duration at particular locations; physical activity behaviors in relation to digital communication behaviors; etc.) and/or other medical status features based on evaluating the at least one of the log of use data and the mobility supplementary data against the first feature engineering rule. In another example, Block S {\textbar} 130 {\textbar}  can include obtaining a second feature engineering rule operable to associate the mobility-communication features (and/or other medical status features) with care provider data; and modifying the features based on the care provider data (e.g., labeling the features with care provider inputs concerning the patient behaviors indicated by the features; presenting patient behaviors in a medical status analysis to a care provider, and enabling the care provider to collect and transmit patient responses concerning the patient behaviors, which can be used to generate and/or label medical status features). In a specific example, mobility-communication features including digital communication frequency outside the user's household can be associated with user-provider interaction data indicating a user's severity of anxiety associated with the digital communication frequency. However, applying medical status features can be performed in any suitable manner. {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  can additionally or alternatively include generating, applying, and/or otherwise manipulating medical status models, which preferably output one or more components of a medical status analysis based on data collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar}  and/or other suitable inputs. As shown in  {\textbar} {FIG}. 4 {\textbar} , medical status models can include diagnosis models (e.g., depression diagnosis model; anxiety diagnosis model; bipolar diagnosis model; therapy response models; etc.), therapy models, and/or any other suitable models. In an example, Block S {\textbar} 130 {\textbar}  can include determining a diagnosis with a diagnosis model; and determining a therapeutic intervention with a therapeutic intervention model based on the diagnosis. In another example, Block S {\textbar} 130 {\textbar}  can include, in response to collecting a care provider dataset (e.g., including user-provider interaction data) during a user-care provider interaction period: retrieving the diagnosis model and/or therapeutic intervention model during the user-care provider interaction period; and updating the medical status analysis in real-time during the user-care provider interaction period based on the diagnosis model, the therapeutic intervention model, and the care provider dataset. {\textbar} In a variation of Block S {\textbar}   {\textbar} 130 {\textbar} , generating patient medical status analysis includes generating a decision tree model with internal nodes and branches selected based on correlations between digital behavior data and medical statuses (e.g., correlations between different phone calling characteristics and depression), and identifying a medical status of a patient (e.g., a diagnosis, a treatment recommendation, etc.) based on the decision tree. In another variation, generating patient medical status analysis includes employing a machine learning model. Machine learning algorithms for medical status models and/or other suitable models can include algorithms analogous to those described in U.S. application Ser. No. 15/265,454 filed on 14 Sep. 2016. In specific examples, Block S {\textbar} 130 {\textbar}  can include training and applying a reinforcement learning model (e.g., deep reinforcement learning model), such as a reinforcement learning model for maximizing a reward (e.g., optimizing therapeutic interventions for improving user response in relation to use conditions; personalizing medical status analyses for optimizing care provider support, such as in relation to time spent by the care provider during patient visits; optimizing for care provider confidence in diagnoses and/or recommended therapeutic interventions; etc.), and/or any other suitable type of reinforcement learning models. {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  can additionally or alternatively include updating medical status models. In an example, the method  {\textbar} 100 {\textbar}  can include presenting a diagnosis and a therapeutic intervention to a care provider based on one or more medical status models; receiving care provider validation (e.g., included in care provider data) of the diagnosis and/or therapeutic interventions at an application executing on a care provider computing device; generating a second model based on the care provider validation; monitoring user response to the therapeutic intervention over the course of a time period; generating an updated medical status analysis using the second model based on the monitored patient response data; and providing decision support to the care provider at a follow-up visit based on the updated medical status analysis. In another example, the method  {\textbar} 100 {\textbar}  can include: determining an expected patient response based on a care provider-validated diagnosis and/or therapeutic intervention; and generating an updated diagnosis and/or therapeutic intervention based on a comparison between the expected patient response and the monitored patient response data. However, medical status models can be otherwise used and/or updated. {\textbar} Regarding Block S {\textbar}   {\textbar} 130 {\textbar} , types of medical status analyses can vary across different stages of the patient care process. For example, a diagnosis model and a first therapy model can be operable to generate diagnostic results and an initial medication recommendation for a patient during an initial visit to a care provider, and a second therapy model tailored for modifying the initial medication recommendation can be used in a follow-up visit based on treatment response monitoring data collected between the initial visit and the follow-up visit. However, generating medical status analysis in relation to different periods in the user-provider relationship timeline can be performed in any suitable manner. {\textbar} In relation to Block S {\textbar}   {\textbar} 130 {\textbar} , generating medical status analyses is preferably in response to receiving a user request for patient medical status analysis to be transmitted to an entity (e.g., a care provider). Generating medical status analysis can be performed in real-time, such that medical status analysis can be generated during a patient's visit with a care provider. In a specific example where the user has provided permission for medical status analysis to be shared with a care provider, a care provider can request (e.g., at an application executing on a care provider mobile computing device) the medical status analysis for the user during the user-provider, and in response to the care provider request, patient medical status analysis can be automatically generated for transmission to the care provider (e.g., to the care provider mobile computing device). {\textbar} Additionally or alternatively, generating medical status analysis can be performed according to a generation schedule (e.g., generation frequency) for the medical status analysis (e.g., generating the medical status analysis according to when the medical status analysis is to be transmitted to the target destination), which can be based on at least one of: a user and/or care provider schedule (e.g., accommodating for when a patient will be having an appointment with the care provider, for when the care provider has an opening in their schedule to receive and assess the patient's medical status analysis), time intervals (e.g., generation at every minute, hour, day, week, etc.), preferences (e.g., patient preferences, care provider preferences, etc.), data characteristics (e.g., based on a sufficient amount and/or type of collected data to be able to generate patient medical status analysis with a high degree of confidence), stage in the patient care process (e.g., generating medical status analyses with greater frequency post-therapeutic intervention provision; etc.), diagnosis and/or condition (e.g., generating medical status analyses with greater frequency for conditions of greater severity, etc.), and/or any other suitable criteria. For example, Block S {\textbar}   {\textbar} 130 {\textbar}  can include determining a medical status generation schedule (e.g., generation frequency) based on the diagnosis associated with the condition, where updating the medical status analysis includes updating the medical status analysis based on the medical status generation schedule (e.g., generating a medical status analysis every day after a user's daily consumption of medication, etc.) and/or other suitable datasets (e.g., care provider datasets). However, generating medical status analysis can be performed at any suitable time and frequency. {\textbar} As shown in  {\textbar}   {\textbar} {FIG}. 3 {\textbar} , generating medical status analysis can be performed for a single patient, concurrently for multiple patients (e.g., by leveraging parallel computing principles and thereby improving the efficiency of the computing system), concurrently for different types of user condition, types of medical status analyses (e.g., concurrently running a diagnosis model and a therapy model), concurrently for multiple care providers, and/or with any suitable sequence for any suitable combination of entities. However, generating medical status analysis can be performed at any suitable time and frequency. {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  can additionally or alternatively include matching a user to a care provider, which functions to identify a care provider suited to provide personalized care to the user. For example, the method  {\textbar} 100 {\textbar}  can include: determining effectiveness of the therapeutic intervention; in response to the effectiveness satisfying a threshold condition (e.g., a user response below a threshold), determining a match between a user and a first care provider (e.g., a specialist for the user condition, etc.) based on at least one of a log of use dataset, a mobility supplementary dataset, a diagnosis, and/or other suitable data; and presenting the match to a second care provider (e.g., a recommendation for a consulting entity). A consulting entity (e.g., a care provider) is preferably patient-approved (e.g., consultants that the patient has previously seen, that the patient has previously pre-approved such as through an medical monitoring application executing on a patient mobile computing device, etc.). Automatic selection of potential consultants can be based on care provider characteristics (e.g., care provider experience with the platform, care provider experience with given conditions, care provider relationship with the patient, care provider relationship with other care providers, care provider expertise, etc.), patient characteristics (e.g., patient situation, diagnosis, response, digital behavior data, etc.), consultant characteristics (e.g., consultant profession, consultant expertise, consultant experience, etc.), communication considerations (e.g., wireless connectivity, form of communication preferences, language barriers, demographic information, etc.), and/or any other suitable criteria. In a specific example, the method can include: collecting patient digital communication behavior in relation to patient text messaging characteristics associated with a mobile computing device, generating a social anxiety score for the user based on the patient text messaging characteristics, ranking a set of care provider profiles based on professional experience in relation to social anxiety and socially anxious patients, and presenting care provider profiles to the user for initiating a user-provider relationship and transmission of a patient medical status analysis based on the social anxiety score and the ranking of the set of care provider profiles. Additionally or alternatively, matching users to care providers can be performed in any suitable manner. However, Block S {\textbar} 130 {\textbar}  can be performed in a manner analogous to that described in U.S. application Ser. No. 15/482,995 filed 10 Apr. 2017, which is incorporated in its entirety by this reference, and/or in any suitable manner. {\textbar} 3.4.A Generating a Diagnostic Analysis. {\textbar}   {\textbar} As shown in  {\textbar}   {\textbar} {FIGS}. 1C, 2-3, and 14A-14C {\textbar} , Block S {\textbar} 130 {\textbar}  preferably includes determining one or more diagnoses, which functions to determine information regarding one or more user conditions for a user. A diagnosis can include one or more of: a risk and/or severity value indicating a probability of a patient being afflicted with a given condition, general mental or physiological health indicators, comparisons with other groups of individuals (e.g., based on demographic and/or behavioral characteristics shared between the patient and the group of individuals), prevalence information (e.g., prevalence of depression in a given population), symptom information, and/or any other suitable diagnostic information. {\textbar} In a variation, a diagnosis can be generated without care provider data. For example, a diagnostic analysis can be generated based on collected patient digital behavior data, where the diagnostic analysis is provided to the care provider without the care provider needing to input any patient information. In another variation, generating a diagnostic analysis can be based on collected user data (e.g., log of use data, mobility supplementary data, etc.) and care provider data. In a specific example, a preliminary diagnostic analysis can be generated without care provider input and presented to the care provider during an initial visit between a care provider and a patient. The preliminary diagnostic analysis can guide further diagnostic steps that can be taken by the care provider (e.g., a series of questions to ask the patient). The care provider can input patient data (e.g., patient answers to care provider questions) into a computing device (e.g., an application executing on the smartphone of the care provider), where generating medical status analysis can include generating an updated diagnostic analysis based on the care provider-inputted data. Additionally or alternatively, generating a diagnostic analysis can include any suitable elements described in application Ser. No. 15/069,163 filed 14 Mar. 2016, which is incorporated herein in its entirety by this reference, and/or can be performed in any suitable manner. {\textbar}   {\textbar} 3.4.B Determining a Therapeutic Intervention {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  preferably includes determining one or more therapeutic interventions, which functions to analyze user behaviors and/or diagnoses to identify therapeutic interventions for improving a user condition. Therapeutic interventions can include any one or more of: patient medical reports, therapeutic intervention recommendations (e.g., instruction for a guardian, health professional, care provider, and/or any other suitable individual to follow in implementing the therapy recommendation, which can facilitate therapy implementation, for example, in situations where a patient is incapable of fully implementing the therapy recommendation; etc.); health-related notifications (e.g., health tips provided through automated communications, etc.); therapy interventions (e.g., cognitive behavioral therapy exercises; etc.); care provider-related interventions (e.g., telemedicine; scheduling care provider appointments; etc.); physical interventions (e.g., breathing exercises; meditation exercises; acupuncture; hypnosis; brain stimulation such as through magnetic pulses and/or electrical stimulation; etc.); dietary interventions (e.g., probiotics, nutritional supplements, etc.); medication interventions; auditory interventions (e.g., controlling the mobile device to emit music samples in accordance with music therapy; controlling a personal assistance device to vocally emit content components of automated communications, such as with a tone determined based on a format component; etc.); mobile device and/or supplementary medical device interventions (e.g., modifying device operation parameters; etc.); ambient environment interventions (e.g., modification of light parameters, air quality and/or composition parameters, temperature parameters, humidity parameters; etc.) and/or any other suitable types of interventions. Medication interventions can include one or more of: medication type (prescription, over-the-counter, small-molecule, biopharmaceutical, recombinant proteins, vaccines, antibodies, gene therapy, cell therapy, blood products, etc.), medication origin (e.g., herbal, plant, microbial, animal, chemical synthesis, genetic engineering, radioactive material, etc.), dosage (e.g., frequency, amount, time, dosage form, etc.), instructions (e.g., how to implement the medication regimen, after a meal, on an empty stomach, etc.), medication interactions (e.g., with another drug, etc.), results information (e.g., research supporting the type of medication, publications citing the recommended dosage, etc.), supplemental resources (e.g., hyperlinks to additional information about the medication regiment, etc.), and/or any other suitable medication parameters. {\textbar} As shown in  {\textbar}   {\textbar} {FIGS}. 2 and 10 {\textbar} , in a variation, determining therapeutic interventions can be performed for multiple stages of a user-provider relationship. In a specific example, Block S {\textbar} 130 {\textbar}  can include selecting an initial list of potential therapeutic interventions, narrowing the initial list based on patient digital behavior information, symptoms, drug information, and/or other suitable information, and presenting the narrowed list of potential therapies to a care provider for providing decision support. Additionally or alternatively, a prioritized list of therapeutic interventions (e.g., prioritized based on strength of model recommendation) can be presented to the care provider. User response to the therapeutic interventions can be monitored (e.g., through data collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} , etc.) and used in updating therapeutic interventions, which can include one or more of: modifying dosage (e.g., increasing or decreasing dosage, changing frequency, etc.), augmenting the medication regimen (e.g., adding medication types, removing medication types, etc.), switching a medication type, and/or any other suitable modifications. For example, if a patient exhibits no response to medication “A”, then a therapy recommendation modification of switching to medication “B’ can be generated and presented to the care provider. If a patient exhibits a partial response to medication “A”, then dosage parameters for medication “A” can be altered (e.g., increased dosage). Additionally or alternatively, updating therapeutic interventions can be performed for any suitable number of stages of a user-provider relationship (e.g., multiple stages of partial or no response to medications, and corresponding updates to therapeutic interventions in response to the partial or no response, etc.). However, determining therapeutic interventions can be performed in any suitable manner. {\textbar} 3.5 Method—Promoting a Medical Status Analysis. {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 140 {\textbar}  recites: promoting one or more medical status analyses (e.g., diagnoses, therapeutic interventions), which functions to present, provide, administer, and/or otherwise promote one ore more components of a medical status analyses to users, care providers, and/or other suitable entities for improving care determination by a care provider. Promoting medical status analyses can include one or more of: transmitting and/or presenting medical status analyses; guiding care provider decision-making based on medical status analyses (e.g., interactive step-wise decision making tool, etc.); facilitating digital communication (e.g., between a first and a second care provider, such as between a health coach and a licensed therapist; between one or more patients and one or more care providers, etc.); promoting provision of therapeutic interventions from the medical status analyses (e.g., automatically generating medication prescriptions, transmitting prescriptions to pharmacies, automatically scheduling a future care provider appointment, facilitating healthcare payment, aiding with healthcare insurance logistics, controlling user devices to administer the therapeutic intervention; etc.), and/or other suitable processes. {\textbar} Regarding Block S {\textbar}   {\textbar} 140 {\textbar} , promoting medical status analyses can be performed at specified time intervals (e.g., providing a set of digital patient medical reports to a care provider at the beginning of each day), according to a care provider appointment schedule, for any stage of a user-provider relationship, based on preferences (e.g., a user preference, a care provider preference, etc.), based on rules (e.g., providing decision support in response to disease severity levels exceeding a established threshold, etc.), and/or at any suitable time. Block S {\textbar} 140 {\textbar}  is preferably performable in real-time (e.g., during a user-provider interaction, immediately upon request for decision support, etc.), in order facilitate the provision of time-sensitive information (e.g., patient medical information relevant to accurately diagnosing patient issues and providing therapeutically effective treatments, etc.) during a limited time window of the user-provider interaction. However, Block S {\textbar} 140 {\textbar}  can be performed at any suitable time and frequency. {\textbar} In a variation, promoting medical status analyses can be performed at multiple instances for a user (e.g., over the course of a user-provider relationship, at different stages of the patient care process, etc.). For example, Block S {\textbar}   {\textbar} 140 {\textbar}  can include promoting a medical status analysis for an initial user-provider interaction (e.g., initial visit), monitoring effectiveness of a therapeutic intervention based on patient response to the therapeutic intervention, and promoting an updated medical status analysis at a follow-up user-provider interaction based on the effectiveness. In a specific example, promoting medical status analyses can include providing a first medical status analysis (e.g., a preliminary patient medical report detailing a preliminary diagnosis without an associated therapeutic intervention) to a care provider prior to an initial interaction between the care provider and patient; providing a second decision support (e.g., an updated patient medical report detailing a comprehensive diagnosis with corresponding therapeutic interventions) in real-time to a care provider during the initial interaction and in response to receiving user-care provider interaction data including user responses to care provider questions administered at the initial interaction; collecting patient response supplementary data concerning a care provider-recommended therapeutic intervention; providing a third medical status analysis (e.g., notifications alerting the care provider to how the patient is responding to the care provider-recommended therapeutic intervention) based on the collected patient response supplementary data and prior to a follow-up interaction between the care provider and the patient; providing a fourth medical status analysis (e.g., facilitating a digital communication between a care provider and a consultant to aid a care provider in utilizing a follow-up digital patient medical report analyzing the patient's response to the care provider-recommended therapeutic intervention and providing suggestions to modify the treatment regimen, etc.) to the care provider during the follow-up interaction, and providing a fifth medical status analysis (e.g., a digital update informing the care provider of the efficacy of the modified treatment regimen; facilitating a digital communication between the care provider and the patient to check on the patient's status) to the care provider after the follow-up interaction. However, performing Block S {\textbar} 140 {\textbar}  in multiple instances can be performed in any suitable manner. {\textbar} In another variation, Block S {\textbar}   {\textbar} 140 {\textbar}  can include automatically promoting medical status analyses based on satisfaction of a threshold condition (e.g., a risk of depression exceeding a risk threshold). Threshold conditions can be based on diagnoses (e.g., risk thresholds, severity thresholds, type of user condition thresholds, etc.), therapeutic interventions (e.g., type of therapeutic intervention, urgency associated with a patient needing to start a medication regimen, etc.), data collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} , and/or any other suitable information. However, performing Block S {\textbar} 140 {\textbar}  based on satisfaction of a threshold condition can be performed in any suitable manner. In another variation, Block S {\textbar} 140 {\textbar}  support can include promoting a medical status analysis based on a care provider schedule. For example, the method  {\textbar} 100 {\textbar}  can include receiving a care provider schedule (e.g., at a care determination system), analyzing the care provider schedule for appointment information with a set of patients, and promoting medical status analyses based on the appointment information. In a specific example, receiving a care provider schedule can be in response to presenting an option (e.g., at an application executing on a care provider computing device) for a care provider and/or related individual to sync a care provider schedule of patient support, and Block S {\textbar} 140 {\textbar}  can include providing the care provider with a digital patient medical report of a set of digital patient medical reports in accordance with the upcoming patient appointments, with patients for an entire day, week, and/or in accordance with any suitable characteristic of the care provider schedule. In another specific example, Block S {\textbar} 140 {\textbar}  can include receiving a care provider schedule, identifying a patient appointment scheduled for a subsequent day, medical status analyses can be transmitted prior to user-provider interactions, where the medical status analyses can be accessible by the care provider at a care provider device during offline operation (e.g., during the user-provider interaction) and/or when the care provider device is online-enabled. However, performing Block S {\textbar} 140 {\textbar}  according to a care provider schedule can be performed in any suitable manner. {\textbar} Block S {\textbar}   {\textbar} 140 {\textbar}  can additionally or alternatively be based on care provider characteristics (e.g., expertise of care provider, demographic information, behavioral information, background of care provider, preferences, etc.), patient characteristics (e.g., patient preferences, patient communication behaviors, demographic information, behavioral information, etc.), and/or any other suitable data. In a variation, Block S {\textbar} 140 {\textbar}  can include tailoring promotion of a medical status analysis to a care provider based on care provider characteristics. For example, medical status analyses can be modified to suit the designated learning style of the care provider (e.g., providing graphical digital patient medical reports for a visual care provider learner, providing audio digital patient medical reports for an audio care provider learner, etc.). In another example, medical status analysis can be adjusted for the expertise of the care provider (e.g., providing more fundamental mental disorder knowledge for a care provider who is less-experienced in mental conditions but is treating a user with a psychiatric condition, etc.). In another variation, Block S {\textbar} 140 {\textbar}  can include tailoring promotion of a medical status analysis based on patient characteristics including one or more: genomic characteristics, microbiome characteristics, behavioral characteristics, demographic characteristics, individual characteristics, population characteristics, and/or any other suitable information. For example, Block S {\textbar} 140 {\textbar}  can include recommending specific communication approaches to the care provider for accommodating the communication behavior (e.g., derived from datasets from Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} ) of the patient. received by a mental health patient. However, promoting medical status analyses based on care provider characteristics and/or user characteristics can be performed in any suitable manner. {\textbar} Block S {\textbar}   {\textbar} 140 {\textbar}  can additionally or alternatively include providing a patient medical report (e.g., a comprehensive report detailing a diagnosis, a therapeutic intervention recommendation, etc.) to a care provider, based on one or more medical status analyses. As shown in  {\textbar} {FIGS}. 14A-14C, 15A-15C, and 16 {\textbar} , a patient medical report can include one or more of a diagnosis (e.g., severity of medical issue, risk values, type of condition, etc.), a therapeutic intervention recommendation (e.g., medication types, dosages, drug interactions, supplemental information), user demographic information (e.g., name, sex, age), treatment response information (e.g., digital behavior data collected in response to patient implementation of a medication regimen, biosignal data, survey response data, etc.), reasoning components (e.g., sources of data used in determining components of the medical status analysis, etc.), user history with care providers (e.g., length of working with a health coach, a health professional, etc.), user medical history (e.g., reported symptoms, diagnoses, treatments, family history, etc.), recommendations for other care providers (e.g., contact information of a health professional who can help with treatment, etc.), and/or any other suitable information. In a variation of Block S {\textbar} 140 {\textbar} , a patient medical report can include digital references. Digital references are preferably capable of activation when a care provider computing device is in online operation (e.g., when a care provider computing device transitions from offline operation to online operation), but can alternatively be capable of activation by a care provider whether the care provider computing device is in an offline or online mode. Digital references can include hyperlinks, digital requests (e.g., to a remote server to perform a particular operation), and/or any suitable content. Hyperlinks can link to supplemental resources (e.g., in-depth medication information such as detailed descriptions, exhaustive list of drug interactions, detailed explanatory analysis of how medication recommendations were determined), updated versions of a medical status analysis (e.g., an updated patient medical report based on up-to-date patient data collected from patient smartphone usage), and/or any suitable additional information. In a specific example, a patient medical report can be provided to a care provider for a patient a week before a scheduled user-provider interaction, the patient medical report including digital references to digital destinations (e.g., a website, an application executing on the care provider device, a remote server, etc.) that, when activated, can transmit a request to a care determination system to execute a care status model on up-to-date data for the patient, thereby updating a patient medical report. Additionally or alternatively, providing a patient medical report can be performed in any suitable manner. However, Block S {\textbar} 140 {\textbar}  can be performed in any suitable manner analogous to U.S. application Ser. No. 15/482,995 filed 10 Apr. 2017, which is incorporated in its entirety by this reference, and/or in any suitable manner. {\textbar} 3.6 Method—Determining a Subgroup {\textbar}   {\textbar} The method  {\textbar}   {\textbar} 100 {\textbar}  can additionally or alternatively include Block S {\textbar} 150 {\textbar} , which recites: determining one or more subgroups (e.g., user subgroup, care prouder subgroup), such as with the care determination system and/or other suitable components. Block S {\textbar} 150 {\textbar}  functions to group one or more users and/or care providers based on shared behaviors (e.g., derived from datasets from Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} , etc.) in order to facilitate determination of medical status analyses. For example, Block S {\textbar} 150 {\textbar}  can include: assigning the user to a user subgroup of a set of user subgroups, based on digital communication behaviors and/or mobility supplementary behaviors (e.g., grouping users who infrequently digitally communicate and have a mobility within a predetermined distance threshold from their household), and/or care provider data (e.g., grouping users based user condition information provided by care providers; grouping users based on their behaviors towards user-provider relationships, such as determined from user-provider interactions; etc.), where the user subgroup can share a behavior (e.g., mobility-communication behavior) and can be operable to improve care determination for the condition (e.g., through generation and application of medical status models tailored to the subgroup, etc.); and determining the medical status analysis based on the user subgroup and/or other suitable data (e.g., mobility-communication features, care professional data, etc.). However, determining and/or leveraging subgroups can be performed in any suitable manner analogous to U.S. application Ser. No. 15/482,995 filed 10 Apr. 2017, and/or U.S. application Ser. No. 13/969,339 filed on 16 Aug. 2013, each of which are incorporated in their entirety by this reference, and/or can be performed in any suitable manner. {\textbar} 4. System. {\textbar}   {\textbar} As shown in  {\textbar}   {\textbar} {FIG}. 5 {\textbar} , embodiments of a system  {\textbar} 200 {\textbar}  for improving care determination in relation to a condition of a user associated with a mobile device can include a care determination system  {\textbar} 210 {\textbar}  operable to perform Blocks S {\textbar} 110 {\textbar} -S {\textbar} 150 {\textbar}  and/or other portions of the method  {\textbar} 100 {\textbar} ; and a treatment system  {\textbar} 220 {\textbar}  operable to automatically promote a medical status analysis (e.g., to a care provider) associated with the condition and/or user. The care determination system  {\textbar} 210 {\textbar}  and/or treatment system  {\textbar} 220 {\textbar}  can include a processing system, an interface operable to present medical status analyses; and/or any other suitable components operable to perform any suitable portions of the method  {\textbar} 100 {\textbar} . The system  {\textbar} 200 {\textbar}  can additionally or alternatively include a supplemental device  {\textbar} 230 {\textbar}  (e.g., a supplemental medical device, a supplemental personal assistant device, etc.) and/or any other suitable components. While the components of the system  {\textbar} 200 {\textbar}  are generally described as distinct components, they can be physically and/or logically integrated in any manner. For example, a remote computing system can implement functionality associated with both the care determination system  {\textbar} 210 {\textbar}  and treatment system  {\textbar} 220 {\textbar} . In another example, functionality can be shared between the care determination system  {\textbar} 210 {\textbar} , the treatment system  {\textbar} 220 {\textbar} , and/or any other suitable components of the system  {\textbar} 200 {\textbar} . The system  {\textbar} 200 {\textbar}  and/or components of the system  {\textbar} 200 {\textbar}  (e.g., care determination system  {\textbar} 210 {\textbar} , treatment system  {\textbar} 220 {\textbar} , etc.) can entirely or partially be executed by, hosted on, communicate with, and/or otherwise include: user databases (e.g., storing patient characteristics, user health records, associated care provider characteristics, patient device information, etc.), analysis databases (e.g., storing computational models, collected datasets, features, rules, medical status analyses, etc.), remote computing systems, user devices, care provider devices, and/or any other suitable components. Additionally or alternatively, the components of the system can be distributed across machine and cloud-based computing systems in any other suitable manner. However, the system  {\textbar} 200 {\textbar}  and associated components can be configured in any manner analogous to U.S. application Ser. No. 15/482,995 filed 10 Apr. 2017, U.S. application Ser. No. 13/969,339 entitled “Method for Modeling Behavior and Health Changes” and filed on 16 Aug. 2013, U.S. application Ser. No. 15/265,454 entitled “Method for Providing Health Therapeutic Interventions to a User” and filed on 14 Sep. 2016, and U.S. application Ser. No. 15/245,571 entitled “Method and System for Modeling Behavior and Heart Disease State” and filed on 24 Aug. 2016, each of which are herein incorporated in their entirety by this reference, and/or can be configured in any suitable manner. {\textbar} The care determination system  {\textbar}   {\textbar} 210 {\textbar}  functions to collect and process datasets (e.g., described in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} ) in determining medical status analyses. For example, the care determination system  {\textbar} 210 {\textbar}  can obtain, apply, and/or otherwise manipulate computer-implemented rules (e.g., feature engineering rules) in deriving features for and/or otherwise generating medical status analyses. In a specific example, the care determination system  {\textbar} 210 {\textbar}  can receive mobility supplementary data corresponding to mobility-related sensors including {GPS} receivers operable to collect {GPS} satellite data during the time period; extract features (e.g., with a remote central processing unit) based on the {GPS} satellite data, the features operable to improve determination of medical status analyses; and generate a medical status analysis associated with the location of the {GPS} receiver (e.g., during a time period in which a log of use dataset and/or other suitable datasets were collected, etc.), based on the features. In another specific example, the care determination system  {\textbar} 210 {\textbar}  can receive mobility supplementary data including an orientation of the mobile device (e.g., during a time period), the orientation determined based on signals from a set of inertial sensors mounted respectively at the mobile device; and extract features (e.g., mobility-communication features) based on the orientation. However, the care determination system  {\textbar} 210 {\textbar}  can be configured in any suitable manner. {\textbar} The treatment system  {\textbar}   {\textbar} 220 {\textbar}  functions to promote medical status analyses (e.g., in a manner analogous to Block S {\textbar} 140 {\textbar} , etc.) to care providers, users, and/or any other suitable entities. The treatment system  {\textbar} 220 {\textbar}  can include any one or more of supplementary medical devices  {\textbar} 230 {\textbar}  (e.g., ambient environment devices such as sensing and control systems for temperature, light, air quality and/or composition, humidity; biometric devices such as cardiovascular, {EEG}, {EOG}, {EMG}, {ECG}; medication devices such as automatic medication dispensers; personal assistant devices; etc.), mobile devices (e.g., mobile communication devices from which a log of use dataset is collected; user devices; care provider devices; etc.), and/or any other suitable devices. In an example, the treatment system  {\textbar} 220 {\textbar}  can be operable to generate, transmit, and/or apply control instructions for operating a supplemental device  {\textbar} 230 {\textbar}  and/or other suitable device (e.g., a medical device of the treatment system  {\textbar} 220 {\textbar} ) to promote the medical status analyses (e.g., controlling a user device administer a guided meditation to the user, etc.). In another example, the treatment system  {\textbar} 220 {\textbar}  can be operable to automatically initiate a signal that controls an automated medication system (e.g., a signal for updating medication regimen parameters such as schedule, dosage, medication type, etc.; a signal activating the automated medication system to alert the user in relation to a medication regimen; etc.). However, the treatment system  {\textbar} 220 {\textbar}  can be configured in any suitable manner. {\textbar} An alternative embodiment preferably implements the above methods in a computer-readable medium storing computer-readable instructions. The instructions are preferably executed by computer-executable components preferably integrated with a user interface configuration system. The computer-readable medium may be stored on any suitable computer readable media such as {RAMs}, {ROMs}, flash memory, {EEPROMs}, optical devices ({CD} or {DVD}), hard drives, floppy drives, or any suitable device. The computer-executable component is preferably a processor but the instructions may alternatively or additionally be executed by any suitable dedicated hardware device. Although omitted for conciseness, the preferred embodiments include every combination and permutation of the various system components and the various method processes. {\textbar}   {\textbar} The {FIGURES} illustrate the architecture, functionality and operation of possible implementations of systems, methods and computer program products according to preferred embodiments, example configurations, and variations thereof. In this regard, each block in the flowchart or block diagrams may represent a module, segment, step, or portion of code, which includes one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block can occur out of the order noted in the {FIGURES}. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions. As a person skilled in the art will recognize from the previous detailed description and from the figures and claims, modifications and changes can be made to the preferred embodiments of the invention without departing from the scope of this invention defined in the following claims. {CROSS}-{REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar}   {\textbar} This application is a continuation of U.S. application Ser. No. 15/587,599, filed 5 May 2017, which is a continuation-in-part of U.S. application Ser. No. 13/969,349 filed 16 Aug. 2013, which claims the benefit of U.S. Provisional Application Ser. No. 61/683,867 filed on 16 Aug. 2012 and U.S. Provisional Application Ser. No. 61/683,869 filed on 16 Aug. 2012, which are each incorporated in its entirety herein by this reference. {\textbar}   {\textbar} This application is a continuation of U.S. application Ser. No. 15/587,599, filed 5 May 2017, which claims the benefit of U.S. Provisional Application No. 62/359,600 filed 7 Jul. 2016, and U.S. Provisional Application No. 62/332,897 filed 6 May 2016, each of which are incorporated in their entirety by this reference. {\textbar}   {\textbar} {TECHNICAL} {FIELD} {\textbar}   {\textbar} This invention relates generally to the digital health field, and more specifically to a new and useful system and method of leveraging patient digital communication behavior to provide decision support for care providers. {\textbar}   {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {FIGURES} {\textbar}   {\textbar} {FIGS}. 1A-1C {\textbar}   {\textbar}  are schematic representations of variations of a method for improving care determination; {\textbar} {FIG}. 2 {\textbar}   {\textbar}  is a schematic representation of a variation of a method for improving care determination; {\textbar} {FIG}. 3 {\textbar}   {\textbar}  is a schematic representation of a variation of a method for improving care determination associated with multiple users; {\textbar} {FIG}. 4 {\textbar}   {\textbar}  is a schematic representation of a variation of a method for improving care determination using multiple models; {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a schematic representation of variations of a system; {\textbar} {FIGS}. 6A-6B, 7, 8, 9A-9B {\textbar}   {\textbar}  are examples of patient and/or care provider experiences in variations of a method; {\textbar} {FIG}. 10 {\textbar}   {\textbar}  is a schematic representation of a decision flow for promoting therapeutic interventions according to a variation of a method; {\textbar} {FIGS}. 11-13 {\textbar}   {\textbar}  are schematic representations of examples of presenting medical status analyses; {\textbar} {FIGS}. 14A-14C, 15A-15C, and 16 {\textbar}   {\textbar}  are schematic representations of examples of medical status analyses; and {\textbar} {FIGS}. 17A-17E {\textbar}   {\textbar}  are schematic representations of examples of survey questions according to variations of a method. {\textbar} {DESCRIPTION} {OF} {THE} {PREFERRED} {EMBODIMENTS} {\textbar}   {\textbar} The following description of the preferred embodiments of the invention is not intended to limit the invention to these preferred embodiments, but rather to enable any person skilled in the art to make and use this invention. {\textbar}   {\textbar} 1. Overview. {\textbar}   {\textbar} As shown in  {\textbar}   {\textbar} {FIGS}. 1A-1C and 2-3 {\textbar} , embodiments of a method  {\textbar} 100 {\textbar}  for improving care determination for care providers (e.g., care professionals) in relation to a condition of a user (e.g., patient) associated with a mobile device can include: collecting a log of use dataset associated with user digital communication behavior at the mobile device S {\textbar} 110 {\textbar} ; collecting a mobility supplementary dataset corresponding to a mobility-related sensor of the mobile device S {\textbar} 120 {\textbar} ; determining a medical status analysis for a condition of the user based on at least one of the log of use dataset and the mobility supplementary dataset, the medical status analysis including at least one of a diagnosis and a therapeutic intervention associated with the condition S {\textbar} 130 {\textbar} ; and promoting the at least one of the diagnosis and the therapeutic intervention to a care provider S {\textbar} 140 {\textbar} . The method  {\textbar} 100 {\textbar}  can additionally or alternatively include collecting a care provider dataset (e.g., a care professional dataset) from a care provider S {\textbar} 125 {\textbar} ; assigning the user to a user subgroup S {\textbar} 150 {\textbar} ; and/or any other suitable processes. {\textbar} The method  {\textbar}   {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar}  function to leverage patient digital communication behaviors (e.g., text messaging characteristics, phone calling characteristics, etc.) and/or other behaviors (e.g., mobility behaviors, user-provider interaction behaviors associated with interactions between a user and a care provider, behaviors determined based on user inputs such as survey responses, device event behaviors, etc.) to provide one or more care providers with diagnostic and/or therapeutic intervention information pertaining to the user and/or user condition. As shown in  {\textbar} {FIGS}. 6A-6B, 7-8, and 9A-9B {\textbar} , in variations of the method  {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar} , tools can be provided to care providers for improving accuracy and confidence in diagnostic and/or therapeutic decisions regarding patient treatment, and/or tools can be provided to patients for increasing treatment information transparency and confidence in a care provider's recommended treatments. A care provider can include a primary care physician, but can additionally or alternatively include a psychiatrist, therapist, heath coach, nurse practitioner, guardian, friend, other healthcare professional and/or any other suitable provider of care for one or more users. In variations, the method  {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar}  can additionally or alternatively function to support care determination for characterizing and/or improving user conditions including any one or more of: psychiatric and behavioral disorders (e.g., a psychological disorder; depression; anxiety; bipolar disorder; mania; psychosis; associated symptoms; etc.); communication-related conditions (e.g., expressive language disorder; stuttering; phonological disorder; autism disorder; voice conditions; hearing conditions; eye conditions; etc.); sleep-related conditions (e.g., insomnia, sleep apnea; etc.); cardiovascular-related conditions (e.g., coronary artery disease; high blood pressure; hypertension etc.); rheumatoid-related conditions (e.g., arthritis, etc.); pain-related conditions (e.g., chronic pain; etc.); energy-related conditions (e.g., fatigue; lethargy; etc.) endocrine-related conditions; genetic-related conditions; and/or any other suitable type of conditions. User conditions can include at least one of: symptoms, causes, diseases, disorders, side effects (e.g., from medications; etc.), and/or any other suitable aspects associated with conditions. {\textbar} One or more instances of the method  {\textbar}   {\textbar} 100 {\textbar}  and/or processes described herein can be performed asynchronously (e.g., sequentially), concurrently (e.g., in parallel; concurrently on different threads for parallel computing to improve system processing ability for supporting care providers; etc.), in temporal relation to a trigger event, and/or in any other suitable order at any suitable time and frequency by and/or using one or more instances of the system  {\textbar} 200 {\textbar} , elements, and/or entities described herein. However, the method  {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar}  can be configured in any suitable manner. {\textbar} 2. Benefits. {\textbar}   {\textbar} In specific examples, the method and/or system can confer several benefits over conventional methodologies for diagnosing patient conditions and prescribing effective treatments. First, given the potential time pressures and complex patient conditions present in conventional healthcare, traditional diagnostic and therapy recommendation approaches can require a significant time investment in order for a care provider to feel confident about the accuracy of a given diagnosis and/or treatment recommendation. Second, a care provider and/or other care provider may not possess the requisite training and/or updated knowledge base (e.g., recent research findings) to sufficiently provide treatment (e.g., medication prescription, titration, etc.) to patients with different user conditions. Third, from a patient perspective, sub-optimal treatment can arise from lack of monitoring (e.g., of effectiveness, of patient response to treatments in natural settings before, during, and/or after treatment provision, etc.) and/or patient adherence to treatment, leading to care providers possessing insufficient response information to make an informed decision on how to modify a current treatment based on a patient's response to the current treatment. As patient data spanning extended periods of time (e.g., obtained through continuous monitoring) can be integral for the iterative process of improving a patient's treatment regimen (e.g., recommending an initial treatment, monitoring responses during a titration period, modifying medication based on the response, etc.), there can be a need for a long-term full-stack solution that interfaces with both patient and provider. Examples of the method  {\textbar}   {\textbar} 100 {\textbar}  and/or system  {\textbar} 200 {\textbar}  can confer technologically-rooted solutions to at least the challenges described above. {\textbar} First, the technology can confer improvements in computer-related technology (e.g., digitally provided care provider support; digitally managed treatment response monitoring and analytics; artificial intelligence; computational modeling of diagnosis and treatment determination; etc.) by facilitating computer performance of functions not previously performable. For example, the technology can improve digitally administered care provider support through providing a full-stack solution leveraging passively collected digital communication data, supplementary data, care provider data, and/or other suitable data that would not exist but for advances in mobile devices (e.g., smartphones) and associated digital communication protocols. In a specific example, the technology can provide a full-stack solution starting from monitoring patient digital communication behaviors and patient status before a patient makes an initial visit to a care provider, to providing care providers with relevant patient medical status analysis in real-time during a user-provider interaction, to monitoring patient response to treatments following a user-provider interaction, to providing further decision support for a care provider in deciding whether to modify aspects of the treatment (e.g., type of medication, medication dosage, etc.). Models and/or approaches to generate such analyses and/or recommendations can be iteratively refined to provide such outputs with improved efficiency and specificity for real-time care provider support (e.g., thereby improving the care determination system). {\textbar}   {\textbar} Second, the technology can confer improvements in computer-related technology through an inventive distribution of functionality across a network including a care determination system (e.g., a remote computing system receiving and analyzing digital communication data, supplementary data, interactions with care providers, across a plurality of users), a plurality of mobile devices (e.g., associated with users possessing a diversity of communication behaviors, user-provider relationships, user conditions, and/or other suitable characteristics changing over time), a treatment system (e.g., operable to present medical status analyses including diagnoses and/or therapeutic interventions to care providers, to users, and/or other suitable entities), and/or other suitable components. For example, the care determination system can include functionality of analyzing digital communication data and/or other data previously unused for determining medical status analyses, such as user digital communication data and mobility supplementary data passively collected throughout a treatment regimen (e.g., enabling treatment evaluation based on continuously collected data for pre- and post-treatment provision periods, etc.); digital communication data derived from a population of patients with varying conditions; and/or other suitable data. {\textbar}   {\textbar} Third, the technology can confer improvements in computer-related technology through computer-implemented rules (e.g., feature engineering rules; user preference rules, such as rules describing permissions for types of data collected and/or usable by the care determination system in generating a medical status analysis shared with a care provider; care provider rules, such as rules describing generation of medical status analyses tailored to a care provider to most efficiently guide the care provider; etc.). The increasing prevalence of user digital communication across a plurality of communication protocols and technologies can translate into a plethora of digital communication data (e.g., for both users and care providers), supplementary data (e.g., mobility data, device event data, survey data, etc.), care provider data, and/or other types of data, giving rise to questions of how to process and analyze the vast array of data. However, the technology can address such challenges by, for example, applying feature engineering rules in generating features (e.g., mobility-communication features associated with digital communication behavior and mobility behavior, such as in relation to the treatment regimen) operable to improve processing speed, accuracy, and/or personalization associated medical status analyses and/or other suitable aspects, thereby improving digitally administered care provider support for facilitating improved understanding of patient status. {\textbar}   {\textbar} Fourth, the technology can leverage specialized computing devices (e.g., mobile computing devices with mobility-related sensors, care provider devices, automatic medication dispensers, biosensors, etc.) in facilitating continuous monitoring of a patient (e.g., tracking patient response to recommended treatments), in motivating patient adherence (e.g., by modifying user device operation to alert and/or prompt the user to abide by a treatment regimen based on diagnostic analyses and/or therapy recommendations generated through the method, to automatically control medication dispensation, etc.), and/or providing relevant medical status analysis to the appropriate entities (e.g., at a computing devices of care provider, of a guardian, of a friend, of a family member, etc.). In an example, the technology can apply non-generalized location sensors (e.g., {GPS} systems) to the novel application of care determination through passive continuous monitoring of a patient throughout a treatment regimen. {\textbar}   {\textbar} Fifth, the technology can improve the technical fields of at least digital communication, computational modeling of user and/or care provider behavior, digital medicine, diagnostic and/or treatment prediction, and/or other relevant fields. For example, the technology can continuously collect and utilize datasets unique to internet-enabled mobile computing devices (e.g., social network usage, text messaging characteristics, application usage, patient response monitoring data facilitated through the mobile computing device, etc.) in order to provide real-time, digitally provided care provider decision support in any user-provider interaction. Such decision support can provide the care provider with confidence in their decisions, as care providers can face patients with complex conditions outside of a care providers comfort zone (e.g., psychological conditions associated with a mental health patient), where the conditions can be worsened by inaptly prescribed medications. Additionally or alternatively, the technology can provide decision support that is based on up-to-date medical research, which can be difficult for a care provider to stay abreast of, thereby aiding a care provider in feeling confident that all potential diagnostic and therapeutic options have been considered. Further, the technology can reduce the time required for a care provider to perform an accurate diagnosis and/or treatment recommendation, which can lead to less care provider stress and better patient care. In another example, the technology can take advantage of such datasets (e.g. patient response data to medication, etc.) to better improve the understanding of mental conditions in the field. In another example, the technology can collect patient digital communication behaviors and/or other suitable behaviors with respect to mobile computing devices, determine correlations between the patient digital communication behaviors and patient medical status (e.g., at high risk of depression, low signs of bipolar disorder, etc.), and present the patient medical status analysis to a care provider in a form tailored to guide the care provider in efficiently and accurately making diagnostic and therapeutic choices for the patient. In a specific example, the technology can provide a care provider with likely diagnoses of a patient, which can aid the care provider in narrowing the number and/or types of diagnostic tests to perform on the patient, thereby leading to faster, cheaper, and more accurate user-provider interactions. {\textbar}   {\textbar} Sixth, the technology can provide technical solutions necessarily rooted in computer technology (e.g., utilizing computer models to extract patient health insights from datasets unique to internet-enabled mobile computing devices, in order to provide real-time decision support to care providers at care provider computing devices; modifying visually perceptible digital elements of medical status analyses to tailor the medical status analyses to improving efficient and accurate digitally administered care provider support; etc.) to overcome issues specifically arising with computer technology (e.g., issues surrounding how to use patient digital communication behavior information to improved diagnostic and therapeutic recommendations for patients; issues surrounding how to improve display of medical status analyses at digital interfaces; etc.). {\textbar}   {\textbar} Seventh, the technology can transform entities (e.g., mobile devices, care determination system, treatment system, users, care providers etc.) into different states or things. In an example, the technology can activate applications executing on user devices and/or care provider devices through providing medical status analyses at the applications. In another example, the technology can provide diagnosis- and therapeutic intervention-support to care providers and/or other suitable digital support, thereby transforming the care provider and the associated care provider devices. In another example, the technology can determine and/or update therapeutic intervention recommendations for improving user conditions, thereby transforming the user condition and the health of the user. {\textbar}   {\textbar} As such, the technology can provide a centralized, full-stack approach to leveraging digital monitoring of, engagement of, and/or treatment of a patient to inform digital administration of care provider support, leading to improved effectiveness and/or efficiency of care delivery, cost savings, and care delivery scalability. The technology can, however, provide any other suitable benefit(s) in the context of using non-generalized computer systems for improving care determination. {\textbar}   {\textbar} 3.1 Method—Collecting Communication Behavior Data. {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 110 {\textbar}  recites: collecting a log of use dataset associated with user digital communication behavior at a mobile device (e.g., mobile communication device). Block S {\textbar} 110 {\textbar}  functions to unobtrusively collect and/or retrieve communication-related data (e.g., indicative of digital communication behaviors, mobile application usage, mobile computing device usage, etc.) upon which diagnostic analysis and/or therapeutic recommendations can be inferred. A user is preferably an individual seeking medical attention and/or an individual with a user condition, but can additionally or alternatively be any suitable entity (e.g., human, animal, etc.) possessing any suitable relationship with a care provider. Patient digital behavior data preferably indicates digital behaviors with correlations to medical status (e.g., medical symptom information, diagnostic information, treatment information, treatment efficacy, patient adherence, etc.), but can additionally or alternatively be indicative of any suitable patient characteristic. Collected patient digital behavior data can include logs of use of native communication applications (e.g., phone calling applications, messaging applications, virtual assistant applications, social networking applications, applications facilitating communication with a care provider, etc.), of medical software applications (e.g., cognitive behavioral therapy applications, patient monitoring applications, biosignal detectors, biosensor software, etc.), and/or any suitable data collectable and/or derived from a device of the patient. As such, Block S {\textbar} 110 {\textbar}  preferably enables collection of one or more of: phone call-related data (e.g., number of sent and/or received calls, call duration, call start and/or end time, location of the user before, during, and/or after a call, and number of and time points of missed or ignored calls); text messaging (e.g., {SMS} text messaging) data (e.g., number of messages sent and/or received, message length associated with a contact of the user, message entry speed, delay between message completion time point and sending time point, message efficiency, message accuracy, time of sent and/or received messages, location of the user when receiving and/or sending a message, media such as images, charts and graphs, audio, video, file, links, emojis, clipart, etc.); data on textual messages sent through other communication venues (e.g., public and/or private textual messages sent to contacts of the user through an online social networking system, reviews of products, services, or businesses through an online ranking and/or review service, status updates, “likes” of content provided through an online social networking system), vocal and textual content (e.g., text and/or voice data that can be used to derive features indicative of negative or positive sentiments; textual and/or audio inputs collected from a user in response to automated textual and/or voice communications; etc.) and/or any other suitable type of data. However, patient digital behavior data can include any suitable information relevant to efficiently and/or accurately providing diagnostic results and/or treatment recommendations for a patient. {\textbar} Patient digital behavior data is preferably recorded at a mobile computing device associated with a user (e.g., a smartphone, tablet, smartwatch, laptop, etc., of a user). Additionally or alternatively, patient digital behavior data can be collected from computing devices associated with a care provider (e.g., patient data inputted by a care provider surveying a patient during a doctor appointment), a guardian (e.g., patient data inputted by a guardian administering a medication regimen to a patient), a third party (e.g., database information concerning electronic health records, patient demographic information, patient behavioral information, patient digital communication data, etc.), and/or other suitable entity. In a variation, collecting patient digital behavior data can be performed continuously in real-time as the patient uses a corresponding mobile computing device. For example, as a patient writes and sends a text message, text messaging characteristics (e.g., content, length, recipient, timestamp, time to write, grammar, etc.) regarding the text message can be recorded and transmitted to a remote server for subsequent analysis. {\textbar}   {\textbar} Communications from the log of use are preferably associated with one or more temporal indicators (e.g., during, before, and/or after the user-provider interactions such as visits; time period associated with a treatment regiment, etc.). The temporal indicators can include at least one of: a time period (e.g., seconds, minutes, hours, days, etc.), an absolute time (e.g., indicated by a timestamp), be specific to a user (e.g., a time period associated with a user's daily activity), be specific to a user condition (e.g., a time period associated with medication provision, etc.), be specific to a care provider (e.g., a time period associated with care provider operating hours; etc.), and/or can include any suitable type of temporal indicator. For example, a log of use can include digital communication behavior data collected during a time period (e.g., prior to a user-provider interaction) in which supplementary datasets are collected, where the time period can additionally or alternatively be associated with collected care provider datasets (e.g., care provider data for therapeutic interventions administered to the user to improve symptoms experienced during the time period; user-provider interactions during the time period; care provider inputs commenting upon the log of use data and/or supplementary data collected during the time period; etc.). In an example, generating patient medical status analysis can be based on patient digital behavior data including mobile computing device usage collected over a period of a first and second month, medical device data collected over the second month, a human coach-patient interaction during the second month, and a survey response received in the first day of the first month. Alternatively, generating medical status analysis can be determined from user data associated with the same temporal indicator (e.g., only using data collected during a specific week of the year). Additionally or alternatively, digital behavior data leveraged in determining medical status analysis can have any suitable temporal relationship. However, log of use datasets, other datasets, and associated time periods can be configured and/or related in any suitable manner. {\textbar}   {\textbar} In a variation, collecting patient digital behavior data can be in response to satisfaction of a condition (e.g., a patient engaging in unexpected or high-risk digital communication behavior, a patient permitting a medical monitoring application to record digital behaviors of the patient, a care provider requesting a medical status update for a patient being monitored, treatment response efficacy below an efficacy threshold, a patient requesting a patient medical report to be transmitted to a care provider, and/or any other suitable condition or criteria). However, Block S {\textbar}   {\textbar} 110 {\textbar}  can be performed in any suitable manner. {\textbar} 3.2 Method—Collecting a Supplementary Dataset. {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 120 {\textbar}  recites: collecting a supplementary dataset characterizing activity of the user (e.g., in association with a time period), which functions to unobtrusively receive non-communication-related data from a user's mobile device and/or other device configured to receive contextual data from the user. Supplementary datasets can include any one or more of: device sensor datasets (e.g., mobility supplementary datasets; etc.); medical device data; survey datasets; application usage datasets (e.g., social networking datasets; treatment provision application datasets); device usage information (e.g., screen usage information, physical movement of the mobile device, etc.), device authentication information (e.g., information associated with authenticated unlocking of the mobile device); third-party data; and/or any suitable mobile computing device data. Social networking characteristics can include quantitative characteristics (e.g., amount of posts, amount of views, degree of using a social networking feature, number of social networking friends, number of professional contacts, etc.), content characteristics (e.g., post content, comment content, media content, profile content, etc.), change in activity (e.g., change in social network activity, change in posts frequency, change in content tone, change in social network relationships, etc.), and/or any other suitable social networking characteristics. Mobile computing device sensor information can include recorded biosignals (e.g., heart rate, blood pressure, {EEG} signals, blood sugar levels, etc.), location information (e.g., {GPS} sensor information), physical activity information (e.g., inertial sensor data including gyroscope data, accelerometer data, etc.), light sensor information (e.g., measuring amount of user light exposure, etc.), and/or any other suitable mobile computing device sensor information. However, mobile computing device usage information can include any other suitable information. {\textbar} In a variation, Block S {\textbar}   {\textbar} 120 {\textbar} , can include collecting a mobility supplementary dataset. For instance, the supplementary dataset can include a mobility supplementary dataset including a log of times when the user has picked up and/or placed the mobile device down, in able to determine when the mobile device was in use. Such data can be used to flag certain time periods as time periods where the user was awake. In variations, Block S {\textbar} 120 {\textbar}  can include receiving a mobility supplementary dataset including location information of the user by way of one or more of: receiving a {GPS} location of the user (e.g., from a {GPS} sensor within the mobile device of the user), estimating the location of the user through triangulation of local cellular towers in communication with the mobile device, identifying a geo-located local Wi-Fi hotspot during a phone call, and in any other suitable manner. In specific examples, mobility supplementary datasets can include one or more of: user location data (e.g., a user located inside their private house when communicating with a care provider about a treatment regimen, etc.), physical activity data (e.g., footstep parameters; heart rate above a threshold amount exceeding an average resting heart rate while communicating with a care provider and/or care determination system; accelerometer and/or gyroscope data; breathing patterns; other cardiovascular and/or physical activity parameters; physical isolation lethargy; etc.), and/or any other suitable data. For example, Block S {\textbar} 120 {\textbar}  can include collecting a mobility supplementary dataset indicating the locations of the user within a predetermined time period of the user taking a medication (e.g., before, during, after taking the medication, etc.) for a treatment regimen. In another example, Block S {\textbar} 120 {\textbar}  can include receiving a mobility supplementary dataset indicating locations at which therapeutic interventions were promoted to the user. However, collecting mobility supplementary datasets can be performed in any suitable manner. {\textbar} In another variation, Block S {\textbar}   {\textbar} 120 {\textbar}  can include collecting a survey dataset (e.g., survey responses from the patient; patient responses to care provider-administered questions and inputted by a care provider; etc.). A presented survey can prompt for information regarding user demographic, behavior, digital communication activity, current medical status, historical medical status, family medical status and/or any suitable user information relevant to providing diagnostic analyses and therapy recommendations. As shown in  {\textbar} {FIGS}. 17A-17E {\textbar} , in specific examples, a digital survey can be presented to a user, asking for information regarding: demographic information (e.g., gender, ethnicity, age, name), medical history (e.g., previous diagnoses, previous treatments), current medical status (e.g., current medications, current symptoms, current conditions), future plans (e.g., health plans, exercise plans, habits, life plans, etc.), mental condition (e.g., mental thoughts, anxiety, stress, mood, emotions, etc.), and/or other suitable information. However, collecting a survey dataset can be performed in any suitable manner. {\textbar} In another variation, Block S {\textbar}   {\textbar} 120 {\textbar}  can include collecting usage data for a therapy provision application executing on a mobile computing device of the patient. Therapy provision applications can include any application suitable for and/or designed for facilitating a therapeutic effect on a user (e.g., through administering a therapeutic intervention; etc.). For example, a therapy provision application can include elements related to cognitive behavioral therapy, acceptance and commitment therapy, anger management, mindfulness, couples therapy, trauma relief therapy, and/or any other suitable elements for aiding in psychological ailments (e.g., helping with mood recognition, dealing with negative emotions, overcoming self-esteem issues, striving for positive emotions, handling stress, etc.). However, collecting therapy provision application data and/or other suitable application data can be performed in any suitable manner. {\textbar} In another variation, Block S {\textbar}   {\textbar} 120 {\textbar}  can include collecting medical device data. Medical device data can be collected from medical devices including any one or more of: a biosensor, a biosignal detector, a mobile computing device executing a medical application, a medication adherence device (e.g., automatic medication dispenser, alert devices, chip-embedded medication), and/or any other suitable medical device. For example, a log of patient usage of an automatic medication dispenser can be used in characterizing patient response to a medication regimen. Additionally or alternatively, the medical device data can be directly used in generating a diagnostic analysis and/or therapy recommendation for the patient. For example, {EEG} readings can be directly used (e.g., in combination with digital communication behaviors) for diagnosing the risk severity of depression in an at-risk individual. However, collecting medical device data can be performed in any suitable manner. {\textbar} In another variation Block S {\textbar}   {\textbar} 120 {\textbar}  can include collecting a device event dataset, such as in a manner analogous to that described in U.S. application Ser. No. 13/969,339 filed on 16 Aug. 2013. However, collecting supplementary data can be performed in any suitable manner. {\textbar} 3.3 Method—Collecting Care Provider Data {\textbar}   {\textbar} The method  {\textbar}   {\textbar} 100 {\textbar}  can additionally or alternatively include Block S {\textbar} 125 {\textbar} , which recites: collecting care provider data (e.g., care professional data), which functions to receive datasets associated with one or more care providers, user conditions (e.g., user-provider interactions relating to the user condition; therapeutic interventions promoted through medical status analyses and/or administered by care providers for the user condition; etc.), and/or other suitable entities. A care provider dataset preferably includes care provider analyses (e.g., regarding components of medical status analyses, regarding the user condition, etc.), survey responses (e.g., responses from care providers to surveys analogous to those described in Block S {\textbar} 140 {\textbar} ), assessments and/or insights regarding user-provider interactions (e.g., communications between one or more users and care providers; in-person communications; textual communications, audio; video; automated communications; communication content; etc.), regarding medical status analyses (e.g., care provider modifications to medical status analyses; care providers' actual diagnosis and/or therapeutic intervention in relation to a medical status analysis' predicted diagnosis and/or therapeutic intervention; care provider inputs associated with medical status analyses, such as comments on diagnoses from medical status analyses; etc.), regarding therapeutic interventions, and/or any other suitable aspects, but can include any suitable data in relation to one or more users. User-provider interactions can be through any one or more of: in-person communication (e.g., a scheduled appointment), digital communication (e.g., text messaging communication), and/or any suitable venue. In another variation, Block S {\textbar} 125 {\textbar}  can include collecting electronic health records (e.g., from retrieving electronic health records generated from data associated with the method  {\textbar} 100 {\textbar} ; from querying third-party databases; from receiving electronic health records and/or associated data from care providers, etc.), which can be subsequently processed (e.g., through natural language processing; extracting features; etc.) for use in other portions of the method  {\textbar} 100 {\textbar}  (e.g., determining medical status analyses and/or therapeutic interventions, etc.). However, collecting and/or processing electronic health records can be performed in any suitable manner. {\textbar} For Block S {\textbar}   {\textbar} 125 {\textbar} , care provider data can be collected through a web interface, an application executing on a mobile device (e.g., a care provider device), and/or any suitable venue. For example, Block S {\textbar} 125 {\textbar}  can include receiving a care provider dataset in response to prompting a care provider to provide a care provider input (e.g., at a web interface displaying user information including a user improvement evaluation, etc.), such as during and/or after a user-provider interaction (e.g., an in-person visit). In another example, Block S {\textbar} 125 {\textbar}  can include receiving care provider data in real-time during a user-provider interaction (e.g., where the care provider data includes care-provider interaction data such as the user's answers to the care provider's questions associated with the user condition; etc.). Additionally or alternatively, receiving a care provider dataset can be performed in any manner analogous to embodiments, variations, and examples described in U.S. application Ser. No. 15/005,923, entitled “Method for Providing Therapy to an Individual” and filed on 25 Jan. 2016, which is herein incorporated in its entirety by this reference. However, Block S {\textbar} 125 {\textbar}  can be performed in any suitable manner. {\textbar} Blocks S {\textbar}   {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar}  preferably include collecting datasets associated with a time period and/or other suitable temporal indicator, where different collected datasets can be: collected during the same time period (e.g., received at the care determination system during the time period; sampled during the time period; etc.); related to datasets collected during the time period (e.g., a care provider dataset including care provider assessments of log of use data collected during the time period; etc.); and/or otherwise associated with temporal indicators. Additionally or alternatively, collecting datasets can include any suitable elements described in U.S. application Ser. No. 13/969,339 filed 16 Aug. 2013, which are incorporated herein in their entirety by this reference. However, collecting patient digital behavior can be performed in one or more of the approaches described above, and/or performed in any other suitable manner. {\textbar} 3.4 Method—Determining a Medical Status Analysis {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  recites: determining a medical status analysis (e.g., care status analysis) for a condition of the user based on at least one of a log of use dataset and a mobility supplementary dataset. Block S {\textbar} 130 {\textbar}  functions determine medically relevant information regarding a user and/or user condition. As shown in  {\textbar} {FIGS}. 11-13 {\textbar} , medical status analyses preferably include a diagnosis and/or therapeutic intervention (e.g., a therapy recommendation; treatment recommendation; etc.). Additionally or alternatively, medical status analyses can include symptom information (e.g., predicted current symptoms, potential future symptoms), supplemental user information (e.g., automatically identified demographic information, behavioral information, familial information, etc.), a supplemental medical status analysis (e.g., drug interactions; reasoning components including the sources of information upon which the medical status analysis is based; references to additional information regarding a generated diagnostic analysis and/or therapy recommendation; etc.); user behaviors determined based on datasets collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} ; options for care providers to provide care provider data; digital behavior data for other patients; correlations between digital behavior data and conditions; reference patient profiles (e.g., digital behavior profiles of patients with known conditions and/or treatment responses, composite patient profiles, manually curated patient profiles, automatically generated patient profiles, and/or any suitable reference patient profile; etc.); general medical information derived from databases and/or other resources (e.g., Diagnostic and Statistical Manual of Mental Disorders, International Statistical Classification of Disease and Related Health Problems, resources from the American Psychiatric Association, the World Health Organization, drug regulation agencies, health insurance companies, pharmaceutical companies, policy organizations, research organizations, educational institutions, etc.); therapeutic interventions prescribed to patients (e.g., prescribed and/or verified as efficacious for patients sharing the condition, patients with shared medical parameters; etc.); and/or any other suitable information. In a variation, determining a medical status analysis can include automatically ranking (e.g., triaging) users from a set of users (e.g., patients associated with a particular care provider; patients sharing a demographic; patients associated with a hospital; patients sharing a condition; etc.) for assigning degrees of urgency for providing care and/or for determining suitable types of therapeutic interventions for different users. For example, the method  {\textbar} 100 {\textbar}  can include identifying a subset of users associated with conditions suitable for treatment through a subset of therapeutic interventions (e.g., therapy, psychiatry, specialized care provider visits, etc.). Ranking users can be based on condition, user response monitoring, therapeutic intervention effectiveness, datasets collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar}  (e.g., user-provider interaction data, electronic health records, survey data, logs of use, mobility supplementary data, etc.), and/or any other suitable criteria. Additionally or alternatively, such criteria can be used in ranking and/or otherwise evaluating care providers (e.g., determining a metric indicative of the degree to which care providers are following best practices, such as determined based on reasoning components, etc.). For example, evaluating care providers can be based on at least one of user-provider interactions, care provider inputs, electronic health records, and/or other suitable criteria. Ranking users and/or care providers can be performed at any suitable time and/or frequency (e.g., updating the triaging of users based on user response monitoring, such as by updating the ranking associated with a user to recommend therapy for the user, etc.). Rankings can additionally or alternatively be used in determining the timing and/or frequency of determining a medical status analysis and/or in other suitable portions of the method  {\textbar} 100 {\textbar}  (e.g., determining therapeutic interventions; promoting medical status analyses; etc.), and/or used for any suitable purpose. However, ranking users and/or care providers can be performed in any suitable manner analogous to U.S. application Ser. No. 15/005,923 filed 25 Jan. 2016, which is herein incorporated in its entirety by this reference. {\textbar} Regarding Block S {\textbar}   {\textbar} 130 {\textbar} , generating medical status analyses is preferably based on datasets collected in Blocks S {\textbar} 1100 {\textbar} -S {\textbar} 125 {\textbar} . In a variation, Block S {\textbar} 130 {\textbar}  can be based on log of use data. For example, the method  {\textbar} 100 {\textbar}  can include identifying correlations between digital communication behavior from a set of users (e.g., population of users) and one or more user conditions (e.g., a correlation between decreased digital communication frequency and severity of depression); determining a medical status analysis for a user based on the correlations and a log of use dataset for the user; promoting a therapeutic intervention according to the medical status analyses; and updating the medical status analysis based on an updated log of use dataset for the user and the correlations (e.g., determining an improvement in depression based on an increase in digital communication frequency for the user in response to the therapeutic intervention; etc.). {\textbar} In another variation, Block S {\textbar}   {\textbar} 130 {\textbar}  can be based on mobility supplementary datasets. For example, the method  {\textbar} 100 {\textbar}  can include: identifying a partial response to a promoted medication dosage (e.g., recommended in a medical status analysis) based on log of use dataset and a mobility supplementary dataset (e.g., indicating, during post-therapeutic intervention periods, an increased amount of digital communications at locations of a greater average distance from the user's household, etc.); and updating the medical status analysis (e.g., increasing the medication dosage) based on the identified partial response. However, determining medical status analyses based on mobility supplementary datasets and/or log of use datasets can be performed in any manner analogous to U.S. application Ser. No. 13/969,349 filed 16 Aug. 2013, which is incorporated in its entirety by this reference. {\textbar} In another variation, Block S {\textbar}   {\textbar} 130 {\textbar}  can be based on interaction data (e.g., collected from log of use data; from care provider data; etc.) for interactions between users and/or care providers. For example, Block S {\textbar} 130 {\textbar}  can be based on interactions between a user and a plurality of care providers. In a specific example, Block S {\textbar} 130 {\textbar}  can include: determining (e.g., updating) a medical status analysis based on user-first care provider interaction data between the user and a first care provider (e.g., verbal communications regarding physical symptoms experienced by the user and associated with the user condition, etc.), and user-second care provider interaction data between the user and a second care provider (e.g., textual communications regarding psychological symptoms experienced by the user and associated with the user condition, etc.). In another example, Block S {\textbar} 130 {\textbar}  can be based on interactions between a care provider and multiple users, such as through personalizing a medical status analysis to a care provider based on interactions between the care provider and their patients (e.g., including therapeutic interventions in a medical status analysis that are commonly recommended by the care provider for a user condition; including summaries of previous interactions between the care provider and patients; including recommended interactions to the care provider based on historic interactions associated with the care provider; leveraging user-provider interactions concerning a first patient in order to provide analogous insights for a second patient of the care provider; etc.). In another example, Block S {\textbar} 130 {\textbar}  can be based on interactions between care providers. In a specific example, Block S {\textbar} 130 {\textbar}  can include: determining a medical status analysis based on first care provider-second care provider interaction data for interactions between care providers (e.g., interaction data associated with a first care provider consulting a second care provider concerning the user and/or user condition, such as interaction data concerning symptoms, diagnoses, therapeutic interventions, and/or other suitable components of medical status analyses). Any suitable format of interactions between care providers and/or users can be facilitated at any suitable time. For example, the method  {\textbar} 100 {\textbar}  can include automatically initiating, during a user-care provider interaction period (e.g., during an initial visit; follow-up visit; digital communication period; etc.), a telemedicine communication through a wireless communicable link between a first care provider device associated with the first care provider, and a second care provider device associated with the second care provider; and collecting the first care provider-second care provider interaction data based on the telemedicine communication (e.g., transcribing the telemedicine communication; analyzing the transcription; etc.). {\textbar} In another variation, Block S {\textbar}   {\textbar} 130 {\textbar}  can be based on one or more user conditions. For example, Block S {\textbar} 130 {\textbar}  can include determining reasoning components (e.g., information sources associated with the user condition) of a medical status analysis based on the condition (e.g., mapping the user condition to a plurality of information sources associated with diagnosis and/or therapeutic interventions for the user condition; determining the medical status analysis based on the information sources; etc.). In another example, Block S {\textbar} 130 {\textbar}  can include modifying a visually perceptible digital element of the medical status analysis based on a user condition (e.g., using colors, fonts, graphics, and/or other suitable format components for highlighting portions of the medical status analysis to optimize care determination by a care provider, such as highlighting user conditions with high risk; highlighting side effects of a promoted therapeutic interventions; etc.), where the visually perceptible digital element can be associated with the reasoning component (e.g., highlighting the primary information sources from which the diagnosis is based, etc.) and be operable to improve display of the care status analysis. Additionally or alternatively, modifying perceptible elements of medical status analyses can be based on any suitable criteria. However, determining medical status analyses based on any suitable data can be performed in any suitable manner. {\textbar} Regarding Block S {\textbar}   {\textbar} 130 {\textbar} , determining a medical status analysis is preferably based on one or more medical status features. Medical status features can include any one or more of: mobility features (e.g., location, physical activity behaviors, inertial sensor data, etc.), user condition features (e.g., diagnostic features; user response to therapeutic interventions; survey response data; etc.), textual features (e.g., word frequency, sentiment, punctuation associated with words present in text messages; length; textual features extracted from transcriptions of phone calls associated with the user; etc.), graphical features (e.g., emojis used in text messages; media posted to social networking sites; media transmitted and/or received through digital messages; associated pixel values; etc.), audio features (e.g., Mel Frequency Cepstral Coefficients extracted from audio captured in telemedicine communications, phone calls; etc.), cross-user features (e.g., average frequency of text messages; average length and/or duration of phone calls and/or text messaging; users participating in a digital communication; etc.), cross-care provider features (e.g., care provider communication features associated with subgroups of care providers, etc.), and/or any other suitable features. {\textbar} Regarding Block S {\textbar}   {\textbar} 130 {\textbar} , determining medical status features is preferably based on applying one or more computer-implemented rules (e.g., a feature engineering rule; a user preference rule; rules operable to improve care determination systems, treatment systems, and/or associated medical status models, etc.), but medical status features can be determined based on any suitable information. In an example, Block S {\textbar} 130 {\textbar}  can include establishing and/or storing computer-implemented rules (e.g., to be used in determining the medical status analysis) based on one or more reasoning components (e.g., third-party information sources; meta-analysis performed on data associated with different portions of the method  {\textbar} 100 {\textbar} , such as user response monitoring data). In another example, Block S {\textbar} 130 {\textbar}  can include obtaining a first feature engineering rule defining a medical status analysis as a function of at least one of log of use data and mobility supplementary data; and generating mobility-communication features (e.g., digital communication frequency and/or duration at particular locations; physical activity behaviors in relation to digital communication behaviors; etc.) and/or other medical status features based on evaluating the at least one of the log of use data and the mobility supplementary data against the first feature engineering rule. In another example, Block S {\textbar} 130 {\textbar}  can include obtaining a second feature engineering rule operable to associate the mobility-communication features (and/or other medical status features) with care provider data; and modifying the features based on the care provider data (e.g., labeling the features with care provider inputs concerning the patient behaviors indicated by the features; presenting patient behaviors in a medical status analysis to a care provider, and enabling the care provider to collect and transmit patient responses concerning the patient behaviors, which can be used to generate and/or label medical status features). In a specific example, mobility-communication features including digital communication frequency outside the user's household can be associated with user-provider interaction data indicating a user's severity of anxiety associated with the digital communication frequency. However, applying medical status features can be performed in any suitable manner. {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  can additionally or alternatively include generating, applying, and/or otherwise manipulating medical status models, which preferably output one or more components of a medical status analysis based on data collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar}  and/or other suitable inputs. As shown in  {\textbar} {FIG}. 4 {\textbar} , medical status models can include diagnosis models (e.g., depression diagnosis model; anxiety diagnosis model; bipolar diagnosis model; therapy response models; etc.), therapy models, and/or any other suitable models. In an example, Block S {\textbar} 130 {\textbar}  can include determining a diagnosis with a diagnosis model; and determining a therapeutic intervention with a therapeutic intervention model based on the diagnosis. In another example, Block S {\textbar} 130 {\textbar}  can include, in response to collecting a care provider dataset (e.g., including user-provider interaction data) during a user-care provider interaction period: retrieving the diagnosis model and/or therapeutic intervention model during the user-care provider interaction period; and updating the medical status analysis in real-time during the user-care provider interaction period based on the diagnosis model, the therapeutic intervention model, and the care provider dataset. {\textbar} In a variation of Block S {\textbar}   {\textbar} 130 {\textbar} , generating patient medical status analysis includes generating a decision tree model with internal nodes and branches selected based on correlations between digital behavior data and medical statuses (e.g., correlations between different phone calling characteristics and depression), and identifying a medical status of a patient (e.g., a diagnosis, a treatment recommendation, etc.) based on the decision tree. In another variation, generating patient medical status analysis includes employing a machine learning model. Machine learning algorithms for medical status models and/or other suitable models can include algorithms analogous to those described in U.S. application Ser. No. 15/265,454 filed on 14 Sep. 2016. In specific examples, Block S {\textbar} 130 {\textbar}  can include training and applying a reinforcement learning model (e.g., deep reinforcement learning model), such as a reinforcement learning model for maximizing a reward (e.g., optimizing therapeutic interventions for improving user response in relation to use conditions; personalizing medical status analyses for optimizing care provider support, such as in relation to time spent by the care provider during patient visits; optimizing for care provider confidence in diagnoses and/or recommended therapeutic interventions; etc.), and/or any other suitable type of reinforcement learning models. {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  can additionally or alternatively include updating medical status models. In an example, the method  {\textbar} 100 {\textbar}  can include presenting a diagnosis and a therapeutic intervention to a care provider based on one or more medical status models; receiving care provider validation (e.g., included in care provider data) of the diagnosis and/or therapeutic interventions at an application executing on a care provider computing device; generating a second model based on the care provider validation; monitoring user response to the therapeutic intervention over the course of a time period; generating an updated medical status analysis using the second model based on the monitored patient response data; and providing decision support to the care provider at a follow-up visit based on the updated medical status analysis. In another example, the method  {\textbar} 100 {\textbar}  can include: determining an expected patient response based on a care provider-validated diagnosis and/or therapeutic intervention; and generating an updated diagnosis and/or therapeutic intervention based on a comparison between the expected patient response and the monitored patient response data. However, medical status models can be otherwise used and/or updated. {\textbar} Regarding Block S {\textbar}   {\textbar} 130 {\textbar} , types of medical status analyses can vary across different stages of the patient care process. For example, a diagnosis model and a first therapy model can be operable to generate diagnostic results and an initial medication recommendation for a patient during an initial visit to a care provider, and a second therapy model tailored for modifying the initial medication recommendation can be used in a follow-up visit based on treatment response monitoring data collected between the initial visit and the follow-up visit. However, generating medical status analysis in relation to different periods in the user-provider relationship timeline can be performed in any suitable manner. {\textbar} In relation to Block S {\textbar}   {\textbar} 130 {\textbar} , generating medical status analyses is preferably in response to receiving a user request for patient medical status analysis to be transmitted to an entity (e.g., a care provider). Generating medical status analysis can be performed in real-time, such that medical status analysis can be generated during a patient's visit with a care provider. In a specific example where the user has provided permission for medical status analysis to be shared with a care provider, a care provider can request (e.g., at an application executing on a care provider mobile computing device) the medical status analysis for the user during the user-provider, and in response to the care provider request, patient medical status analysis can be automatically generated for transmission to the care provider (e.g., to the care provider mobile computing device). {\textbar} Additionally or alternatively, generating medical status analysis can be performed according to a generation schedule (e.g., generation frequency) for the medical status analysis (e.g., generating the medical status analysis according to when the medical status analysis is to be transmitted to the target destination), which can be based on at least one of: a user and/or care provider schedule (e.g., accommodating for when a patient will be having an appointment with the care provider, for when the care provider has an opening in their schedule to receive and assess the patient's medical status analysis), time intervals (e.g., generation at every minute, hour, day, week, etc.), preferences (e.g., patient preferences, care provider preferences, etc.), data characteristics (e.g., based on a sufficient amount and/or type of collected data to be able to generate patient medical status analysis with a high degree of confidence), stage in the patient care process (e.g., generating medical status analyses with greater frequency post-therapeutic intervention provision; etc.), diagnosis and/or condition (e.g., generating medical status analyses with greater frequency for conditions of greater severity, etc.), and/or any other suitable criteria. For example, Block S {\textbar}   {\textbar} 130 {\textbar}  can include determining a medical status generation schedule (e.g., generation frequency) based on the diagnosis associated with the condition, where updating the medical status analysis includes updating the medical status analysis based on the medical status generation schedule (e.g., generating a medical status analysis every day after a user's daily consumption of medication, etc.) and/or other suitable datasets (e.g., care provider datasets). However, generating medical status analysis can be performed at any suitable time and frequency. {\textbar} As shown in  {\textbar}   {\textbar} {FIG}. 3 {\textbar} , generating medical status analysis can be performed for a single patient, concurrently for multiple patients (e.g., by leveraging parallel computing principles and thereby improving the efficiency of the computing system), concurrently for different types of user condition, types of medical status analyses (e.g., concurrently running a diagnosis model and a therapy model), concurrently for multiple care providers, and/or with any suitable sequence for any suitable combination of entities. However, generating medical status analysis can be performed at any suitable time and frequency. {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  can additionally or alternatively include matching a user to a care provider, which functions to identify a care provider suited to provide personalized care to the user. For example, the method  {\textbar} 100 {\textbar}  can include: determining effectiveness of the therapeutic intervention; in response to the effectiveness satisfying a threshold condition (e.g., a user response below a threshold), determining a match between a user and a first care provider (e.g., a specialist for the user condition, etc.) based on at least one of a log of use dataset, a mobility supplementary dataset, a diagnosis, and/or other suitable data; and presenting the match to a second care provider (e.g., a recommendation for a consulting entity). A consulting entity (e.g., a care provider) is preferably patient-approved (e.g., consultants that the patient has previously seen, that the patient has previously pre-approved such as through an medical monitoring application executing on a patient mobile computing device, etc.). Automatic selection of potential consultants can be based on care provider characteristics (e.g., care provider experience with the platform, care provider experience with given conditions, care provider relationship with the patient, care provider relationship with other care providers, care provider expertise, etc.), patient characteristics (e.g., patient situation, diagnosis, response, digital behavior data, etc.), consultant characteristics (e.g., consultant profession, consultant expertise, consultant experience, etc.), communication considerations (e.g., wireless connectivity, form of communication preferences, language barriers, demographic information, etc.), and/or any other suitable criteria. In a specific example, the method can include: collecting patient digital communication behavior in relation to patient text messaging characteristics associated with a mobile computing device, generating a social anxiety score for the user based on the patient text messaging characteristics, ranking a set of care provider profiles based on professional experience in relation to social anxiety and socially anxious patients, and presenting care provider profiles to the user for initiating a user-provider relationship and transmission of a patient medical status analysis based on the social anxiety score and the ranking of the set of care provider profiles. Additionally or alternatively, matching users to care providers can be performed in any suitable manner. However, Block S {\textbar} 130 {\textbar}  can be performed in a manner analogous to that described in U.S. application Ser. No. 15/482,995 filed 10 Apr. 2017, which is incorporated in its entirety by this reference, and/or in any suitable manner. {\textbar} 3.4.A Generating a Diagnostic Analysis. {\textbar}   {\textbar} As shown in  {\textbar}   {\textbar} {FIGS}. 1C, 2-3, and 14A-14C {\textbar} , Block S {\textbar} 130 {\textbar}  preferably includes determining one or more diagnoses, which functions to determine information regarding one or more user conditions for a user. A diagnosis can include one or more of: a risk and/or severity value indicating a probability of a patient being afflicted with a given condition, general mental or physiological health indicators, comparisons with other groups of individuals (e.g., based on demographic and/or behavioral characteristics shared between the patient and the group of individuals), prevalence information (e.g., prevalence of depression in a given population), symptom information, and/or any other suitable diagnostic information. {\textbar} In a variation, a diagnosis can be generated without care provider data. For example, a diagnostic analysis can be generated based on collected patient digital behavior data, where the diagnostic analysis is provided to the care provider without the care provider needing to input any patient information. In another variation, generating a diagnostic analysis can be based on collected user data (e.g., log of use data, mobility supplementary data, etc.) and care provider data. In a specific example, a preliminary diagnostic analysis can be generated without care provider input and presented to the care provider during an initial visit between a care provider and a patient. The preliminary diagnostic analysis can guide further diagnostic steps that can be taken by the care provider (e.g., a series of questions to ask the patient). The care provider can input patient data (e.g., patient answers to care provider questions) into a computing device (e.g., an application executing on the smartphone of the care provider), where generating medical status analysis can include generating an updated diagnostic analysis based on the care provider-inputted data. Additionally or alternatively, generating a diagnostic analysis can include any suitable elements described in application Ser. No. 15/069,163 filed 14 Mar. 2016, which is incorporated herein in its entirety by this reference, and/or can be performed in any suitable manner. {\textbar}   {\textbar} 3.4.B Determining a Therapeutic Intervention {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 130 {\textbar}  preferably includes determining one or more therapeutic interventions, which functions to analyze user behaviors and/or diagnoses to identify therapeutic interventions for improving a user condition. Therapeutic interventions can include any one or more of: patient medical reports, therapeutic intervention recommendations (e.g., instruction for a guardian, health professional, care provider, and/or any other suitable individual to follow in implementing the therapy recommendation, which can facilitate therapy implementation, for example, in situations where a patient is incapable of fully implementing the therapy recommendation; etc.); health-related notifications (e.g., health tips provided through automated communications, etc.); therapy interventions (e.g., cognitive behavioral therapy exercises; etc.); care provider-related interventions (e.g., telemedicine; scheduling care provider appointments; etc.); physical interventions (e.g., breathing exercises; meditation exercises; acupuncture; hypnosis; brain stimulation such as through magnetic pulses and/or electrical stimulation; etc.); dietary interventions (e.g., probiotics, nutritional supplements, etc.); medication interventions; auditory interventions (e.g., controlling the mobile device to emit music samples in accordance with music therapy; controlling a personal assistance device to vocally emit content components of automated communications, such as with a tone determined based on a format component; etc.); mobile device and/or supplementary medical device interventions (e.g., modifying device operation parameters; etc.); ambient environment interventions (e.g., modification of light parameters, air quality and/or composition parameters, temperature parameters, humidity parameters; etc.) and/or any other suitable types of interventions. Medication interventions can include one or more of: medication type (prescription, over-the-counter, small-molecule, biopharmaceutical, recombinant proteins, vaccines, antibodies, gene therapy, cell therapy, blood products, etc.), medication origin (e.g., herbal, plant, microbial, animal, chemical synthesis, genetic engineering, radioactive material, etc.), dosage (e.g., frequency, amount, time, dosage form, etc.), instructions (e.g., how to implement the medication regimen, after a meal, on an empty stomach, etc.), medication interactions (e.g., with another drug, etc.), results information (e.g., research supporting the type of medication, publications citing the recommended dosage, etc.), supplemental resources (e.g., hyperlinks to additional information about the medication regiment, etc.), and/or any other suitable medication parameters. {\textbar} As shown in  {\textbar}   {\textbar} {FIGS}. 2 and 10 {\textbar} , in a variation, determining therapeutic interventions can be performed for multiple stages of a user-provider relationship. In a specific example, Block S {\textbar} 130 {\textbar}  can include selecting an initial list of potential therapeutic interventions, narrowing the initial list based on patient digital behavior information, symptoms, drug information, and/or other suitable information, and presenting the narrowed list of potential therapies to a care provider for providing decision support. Additionally or alternatively, a prioritized list of therapeutic interventions (e.g., prioritized based on strength of model recommendation) can be presented to the care provider. User response to the therapeutic interventions can be monitored (e.g., through data collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} , etc.) and used in updating therapeutic interventions, which can include one or more of: modifying dosage (e.g., increasing or decreasing dosage, changing frequency, etc.), augmenting the medication regimen (e.g., adding medication types, removing medication types, etc.), switching a medication type, and/or any other suitable modifications. For example, if a patient exhibits no response to medication “A”, then a therapy recommendation modification of switching to medication “B’ can be generated and presented to the care provider. If a patient exhibits a partial response to medication “A”, then dosage parameters for medication “A” can be altered (e.g., increased dosage). Additionally or alternatively, updating therapeutic interventions can be performed for any suitable number of stages of a user-provider relationship (e.g., multiple stages of partial or no response to medications, and corresponding updates to therapeutic interventions in response to the partial or no response, etc.). However, determining therapeutic interventions can be performed in any suitable manner. {\textbar} 3.5 Method—Promoting a Medical Status Analysis. {\textbar}   {\textbar} Block S {\textbar}   {\textbar} 140 {\textbar}  recites: promoting one or more medical status analyses (e.g., diagnoses, therapeutic interventions), which functions to present, provide, administer, and/or otherwise promote one ore more components of a medical status analyses to users, care providers, and/or other suitable entities for improving care determination by a care provider. Promoting medical status analyses can include one or more of: transmitting and/or presenting medical status analyses; guiding care provider decision-making based on medical status analyses (e.g., interactive step-wise decision making tool, etc.); facilitating digital communication (e.g., between a first and a second care provider, such as between a health coach and a licensed therapist; between one or more patients and one or more care providers, etc.); promoting provision of therapeutic interventions from the medical status analyses (e.g., automatically generating medication prescriptions, transmitting prescriptions to pharmacies, automatically scheduling a future care provider appointment, facilitating healthcare payment, aiding with healthcare insurance logistics, controlling user devices to administer the therapeutic intervention; etc.), and/or other suitable processes. {\textbar} Regarding Block S {\textbar}   {\textbar} 140 {\textbar} , promoting medical status analyses can be performed at specified time intervals (e.g., providing a set of digital patient medical reports to a care provider at the beginning of each day), according to a care provider appointment schedule, for any stage of a user-provider relationship, based on preferences (e.g., a user preference, a care provider preference, etc.), based on rules (e.g., providing decision support in response to disease severity levels exceeding a established threshold, etc.), and/or at any suitable time. Block S {\textbar} 140 {\textbar}  is preferably performable in real-time (e.g., during a user-provider interaction, immediately upon request for decision support, etc.), in order facilitate the provision of time-sensitive information (e.g., patient medical information relevant to accurately diagnosing patient issues and providing therapeutically effective treatments, etc.) during a limited time window of the user-provider interaction. However, Block S {\textbar} 140 {\textbar}  can be performed at any suitable time and frequency. {\textbar} In a variation, promoting medical status analyses can be performed at multiple instances for a user (e.g., over the course of a user-provider relationship, at different stages of the patient care process, etc.). For example, Block S {\textbar}   {\textbar} 140 {\textbar}  can include promoting a medical status analysis for an initial user-provider interaction (e.g., initial visit), monitoring effectiveness of a therapeutic intervention based on patient response to the therapeutic intervention, and promoting an updated medical status analysis at a follow-up user-provider interaction based on the effectiveness. In a specific example, promoting medical status analyses can include providing a first medical status analysis (e.g., a preliminary patient medical report detailing a preliminary diagnosis without an associated therapeutic intervention) to a care provider prior to an initial interaction between the care provider and patient; providing a second decision support (e.g., an updated patient medical report detailing a comprehensive diagnosis with corresponding therapeutic interventions) in real-time to a care provider during the initial interaction and in response to receiving user-care provider interaction data including user responses to care provider questions administered at the initial interaction; collecting patient response supplementary data concerning a care provider-recommended therapeutic intervention; providing a third medical status analysis (e.g., notifications alerting the care provider to how the patient is responding to the care provider-recommended therapeutic intervention) based on the collected patient response supplementary data and prior to a follow-up interaction between the care provider and the patient; providing a fourth medical status analysis (e.g., facilitating a digital communication between a care provider and a consultant to aid a care provider in utilizing a follow-up digital patient medical report analyzing the patient's response to the care provider-recommended therapeutic intervention and providing suggestions to modify the treatment regimen, etc.) to the care provider during the follow-up interaction, and providing a fifth medical status analysis (e.g., a digital update informing the care provider of the efficacy of the modified treatment regimen; facilitating a digital communication between the care provider and the patient to check on the patient's status) to the care provider after the follow-up interaction. However, performing Block S {\textbar} 140 {\textbar}  in multiple instances can be performed in any suitable manner. {\textbar} In another variation, Block S {\textbar}   {\textbar} 140 {\textbar}  can include automatically promoting medical status analyses based on satisfaction of a threshold condition (e.g., a risk of depression exceeding a risk threshold). Threshold conditions can be based on diagnoses (e.g., risk thresholds, severity thresholds, type of user condition thresholds, etc.), therapeutic interventions (e.g., type of therapeutic intervention, urgency associated with a patient needing to start a medication regimen, etc.), data collected in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} , and/or any other suitable information. However, performing Block S {\textbar} 140 {\textbar}  based on satisfaction of a threshold condition can be performed in any suitable manner. In another variation, Block S {\textbar} 140 {\textbar}  support can include promoting a medical status analysis based on a care provider schedule. For example, the method  {\textbar} 100 {\textbar}  can include receiving a care provider schedule (e.g., at a care determination system), analyzing the care provider schedule for appointment information with a set of patients, and promoting medical status analyses based on the appointment information. In a specific example, receiving a care provider schedule can be in response to presenting an option (e.g., at an application executing on a care provider computing device) for a care provider and/or related individual to sync a care provider schedule of patient support, and Block S {\textbar} 140 {\textbar}  can include providing the care provider with a digital patient medical report of a set of digital patient medical reports in accordance with the upcoming patient appointments, with patients for an entire day, week, and/or in accordance with any suitable characteristic of the care provider schedule. In another specific example, Block S {\textbar} 140 {\textbar}  can include receiving a care provider schedule, identifying a patient appointment scheduled for a subsequent day, medical status analyses can be transmitted prior to user-provider interactions, where the medical status analyses can be accessible by the care provider at a care provider device during offline operation (e.g., during the user-provider interaction) and/or when the care provider device is online-enabled. However, performing Block S {\textbar} 140 {\textbar}  according to a care provider schedule can be performed in any suitable manner. {\textbar} Block S {\textbar}   {\textbar} 140 {\textbar}  can additionally or alternatively be based on care provider characteristics (e.g., expertise of care provider, demographic information, behavioral information, background of care provider, preferences, etc.), patient characteristics (e.g., patient preferences, patient communication behaviors, demographic information, behavioral information, etc.), and/or any other suitable data. In a variation, Block S {\textbar} 140 {\textbar}  can include tailoring promotion of a medical status analysis to a care provider based on care provider characteristics. For example, medical status analyses can be modified to suit the designated learning style of the care provider (e.g., providing graphical digital patient medical reports for a visual care provider learner, providing audio digital patient medical reports for an audio care provider learner, etc.). In another example, medical status analysis can be adjusted for the expertise of the care provider (e.g., providing more fundamental mental disorder knowledge for a care provider who is less-experienced in mental conditions but is treating a user with a psychiatric condition, etc.). In another variation, Block S {\textbar} 140 {\textbar}  can include tailoring promotion of a medical status analysis based on patient characteristics including one or more: genomic characteristics, microbiome characteristics, behavioral characteristics, demographic characteristics, individual characteristics, population characteristics, and/or any other suitable information. For example, Block S {\textbar} 140 {\textbar}  can include recommending specific communication approaches to the care provider for accommodating the communication behavior (e.g., derived from datasets from Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} ) of the patient. received by a mental health patient. However, promoting medical status analyses based on care provider characteristics and/or user characteristics can be performed in any suitable manner. {\textbar} Block S {\textbar}   {\textbar} 140 {\textbar}  can additionally or alternatively include providing a patient medical report (e.g., a comprehensive report detailing a diagnosis, a therapeutic intervention recommendation, etc.) to a care provider, based on one or more medical status analyses. As shown in  {\textbar} {FIGS}. 14A-14C, 15A-15C, and 16 {\textbar} , a patient medical report can include one or more of a diagnosis (e.g., severity of medical issue, risk values, type of condition, etc.), a therapeutic intervention recommendation (e.g., medication types, dosages, drug interactions, supplemental information), user demographic information (e.g., name, sex, age), treatment response information (e.g., digital behavior data collected in response to patient implementation of a medication regimen, biosignal data, survey response data, etc.), reasoning components (e.g., sources of data used in determining components of the medical status analysis, etc.), user history with care providers (e.g., length of working with a health coach, a health professional, etc.), user medical history (e.g., reported symptoms, diagnoses, treatments, family history, etc.), recommendations for other care providers (e.g., contact information of a health professional who can help with treatment, etc.), and/or any other suitable information. In a variation of Block S {\textbar} 140 {\textbar} , a patient medical report can include digital references. Digital references are preferably capable of activation when a care provider computing device is in online operation (e.g., when a care provider computing device transitions from offline operation to online operation), but can alternatively be capable of activation by a care provider whether the care provider computing device is in an offline or online mode. Digital references can include hyperlinks, digital requests (e.g., to a remote server to perform a particular operation), and/or any suitable content. Hyperlinks can link to supplemental resources (e.g., in-depth medication information such as detailed descriptions, exhaustive list of drug interactions, detailed explanatory analysis of how medication recommendations were determined), updated versions of a medical status analysis (e.g., an updated patient medical report based on up-to-date patient data collected from patient smartphone usage), and/or any suitable additional information. In a specific example, a patient medical report can be provided to a care provider for a patient a week before a scheduled user-provider interaction, the patient medical report including digital references to digital destinations (e.g., a website, an application executing on the care provider device, a remote server, etc.) that, when activated, can transmit a request to a care determination system to execute a care status model on up-to-date data for the patient, thereby updating a patient medical report. Additionally or alternatively, providing a patient medical report can be performed in any suitable manner. However, Block S {\textbar} 140 {\textbar}  can be performed in any suitable manner analogous to U.S. application Ser. No. 15/482,995 filed 10 Apr. 2017, which is incorporated in its entirety by this reference, and/or in any suitable manner. {\textbar} 3.6 Method—Determining a Subgroup {\textbar}   {\textbar} The method  {\textbar}   {\textbar} 100 {\textbar}  can additionally or alternatively include Block S {\textbar} 150 {\textbar} , which recites: determining one or more subgroups (e.g., user subgroup, care prouder subgroup), such as with the care determination system and/or other suitable components. Block S {\textbar} 150 {\textbar}  functions to group one or more users and/or care providers based on shared behaviors (e.g., derived from datasets from Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} , etc.) in order to facilitate determination of medical status analyses. For example, Block S {\textbar} 150 {\textbar}  can include: assigning the user to a user subgroup of a set of user subgroups, based on digital communication behaviors and/or mobility supplementary behaviors (e.g., grouping users who infrequently digitally communicate and have a mobility within a predetermined distance threshold from their household), and/or care provider data (e.g., grouping users based user condition information provided by care providers; grouping users based on their behaviors towards user-provider relationships, such as determined from user-provider interactions; etc.), where the user subgroup can share a behavior (e.g., mobility-communication behavior) and can be operable to improve care determination for the condition (e.g., through generation and application of medical status models tailored to the subgroup, etc.); and determining the medical status analysis based on the user subgroup and/or other suitable data (e.g., mobility-communication features, care professional data, etc.). However, determining and/or leveraging subgroups can be performed in any suitable manner analogous to U.S. application Ser. No. 15/482,995 filed 10 Apr. 2017, and/or U.S. application Ser. No. 13/969,339 filed on 16 Aug. 2013, each of which are incorporated in their entirety by this reference, and/or can be performed in any suitable manner. {\textbar} 4. System. {\textbar}   {\textbar} As shown in  {\textbar}   {\textbar} {FIG}. 5 {\textbar} , embodiments of a system  {\textbar} 200 {\textbar}  for improving care determination in relation to a condition of a user associated with a mobile device can include a care determination system  {\textbar} 210 {\textbar}  operable to perform Blocks S {\textbar} 110 {\textbar} -S {\textbar} 150 {\textbar}  and/or other portions of the method  {\textbar} 100 {\textbar} ; and a treatment system  {\textbar} 220 {\textbar}  operable to automatically promote a medical status analysis (e.g., to a care provider) associated with the condition and/or user. The care determination system  {\textbar} 210 {\textbar}  and/or treatment system  {\textbar} 220 {\textbar}  can include a processing system, an interface operable to present medical status analyses; and/or any other suitable components operable to perform any suitable portions of the method  {\textbar} 100 {\textbar} . The system  {\textbar} 200 {\textbar}  can additionally or alternatively include a supplemental device  {\textbar} 230 {\textbar}  (e.g., a supplemental medical device, a supplemental personal assistant device, etc.) and/or any other suitable components. While the components of the system  {\textbar} 200 {\textbar}  are generally described as distinct components, they can be physically and/or logically integrated in any manner. For example, a remote computing system can implement functionality associated with both the care determination system  {\textbar} 210 {\textbar}  and treatment system  {\textbar} 220 {\textbar} . In another example, functionality can be shared between the care determination system  {\textbar} 210 {\textbar} , the treatment system  {\textbar} 220 {\textbar} , and/or any other suitable components of the system  {\textbar} 200 {\textbar} . The system  {\textbar} 200 {\textbar}  and/or components of the system  {\textbar} 200 {\textbar}  (e.g., care determination system  {\textbar} 210 {\textbar} , treatment system  {\textbar} 220 {\textbar} , etc.) can entirely or partially be executed by, hosted on, communicate with, and/or otherwise include: user databases (e.g., storing patient characteristics, user health records, associated care provider characteristics, patient device information, etc.), analysis databases (e.g., storing computational models, collected datasets, features, rules, medical status analyses, etc.), remote computing systems, user devices, care provider devices, and/or any other suitable components. Additionally or alternatively, the components of the system can be distributed across machine and cloud-based computing systems in any other suitable manner. However, the system  {\textbar} 200 {\textbar}  and associated components can be configured in any manner analogous to U.S. application Ser. No. 15/482,995 filed 10 Apr. 2017, U.S. application Ser. No. 13/969,339 entitled “Method for Modeling Behavior and Health Changes” and filed on 16 Aug. 2013, U.S. application Ser. No. 15/265,454 entitled “Method for Providing Health Therapeutic Interventions to a User” and filed on 14 Sep. 2016, and U.S. application Ser. No. 15/245,571 entitled “Method and System for Modeling Behavior and Heart Disease State” and filed on 24 Aug. 2016, each of which are herein incorporated in their entirety by this reference, and/or can be configured in any suitable manner. {\textbar} The care determination system  {\textbar}   {\textbar} 210 {\textbar}  functions to collect and process datasets (e.g., described in Blocks S {\textbar} 110 {\textbar} -S {\textbar} 125 {\textbar} ) in determining medical status analyses. For example, the care determination system  {\textbar} 210 {\textbar}  can obtain, apply, and/or otherwise manipulate computer-implemented rules (e.g., feature engineering rules) in deriving features for and/or otherwise generating medical status analyses. In a specific example, the care determination system  {\textbar} 210 {\textbar}  can receive mobility supplementary data corresponding to mobility-related sensors including {GPS} receivers operable to collect {GPS} satellite data during the time period; extract features (e.g., with a remote central processing unit) based on the {GPS} satellite data, the features operable to improve determination of medical status analyses; and generate a medical status analysis associated with the location of the {GPS} receiver (e.g., during a time period in which a log of use dataset and/or other suitable datasets were collected, etc.), based on the features. In another specific example, the care determination system  {\textbar} 210 {\textbar}  can receive mobility supplementary data including an orientation of the mobile device (e.g., during a time period), the orientation determined based on signals from a set of inertial sensors mounted respectively at the mobile device; and extract features (e.g., mobility-communication features) based on the orientation. However, the care determination system  {\textbar} 210 {\textbar}  can be configured in any suitable manner. {\textbar} The treatment system  {\textbar}   {\textbar} 220 {\textbar}  functions to promote medical status analyses (e.g., in a manner analogous to Block S {\textbar} 140 {\textbar} , etc.) to care providers, users, and/or any other suitable entities. The treatment system  {\textbar} 220 {\textbar}  can include any one or more of supplementary medical devices  {\textbar} 230 {\textbar}  (e.g., ambient environment devices such as sensing and control systems for temperature, light, air quality and/or composition, humidity; biometric devices such as cardiovascular, {EEG}, {EOG}, {EMG}, {ECG}; medication devices such as automatic medication dispensers; personal assistant devices; etc.), mobile devices (e.g., mobile communication devices from which a log of use dataset is collected; user devices; care provider devices; etc.), and/or any other suitable devices. In an example, the treatment system  {\textbar} 220 {\textbar}  can be operable to generate, transmit, and/or apply control instructions for operating a supplemental device  {\textbar} 230 {\textbar}  and/or other suitable device (e.g., a medical device of the treatment system  {\textbar} 220 {\textbar} ) to promote the medical status analyses (e.g., controlling a user device administer a guided meditation to the user, etc.). In another example, the treatment system  {\textbar} 220 {\textbar}  can be operable to automatically initiate a signal that controls an automated medication system (e.g., a signal for updating medication regimen parameters such as schedule, dosage, medication type, etc.; a signal activating the automated medication system to alert the user in relation to a medication regimen; etc.). However, the treatment system  {\textbar} 220 {\textbar}  can be configured in any suitable manner. {\textbar} An alternative embodiment preferably implements the above methods in a computer-readable medium storing computer-readable instructions. The instructions are preferably executed by computer-executable components preferably integrated with a user interface configuration system. The computer-readable medium may be stored on any suitable computer readable media such as {RAMs}, {ROMs}, flash memory, {EEPROMs}, optical devices ({CD} or {DVD}), hard drives, floppy drives, or any suitable device. The computer-executable component is preferably a processor but the instructions may alternatively or additionally be executed by any suitable dedicated hardware device. Although omitted for conciseness, the preferred embodiments include every combination and permutation of the various system components and the various method processes. {\textbar}   {\textbar} The {FIGURES} illustrate the architecture, functionality and operation of possible implementations of systems, methods and computer program products according to preferred embodiments, example configurations, and variations thereof. In this regard, each block in the flowchart or block diagrams may represent a module, segment, step, or portion of code, which includes one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block can occur out of the order noted in the {FIGURES}. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions. As a person skilled in the art will recognize from the previous detailed description and from the figures and claims, modifications and changes can be made to the preferred embodiments of the invention without departing from the scope of this invention defined in the following claims.
Issue: {US}10014077B2},
}

@patent{lyoo_etal21b,
	location = {{US}},
	title = {Method and apparatus for predicting posttraumatic behavior problem},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {Provided is a method and apparatus for predicting a posttraumatic behavior problem that may predict a posttraumatic violent behavior problem of an individual, in detail, that may determine a biological phenotype of an individual experiencing a traumatic event within a predetermined period after the individual is exposed to the traumatic event, predict a violent symptom presentation probability of the individual based on the biological phenotype of the individual, and suggest an objective basis for preventive intervention in a development of posttraumatic stress disorder ({PTSD}) of the individual based on a prediction result.
Provided is a method and apparatus for predicting a posttraumatic behavior problem that may predict a posttraumatic violent behavior problem of an individual, in detail, that may determine a biological phenotype of an individual experiencing a traumatic event within a predetermined period after the individual is exposed to the traumatic event, predict a violent symptom presentation probability of the individual based on the biological phenotype of the individual, and suggest an objective basis for preventive intervention in a development of posttraumatic stress disorder ({PTSD}) of the individual based on a prediction result.
Provided is a method and apparatus for predicting a posttraumatic behavior problem that may predict a posttraumatic violent behavior problem of an individual, in detail, that may determine a biological phenotype of an individual experiencing a traumatic event within a predetermined period after the individual is exposed to the traumatic event, predict a violent symptom presentation probability of the individual based on the biological phenotype of the individual, and suggest an objective basis for preventive intervention in a development of posttraumatic stress disorder ({PTSD}) of the individual based on a prediction result.},
	type = {patent},
	author = {Lyoo, In Kyoon and Cho, Han Byul and Hong, Ga Hae},
	urldate = {2020-11-12},
	date = {2021-04-22},
	note = {Edition: A61B000500 {\textbar} A61B0005024 {\textbar} A61B00050531 {\textbar} G01N003368 {\textbar} G01N003374 {\textbar} G16H005020 {\textbar} G16H005030 {CPC}  - A61B00054088 {\textbar} A61B0005024 {\textbar} A61B000502405 {\textbar} A61B00050531 {\textbar} A61B00054884 {\textbar} A61B00057275 {\textbar} G01N00336896 {\textbar} G01N003374 {\textbar} G16H005020 {\textbar} G16H005030 {\textbar} G01N28002814 {\textbar} G01N2800301 {EP}; {KR}; {US} {US} 1 {\textbar} . A method of predicting a posttraumatic behavior problem, the method comprising:  {\textbar} receiving, via at least one processor, primary posttraumatic physical information associated with an individual within a predetermined time period after exposure to a traumatic event; {\textbar}   {\textbar} analyzing, via the at least one processor, the primary posttraumatic physical information to determine whether the received primary posttraumatic physical information corresponds to a first type, a second type, a third type, or a fourth type of the traumatic event, wherein the first, second, third, and fourth types of the traumatic event are different from each other; {\textbar}   {\textbar} performing, via the at least one processor, a cluster analysis on the primary posttraumatic physical information for each of the first, second, third, and fourth types and determining, via the at least one processor, a biological phenotype associated with the individual based on the cluster analysis, wherein the biological phenotype includes a first phenotype, a second phenotype, and a third phenotype; {\textbar}   {\textbar} classifying, via the at least one processor, the individual as the first, second, or third phenotype; {\textbar}   {\textbar} receiving, via the at least one processor, secondary posttraumatic physical information associated with the individual, wherein the secondary posttraumatic physical information is different from the primary posttraumatic physical information; and {\textbar}   {\textbar} predicting, via the at least one process, a violent symptom presentation probability that the individual will exhibit violent behavior by applying the primary and secondary posttraumatic physical information to a nonlinear violent behavior prediction model. {\textbar}   {\textbar} 2 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the first type of the traumatic event is physical violence, wherein the second type of the traumatic event is sexual violence, wherein the third type of the traumatic event is accidents/disasters, and wherein the fourth type of the traumatic event is trauma other than physical violence, sexual violence, and accidents/disasters. {\textbar} 3 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the primary posttraumatic physical information includes (i) one or more of: a heart rate, a heart rate variability ({HRV}), and a skin conductance ({SC}) of the individual, and (ii) one or more of: immune function, oxidative stress, a neuroplasticity, and a hypothalamic-pituitary-adrenal ({HPA}) axis derived from a blood sample of the individual. {\textbar} 4 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein  {\textbar} the first phenotype is an emotional phenotype, wherein the second phenotype is a behavioral phenotype, and wherein the third phenotype is a cognitive phenotype; and {\textbar}   {\textbar} wherein the performing of the cluster analysis comprises collecting the primary posttraumatic physical information for each for each of the first, second, third, and fourth types and determining which types form at least a cluster of the primary posttraumatic physical information having a high index of correlation. {\textbar}   {\textbar} 5 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the secondary posttraumatic physical information comprises neuroimaging of a brain of the individual for measuring an activity of a region of the brain. {\textbar} 6 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the nonlinear violent behavior prediction model is trained, via machine learning, using at least posttraumatic physical response information and trauma outcome or characteristic information of a sample group preselected for the type of the traumatic event. {\textbar} 7 {\textbar} . An apparatus for predicting a posttraumatic behavior problem, the apparatus comprising:  {\textbar} at least processor for executing stored instructions to: {\textbar}   {\textbar} receive primary posttraumatic physical information associated with an individual within a predetermined time period after exposure to a traumatic event; {\textbar}   {\textbar} analyze the primary posttraumatic physical information to determine whether the received primary posttraumatic physical information corresponds to a first type, a second type, a third type, or a fourth type of the traumatic event, wherein the first, second, third, and fourth types of the traumatic event are different from each other; {\textbar}   {\textbar} perform a cluster analysis on the primary posttraumatic physical information for each of the first, second, third, and fourth types and determine a biological phenotype associated with the individual based on the cluster analysis, wherein the biological phenotype includes a first phenotype, a second phenotype, and a third phenotype; {\textbar}   {\textbar} classify the individual as the first, second, or third phenotype; {\textbar}   {\textbar} receive secondary posttraumatic physical information associated with the individual, wherein the secondary posttraumatic physical information is different from the primary posttraumatic physical information; and {\textbar}   {\textbar} predict a violent symptom presentation probability that the individual will exhibit violent behavior by applying the primary and secondary posttraumatic physical information to a nonlinear violent behavior prediction model. {\textbar}   {\textbar} 8 {\textbar} . The apparatus of  {\textbar} claim 7 {\textbar} , wherein the first type of the traumatic event is physical violence, wherein the second type of the traumatic event is sexual violence, wherein the third type of the traumatic event is accidents/disasters, and wherein the fourth type of the traumatic event is trauma other than physical violence, sexual violence, and accidents/disasters. {\textbar} 9 {\textbar} . The apparatus of  {\textbar} claim 8 {\textbar} , wherein the primary posttraumatic physical information includes (i) one or more of: a heart rate, a heart rate variability ({HRV}), and a skin conductance ({SC}) of the individual, and (ii) one or more of: immune function, oxidative stress, a neuroplasticity, and a hypothalamic-pituitary-adrenal ({HPA}) axis derived from a blood sample of the individual. {\textbar} 10 {\textbar} . The apparatus of  {\textbar} claim 8 {\textbar} , wherein the first phenotype is an emotional phenotype, wherein the second phenotype is a behavioral phenotype, and wherein the third phenotype is a cognitive phenotype, and wherein the performance of the cluster analysis comprises the at least one processor configured to collect the primary posttraumatic physical information for each for each of the first, second, third, and fourth types and determine which types form at least a cluster of the primary posttraumatic physical information having a high index of correlation. {\textbar} 11 {\textbar} . The apparatus of  {\textbar} claim 7 {\textbar} , wherein the secondary posttraumatic physical information comprises neuroimaging of a brain of the individual for measuring an activity of a region of the brain. {\textbar} 12 {\textbar} . The apparatus of  {\textbar} claim 8 {\textbar} , wherein the nonlinear violent behavior prediction model is trained, via machine learning, using at least posttraumatic physical response information and trauma outcome or characteristic information of a sample group preselected for the type of the traumatic event. 1 {\textbar} . A method of predicting a posttraumatic behavior problem, the method comprising:  {\textbar} receiving, via at least one processor, primary posttraumatic physical information associated with an individual within a predetermined time period after exposure to a traumatic event; {\textbar}   {\textbar} analyzing, via the at least one processor, the primary posttraumatic physical information to determine whether the received primary posttraumatic physical information corresponds to a first type, a second type, a third type, or a fourth type of the traumatic event, wherein the first, second, third, and fourth types of the traumatic event are different from each other; {\textbar}   {\textbar} performing, via the at least one processor, a cluster analysis on the primary posttraumatic physical information for each of the first, second, third, and fourth types and determining, via the at least one processor, a biological phenotype associated with the individual based on the cluster analysis, wherein the biological phenotype includes a first phenotype, a second phenotype, and a third phenotype; {\textbar}   {\textbar} classifying, via the at least one processor, the individual as the first, second, or third phenotype; {\textbar}   {\textbar} receiving, via the at least one processor, secondary posttraumatic physical information associated with the individual, wherein the secondary posttraumatic physical information is different from the primary posttraumatic physical information; and {\textbar}   {\textbar} predicting, via the at least one process, a violent symptom presentation probability that the individual will exhibit violent behavior by applying the primary and secondary posttraumatic physical information to a nonlinear violent behavior prediction model. {\textbar}   {\textbar} 2 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the first type of the traumatic event is physical violence, wherein the second type of the traumatic event is sexual violence, wherein the third type of the traumatic event is accidents/disasters, and wherein the fourth type of the traumatic event is trauma other than physical violence, sexual violence, and accidents/disasters. {\textbar} 3 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the primary posttraumatic physical information includes (i) one or more of: a heart rate, a heart rate variability ({HRV}), and a skin conductance ({SC}) of the individual, and (ii) one or more of: immune function, oxidative stress, a neuroplasticity, and a hypothalamic-pituitary-adrenal ({HPA}) axis derived from a blood sample of the individual. {\textbar} 4 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein  {\textbar} the first phenotype is an emotional phenotype, wherein the second phenotype is a behavioral phenotype, and wherein the third phenotype is a cognitive phenotype; and {\textbar}   {\textbar} wherein the performing of the cluster analysis comprises collecting the primary posttraumatic physical information for each for each of the first, second, third, and fourth types and determining which types form at least a cluster of the primary posttraumatic physical information having a high index of correlation. {\textbar}   {\textbar} 5 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the secondary posttraumatic physical information comprises neuroimaging of a brain of the individual for measuring an activity of a region of the brain. {\textbar} 6 {\textbar} . The method of  {\textbar} claim 1 {\textbar} , wherein the nonlinear violent behavior prediction model is trained, via machine learning, using at least posttraumatic physical response information and trauma outcome or characteristic information of a sample group preselected for the type of the traumatic event. {\textbar} 7 {\textbar} . An apparatus for predicting a posttraumatic behavior problem, the apparatus comprising:  {\textbar} at least processor for executing stored instructions to: {\textbar}   {\textbar} receive primary posttraumatic physical information associated with an individual within a predetermined time period after exposure to a traumatic event; {\textbar}   {\textbar} analyze the primary posttraumatic physical information to determine whether the received primary posttraumatic physical information corresponds to a first type, a second type, a third type, or a fourth type of the traumatic event, wherein the first, second, third, and fourth types of the traumatic event are different from each other; {\textbar}   {\textbar} perform a cluster analysis on the primary posttraumatic physical information for each of the first, second, third, and fourth types and determine a biological phenotype associated with the individual based on the cluster analysis, wherein the biological phenotype includes a first phenotype, a second phenotype, and a third phenotype; {\textbar}   {\textbar} classify the individual as the first, second, or third phenotype; {\textbar}   {\textbar} receive secondary posttraumatic physical information associated with the individual, wherein the secondary posttraumatic physical information is different from the primary posttraumatic physical information; and {\textbar}   {\textbar} predict a violent symptom presentation probability that the individual will exhibit violent behavior by applying the primary and secondary posttraumatic physical information to a nonlinear violent behavior prediction model. {\textbar}   {\textbar} 8 {\textbar} . The apparatus of  {\textbar} claim 7 {\textbar} , wherein the first type of the traumatic event is physical violence, wherein the second type of the traumatic event is sexual violence, wherein the third type of the traumatic event is accidents/disasters, and wherein the fourth type of the traumatic event is trauma other than physical violence, sexual violence, and accidents/disasters. {\textbar} 9 {\textbar} . The apparatus of  {\textbar} claim 8 {\textbar} , wherein the primary posttraumatic physical information includes (i) one or more of: a heart rate, a heart rate variability ({HRV}), and a skin conductance ({SC}) of the individual, and (ii) one or more of: immune function, oxidative stress, a neuroplasticity, and a hypothalamic-pituitary-adrenal ({HPA}) axis derived from a blood sample of the individual. {\textbar} 10 {\textbar} . The apparatus of  {\textbar} claim 8 {\textbar} , wherein the first phenotype is an emotional phenotype, wherein the second phenotype is a behavioral phenotype, and wherein the third phenotype is a cognitive phenotype, and wherein the performance of the cluster analysis comprises the at least one processor configured to collect the primary posttraumatic physical information for each for each of the first, second, third, and fourth types and determine which types form at least a cluster of the primary posttraumatic physical information having a high index of correlation. {\textbar} 11 {\textbar} . The apparatus of  {\textbar} claim 7 {\textbar} , wherein the secondary posttraumatic physical information comprises neuroimaging of a brain of the individual for measuring an activity of a region of the brain. {\textbar} 12 {\textbar} . The apparatus of  {\textbar} claim 8 {\textbar} , wherein the nonlinear violent behavior prediction model is trained, via machine learning, using at least posttraumatic physical response information and trauma outcome or characteristic information of a sample group preselected for the type of the traumatic event. 1 {\textbar} . A method of predicting a posttraumatic behavior problem, the method comprising:  {\textbar} receiving, via at least one processor, primary posttraumatic physical information associated with an individual within a predetermined time period after exposure to a traumatic event; {\textbar}   {\textbar} analyzing, via the at least one processor, the primary posttraumatic physical information to determine whether the received primary posttraumatic physical information corresponds to a first type, a second type, a third type, or a fourth type of the traumatic event, wherein the first, second, third, and fourth types of the traumatic event are different from each other; {\textbar}   {\textbar} performing, via the at least one processor, a cluster analysis on the primary posttraumatic physical information for each of the first, second, third, and fourth types and determining, via the at least one processor, a biological phenotype associated with the individual based on the cluster analysis, wherein the biological phenotype includes a first phenotype, a second phenotype, and a third phenotype; {\textbar}   {\textbar} classifying, via the at least one processor, the individual as the first, second, or third phenotype; {\textbar}   {\textbar} receiving, via the at least one processor, secondary posttraumatic physical information associated with the individual, wherein the secondary posttraumatic physical information is different from the primary posttraumatic physical information; and {\textbar}   {\textbar} predicting, via the at least one process, a violent symptom presentation probability that the individual will exhibit violent behavior by applying the primary and secondary posttraumatic physical information to a nonlinear violent behavior prediction model. 1 {\textbar} . A method of predicting a posttraumatic behavior problem, the method comprising:  {\textbar} receiving, via at least one processor, primary posttraumatic physical information associated with an individual within a predetermined time period after exposure to a traumatic event; {\textbar}   {\textbar} analyzing, via the at least one processor, the primary posttraumatic physical information to determine whether the received primary posttraumatic physical information corresponds to a first type, a second type, a third type, or a fourth type of the traumatic event, wherein the first, second, third, and fourth types of the traumatic event are different from each other; {\textbar}   {\textbar} performing, via the at least one processor, a cluster analysis on the primary posttraumatic physical information for each of the first, second, third, and fourth types and determining, via the at least one processor, a biological phenotype associated with the individual based on the cluster analysis, wherein the biological phenotype includes a first phenotype, a second phenotype, and a third phenotype; {\textbar}   {\textbar} classifying, via the at least one processor, the individual as the first, second, or third phenotype; {\textbar}   {\textbar} receiving, via the at least one processor, secondary posttraumatic physical information associated with the individual, wherein the secondary posttraumatic physical information is different from the primary posttraumatic physical information; and {\textbar}   {\textbar} predicting, via the at least one process, a violent symptom presentation probability that the individual will exhibit violent behavior by applying the primary and secondary posttraumatic physical information to a nonlinear violent behavior prediction model. {CROSS}-{REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar}   {\textbar} This application is a continuation of co-pending U.S. patent application Ser. No. 15/882,254, filed Jan. 29, 2018, and entitled “{METHOD} {AND} {APPARATUS} {FOR} {PREDICTING} {POSTTRAUMATIC} {BEHAVIOR} {PROBLEM}”, which claims the benefit of priority to Korean Patent Application 10-2017-0145501, Nov. 2, 2017, which application is incorporated herein by reference in its entirety for all purposes. {\textbar}   {\textbar} {TECHNICAL} {FIELD} {\textbar}   {\textbar} Embodiments relate to a method and apparatus for predicting a posttraumatic behavior problem, and more particularly, to a method of predicting a behavior problem that may occur in the future from neurophysiological phenomena and symptoms presented by an individual immediately after exposure to a traumatic event. {\textbar}   {\textbar} {BACKGROUND} {ART} {\textbar}   {\textbar} Posttraumatic stress disorder ({PTSD}) includes a maladjustive response of an individual to an environmental stress event provided externally in life, a mental response of a patient experiencing a traumatic event, and a neurophysiological response related to stress. It is known that a brain process is based on such responses. {PTSD} may develop immediately after the stress event, or may not develop until weeks, months, or years after the stress event. That is, {PTSD} is a disorder of feeling excessive anxiety after watching or directly experiencing an accident, violence, or a disaster. Different {PTSD} symptoms are presented based on the frequency and strength of watching or experiencing such trauma, and a neurophysiological characteristic of an individual. {\textbar}   {\textbar} The {PTSD} symptoms include re-experiencing, avoidance, and hyperarousal. In detail, re-experiencing is a symptom of frequently having sudden memories of a traumatic scene, and experiencing the same feeling at that time again. Avoidance is a symptom, opposite to re-experiencing, of avoiding mentioning a traumatic event. Hyperarousal is a symptom of being oversensitive to a little sound or motion due to hyper-sensitive nerves. {\textbar}   {\textbar} {PTSD} causes physical distress such as headache, stomachache or muscular pain, or improves mental symptoms such as depression, a personality disorder, anxiety disorder or schizophrenia. {PTSD} patients may be addicted to alcohol or drugs to relieve pain, or show extreme behaviors. In particular, {PTSD} patients showing behavioral symptoms remarkably are at a risk of violence or self-harm, which is also a serious social issue. Thus, it is mightily significant to predict a behavior problem to be presented after exposure to trauma. {\textbar}   {\textbar} Cognitive behavioral therapy ({CBT}) is a representative treatment that may minimize {PTSD}-related problems. {CBT} makes a {PTSD} patient confront memories of a traumatic event that the patient consistently suppresses and avoids, thereby treating distorted cognition about the patient, others and the world. {CBT} is performed in combination with drug treatment and psychotherapy. {\textbar}   {\textbar} However, in reality, a small portion of patients take actions against a development of {PTSD} or receive treatment before the development of {PTSD} since a few realize problems of {PTSD}. In addition, it takes time to treat {PTSD} patients who are overly nervous and show drastic emotional changes in response to slight actions or speeches of others. {\textbar}   {\textbar} Further, currently there is no method to detect a development of {PTSD} before patients present and express {PTSD} symptoms. However, even before the presentation of such symptoms, a neurophysiological response, a hematological response, and a neuroimaging characteristic change slightly. Thus, by analyzing the neurophysiological response, the hematological response, and the neuroimaging characteristic (hereinafter, posttraumatic physical response information) preceding the presentation of symptoms, the presentation of {PTSD} symptoms may be predicted. In particular, behavioral symptoms such as violence and self-harm are serious issues and greatly affect the society, and thus suitable treatment is to be applied by predicting a symptom presentation risk before the presentation of symptoms. However, each time of the posttraumatic physical response information has a little effect size to predict the presentation of {PTSD} symptoms, and thus an approach to efficiently integrate and analyze the items of the posttraumatic physical response information is essential. {\textbar}   {\textbar} Accordingly, there is needed a method of verifying posttraumatic physical response information of a patient that may change before a development of {PTSD} after experiencing a traumatic event, and predicting a {PTSD}-related problem presentation probability in advance by integrally analyzing the posttraumatic physical response information. {\textbar}   {\textbar} {DISCLOSURE} {OF} {INVENTION} {\textbar}   {\textbar} Technical Goals {\textbar}   {\textbar} An aspect provides a method of predicting a behavior problem that may verify whether an individual is classified as a biological phenotype based on posttraumatic physical response information of the individual obtained within first three months after the individual is exposed to a traumatic event, extract a violent behavior risk group based on the classified biological phenotype, and predict a violent symptom presentation probability of the individual through the extracted violent behavior risk group. {\textbar}   {\textbar} Another aspect provides a method of predicting a behavior problem that may obtain posttraumatic physical response information of an individual within three months immediately after the individual is exposed to trauma, known as a prime time for preventive intervention in a development of posttraumatic stress disorder ({PTSD}), predict a violent behavior risk group with a high violent behavioral symptom presentation probability of the individual, and apply preventive intervention suitable for the predicted violent behavior risk group to the individual. {\textbar}   {\textbar} Technical Solutions {\textbar}   {\textbar} According to an aspect, there is provided a method of predicting a posttraumatic behavior problem, the method including classifying an individual based on a type of a traumatic event to which the individual is exposed, obtaining, from the individual, primary posttraumatic physical information of the individual within a predetermined period after the exposure to the traumatic event, determining a violent behavior risk group based on a biological phenotype of the individual by analyzing the primary posttraumatic physical information, obtaining secondary posttraumatic physical information of the individual to determine a specificity of the violent behavior risk group, and predicting a violent symptom presentation probability of the individual based on the primary posttraumatic physical information and the secondary posttraumatic physical information. {\textbar}   {\textbar} The type of the traumatic event may be classified as physical violence, sexual violence, accidents/disasters, or others based on a characteristic of the traumatic event. {\textbar}   {\textbar} The primary posttraumatic physical information may include a neurophysiological element related to autonomic nerve modulation, and a blood substance element related to oxidative stress, neuroregeneration and a hypothalamic-pituitary-adrenal axis ({HPA}) of the individual. {\textbar}   {\textbar} The determining may include classifying the individual as one of an emotional phenotype, a behavioral phenotype, and a cognitive phenotype by applying a cluster analysis based on the primary posttraumatic physical information, and determining a biological phenotype corresponding to the classified phenotype to be the violent behavior risk group of the individual. {\textbar}   {\textbar} The biological phenotype may have a characteristic of a biased phenotype of a predetermined symptom expressed by the individual for a short period of time or a long period of time as a mental maladjustment symptom after the individual is exposed to the traumatic event. {\textbar}   {\textbar} The obtaining of the secondary posttraumatic physical information may include obtaining, as the secondary posttraumatic physical information, neuroimaging information about a brain reward circuit related to a violent behavior in brain tissue. {\textbar}   {\textbar} The predicting may include predicting the violent symptom presentation probability of the individual in view of a correlation between elements based on the primary posttraumatic physical information and the secondary posttraumatic physical information. {\textbar}   {\textbar} According to another aspect, there is also provided an apparatus for predicting a posttraumatic behavior problem, the apparatus including a processor configured to classify an individual based on a type of a traumatic event to which the individual is exposed, obtain, from the individual, primary posttraumatic physical information of the individual within a predetermined period after the exposure to the traumatic event, determine a violent behavior risk group based on a biological phenotype of the individual by analyzing the primary posttraumatic physical information, obtain secondary posttraumatic physical information of the individual to determine a specificity of the violent behavior risk group, and predict a violent symptom presentation probability of the individual based on the primary posttraumatic physical information and the secondary posttraumatic physical information. {\textbar}   {\textbar} {BRIEF} {DESCRIPTION} {OF} {DRAWINGS} {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  illustrates an apparatus for predicting a posttraumatic violent behavior problem according to an embodiment. {\textbar} {FIGS}. 2 {\textbar}   {\textbar} a {\textbar}  through 2 {\textbar} c {\textbar} illustrate posttraumatic physical response information of an individual according to an embodiment. {\textbar} {FIG}. 3 {\textbar}   {\textbar}  illustrates an operation of predicting a presentation of a violent symptom according to an embodiment. {\textbar} {FIGS}. 4 {\textbar}   {\textbar} a {\textbar}  and 4 {\textbar} b {\textbar} are graphs illustrating characteristics of biological phenotypes according to an embodiment. {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a flowchart illustrating a method of predicting a posttraumatic behavior problem according to an embodiment. {\textbar} {FIG}. 6 {\textbar}   {\textbar}  is a block diagram illustrating an example of predicting a violent behavior problem of an individual according to an embodiment. {\textbar} {FIG}. 7 {\textbar}   {\textbar}  is a diagram of an apparatus for predicting posttraumatic violent behavior according to an embodiment. {\textbar} {BEST} {MODE} {FOR} {CARRYING} {OUT} {THE} {INVENTION} {\textbar}   {\textbar} Hereinafter, reference will now be made in detail to embodiments with reference to the accompanying drawings. {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  illustrates an apparatus for predicting a posttraumatic violent behavior problem according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , a posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may predict a violent symptom presentation probability based on neurophysiological phenomenon information, hematological change information, and neuroimaging information of an individual  {\textbar} 103 {\textbar}  exposed to a traumatic event  {\textbar} 102 {\textbar} . In detail, the traumatic event  {\textbar} 102 {\textbar}  is a distressing event that the individual  {\textbar} 103 {\textbar}  may experience in life, and includes various incidents such as traffic accidents, murder incidents, and natural disasters that impair general adaptability. A type of the traumatic event  {\textbar} 102 {\textbar}  may be classified as physical violence, sexual violence, accidents/disasters, or others based on a characteristic of an event or incident applied to the individual  {\textbar} 103 {\textbar} . The individual  {\textbar} 103 {\textbar}  may directly or indirectly experience the traumatic event  {\textbar} 102 {\textbar}  unwillingly, and present mental symptoms of a maladjustment response after experiencing the traumatic event  {\textbar} 102 {\textbar} . {\textbar} \{circle around (1)\} Physical violence is a traumatic event that applies physical damage to a body of an individual or brings a financial loss, and may correspond to direct physical violence. For example, physical violence may include bullying and gang assaults. {\textbar}   {\textbar} \{circle around (2)\} Sexual violence is a traumatic event in which an individual is sexually assaulted against will of the individual, and may correspond to all sexual acts and assaults by mental or psychological pressure. For example, sexual violence may include sexual harassment, indecent assaults, and rape. {\textbar}   {\textbar} \{circle around (3)\} Accidents/disasters are one-session traumatic events, and may correspond to man-made incidents that occur unexpectedly or abnormal natural phenomena. For example, accidents/disasters may include earthquake, typhoon, flood, drought, tsunami, fire, and epidemic of a disease. {\textbar}   {\textbar} \{circle around (4)\} Others may correspond to traumatic events that do not belong to physical violence, sexual violence, and accidents/disasters described above. For example, others may include death of a parent, spouse or child, and severe stress. {\textbar}   {\textbar} A neurophysiological phenomenon, a hematological change, and a neuroimaging change may be observed immediately or at a relatively early stage after the exposure to the traumatic event  {\textbar}   {\textbar} 102 {\textbar}  before posttraumatic stress disorder ({PTSD}) symptoms are presented. The {PTSD} symptoms may be presented within a short period of time, or may be hidden for a long time and presented in an unexpected situation based on a type of the traumatic event  {\textbar} 102 {\textbar} , an exposure count, interpersonal involvement, and a neurophysiological characteristic of an individual. {\textbar} In view of the foregoing, the posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may obtain posttraumatic physical response information of the individual  {\textbar} 103 {\textbar}  within three months immediately after the exposure to the traumatic event  {\textbar} 102 {\textbar} . In particular, preventive intervention in a violent behavior may be effective within three months after exposure to trauma. Thus, it is important to predict a violent behavior within three months after the exposure to trauma. That is, a period of three months after a development of {PTSD} is known as a prime time for preventive intervention in {PTSD} symptoms. Although the symptoms are not presented within three months immediately after the trauma, it is extremely important to predict a violent behavior risk group with a high violent behavior symptom presentation probability and apply suitable preventive intervention. {\textbar} The traumatic event  {\textbar}   {\textbar} 102 {\textbar}  may be a personal issue of the individual  {\textbar} 103 {\textbar}  exposed to the traumatic event  {\textbar} 102 {\textbar} , and also be a social issue. Thus, the posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may detect a physical change in the individual  {\textbar} 103 {\textbar}  within a short period of time after the individual  {\textbar} 103 {\textbar}  experiences the traumatic event  {\textbar} 102 {\textbar} . {\textbar} The posttraumatic physical response information may be obtained by being classified into primary posttraumatic physical information and secondary posttraumatic physical information to determine a specificity related to violence of an individual, a time, or a point in time at which information is obtained from the individual. For example, the primary posttraumatic physical information of the individual may be obtained within a predetermined period after exposure to a traumatic event. In addition, the secondary posttraumatic physical information of the individual may be obtained to determine a specificity of a violent behavior risk group of the individual classified based on the primary posttraumatic physical information. That is, as information (predictors) to be used to predict and determine a violent behavior of the individual in advance, the posttraumatic physical response information including the primary posttraumatic physical information and the secondary posttraumatic physical information may be obtained. {\textbar}   {\textbar} When obtaining the primary posttraumatic physical information, different types of physical response information may be obtained to determine a specific posttraumatic response presented for each type of the traumatic event that the individual experiences. A different event may be imprinted on a brain of the individual based on a type of the traumatic event that the individual experiences. Thus, a different posttraumatic response may be presented by the individual. That is, an individual having experienced a “traffic accident” and an individual having experienced the “Iraq War” may have similar direct/indirect experiences of death. However, the two individuals may present different posttraumatic responses due to different causes of the experiences of death, and thus different types of information may need to be obtained to determine the different posttraumatic responses. {\textbar}   {\textbar} Accordingly, a different type of posttraumatic physical response information to be used to predict a biological phenotype may be obtained based on a type of a traumatic event to which an individual is exposed, and thus a different prediction model may be applied based on the type of the traumatic event. {\textbar}   {\textbar} To determine {PTSD} symptoms presented by the individual  {\textbar}   {\textbar} 103 {\textbar}  more objectively, a neurophysiological element and a blood substance element may be obtained as the primary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may obtain information about elements that may physically change in response to a traumatic event after exposure to the traumatic event. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may determine a biological phenotype based on a characteristic of a biological phenotype group of the individual by applying a cluster analysis based on the primary posttraumatic physical information. In detail, specific posttraumatic physical response information may be obtained based on each type of the traumatic event. A behavioral trauma presentation level and a type of posttraumatic physical response information to be used to predict the same may be different based on the type of the traumatic event, and thus a posttraumatic behavior problem predicting apparatus corresponding to each type of the traumatic event may be established. The primary posttraumatic physical information corresponding to each type of the traumatic event may be collected and form a cluster or groups of information having a high index of correlation. Herein, three clusters may be defined and classified based on posttraumatic responses. Based on the cluster analysis, each individual may be classified as one of an emotional phenotype, a behavioral phenotype, and a cognitive phenotype. {\textbar} That is, the biological phenotype of the individual may be classified through the cluster analysis from the primary posttraumatic physical information based on the type of the traumatic event. In an example, a presentation of a posttraumatic symptom of the individual may be classified as the cognitive phenotype based on primary posttraumatic physical information of the individual experiencing physical violence. The presentation of the posttraumatic symptom of the individual may be classified as the emotional phenotype based on primary posttraumatic physical information of the individual experiencing accidents/disasters. Since a different biological phenotype is expressed based on the type of the traumatic event and how the individual accepts the traumatic event, a violent behavior risk group corresponding to the type of the traumatic event may be adaptively determined and classified based on a condition of each individual, rather than being preset. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may additionally obtain the secondary posttraumatic physical information including neuroimaging information specific to a violent behavior, after the primary posttraumatic physical information is obtained. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may utilize the primary posttraumatic physical information and the secondary posttraumatic physical information to predict a violent behavior. A nonlinear prediction equation to be used to predict a violent behavior may be established in advance through a sample group. {\textbar} That is, to establish the nonlinear prediction equation to be applied to the posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar} , a sample group may be formed based on each type of the traumatic event, and posttraumatic physical response information of individuals may be obtained. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may analyze an odds ratio to predict a violent behavior problem based on the posttraumatic physical response information, and extract factors with relatively high odds ratios from the posttraumatic physical response information. Then, the posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may secondarily extract factors with a lowest correlation therebetween from the extracted factors with the relatively high odds ratios. An operation of extracting factors with a lowest correlation may be a process of selecting a minimum number of factors by excluding factors having duplicate effects, in a nonlinear violent behavior prediction model. The secondarily extracted factors may be used to establish the nonlinear equation to predict a behavior problem for a sample group corresponding to the type of the traumatic event. In this example, a nonlinear equation exhibiting a highest prediction rate using a minimum number of factors may be selected. {\textbar} Here, the nonlinear violent behavior prediction model may be represented using a series of process of extracting a minimum number of specific posttraumatic response information through machine learning using or being trained by posttraumatic physical response information (predictors) and trauma group information (outcome or trauma characteristics) of a sample group selected in advance based on the type of the traumatic event, and establishing a nonlinear equation utilizing the extracted information to be used by the nonlinear violent behavior prediction model. {\textbar}   {\textbar} Through the above process, a nonlinear equation and factors of the posttraumatic physical response information finally selected from the sample group based on each type of the traumatic event may be selected finally. Based on the nonlinear equation and the factors of the posttraumatic physical response information, posttraumatic response information may be obtained by selecting factors of the posttraumatic physical response information within one month after exposure to trauma, and a behavior problem prediction rate may be extracted by applying the nonlinear equation. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may objectify a negative response of the individual to the traumatic event by complexly examining each element. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may classify the individual as one of the emotional phenotype, the behavioral phenotype, and the cognitive phenotype by applying the cluster analysis based on the primary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may determine a biological phenotype corresponding to the classified phenotype to be the violent behavior risk group of the individual. Here, the biological phenotype may have a characteristic of a biased phenotype of a predetermined symptom expressed by the individual for a short period of time or a long period of time as a mental maladjustment symptom after the individual is exposed to the traumatic event. In an example, the characteristic of the biological phenotype may indicate each posttraumatic symptom that may be presented by the individual, for example, depression, impulsivity, anger, alcohol use, attention, or emotion recognition. {\textbar} The posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may predict a violent symptom presentation probability, for individuals belonging to a risk group belonging to the violent behavior risk group, that is, one of the emotional phenotype, the behavioral phenotype, and the cognitive phenotype. That is, the posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may predict an individual with a high probability of presenting a behavior problem such as violence or self-harm after exposure to a traumatic event based on a biological phenotype of the individual. For example, the posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may discover, at an early stage, a violent behavior risk group (behavioral type) with a high probability of presenting violence within one to three months after the exposure to the traumatic event. The violence presented after the exposure to the traumatic event may be determined based on a level of addiction (dependence) to alcohol and illegal drugs, a frequency of self-harm and suicide, a predetermined or higher frequency of impulsive behavior, a frequency of anger-out behavior, or a frequency of harming others and aggressive behavior. {\textbar} Here, the posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may determine the violent behavior risk group of the individual using indicators of a neurophysiological element, a blood substance element, and a neurological element (neuroimaging) as the posttraumatic physical response information indicating a physical change in the individual, thereby efficiently and accurately extracting a high violent behavior risk group with a high probability of presenting violence after trauma. {\textbar} Ultimately, the posttraumatic behavior problem predicting apparatus may predict a behavioral response to be presented by an individual in advance based on a principle of conditioning by exposure to a traumatic event, and provide criteria for receiving suitable treatment with respect to the behavioral response, thereby suggesting a basis for preventive prediction and intervention in posttraumatic violence. The behavioral response may refer to a symptom of more intensively presenting a behavior to reduce anxiety caused by severe pain and stress as an anxiety response to a conditioned stimulus is conditionally formed by stimulation of an individual by a traumatic event or a cue related to the traumatic event. {\textbar}   {\textbar} That is, the posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may predict violence of the individual  {\textbar} 103 {\textbar}  to be triggered by negative thoughts or emotions of the individual  {\textbar} 103 {\textbar}  exposed to the traumatic event  {\textbar} 102 {\textbar} , and suggest a basis for inducing treatment of the individual  {\textbar} 103 {\textbar}  to change the violence to an effective alternative behavior. {\textbar} {FIGS}. 2 {\textbar}   {\textbar} a {\textbar}  through 2 {\textbar} c {\textbar} illustrate posttraumatic physical response information of an individual according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIGS}. 2 {\textbar} a {\textbar}  through 2 {\textbar} c {\textbar} , a posttraumatic behavior problem predicting apparatus may obtain posttraumatic physical response information to predict a high violent behavior risk group with a high probability of presenting violence, for an individual exposed to a traumatic event. The posttraumatic behavior problem predicting apparatus may obtain the posttraumatic physical response information in three domains to determine a physical change in the individual in response to a mental symptom. {\textbar} The posttraumatic behavior problem predicting apparatus may obtain a neurophysiological element and a blood substance element to complexly examine elements that may be associated with a response to a traumatic event. In detail, the posttraumatic behavior problem predicting apparatus may determine a posttraumatic response to be presented specifically based on a type of the traumatic event from the neurophysiological element and the blood substance element. In detail, primary posttraumatic physical information may be obtained from all individuals exposed to traumatic events. In this example, all the individuals correspond to a group of individuals experiencing different traumatic events, and may present different posttraumatic responses based on types of the traumatic events. In an example, an individual experiencing a traumatic event of which a type is classified as physical violence may have a high concentration of a substance that represents an inflammation-immune system in the blood in response to an event of substantially applying physical harm. An individual experiencing a traumatic event of which a type is classified as sexual violence may have a high concentration of a substance that represents a female sex hormone. Ultimately, the posttraumatic behavior problem predicting apparatus may obtain a different type of primary posttraumatic physical information based on a type of a traumatic event in response to a posttraumatic response to be presented as a maladjustment symptom of an individual exposed to the traumatic event. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may obtain secondary posttraumatic physical information including neuroimaging information of the individual as a neurologic element. In this example, the neurophysiological element and the blood substance element that may be relatively easy to collect may be defined as primary basic posttraumatic physical information, and a neuroimaging element that may be relatively difficult to collect but have a relatively high specificity to predict a violent behavior may be defined as secondary intensive posttraumatic physical response information. {\textbar}   {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 2 {\textbar} a {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain the neurophysiological element as an element related to autonomic nerve modulation of the individual. In detail, the posttraumatic behavior problem predicting apparatus may obtain the neurophysiological element to determine a condition with respect to physical function modulation as a maladjustment symptom of the individual exposed to the traumatic event. The posttraumatic behavior problem predicting apparatus may measure, as the neurophysiological element, a heart rate, a heart rate variability ({HRV}), or a skin conductance ({SC}) of the individual. In particular, the heart rate and the {HRV} may be classified as the primary posttraumatic physical information, and the {SC} may be classified as one-session trauma group-specific information, whereby the primary posttraumatic physical information may be obtained based on a type of the traumatic event to which the individual is exposed. {\textbar} Here, the heart rate indicates the number of heartbeats that increases or decreases based on a condition of the individual, and the {HRV} may be indicated using a low-frequency ({LF})/high-frequency ({HF}) ratio measured from the individual. In addition, the {SC} may be indicated in proportion to a humidity of the skin based on a condition of the individual. In an example, in a case in which the individual feels anxiety in response to a traumatic event, the heart rate may sharply increase, the {HRV} may show an imbalance in sympathetic-parasympathetic nerves based on the {LF}/{HF} ratio, and the {SC} may increase. {\textbar}   {\textbar} Anxiety, denial, or threat which is a {PTSD} symptom to be presented by an individual in response to a traumatic event may cause a tension in a human body, which may lead to a physical disorder such as hyperventilation or hyperactivity. In particular, the heart is an internal organ that may first physically respond to hyperarousal of the body. Thus, the posttraumatic behavior problem predicting apparatus may measure the neurophysiological element that changes in response to an infiltration symptom, an avoidance symptom, a cognitive/emotional denial symptom, or an arousal/response symptom of the individual. {\textbar}   {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 2 {\textbar} b {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain the blood substance element flowing in blood vessels of the individual and to be used to determine a state of an oxidative nutrient. In detail, the posttraumatic behavior problem predicting apparatus may obtain the blood substance element to determine a symptom to be presented through the blood as a maladjustment symptom of the individual exposed to the traumatic event. The posttraumatic behavior problem predicting apparatus may collect a small amount of venous blood sample, and measure a concentration of a predetermined substance that reflects an immune function, oxidative stress, a neuroplasticity, or a hypothalamic-pituitary-adrenal ({HPA}) axis of the individual. {\textbar} Here, the immune function may indicate a distribution concentration of immune cells included in the blood, the oxidative stress may indicate a distribution concentration of a blood coagulation substance included in the blood, and the neuroplasticity may indicate a presence and absence of blood to be supplied while a neural pathway of the brain is changed and reorganized structurally and functionally by external stimulation, experience, and learning. An element related to the {HPA} axis may indicate a ratio of a stress hormone secreted and released in the blood by stress that the individual may experience in response to exposure to trauma. In particular, a concentration of a substance that represents an inflammation-immune system in the blood may be classified as posttraumatic physical response information specific to a physical violence trauma group, and information related to a concentration of a female hormone-related substance in the blood may be classified as posttraumatic physical response information specific to a sexual violence trauma group. {\textbar}   {\textbar} In an example, in a case in which the individual feels anxiety in response to a traumatic event, an activity of an immune system of the individual may decrease, a distribution concentration of immune cells may decrease, and a blood supply ratio in the body may decrease as a concentration of a blood coagulation substance increases (oxidative stress) and a stress hormone is released in the blood (the {HPA} axis) due to stress. {\textbar}   {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 2 {\textbar} c {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain the neuroimaging element to determine a structure of a brain region highly related to violence or fear response. In detail, the posttraumatic behavior problem predicting apparatus may obtain the neuroimaging element as a neurological element to measure a connectivity or an activity of the brain region in response to a traumatic event. The neuroimaging element may be a magnetic resonance imaging ({MRI}) image to be used to determine violence based on whether brain tissue is activated. The neuroimaging information may be relatively difficult to collect, and thus may be classified as the secondary posttraumatic physical information and utilized to predict a violent behavior. {\textbar} In general, the amygdala and the hippocampus of the human brain are known as storing or erasing memories of a situation that a person experiences. In this example, memories about anxiety and fear caused by a traumatic event may be imprinted on the brain through a fear circuit including the amygdala and the hippocampus. After experiencing the traumatic event, anxiety and fear may be triggered by the imprinted memories of the traumatic event in a situation in which the person does not feel fear due to functional or structural characteristics of the fear circuit and a brain structure connected thereto. {\textbar}   {\textbar} In particular, to predict a posttraumatic violent behavior symptom, a responsiveness to a traumatic stimulus and the volume of each of the nucleus accumbens and the prefrontal cortex belonging to a brain reward circuit may be significant. That is, the nucleus accumbens may increase a sensitivity with respect to a violent behavior by inducing an emotion or a behavior to enhance the brain reward circuit, and the prefrontal cortex may act as a control tower that modulates the operation of the nucleus accumbens to restrain a presentation of the violent behavior. {\textbar}   {\textbar} That is, it may be predicted that the brain reward circuit may be activated and a violent behavior may be presented as the volume of the nucleus accumbens increases, the responsiveness of the nucleus accumbens with respect to the traumatic stimulus increases, the volume of the prefrontal cortex decreases, and the responsiveness of the prefrontal cortex with respect to the traumatic stimulus decreases. {\textbar}   {\textbar} Thus, the posttraumatic behavior problem predicting apparatus may obtain the neuroimaging element to determine whether the fear circuit and the reward circuit in the brain are activated, and whether a brain-nervous system is activated in response to the activation of the fear circuit and the reward circuit, thereby determining the connectivity, the activity, and the brain structure in response to the exposure of the individual to trauma. {\textbar}   {\textbar} {FIG}. 3 {\textbar}   {\textbar}  illustrates an operation of predicting a presentation of a violent symptom according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 3 {\textbar} , a violent behavior problem predicting apparatus may analyze a neurophysiological element, a blood substance element, and a neuroimaging element as posttraumatic physical response information, and calculate a score for each element. Here, the score for each element may be calculated using a nonlinear equation between elements secondarily extracted from a sample group based on a type of a traumatic event, as described with reference to  {\textbar} {FIG}. 1 {\textbar} . Types of the extracted elements and the nonlinear equation may differ based on each type of the traumatic event. In view of the above, a posttraumatic behavior problem predicting apparatus may be individualized based on each type of the traumatic event, and a specific violent behavior problem predicting apparatus may be applied based on a type of the traumatic event to which an individual is exposed. That is, the posttraumatic behavior problem predicting apparatus may calculate the score for each element to determine a seriousness of a mental symptom of the individual exposed to the traumatic event based on each of the elements of the posttraumatic physical response information. {\textbar} In this example, each element may have a different range of value indicating an anxiety symptom or a stress symptom of the individual exposed to the traumatic event based on a characteristic of each element, and thus the score calculated for each element may be normalized from “−1” to “1”. The posttraumatic behavior problem predicting apparatus may determine a characteristic of a future biological phenotype of the individual based on the normalized score of each element of the posttraumatic physical response information. In particular, to distinguish behavioral trauma to predict a violent behavior, a determiner of the posttraumatic behavior problem predicting apparatus may classify the individual as one of an emotional phenotype, a behavioral phenotype, and a cognitive phenotype through a cluster analysis based on the primary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus may determine a problem behavior with a greatest value of a presentation index corresponding to a characteristic of the behavioral trauma to be a biological phenotype through the cluster analysis, thereby determining trauma of the individual. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may extract a violent behavior risk group corresponding to the biological phenotype, and finally predict a violent behavior presentation probability by integrating the violent behavior risk group and the secondary posttraumatic physical information. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may determine whether a future behavioral trauma group is generated immediately after exposure to trauma, using the nonlinear equation of the score of each element of the posttraumatic physical response information immediately after the exposure to trauma before a characteristic of the behavioral trauma group is presented. In an example, the posttraumatic behavior problem predicting apparatus may determine the characteristic of the biological phenotype which may be classified as future impulsivity, anger, attention, alcohol use, or the like based on the score of each of the neurophysiological element, the blood substance element, and the neurologic element. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may determine whether the biological phenotype is generated and a probability related thereto based on the characteristic of the biological phenotype to be generated in the future based on the posttraumatic physical response information obtained from the individual immediately after the exposure to trauma. In detail, the posttraumatic behavior problem predicting apparatus may analyze an odds ratio with which each element of the posttraumatic physical response information is classified as the biological phenotype. The posttraumatic behavior problem predicting apparatus may select a posttraumatic physical response factor with a high odds ratio for each biological phenotype. Characteristics of a behavioral trauma group to verify that a predicted cluster of the posttraumatic physical response factor is a cluster with a high probability of behavior problems are shown in  {\textbar}   {\textbar} {FIGS}. 4 {\textbar} a {\textbar} and  {\textbar} 4 {\textbar} b {\textbar} .  {\textbar} Therefore, the posttraumatic behavior problem predicting apparatus may assume that a posttraumatic physical response factor with a great rate of predicting a high violent behavior risk group and with a low correlation between factors has a great power of explanation, and repeatedly analyze a combination of these various factors, thereby extracting factors that maximize the rate of predicting a high violent behavior risk group. {\textbar}   {\textbar} In detail, a predictor of the posttraumatic behavior problem predicting apparatus may extract the factors based on information related to a sample group for each type of the traumatic event, in an order of a factor having a highest index of correlation, by obtaining an index of correlation between each posttraumatic physical response factor (neurophysiological-neuroimaging response information) and trauma characteristics (outcome). Here, the trauma characteristics are information to be used to determine a biological phenotype group to be predicted herein, and may be expressed in an ascending order of presentation index scores specific to each characteristic. {\textbar}   {\textbar} In addition, the posttraumatic behavior problem predicting apparatus may apply a weight to a method of obtaining a posttraumatic physical response factor by incorporating an index of easiness therein if information is relatively easy to obtain. In an example, an index of easiness for obtaining a factor measurable by taking a small amount of venous blood sample may be calculated to be higher than that of a factor obtainable through a relatively complex neuroimaging analysis. As described with reference to  {\textbar}   {\textbar} {FIGS}. 2 {\textbar} a {\textbar}  through 2 {\textbar} c {\textbar} , in a case in which factors have duplicate effects, the factors having duplicate effects may be excluded, and factors with a lowest correlation between factors and with a highest index of correlation with the trauma characteristics may be extracted to construct the nonlinear equation using a minimum number of factors. That is, the posttraumatic behavior problem predicting apparatus may primarily extract factors with high indices of correlation with the behavioral trauma and with high indices of easiness for obtaining information from the posttraumatic physical response factors. The posttraumatic behavior problem predicting apparatus may repeatedly analyze a combination with a lowest index of correlation between the primarily extracted factors, thereby finally selecting a nonlinear equation and a minimum number of posttraumatic physical response factors with a greatest predictability with respect to the behavioral trauma. The above process may be repeatedly performed based on each type of the traumatic event. {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a flowchart illustrating a method of predicting a posttraumatic behavior problem according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 5 {\textbar} , in operation  {\textbar} 501 {\textbar} , a posttraumatic behavior problem predicting apparatus may classify an individual based on a type of a traumatic event to which the individual is exposed. The posttraumatic behavior problem predicting apparatus may classify the individual based on the type of the traumatic event that may be classified as physical violence, sexual violence, accidents/disasters, or others based on a characteristic of the traumatic event. {\textbar} In operation  {\textbar}   {\textbar} 502 {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain primary posttraumatic physical information of the individual at an early stage within a predetermined period after the exposure the traumatic event. The posttraumatic behavior problem predicting apparatus may obtain a neurophysiological element and a blood substance element as the primary posttraumatic physical information of the individual. Here, the neurophysiological element may include biometric information related to autonomic nerve modulation of the individual. The blood substance element may include blood information related to oxidative stress, neuroregeneration and an {HPA} of the individual. {\textbar} That is, the posttraumatic behavior problem predicting apparatus may obtain posttraumatic physical response information to be presented as a physically abnormal phenomenon to determine a presentation of a mental symptom and a posttraumatic symptom type with respect to the individual exposed to the traumatic event. {\textbar}   {\textbar} In operation  {\textbar}   {\textbar} 503 {\textbar} , the posttraumatic behavior problem predicting apparatus may determine a violent behavior risk group based on a biological phenotype of the individual by analyzing the primary posttraumatic physical information of the individual. The posttraumatic behavior problem predicting apparatus may determine the biological phenotype based on a characteristic of the biological phenotype of the individual by applying a cluster analysis based on the posttraumatic physical response information. Here, the biological phenotype may have a characteristic of a biased phenotype of a predetermined symptom expressed by the individual for a short period of time or a long period of time as a mental maladjustment symptom after the individual is exposed to the traumatic event. That is, the characteristic of the biological phenotype may be used to verify a paraesthesia behavior presented by stress that the individual experiences. The posttraumatic behavior problem predicting apparatus may determine the biological phenotype of the individual through the paraesthesia behavior. {\textbar} For this, the posttraumatic behavior problem predicting apparatus may calculate a score for each of the neurophysiological element and the blood substance element by analyzing the neurophysiological element and the blood substance element. The posttraumatic behavior problem predicting apparatus may calculate the score for each element to determine a seriousness with respect to the mental symptom of the individual exposed to the traumatic event based on each of the elements of the posttraumatic physical response information. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may determine the characteristic of the biological phenotype of the individual based on the calculated score for each element. In an example, the posttraumatic behavior problem predicting apparatus may determine the characteristic of the biological phenotype which may be classified as impulsivity, anger, attention, alcohol use, or the like based on the score of each of the neurophysiological element, the blood substance element, and a neuroimaging element. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may classify the individual as one of an emotional phenotype, a behavioral phenotype, and a cognitive phenotype by applying a cluster analysis based on the primary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus may determine a biological phenotype corresponding to the classified phenotype to be a violent behavior risk group of the individual. {\textbar}   {\textbar} In operation  {\textbar}   {\textbar} 504 {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain secondary posttraumatic physical information of the individual to determine a specificity of the violent behavior risk group. The posttraumatic behavior problem predicting apparatus may obtain, as the secondary posttraumatic physical information, neuroimaging information about a brain reward circuit related to a violent behavior in brain tissue. {\textbar} In operation  {\textbar}   {\textbar} 505 {\textbar} , the posttraumatic behavior problem predicting apparatus may predict a violent symptom presentation probability of the individual based on the primary posttraumatic physical information and the secondary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus may predict the violent symptom presentation probability in view of a correlation between the elements of the posttraumatic physical response information with respect to the biological phenotype. Here, the posttraumatic behavior problem predicting apparatus may predict the violent symptom presentation probability based on the primary posttraumatic physical information and the secondary posttraumatic physical information by applying a nonlinear equation extracted from a sample group classified based on the type of the traumatic event. {\textbar} In an example, in a case of the classified type of the traumatic event to which the individual is exposed corresponds to 1) physical violence, 2) sexual violence, 3) accidents/disasters, or 4) others, the posttraumatic behavior problem predicting apparatus may predict the violent symptom presentation probability by applying a nonlinear equation extracted from 1) a physical violence sample group, 2) a sexual violence sample group, 3) a one-session trauma (accidents/disasters) sample group, or 4) other sample groups. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may provide treatment criteria for a mental symptom of an individual predicted to have a high violent symptom presentation probability before a violent symptom is presented, thereby providing a basis for linking the individual to treatment before the mental symptom is aggravated. {\textbar}   {\textbar} Ultimately, different posttraumatic behavior problem predicting apparatuses corresponding to types of traumatic events to which a sample group is exposed may be utilized through machine learning of the sample group based on the types of the traumatic events. In addition, the posttraumatic behavior problem predicting apparatus may predict a characteristic of a posttraumatic violent behavior yet to be presented by the individual exposed to the traumatic event based on a posttraumatic physical response level collected immediately after the individual is exposed to the traumatic event. {\textbar}   {\textbar} {FIG}. 6 {\textbar}   {\textbar}  is a block diagram illustrating an example of predicting a violent behavior problem of an individual according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 6 {\textbar} , a type of a traumatic event to which an individual is exposed may be classified as (i) physical violence, (ii) sexual violence, (iii) accidents/disasters, or (iv) others. After the exposure to the traumatic event, primary posttraumatic physical information specific to a posttraumatic response may be obtained from the individual. The primary posttraumatic physical information obtained based on the type of the traumatic event may be collected, and the individual may be classified as one of a behavioral phenotype, an emotional phenotype, and a cognitive phenotype through a cluster analysis thereon, and a biological phenotype may be extracted. {\textbar} A violent behavior of the individual may be predicted based on the extracted biological phenotype. In detail, a neuroimaging indicator of a brain reward circuit specific to the violent behavior may be obtained as secondary posttraumatic physical information. Then, posttraumatic physical response information may be generated by matching the primary posttraumatic physical information and the secondary posttraumatic physical information. {\textbar}   {\textbar} A violent symptom presentation probability of the individual may be predicted by applying a nonlinear equation extracted from each traumatic event sample group based on the type of the traumatic event to the posttraumatic physical response information. {\textbar}   {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 7 {\textbar} , a diagram of an apparatus for predicting posttraumatic violent behavior is shown. The illustrated apparatus in  {\textbar} {FIG}. 7 {\textbar}  may be identical to the apparatus  {\textbar} 101 {\textbar}  illustrated in  {\textbar} {FIG}. 1 {\textbar} . The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  includes at least one or more processors  {\textbar} 702 {\textbar} , memory  {\textbar} 704 {\textbar} , and one or more interfaces  {\textbar} 706 {\textbar} . The one or more processors  {\textbar} 702 {\textbar}  may be a processor suitable to at least execute stored programmable instructions, as described above, or may be a {CPU} or any other suitable processing circuitry. The memory  {\textbar} 704 {\textbar}  may store various types of data and/or information and executable instructions, also as described above, related to at least the prediction of posttraumatic violent behavior by an individual. Further, memory  {\textbar} 704 {\textbar}  may include data and/or information related to the nonlinear prediction model and cluster analysis described above. The interface(s)  {\textbar} 706 {\textbar}  may be configured to receive or obtain or facilitate the receiving or obtaining of at least posttraumatic physical response information (e.g., primary posttraumatic physical information  {\textbar} 710 {\textbar} , secondary posttraumatic physical information  {\textbar} 712 {\textbar} ) associated with an individual. Examples of interfaces  {\textbar} 706 {\textbar}  may include devices (e.g., devices for measuring heart-related data or metrics, devices for measuring blood and related data, brain scanning devices) for measuring such information and/or computer ports for receiving such information from external devices. {\textbar} The various technologies described in this specification can be implemented as digital electronic circuitry, computer hardware, firmware, software, or combinations of these. The technologies can be implemented as a computer program, that is, an information carrier, for example, a computer program typically embodied in the form of a machine-readable storage (computer-readable medium) or a radio wave signal, to process operation of a data processing device, for example, a programmable processor, a computer, or a plurality of computers, or to control the operation. The computer program can be recorded in any form of program languages including a compiled language and an interpreted language, and can be developed in any form including an independent program or a module, a component, a subroutine, or any other unit suitable for use in a computing environment. The computer program may be deployed to be processed by one computer or multiple computers in one site, or distributed across multiple sites and interconnected through a communication network. {\textbar}   {\textbar} Processors suitable for the execution of a computer program include, for example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. In general, a processor will receive instructions and data from a read-only memory ({ROM}), a random access memory ({RAM}), or both. Elements of a computer may include at least one processor for executing instructions and one or more memory devices for storing instructions and data. In general, a computer may include one or more mass storage devices, for storing data, for example, magnetic, magneto-optical disks, or optical disks, may receive data from them, may transmit data to them, or may be coupled to them to transceive data. Information carriers suitable for embodying computer program instructions and data include magnetic media, e.g., hard disks, floppy disks, and magnetic tapes, optical media, e.g., compact disk {ROMs} ({CD}-{ROMs}) and digital video disks ({DVDs}), magneto-optical media, e.g., floptical disks, semiconductor memory devices, e.g., {RAMs}, flash memories, erasable programmable {ROMs} ({EPROMs}), electrically erasable programmable {ROMs} ({EEPROMs}). The processors and the memories may be supplemented by or incorporated in special purpose logic circuitry. {\textbar}   {\textbar} Further, the computer-readable medium may be an arbitrarily available medium that may be accessed by a computer and may include a computer storage medium and a transmission medium. {\textbar}   {\textbar} While this specification includes details of a plurality of specific implementations, these should not be understood as limitations of any invention or the scope to be claimed, but should be understood as descriptions of features that can be peculiar to specific embodiments of the specific invention. Specific features described herein may be implemented by being combined in a single embodiment in the context of an individual embodiment. On the other hand, various features described in the context of a single embodiment may be implemented individually or in appropriate sub-combinations in a plurality of embodiments. While features may work in specific combinations and may be described as initially claimed so, at least one feature may be excluded from a claimed combination in some cases, and the claimed combination may be changed to a sub-combination or a modification of the sub-combination. {\textbar}   {\textbar} Similarly, although drawings illustrate operations in a particular order, this does not mean that these operations should be performed in the illustrated particular order or sequence or that all illustrated operations should be performed to obtain a desired result. In a particular case, multitasking and parallel processing may be advantageous. Separation of various system components in the above-described embodiments does not mean that such separation is required for all embodiments. In general, described program components and systems may be integrated in a single software product or may be packed in multiple software products. {\textbar}   {\textbar} Meanwhile, embodiments for exemplifying the technical spirit of the present invention have been described and shown above, but the present invention is not limited to shown and described configurations and effects. Those of ordinary skill in the art would appreciate that various changes and modifications of the present invention can be made without departing from the technical spirit. Therefore, it is to be understood that all suitable changes, modifications, and equivalents fall within the scope of the present invention. {CROSS}-{REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar}   {\textbar} This application is a continuation of co-pending U.S. patent application Ser. No. 15/882,254, filed Jan. 29, 2018, and entitled “{METHOD} {AND} {APPARATUS} {FOR} {PREDICTING} {POSTTRAUMATIC} {BEHAVIOR} {PROBLEM}”, which claims the benefit of priority to Korean Patent Application 10-2017-0145501, Nov. 2, 2017, which application is incorporated herein by reference in its entirety for all purposes. {\textbar}   {\textbar} {TECHNICAL} {FIELD} {\textbar}   {\textbar} Embodiments relate to a method and apparatus for predicting a posttraumatic behavior problem, and more particularly, to a method of predicting a behavior problem that may occur in the future from neurophysiological phenomena and symptoms presented by an individual immediately after exposure to a traumatic event. {\textbar}   {\textbar} {BACKGROUND} {ART} {\textbar}   {\textbar} Posttraumatic stress disorder ({PTSD}) includes a maladjustive response of an individual to an environmental stress event provided externally in life, a mental response of a patient experiencing a traumatic event, and a neurophysiological response related to stress. It is known that a brain process is based on such responses. {PTSD} may develop immediately after the stress event, or may not develop until weeks, months, or years after the stress event. That is, {PTSD} is a disorder of feeling excessive anxiety after watching or directly experiencing an accident, violence, or a disaster. Different {PTSD} symptoms are presented based on the frequency and strength of watching or experiencing such trauma, and a neurophysiological characteristic of an individual. {\textbar}   {\textbar} The {PTSD} symptoms include re-experiencing, avoidance, and hyperarousal. In detail, re-experiencing is a symptom of frequently having sudden memories of a traumatic scene, and experiencing the same feeling at that time again. Avoidance is a symptom, opposite to re-experiencing, of avoiding mentioning a traumatic event. Hyperarousal is a symptom of being oversensitive to a little sound or motion due to hyper-sensitive nerves. {\textbar}   {\textbar} {PTSD} causes physical distress such as headache, stomachache or muscular pain, or improves mental symptoms such as depression, a personality disorder, anxiety disorder or schizophrenia. {PTSD} patients may be addicted to alcohol or drugs to relieve pain, or show extreme behaviors. In particular, {PTSD} patients showing behavioral symptoms remarkably are at a risk of violence or self-harm, which is also a serious social issue. Thus, it is mightily significant to predict a behavior problem to be presented after exposure to trauma. {\textbar}   {\textbar} Cognitive behavioral therapy ({CBT}) is a representative treatment that may minimize {PTSD}-related problems. {CBT} makes a {PTSD} patient confront memories of a traumatic event that the patient consistently suppresses and avoids, thereby treating distorted cognition about the patient, others and the world. {CBT} is performed in combination with drug treatment and psychotherapy. {\textbar}   {\textbar} However, in reality, a small portion of patients take actions against a development of {PTSD} or receive treatment before the development of {PTSD} since a few realize problems of {PTSD}. In addition, it takes time to treat {PTSD} patients who are overly nervous and show drastic emotional changes in response to slight actions or speeches of others. {\textbar}   {\textbar} Further, currently there is no method to detect a development of {PTSD} before patients present and express {PTSD} symptoms. However, even before the presentation of such symptoms, a neurophysiological response, a hematological response, and a neuroimaging characteristic change slightly. Thus, by analyzing the neurophysiological response, the hematological response, and the neuroimaging characteristic (hereinafter, posttraumatic physical response information) preceding the presentation of symptoms, the presentation of {PTSD} symptoms may be predicted. In particular, behavioral symptoms such as violence and self-harm are serious issues and greatly affect the society, and thus suitable treatment is to be applied by predicting a symptom presentation risk before the presentation of symptoms. However, each time of the posttraumatic physical response information has a little effect size to predict the presentation of {PTSD} symptoms, and thus an approach to efficiently integrate and analyze the items of the posttraumatic physical response information is essential. {\textbar}   {\textbar} Accordingly, there is needed a method of verifying posttraumatic physical response information of a patient that may change before a development of {PTSD} after experiencing a traumatic event, and predicting a {PTSD}-related problem presentation probability in advance by integrally analyzing the posttraumatic physical response information. {\textbar}   {\textbar} {DISCLOSURE} {OF} {INVENTION} {\textbar}   {\textbar} Technical Goals {\textbar}   {\textbar} An aspect provides a method of predicting a behavior problem that may verify whether an individual is classified as a biological phenotype based on posttraumatic physical response information of the individual obtained within first three months after the individual is exposed to a traumatic event, extract a violent behavior risk group based on the classified biological phenotype, and predict a violent symptom presentation probability of the individual through the extracted violent behavior risk group. {\textbar}   {\textbar} Another aspect provides a method of predicting a behavior problem that may obtain posttraumatic physical response information of an individual within three months immediately after the individual is exposed to trauma, known as a prime time for preventive intervention in a development of posttraumatic stress disorder ({PTSD}), predict a violent behavior risk group with a high violent behavioral symptom presentation probability of the individual, and apply preventive intervention suitable for the predicted violent behavior risk group to the individual. {\textbar}   {\textbar} Technical Solutions {\textbar}   {\textbar} According to an aspect, there is provided a method of predicting a posttraumatic behavior problem, the method including classifying an individual based on a type of a traumatic event to which the individual is exposed, obtaining, from the individual, primary posttraumatic physical information of the individual within a predetermined period after the exposure to the traumatic event, determining a violent behavior risk group based on a biological phenotype of the individual by analyzing the primary posttraumatic physical information, obtaining secondary posttraumatic physical information of the individual to determine a specificity of the violent behavior risk group, and predicting a violent symptom presentation probability of the individual based on the primary posttraumatic physical information and the secondary posttraumatic physical information. {\textbar}   {\textbar} The type of the traumatic event may be classified as physical violence, sexual violence, accidents/disasters, or others based on a characteristic of the traumatic event. {\textbar}   {\textbar} The primary posttraumatic physical information may include a neurophysiological element related to autonomic nerve modulation, and a blood substance element related to oxidative stress, neuroregeneration and a hypothalamic-pituitary-adrenal axis ({HPA}) of the individual. {\textbar}   {\textbar} The determining may include classifying the individual as one of an emotional phenotype, a behavioral phenotype, and a cognitive phenotype by applying a cluster analysis based on the primary posttraumatic physical information, and determining a biological phenotype corresponding to the classified phenotype to be the violent behavior risk group of the individual. {\textbar}   {\textbar} The biological phenotype may have a characteristic of a biased phenotype of a predetermined symptom expressed by the individual for a short period of time or a long period of time as a mental maladjustment symptom after the individual is exposed to the traumatic event. {\textbar}   {\textbar} The obtaining of the secondary posttraumatic physical information may include obtaining, as the secondary posttraumatic physical information, neuroimaging information about a brain reward circuit related to a violent behavior in brain tissue. {\textbar}   {\textbar} The predicting may include predicting the violent symptom presentation probability of the individual in view of a correlation between elements based on the primary posttraumatic physical information and the secondary posttraumatic physical information. {\textbar}   {\textbar} According to another aspect, there is also provided an apparatus for predicting a posttraumatic behavior problem, the apparatus including a processor configured to classify an individual based on a type of a traumatic event to which the individual is exposed, obtain, from the individual, primary posttraumatic physical information of the individual within a predetermined period after the exposure to the traumatic event, determine a violent behavior risk group based on a biological phenotype of the individual by analyzing the primary posttraumatic physical information, obtain secondary posttraumatic physical information of the individual to determine a specificity of the violent behavior risk group, and predict a violent symptom presentation probability of the individual based on the primary posttraumatic physical information and the secondary posttraumatic physical information. {\textbar}   {\textbar} {BRIEF} {DESCRIPTION} {OF} {DRAWINGS} {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  illustrates an apparatus for predicting a posttraumatic violent behavior problem according to an embodiment. {\textbar} {FIGS}. 2 {\textbar}   {\textbar} a {\textbar}  through 2 {\textbar} c {\textbar} illustrate posttraumatic physical response information of an individual according to an embodiment. {\textbar} {FIG}. 3 {\textbar}   {\textbar}  illustrates an operation of predicting a presentation of a violent symptom according to an embodiment. {\textbar} {FIGS}. 4 {\textbar}   {\textbar} a {\textbar}  and 4 {\textbar} b {\textbar} are graphs illustrating characteristics of biological phenotypes according to an embodiment. {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a flowchart illustrating a method of predicting a posttraumatic behavior problem according to an embodiment. {\textbar} {FIG}. 6 {\textbar}   {\textbar}  is a block diagram illustrating an example of predicting a violent behavior problem of an individual according to an embodiment. {\textbar} {FIG}. 7 {\textbar}   {\textbar}  is a diagram of an apparatus for predicting posttraumatic violent behavior according to an embodiment. {\textbar} {BEST} {MODE} {FOR} {CARRYING} {OUT} {THE} {INVENTION} {\textbar}   {\textbar} Hereinafter, reference will now be made in detail to embodiments with reference to the accompanying drawings. {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  illustrates an apparatus for predicting a posttraumatic violent behavior problem according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , a posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may predict a violent symptom presentation probability based on neurophysiological phenomenon information, hematological change information, and neuroimaging information of an individual  {\textbar} 103 {\textbar}  exposed to a traumatic event  {\textbar} 102 {\textbar} . In detail, the traumatic event  {\textbar} 102 {\textbar}  is a distressing event that the individual  {\textbar} 103 {\textbar}  may experience in life, and includes various incidents such as traffic accidents, murder incidents, and natural disasters that impair general adaptability. A type of the traumatic event  {\textbar} 102 {\textbar}  may be classified as physical violence, sexual violence, accidents/disasters, or others based on a characteristic of an event or incident applied to the individual  {\textbar} 103 {\textbar} . The individual  {\textbar} 103 {\textbar}  may directly or indirectly experience the traumatic event  {\textbar} 102 {\textbar}  unwillingly, and present mental symptoms of a maladjustment response after experiencing the traumatic event  {\textbar} 102 {\textbar} . {\textbar} \{circle around (1)\} Physical violence is a traumatic event that applies physical damage to a body of an individual or brings a financial loss, and may correspond to direct physical violence. For example, physical violence may include bullying and gang assaults. {\textbar}   {\textbar} \{circle around (2)\} Sexual violence is a traumatic event in which an individual is sexually assaulted against will of the individual, and may correspond to all sexual acts and assaults by mental or psychological pressure. For example, sexual violence may include sexual harassment, indecent assaults, and rape. {\textbar}   {\textbar} \{circle around (3)\} Accidents/disasters are one-session traumatic events, and may correspond to man-made incidents that occur unexpectedly or abnormal natural phenomena. For example, accidents/disasters may include earthquake, typhoon, flood, drought, tsunami, fire, and epidemic of a disease. {\textbar}   {\textbar} \{circle around (4)\} Others may correspond to traumatic events that do not belong to physical violence, sexual violence, and accidents/disasters described above. For example, others may include death of a parent, spouse or child, and severe stress. {\textbar}   {\textbar} A neurophysiological phenomenon, a hematological change, and a neuroimaging change may be observed immediately or at a relatively early stage after the exposure to the traumatic event  {\textbar}   {\textbar} 102 {\textbar}  before posttraumatic stress disorder ({PTSD}) symptoms are presented. The {PTSD} symptoms may be presented within a short period of time, or may be hidden for a long time and presented in an unexpected situation based on a type of the traumatic event  {\textbar} 102 {\textbar} , an exposure count, interpersonal involvement, and a neurophysiological characteristic of an individual. {\textbar} In view of the foregoing, the posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may obtain posttraumatic physical response information of the individual  {\textbar} 103 {\textbar}  within three months immediately after the exposure to the traumatic event  {\textbar} 102 {\textbar} . In particular, preventive intervention in a violent behavior may be effective within three months after exposure to trauma. Thus, it is important to predict a violent behavior within three months after the exposure to trauma. That is, a period of three months after a development of {PTSD} is known as a prime time for preventive intervention in {PTSD} symptoms. Although the symptoms are not presented within three months immediately after the trauma, it is extremely important to predict a violent behavior risk group with a high violent behavior symptom presentation probability and apply suitable preventive intervention. {\textbar} The traumatic event  {\textbar}   {\textbar} 102 {\textbar}  may be a personal issue of the individual  {\textbar} 103 {\textbar}  exposed to the traumatic event  {\textbar} 102 {\textbar} , and also be a social issue. Thus, the posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may detect a physical change in the individual  {\textbar} 103 {\textbar}  within a short period of time after the individual  {\textbar} 103 {\textbar}  experiences the traumatic event  {\textbar} 102 {\textbar} . {\textbar} The posttraumatic physical response information may be obtained by being classified into primary posttraumatic physical information and secondary posttraumatic physical information to determine a specificity related to violence of an individual, a time, or a point in time at which information is obtained from the individual. For example, the primary posttraumatic physical information of the individual may be obtained within a predetermined period after exposure to a traumatic event. In addition, the secondary posttraumatic physical information of the individual may be obtained to determine a specificity of a violent behavior risk group of the individual classified based on the primary posttraumatic physical information. That is, as information (predictors) to be used to predict and determine a violent behavior of the individual in advance, the posttraumatic physical response information including the primary posttraumatic physical information and the secondary posttraumatic physical information may be obtained. {\textbar}   {\textbar} When obtaining the primary posttraumatic physical information, different types of physical response information may be obtained to determine a specific posttraumatic response presented for each type of the traumatic event that the individual experiences. A different event may be imprinted on a brain of the individual based on a type of the traumatic event that the individual experiences. Thus, a different posttraumatic response may be presented by the individual. That is, an individual having experienced a “traffic accident” and an individual having experienced the “Iraq War” may have similar direct/indirect experiences of death. However, the two individuals may present different posttraumatic responses due to different causes of the experiences of death, and thus different types of information may need to be obtained to determine the different posttraumatic responses. {\textbar}   {\textbar} Accordingly, a different type of posttraumatic physical response information to be used to predict a biological phenotype may be obtained based on a type of a traumatic event to which an individual is exposed, and thus a different prediction model may be applied based on the type of the traumatic event. {\textbar}   {\textbar} To determine {PTSD} symptoms presented by the individual  {\textbar}   {\textbar} 103 {\textbar}  more objectively, a neurophysiological element and a blood substance element may be obtained as the primary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may obtain information about elements that may physically change in response to a traumatic event after exposure to the traumatic event. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may determine a biological phenotype based on a characteristic of a biological phenotype group of the individual by applying a cluster analysis based on the primary posttraumatic physical information. In detail, specific posttraumatic physical response information may be obtained based on each type of the traumatic event. A behavioral trauma presentation level and a type of posttraumatic physical response information to be used to predict the same may be different based on the type of the traumatic event, and thus a posttraumatic behavior problem predicting apparatus corresponding to each type of the traumatic event may be established. The primary posttraumatic physical information corresponding to each type of the traumatic event may be collected and form a cluster or groups of information having a high index of correlation. Herein, three clusters may be defined and classified based on posttraumatic responses. Based on the cluster analysis, each individual may be classified as one of an emotional phenotype, a behavioral phenotype, and a cognitive phenotype. {\textbar} That is, the biological phenotype of the individual may be classified through the cluster analysis from the primary posttraumatic physical information based on the type of the traumatic event. In an example, a presentation of a posttraumatic symptom of the individual may be classified as the cognitive phenotype based on primary posttraumatic physical information of the individual experiencing physical violence. The presentation of the posttraumatic symptom of the individual may be classified as the emotional phenotype based on primary posttraumatic physical information of the individual experiencing accidents/disasters. Since a different biological phenotype is expressed based on the type of the traumatic event and how the individual accepts the traumatic event, a violent behavior risk group corresponding to the type of the traumatic event may be adaptively determined and classified based on a condition of each individual, rather than being preset. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may additionally obtain the secondary posttraumatic physical information including neuroimaging information specific to a violent behavior, after the primary posttraumatic physical information is obtained. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may utilize the primary posttraumatic physical information and the secondary posttraumatic physical information to predict a violent behavior. A nonlinear prediction equation to be used to predict a violent behavior may be established in advance through a sample group. {\textbar} That is, to establish the nonlinear prediction equation to be applied to the posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar} , a sample group may be formed based on each type of the traumatic event, and posttraumatic physical response information of individuals may be obtained. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may analyze an odds ratio to predict a violent behavior problem based on the posttraumatic physical response information, and extract factors with relatively high odds ratios from the posttraumatic physical response information. Then, the posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may secondarily extract factors with a lowest correlation therebetween from the extracted factors with the relatively high odds ratios. An operation of extracting factors with a lowest correlation may be a process of selecting a minimum number of factors by excluding factors having duplicate effects, in a nonlinear violent behavior prediction model. The secondarily extracted factors may be used to establish the nonlinear equation to predict a behavior problem for a sample group corresponding to the type of the traumatic event. In this example, a nonlinear equation exhibiting a highest prediction rate using a minimum number of factors may be selected. {\textbar} Here, the nonlinear violent behavior prediction model may be represented using a series of process of extracting a minimum number of specific posttraumatic response information through machine learning using or being trained by posttraumatic physical response information (predictors) and trauma group information (outcome or trauma characteristics) of a sample group selected in advance based on the type of the traumatic event, and establishing a nonlinear equation utilizing the extracted information to be used by the nonlinear violent behavior prediction model. {\textbar}   {\textbar} Through the above process, a nonlinear equation and factors of the posttraumatic physical response information finally selected from the sample group based on each type of the traumatic event may be selected finally. Based on the nonlinear equation and the factors of the posttraumatic physical response information, posttraumatic response information may be obtained by selecting factors of the posttraumatic physical response information within one month after exposure to trauma, and a behavior problem prediction rate may be extracted by applying the nonlinear equation. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may objectify a negative response of the individual to the traumatic event by complexly examining each element. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may classify the individual as one of the emotional phenotype, the behavioral phenotype, and the cognitive phenotype by applying the cluster analysis based on the primary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may determine a biological phenotype corresponding to the classified phenotype to be the violent behavior risk group of the individual. Here, the biological phenotype may have a characteristic of a biased phenotype of a predetermined symptom expressed by the individual for a short period of time or a long period of time as a mental maladjustment symptom after the individual is exposed to the traumatic event. In an example, the characteristic of the biological phenotype may indicate each posttraumatic symptom that may be presented by the individual, for example, depression, impulsivity, anger, alcohol use, attention, or emotion recognition. {\textbar} The posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may predict a violent symptom presentation probability, for individuals belonging to a risk group belonging to the violent behavior risk group, that is, one of the emotional phenotype, the behavioral phenotype, and the cognitive phenotype. That is, the posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may predict an individual with a high probability of presenting a behavior problem such as violence or self-harm after exposure to a traumatic event based on a biological phenotype of the individual. For example, the posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  may discover, at an early stage, a violent behavior risk group (behavioral type) with a high probability of presenting violence within one to three months after the exposure to the traumatic event. The violence presented after the exposure to the traumatic event may be determined based on a level of addiction (dependence) to alcohol and illegal drugs, a frequency of self-harm and suicide, a predetermined or higher frequency of impulsive behavior, a frequency of anger-out behavior, or a frequency of harming others and aggressive behavior. {\textbar} Here, the posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may determine the violent behavior risk group of the individual using indicators of a neurophysiological element, a blood substance element, and a neurological element (neuroimaging) as the posttraumatic physical response information indicating a physical change in the individual, thereby efficiently and accurately extracting a high violent behavior risk group with a high probability of presenting violence after trauma. {\textbar} Ultimately, the posttraumatic behavior problem predicting apparatus may predict a behavioral response to be presented by an individual in advance based on a principle of conditioning by exposure to a traumatic event, and provide criteria for receiving suitable treatment with respect to the behavioral response, thereby suggesting a basis for preventive prediction and intervention in posttraumatic violence. The behavioral response may refer to a symptom of more intensively presenting a behavior to reduce anxiety caused by severe pain and stress as an anxiety response to a conditioned stimulus is conditionally formed by stimulation of an individual by a traumatic event or a cue related to the traumatic event. {\textbar}   {\textbar} That is, the posttraumatic behavior problem predicting apparatus  {\textbar}   {\textbar} 101 {\textbar}  may predict violence of the individual  {\textbar} 103 {\textbar}  to be triggered by negative thoughts or emotions of the individual  {\textbar} 103 {\textbar}  exposed to the traumatic event  {\textbar} 102 {\textbar} , and suggest a basis for inducing treatment of the individual  {\textbar} 103 {\textbar}  to change the violence to an effective alternative behavior. {\textbar} {FIGS}. 2 {\textbar}   {\textbar} a {\textbar}  through 2 {\textbar} c {\textbar} illustrate posttraumatic physical response information of an individual according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIGS}. 2 {\textbar} a {\textbar}  through 2 {\textbar} c {\textbar} , a posttraumatic behavior problem predicting apparatus may obtain posttraumatic physical response information to predict a high violent behavior risk group with a high probability of presenting violence, for an individual exposed to a traumatic event. The posttraumatic behavior problem predicting apparatus may obtain the posttraumatic physical response information in three domains to determine a physical change in the individual in response to a mental symptom. {\textbar} The posttraumatic behavior problem predicting apparatus may obtain a neurophysiological element and a blood substance element to complexly examine elements that may be associated with a response to a traumatic event. In detail, the posttraumatic behavior problem predicting apparatus may determine a posttraumatic response to be presented specifically based on a type of the traumatic event from the neurophysiological element and the blood substance element. In detail, primary posttraumatic physical information may be obtained from all individuals exposed to traumatic events. In this example, all the individuals correspond to a group of individuals experiencing different traumatic events, and may present different posttraumatic responses based on types of the traumatic events. In an example, an individual experiencing a traumatic event of which a type is classified as physical violence may have a high concentration of a substance that represents an inflammation-immune system in the blood in response to an event of substantially applying physical harm. An individual experiencing a traumatic event of which a type is classified as sexual violence may have a high concentration of a substance that represents a female sex hormone. Ultimately, the posttraumatic behavior problem predicting apparatus may obtain a different type of primary posttraumatic physical information based on a type of a traumatic event in response to a posttraumatic response to be presented as a maladjustment symptom of an individual exposed to the traumatic event. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may obtain secondary posttraumatic physical information including neuroimaging information of the individual as a neurologic element. In this example, the neurophysiological element and the blood substance element that may be relatively easy to collect may be defined as primary basic posttraumatic physical information, and a neuroimaging element that may be relatively difficult to collect but have a relatively high specificity to predict a violent behavior may be defined as secondary intensive posttraumatic physical response information. {\textbar}   {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 2 {\textbar} a {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain the neurophysiological element as an element related to autonomic nerve modulation of the individual. In detail, the posttraumatic behavior problem predicting apparatus may obtain the neurophysiological element to determine a condition with respect to physical function modulation as a maladjustment symptom of the individual exposed to the traumatic event. The posttraumatic behavior problem predicting apparatus may measure, as the neurophysiological element, a heart rate, a heart rate variability ({HRV}), or a skin conductance ({SC}) of the individual. In particular, the heart rate and the {HRV} may be classified as the primary posttraumatic physical information, and the {SC} may be classified as one-session trauma group-specific information, whereby the primary posttraumatic physical information may be obtained based on a type of the traumatic event to which the individual is exposed. {\textbar} Here, the heart rate indicates the number of heartbeats that increases or decreases based on a condition of the individual, and the {HRV} may be indicated using a low-frequency ({LF})/high-frequency ({HF}) ratio measured from the individual. In addition, the {SC} may be indicated in proportion to a humidity of the skin based on a condition of the individual. In an example, in a case in which the individual feels anxiety in response to a traumatic event, the heart rate may sharply increase, the {HRV} may show an imbalance in sympathetic-parasympathetic nerves based on the {LF}/{HF} ratio, and the {SC} may increase. {\textbar}   {\textbar} Anxiety, denial, or threat which is a {PTSD} symptom to be presented by an individual in response to a traumatic event may cause a tension in a human body, which may lead to a physical disorder such as hyperventilation or hyperactivity. In particular, the heart is an internal organ that may first physically respond to hyperarousal of the body. Thus, the posttraumatic behavior problem predicting apparatus may measure the neurophysiological element that changes in response to an infiltration symptom, an avoidance symptom, a cognitive/emotional denial symptom, or an arousal/response symptom of the individual. {\textbar}   {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 2 {\textbar} b {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain the blood substance element flowing in blood vessels of the individual and to be used to determine a state of an oxidative nutrient. In detail, the posttraumatic behavior problem predicting apparatus may obtain the blood substance element to determine a symptom to be presented through the blood as a maladjustment symptom of the individual exposed to the traumatic event. The posttraumatic behavior problem predicting apparatus may collect a small amount of venous blood sample, and measure a concentration of a predetermined substance that reflects an immune function, oxidative stress, a neuroplasticity, or a hypothalamic-pituitary-adrenal ({HPA}) axis of the individual. {\textbar} Here, the immune function may indicate a distribution concentration of immune cells included in the blood, the oxidative stress may indicate a distribution concentration of a blood coagulation substance included in the blood, and the neuroplasticity may indicate a presence and absence of blood to be supplied while a neural pathway of the brain is changed and reorganized structurally and functionally by external stimulation, experience, and learning. An element related to the {HPA} axis may indicate a ratio of a stress hormone secreted and released in the blood by stress that the individual may experience in response to exposure to trauma. In particular, a concentration of a substance that represents an inflammation-immune system in the blood may be classified as posttraumatic physical response information specific to a physical violence trauma group, and information related to a concentration of a female hormone-related substance in the blood may be classified as posttraumatic physical response information specific to a sexual violence trauma group. {\textbar}   {\textbar} In an example, in a case in which the individual feels anxiety in response to a traumatic event, an activity of an immune system of the individual may decrease, a distribution concentration of immune cells may decrease, and a blood supply ratio in the body may decrease as a concentration of a blood coagulation substance increases (oxidative stress) and a stress hormone is released in the blood (the {HPA} axis) due to stress. {\textbar}   {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 2 {\textbar} c {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain the neuroimaging element to determine a structure of a brain region highly related to violence or fear response. In detail, the posttraumatic behavior problem predicting apparatus may obtain the neuroimaging element as a neurological element to measure a connectivity or an activity of the brain region in response to a traumatic event. The neuroimaging element may be a magnetic resonance imaging ({MRI}) image to be used to determine violence based on whether brain tissue is activated. The neuroimaging information may be relatively difficult to collect, and thus may be classified as the secondary posttraumatic physical information and utilized to predict a violent behavior. {\textbar} In general, the amygdala and the hippocampus of the human brain are known as storing or erasing memories of a situation that a person experiences. In this example, memories about anxiety and fear caused by a traumatic event may be imprinted on the brain through a fear circuit including the amygdala and the hippocampus. After experiencing the traumatic event, anxiety and fear may be triggered by the imprinted memories of the traumatic event in a situation in which the person does not feel fear due to functional or structural characteristics of the fear circuit and a brain structure connected thereto. {\textbar}   {\textbar} In particular, to predict a posttraumatic violent behavior symptom, a responsiveness to a traumatic stimulus and the volume of each of the nucleus accumbens and the prefrontal cortex belonging to a brain reward circuit may be significant. That is, the nucleus accumbens may increase a sensitivity with respect to a violent behavior by inducing an emotion or a behavior to enhance the brain reward circuit, and the prefrontal cortex may act as a control tower that modulates the operation of the nucleus accumbens to restrain a presentation of the violent behavior. {\textbar}   {\textbar} That is, it may be predicted that the brain reward circuit may be activated and a violent behavior may be presented as the volume of the nucleus accumbens increases, the responsiveness of the nucleus accumbens with respect to the traumatic stimulus increases, the volume of the prefrontal cortex decreases, and the responsiveness of the prefrontal cortex with respect to the traumatic stimulus decreases. {\textbar}   {\textbar} Thus, the posttraumatic behavior problem predicting apparatus may obtain the neuroimaging element to determine whether the fear circuit and the reward circuit in the brain are activated, and whether a brain-nervous system is activated in response to the activation of the fear circuit and the reward circuit, thereby determining the connectivity, the activity, and the brain structure in response to the exposure of the individual to trauma. {\textbar}   {\textbar} {FIG}. 3 {\textbar}   {\textbar}  illustrates an operation of predicting a presentation of a violent symptom according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 3 {\textbar} , a violent behavior problem predicting apparatus may analyze a neurophysiological element, a blood substance element, and a neuroimaging element as posttraumatic physical response information, and calculate a score for each element. Here, the score for each element may be calculated using a nonlinear equation between elements secondarily extracted from a sample group based on a type of a traumatic event, as described with reference to  {\textbar} {FIG}. 1 {\textbar} . Types of the extracted elements and the nonlinear equation may differ based on each type of the traumatic event. In view of the above, a posttraumatic behavior problem predicting apparatus may be individualized based on each type of the traumatic event, and a specific violent behavior problem predicting apparatus may be applied based on a type of the traumatic event to which an individual is exposed. That is, the posttraumatic behavior problem predicting apparatus may calculate the score for each element to determine a seriousness of a mental symptom of the individual exposed to the traumatic event based on each of the elements of the posttraumatic physical response information. {\textbar} In this example, each element may have a different range of value indicating an anxiety symptom or a stress symptom of the individual exposed to the traumatic event based on a characteristic of each element, and thus the score calculated for each element may be normalized from “−1” to “1”. The posttraumatic behavior problem predicting apparatus may determine a characteristic of a future biological phenotype of the individual based on the normalized score of each element of the posttraumatic physical response information. In particular, to distinguish behavioral trauma to predict a violent behavior, a determiner of the posttraumatic behavior problem predicting apparatus may classify the individual as one of an emotional phenotype, a behavioral phenotype, and a cognitive phenotype through a cluster analysis based on the primary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus may determine a problem behavior with a greatest value of a presentation index corresponding to a characteristic of the behavioral trauma to be a biological phenotype through the cluster analysis, thereby determining trauma of the individual. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may extract a violent behavior risk group corresponding to the biological phenotype, and finally predict a violent behavior presentation probability by integrating the violent behavior risk group and the secondary posttraumatic physical information. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may determine whether a future behavioral trauma group is generated immediately after exposure to trauma, using the nonlinear equation of the score of each element of the posttraumatic physical response information immediately after the exposure to trauma before a characteristic of the behavioral trauma group is presented. In an example, the posttraumatic behavior problem predicting apparatus may determine the characteristic of the biological phenotype which may be classified as future impulsivity, anger, attention, alcohol use, or the like based on the score of each of the neurophysiological element, the blood substance element, and the neurologic element. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may determine whether the biological phenotype is generated and a probability related thereto based on the characteristic of the biological phenotype to be generated in the future based on the posttraumatic physical response information obtained from the individual immediately after the exposure to trauma. In detail, the posttraumatic behavior problem predicting apparatus may analyze an odds ratio with which each element of the posttraumatic physical response information is classified as the biological phenotype. The posttraumatic behavior problem predicting apparatus may select a posttraumatic physical response factor with a high odds ratio for each biological phenotype. Characteristics of a behavioral trauma group to verify that a predicted cluster of the posttraumatic physical response factor is a cluster with a high probability of behavior problems are shown in  {\textbar}   {\textbar} {FIGS}. 4 {\textbar} a {\textbar} and  {\textbar} 4 {\textbar} b {\textbar} .  {\textbar} Therefore, the posttraumatic behavior problem predicting apparatus may assume that a posttraumatic physical response factor with a great rate of predicting a high violent behavior risk group and with a low correlation between factors has a great power of explanation, and repeatedly analyze a combination of these various factors, thereby extracting factors that maximize the rate of predicting a high violent behavior risk group. {\textbar}   {\textbar} In detail, a predictor of the posttraumatic behavior problem predicting apparatus may extract the factors based on information related to a sample group for each type of the traumatic event, in an order of a factor having a highest index of correlation, by obtaining an index of correlation between each posttraumatic physical response factor (neurophysiological-neuroimaging response information) and trauma characteristics (outcome). Here, the trauma characteristics are information to be used to determine a biological phenotype group to be predicted herein, and may be expressed in an ascending order of presentation index scores specific to each characteristic. {\textbar}   {\textbar} In addition, the posttraumatic behavior problem predicting apparatus may apply a weight to a method of obtaining a posttraumatic physical response factor by incorporating an index of easiness therein if information is relatively easy to obtain. In an example, an index of easiness for obtaining a factor measurable by taking a small amount of venous blood sample may be calculated to be higher than that of a factor obtainable through a relatively complex neuroimaging analysis. As described with reference to  {\textbar}   {\textbar} {FIGS}. 2 {\textbar} a {\textbar}  through 2 {\textbar} c {\textbar} , in a case in which factors have duplicate effects, the factors having duplicate effects may be excluded, and factors with a lowest correlation between factors and with a highest index of correlation with the trauma characteristics may be extracted to construct the nonlinear equation using a minimum number of factors. That is, the posttraumatic behavior problem predicting apparatus may primarily extract factors with high indices of correlation with the behavioral trauma and with high indices of easiness for obtaining information from the posttraumatic physical response factors. The posttraumatic behavior problem predicting apparatus may repeatedly analyze a combination with a lowest index of correlation between the primarily extracted factors, thereby finally selecting a nonlinear equation and a minimum number of posttraumatic physical response factors with a greatest predictability with respect to the behavioral trauma. The above process may be repeatedly performed based on each type of the traumatic event. {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a flowchart illustrating a method of predicting a posttraumatic behavior problem according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 5 {\textbar} , in operation  {\textbar} 501 {\textbar} , a posttraumatic behavior problem predicting apparatus may classify an individual based on a type of a traumatic event to which the individual is exposed. The posttraumatic behavior problem predicting apparatus may classify the individual based on the type of the traumatic event that may be classified as physical violence, sexual violence, accidents/disasters, or others based on a characteristic of the traumatic event. {\textbar} In operation  {\textbar}   {\textbar} 502 {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain primary posttraumatic physical information of the individual at an early stage within a predetermined period after the exposure the traumatic event. The posttraumatic behavior problem predicting apparatus may obtain a neurophysiological element and a blood substance element as the primary posttraumatic physical information of the individual. Here, the neurophysiological element may include biometric information related to autonomic nerve modulation of the individual. The blood substance element may include blood information related to oxidative stress, neuroregeneration and an {HPA} of the individual. {\textbar} That is, the posttraumatic behavior problem predicting apparatus may obtain posttraumatic physical response information to be presented as a physically abnormal phenomenon to determine a presentation of a mental symptom and a posttraumatic symptom type with respect to the individual exposed to the traumatic event. {\textbar}   {\textbar} In operation  {\textbar}   {\textbar} 503 {\textbar} , the posttraumatic behavior problem predicting apparatus may determine a violent behavior risk group based on a biological phenotype of the individual by analyzing the primary posttraumatic physical information of the individual. The posttraumatic behavior problem predicting apparatus may determine the biological phenotype based on a characteristic of the biological phenotype of the individual by applying a cluster analysis based on the posttraumatic physical response information. Here, the biological phenotype may have a characteristic of a biased phenotype of a predetermined symptom expressed by the individual for a short period of time or a long period of time as a mental maladjustment symptom after the individual is exposed to the traumatic event. That is, the characteristic of the biological phenotype may be used to verify a paraesthesia behavior presented by stress that the individual experiences. The posttraumatic behavior problem predicting apparatus may determine the biological phenotype of the individual through the paraesthesia behavior. {\textbar} For this, the posttraumatic behavior problem predicting apparatus may calculate a score for each of the neurophysiological element and the blood substance element by analyzing the neurophysiological element and the blood substance element. The posttraumatic behavior problem predicting apparatus may calculate the score for each element to determine a seriousness with respect to the mental symptom of the individual exposed to the traumatic event based on each of the elements of the posttraumatic physical response information. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may determine the characteristic of the biological phenotype of the individual based on the calculated score for each element. In an example, the posttraumatic behavior problem predicting apparatus may determine the characteristic of the biological phenotype which may be classified as impulsivity, anger, attention, alcohol use, or the like based on the score of each of the neurophysiological element, the blood substance element, and a neuroimaging element. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may classify the individual as one of an emotional phenotype, a behavioral phenotype, and a cognitive phenotype by applying a cluster analysis based on the primary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus may determine a biological phenotype corresponding to the classified phenotype to be a violent behavior risk group of the individual. {\textbar}   {\textbar} In operation  {\textbar}   {\textbar} 504 {\textbar} , the posttraumatic behavior problem predicting apparatus may obtain secondary posttraumatic physical information of the individual to determine a specificity of the violent behavior risk group. The posttraumatic behavior problem predicting apparatus may obtain, as the secondary posttraumatic physical information, neuroimaging information about a brain reward circuit related to a violent behavior in brain tissue. {\textbar} In operation  {\textbar}   {\textbar} 505 {\textbar} , the posttraumatic behavior problem predicting apparatus may predict a violent symptom presentation probability of the individual based on the primary posttraumatic physical information and the secondary posttraumatic physical information. The posttraumatic behavior problem predicting apparatus may predict the violent symptom presentation probability in view of a correlation between the elements of the posttraumatic physical response information with respect to the biological phenotype. Here, the posttraumatic behavior problem predicting apparatus may predict the violent symptom presentation probability based on the primary posttraumatic physical information and the secondary posttraumatic physical information by applying a nonlinear equation extracted from a sample group classified based on the type of the traumatic event. {\textbar} In an example, in a case of the classified type of the traumatic event to which the individual is exposed corresponds to 1) physical violence, 2) sexual violence, 3) accidents/disasters, or 4) others, the posttraumatic behavior problem predicting apparatus may predict the violent symptom presentation probability by applying a nonlinear equation extracted from 1) a physical violence sample group, 2) a sexual violence sample group, 3) a one-session trauma (accidents/disasters) sample group, or 4) other sample groups. {\textbar}   {\textbar} The posttraumatic behavior problem predicting apparatus may provide treatment criteria for a mental symptom of an individual predicted to have a high violent symptom presentation probability before a violent symptom is presented, thereby providing a basis for linking the individual to treatment before the mental symptom is aggravated. {\textbar}   {\textbar} Ultimately, different posttraumatic behavior problem predicting apparatuses corresponding to types of traumatic events to which a sample group is exposed may be utilized through machine learning of the sample group based on the types of the traumatic events. In addition, the posttraumatic behavior problem predicting apparatus may predict a characteristic of a posttraumatic violent behavior yet to be presented by the individual exposed to the traumatic event based on a posttraumatic physical response level collected immediately after the individual is exposed to the traumatic event. {\textbar}   {\textbar} {FIG}. 6 {\textbar}   {\textbar}  is a block diagram illustrating an example of predicting a violent behavior problem of an individual according to an embodiment. {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 6 {\textbar} , a type of a traumatic event to which an individual is exposed may be classified as (i) physical violence, (ii) sexual violence, (iii) accidents/disasters, or (iv) others. After the exposure to the traumatic event, primary posttraumatic physical information specific to a posttraumatic response may be obtained from the individual. The primary posttraumatic physical information obtained based on the type of the traumatic event may be collected, and the individual may be classified as one of a behavioral phenotype, an emotional phenotype, and a cognitive phenotype through a cluster analysis thereon, and a biological phenotype may be extracted. {\textbar} A violent behavior of the individual may be predicted based on the extracted biological phenotype. In detail, a neuroimaging indicator of a brain reward circuit specific to the violent behavior may be obtained as secondary posttraumatic physical information. Then, posttraumatic physical response information may be generated by matching the primary posttraumatic physical information and the secondary posttraumatic physical information. {\textbar}   {\textbar} A violent symptom presentation probability of the individual may be predicted by applying a nonlinear equation extracted from each traumatic event sample group based on the type of the traumatic event to the posttraumatic physical response information. {\textbar}   {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 7 {\textbar} , a diagram of an apparatus for predicting posttraumatic violent behavior is shown. The illustrated apparatus in  {\textbar} {FIG}. 7 {\textbar}  may be identical to the apparatus  {\textbar} 101 {\textbar}  illustrated in  {\textbar} {FIG}. 1 {\textbar} . The posttraumatic behavior problem predicting apparatus  {\textbar} 101 {\textbar}  includes at least one or more processors  {\textbar} 702 {\textbar} , memory  {\textbar} 704 {\textbar} , and one or more interfaces  {\textbar} 706 {\textbar} . The one or more processors  {\textbar} 702 {\textbar}  may be a processor suitable to at least execute stored programmable instructions, as described above, or may be a {CPU} or any other suitable processing circuitry. The memory  {\textbar} 704 {\textbar}  may store various types of data and/or information and executable instructions, also as described above, related to at least the prediction of posttraumatic violent behavior by an individual. Further, memory  {\textbar} 704 {\textbar}  may include data and/or information related to the nonlinear prediction model and cluster analysis described above. The interface(s)  {\textbar} 706 {\textbar}  may be configured to receive or obtain or facilitate the receiving or obtaining of at least posttraumatic physical response information (e.g., primary posttraumatic physical information  {\textbar} 710 {\textbar} , secondary posttraumatic physical information  {\textbar} 712 {\textbar} ) associated with an individual. Examples of interfaces  {\textbar} 706 {\textbar}  may include devices (e.g., devices for measuring heart-related data or metrics, devices for measuring blood and related data, brain scanning devices) for measuring such information and/or computer ports for receiving such information from external devices. {\textbar} The various technologies described in this specification can be implemented as digital electronic circuitry, computer hardware, firmware, software, or combinations of these. The technologies can be implemented as a computer program, that is, an information carrier, for example, a computer program typically embodied in the form of a machine-readable storage (computer-readable medium) or a radio wave signal, to process operation of a data processing device, for example, a programmable processor, a computer, or a plurality of computers, or to control the operation. The computer program can be recorded in any form of program languages including a compiled language and an interpreted language, and can be developed in any form including an independent program or a module, a component, a subroutine, or any other unit suitable for use in a computing environment. The computer program may be deployed to be processed by one computer or multiple computers in one site, or distributed across multiple sites and interconnected through a communication network. {\textbar}   {\textbar} Processors suitable for the execution of a computer program include, for example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. In general, a processor will receive instructions and data from a read-only memory ({ROM}), a random access memory ({RAM}), or both. Elements of a computer may include at least one processor for executing instructions and one or more memory devices for storing instructions and data. In general, a computer may include one or more mass storage devices, for storing data, for example, magnetic, magneto-optical disks, or optical disks, may receive data from them, may transmit data to them, or may be coupled to them to transceive data. Information carriers suitable for embodying computer program instructions and data include magnetic media, e.g., hard disks, floppy disks, and magnetic tapes, optical media, e.g., compact disk {ROMs} ({CD}-{ROMs}) and digital video disks ({DVDs}), magneto-optical media, e.g., floptical disks, semiconductor memory devices, e.g., {RAMs}, flash memories, erasable programmable {ROMs} ({EPROMs}), electrically erasable programmable {ROMs} ({EEPROMs}). The processors and the memories may be supplemented by or incorporated in special purpose logic circuitry. {\textbar}   {\textbar} Further, the computer-readable medium may be an arbitrarily available medium that may be accessed by a computer and may include a computer storage medium and a transmission medium. {\textbar}   {\textbar} While this specification includes details of a plurality of specific implementations, these should not be understood as limitations of any invention or the scope to be claimed, but should be understood as descriptions of features that can be peculiar to specific embodiments of the specific invention. Specific features described herein may be implemented by being combined in a single embodiment in the context of an individual embodiment. On the other hand, various features described in the context of a single embodiment may be implemented individually or in appropriate sub-combinations in a plurality of embodiments. While features may work in specific combinations and may be described as initially claimed so, at least one feature may be excluded from a claimed combination in some cases, and the claimed combination may be changed to a sub-combination or a modification of the sub-combination. {\textbar}   {\textbar} Similarly, although drawings illustrate operations in a particular order, this does not mean that these operations should be performed in the illustrated particular order or sequence or that all illustrated operations should be performed to obtain a desired result. In a particular case, multitasking and parallel processing may be advantageous. Separation of various system components in the above-described embodiments does not mean that such separation is required for all embodiments. In general, described program components and systems may be integrated in a single software product or may be packed in multiple software products. {\textbar}   {\textbar} Meanwhile, embodiments for exemplifying the technical spirit of the present invention have been described and shown above, but the present invention is not limited to shown and described configurations and effects. Those of ordinary skill in the art would appreciate that various changes and modifications of the present invention can be made without departing from the technical spirit. Therefore, it is to be understood that all suitable changes, modifications, and equivalents fall within the scope of the present invention.
Issue: {US}20210113144A1},
}

@patent{voss_etal20b,
	location = {{EP}},
	title = {Mobile and wearable video capture and feedback plat-forms for therapy of mental disorders},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	type = {patent},
	author = {Voss, Catalin and Haber, Nicholas Joseph and Wall, Dennis Paul and Kline, Aaron Scott and Winograd, Terry Allen},
	urldate = {2017-05-08},
	date = {2020-01-08},
	note = {Edition: G06K000900 {\textbar} G06Q005022 {\textbar} G06T000720 {\textbar} A61B000500 {\textbar} A61B00050205 {\textbar} A61B000511 {\textbar} A61B00051171 {\textbar} A61B000516 {\textbar} G16H002070 {\textbar} G16H003040 {\textbar} G16H004063 {\textbar} G16H005020 {\textbar} G16H005030 {CPC}  - A61B0005165 {\textbar} A61B00050002 {\textbar} A61B00050036 {\textbar} A61B00050205 {\textbar} A61B00051176 {\textbar} A61B0005163 {\textbar} A61B00054836 {\textbar} A61B00056803 {\textbar} A61B0005681 {\textbar} G06V0010255 {\textbar} G06V001040 {\textbar} G06V0010764 {\textbar} G06V0010945 {\textbar} G06V0040174 {\textbar} G16H002070 {\textbar} G16H003040 {\textbar} G16H004063 {\textbar} G16H005000 {\textbar} G16H005020 {\textbar} G16H005030 {\textbar} A61B00051114 {\textbar} A61B00051126 {\textbar} A61B00051128 {\textbar} A61B00057405 {\textbar} A61B0005742 {\textbar} A61B00057455 {EP}; {KR}; {US} {EP}
Issue: {EP}3452935A4},
}

@patent{jin-pyeong_lee19,
	location = {{KR}},
	title = {Method and apparatus for predicting persistent hemodynamic depression using artificial neural network},
	url = {https://www.derwentinnovation.com/tip-innovation/recordView.do?hideHighlightPanel=true&idType=uid/recordid&datasource=T3&databaseIds=PATENT&category=PAT&recordKeys=KR2009840B120190812&TYPE=RECORDVIEW&fromExternalLink=true&fromLocation=external&isDAJImageAllowed=false},
	abstract = {According to an embodiment of the present invention, a method for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent implantation ({CAS}) may be inputted as learning data of risk factor data and results thereof affecting the development of {PHD} after {CAS}. In order to predict the occurrence of {PHD} after the {CAS} of the target patient and to perform the learning in the {ANN} (Artificial Neural Network), the risk factor data of the patient is input to the learned {ANN} as test data, and the calculation is performed using the {ANN}. And determining whether {PHD} occurs in the target patient, wherein the risk factor data includes patient-specific clinical factors and radiological factors, and the clinical factors include information on gender and age. The radiological factor is characterized in that it includes information about the location of the lesion, the distance away from the branch of the lesion. {\textbar}   {\textbar} 본 발명의 실시 예에 따른 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 방법은 {CAS} 후 {PHD의} 발생에 영향을 미치는 위험인자 데이터 및 그에 대한 결과값을 학습 데이터로 입력받아 {ANN}(Artificial Neural Network)에서 학습을 수행하는 단계 및 대상 환자의 {CAS} 후 {PHD의} 발생 여부를 예측하기 위해, 학습된 {ANN에} 상기 환자의 위험인자 데이터를 테스트 데이터로 입력하고, 상기 {ANN을} 이용한 연산을 수행하여 대상 환자의 {PHD의} 발생 여부를 판단하는 단계를 포함하고, 상기 위험인자 데이터는 환자별 임상인자와 방사선학적 인자를 포함하여 구성되되, 상기 임상인자는 성별, 연령에 대한 정보를 포함하고, 상기 방사선학적 인자는 병변의 위치, 병변의 분기로부터 이격된 거리에 대한 정보를 포함하는 것을 특징으로 한다. 
본 발명의 실시 예에 따른 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 방법은 {CAS} 후 {PHD의} 발생에 영향을 미치는 위험인자 데이터 및 그에 대한 결과값을 학습 데이터로 입력받아 {ANN}(Artificial Neural Network)에서 학습을 수행하는 단계 및 대상 환자의 {CAS} 후 {PHD의} 발생 여부를 예측하기 위해, 학습된 {ANN에} 상기 환자의 위험인자 데이터를 테스트 데이터로 입력하고, 상기 {ANN을} 이용한 연산을 수행하여 대상 환자의 {PHD의} 발생 여부를 판단하는 단계를 포함하고, 상기 위험인자 데이터는 환자별 임상인자와 방사선학적 인자를 포함하여 구성되되, 상기 임상인자는 성별, 연령에 대한 정보를 포함하고, 상기 방사선학적 인자는 병변의 위치, 병변의 분기로부터 이격된 거리에 대한 정보를 포함하는 것을 특징으로 한다.
According to an embodiment of the present invention, a method for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent implantation ({CAS}) may be inputted as learning data of risk factor data and results thereof affecting the development of {PHD} after {CAS}. In order to predict the occurrence of {PHD} after the {CAS} of the target patient and to perform the learning in the {ANN} (Artificial Neural Network), the risk factor data of the patient is input to the learned {ANN} as test data, and the calculation is performed using the {ANN}. And determining whether {PHD} occurs in the target patient, wherein the risk factor data includes patient-specific clinical factors and radiological factors, and the clinical factors include information on gender and age. The radiological factor is characterized in that it includes information about the location of the lesion, the distance away from the branch of the lesion.},
	type = {patent},
	number = {{KR}2009840B1},
	author = {Jin-pyeong, Jeon and Lee, Jay June},
	urldate = {2018-03-19},
	date = {2019-08-12},
	note = {Edition: G16H005030 {\textbar} A61B003410 {\textbar} G16H005020 {CPC}  - G16H005030 {\textbar} A61B003410 {\textbar} G16H001060 {\textbar} G16H005020 {\textbar} G16H005050 {\textbar} A61B2034101 {KR} {KR} 1. 전자 장치에 의해 수행되는 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 방법에 있어서, 상기 전자 장치의 제어부가, {CAS} 후 {PHD의} 발생에 영향을 미치는 위험인자 데이터 및 그에 대한 결과값을 학습 데이터로 입력받아 {ANN}(Artificial Neural Network)에서 학습을 수행하는 단계; 및 상기 제어부가, 대상 환자의 {CAS} 후 {PHD의} 발생 여부를 예측하기 위해, 학습된 {ANN에} 상기 환자의 위험인자 데이터를 테스트 데이터로 입력하고, 상기 {ANN을} 이용한 연산을 수행하여 대상 환자의 {PHD의} 발생 여부를 판단하는 단계;를 포함하고, 상기 위험인자 데이터는 환자별 임상인자와 방사선학적 인자를 포함하여 구성되되, 상기 임상인자는 성별, 연령에 대한 정보를 포함하고, 상기 방사선학적 인자는 병변의 위치, 병변의 분기로부터 이격된 거리에 대한 정보를 포함하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 방법. {\textbar} 2. 제 1항에 있어서, 상기 {ANN은} 입력 레이어, 단일 히든 레이어, 출력 레이어를 포함하여 구성되되, 연산 동작 시, 상기 입력 레이어의 각 노드에는 위험인자에 대한 데이터가 입력되며, 상기 단일 히든 레이어에 {ReLU} 활성화 함수가 적용되는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 방법. {\textbar} 3. 제 1항에 있어서, 상기 학습을 수행하는 단계는 상기 제어부가, 상기 학습 데이터가 입력되면 {ANN를} 이용하여 연산한 결과로 생성된 예상값과 학습 데이터로 입력된 결과값의 오차를 감소시키기 위해 역전파 학습 알고리즘을 적용하여 가중치 계수를 수정하는 단계; 및 상기 제어부가, 상기 가중치 계수를 수정하기 위해 기 설정된 분량의 학습을 완료함에 따라 최후 수정된 가중치 계수를 고정하는 단계;를 포함하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 방법. {\textbar} 4. 제 1항에 있어서, 상기 {ANN의} 학습률은 0.1로 설정되고, 가중치 매개변수 최적화 알고리즘으로는 Adam을 적용하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 방법. {\textbar} 5. 제 1항에 있어서, 상기 위험인자 데이터는 성별, 징후의 여부, 협착의 정도가 70\%이상인지 여부, 석회화, 궤양, 편심 여부, 확장성, 대측성, 국소 마취 여부, 시술시 풍선 팽창 유지 시간이 5초 이상인지 여부, 시술 시 풍선 팽창 압력이 8기압 이상인지 여부, 고혈압 여부, 관상 동맥 질병 및 협착 병변의 위치가 분기로부터 10mm 이내의 거리에 존재하는지 여부를 포함하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 방법. {\textbar} 6. 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 전자장치에 있어서, 입력 레이어, 단일 히든 레이어, 출력 레이어를 포함하여 구성되고, 상기 입력 레이어의 각 노드에 위험인자에 대한 데이터를 입력함에 따라 출력 레이어에서 {PHD의} 발생 여부에 대한 예측값을 산출하도록 {ANN을} 동작하는 제어부; 상기 {ANN의} 학습 및 테스트 동작에 요구되는 가중치 계수, 활성화 함수, 학습률 및 상기 {ANN에} 투입되는 정보인 환자별 위험인자 데이터를 저장하는 저장부;를 포함하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 전자장치. {\textbar} 7. 제 6항에 있어서, 상기 제어부는 학습 데이터를 입력받아 가중치 계수를 수정하는 학습 과정과, 학습 과정이 완료된 후, 입력되는 테스트 데이터를 처리하여 {PHD에} 대한 예측값을 산출하는 테스트 과정을 수행하는 {ANN}; 및 데이터 투입부;를 포함하고, 상기 데이터 투입부는 상기 {ANN이} 학습 과정을 수행하는 경우 환자의 위험인자 데이터 및 해당 환자의 실제 {PHD} 결과값을 포함하는 학습 데이터를 투입하도록 제어하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 전자장치. {\textbar} 8. 제 6항에 있어서, 상기 제어부는 환자 데이터 판독부를 포함하고, 상기 환자 데이터 판독부는 환자의 위험인자 데이터가 {ANN에} 의한 {PHD} 예측을 위해 입력 레이어의 노드에 입력되어야하는 데이터의 최소 항목을 만족하는지 여부를 판단하고, 만족하지 않는 것으로 판단되면 추가 정보를 입력하도록 요청하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 전자장치. {\textbar} 9. 제 6항에 있어서, 상기 제어부는 정확도 산출부를 포함하고, 상기 정확도 산출부는 상기 {ANN의} 출력 레이어의 False노드와 True노드에 입력되는 값을 수신하여 비교하되, 환자별 False 값과 True 값의 차이를 산출하여 {PHD의} 발생 확률을 판단하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 전자장치. {\textbar} 10. 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 전자장치에 있어서, {CAS} 후 {PHD의} 발생에 영향을 미치는 위험인자 데이터 및 그에 대한 결과값을 학습 데이터로 입력받아 학습을 수행하며, 대상 환자의 {CAS} 후 {PHD의} 발생 여부를 예측하기 위해, 상기 환자의 위험인자 데이터를 테스트 데이터로 입력받은 후 연산을 수행하여 대상 환자의 {PHD의} 발생 여부를 판단하는 {ANN을} 구비하는 제어부;를 포함하고, 상기 위험인자 데이터는 환자별 임상인자와 방사선학적 인자를 포함하여 구성되되, 상기 임상인자는 성별, 연령에 대한 정보를 포함하고, 상기 방사선학적 인자는 병변의 위치, 병변의 분기로부터 이격된 거리에 대한 정보를 포함하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 전자장치. {\textbar} 11. 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 전자장치에 있어서, {CAS} 후 {PHD의} 발생에 영향을 미치는 위험인자 데이터 및 그에 대한 결과값을 학습 데이터로 입력받아 학습을 수행하며, 대상 환자의 {CAS} 후 {PHD의} 발생 여부를 예측하기 위해, 상기 환자의 위험인자 데이터를 테스트 데이터로 입력받은 후 연산을 수행하여 대상 환자의 {PHD의} 발생 여부를 판단하는 {ANN을} 구비하는 제어부;를 포함하고, 상기 위험인자 데이터는 성별, 징후의 여부, 협착의 정도가 70\%이상인지 여부, 석회화, 궤양, 편심 여부, 확장성, 대측성, 국소 마취 여부, 시술시 풍선 팽창 유지 시간이 5초 이상인지 여부, 시술 시 풍선 팽창 압력이 8기압 이상인지 여부, 고혈압 여부, 관상 동맥 질병 및 협착 병변의 위치가 분기로부터 10mm 이내의 거리에 존재하는지 여부를 포함하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 전자장치. 1. In the method for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent implantation ({CAS}) performed by an electronic device, the control unit of the electronic device, and the risk factor data affecting the generation of {PHD} after {CAS} Receiving the result of the training as learning data and performing learning in {ANN} (Artificial Neural Network); And the control unit inputs risk factor data of the patient as a test data to the learned {ANN} to predict whether the {PHD} occurs after the target patient, and performs calculation using the {ANN} to generate the {PHD} of the target patient. And determining whether the risk factor data includes patient-specific clinical factors and radiological factors, wherein the clinical factors include information on sex and age, and the radiological factors include A method for predicting persistent hemodynamic abnormality ({PHD}) comprising information on location, distance away from the branch of the lesion. {\textbar} 2. The {ANN} of claim 1, wherein the {ANN} comprises an input layer, a single hidden layer, and an output layer. In operation, data about a risk factor is input to each node of the input layer, and a {ReLU} is input to the single hidden layer. A method for predicting persistent hemodynamic abnormalities ({PHD}), characterized in that an activation function is applied. {\textbar} 3. The method of claim 1, wherein the performing of the learning is performed by the controller in order to reduce an error between an expected value generated as a result of calculating using {ANN} when the learning data is input and a result value input as the learning data. Modifying the weighting coefficient by applying a propagation learning algorithm; And fixing, by the control unit, the last modified weight coefficient according to the completion of a predetermined amount of learning to correct the weight coefficient. {\textbar} 4. The method of claim 1, wherein the learning rate of the {ANN} is set to 0.1, and Adam is applied as a weight parameter optimization algorithm. {\textbar} 5. The method of claim 1, wherein the risk factor data includes sex, signs, stenosis of 70\% or more, calcification, ulceration, eccentricity, swellability, contralaterality, local anesthesia, and balloon inflation maintenance time. Continuous blood flow, characterized in that it is at least 5 seconds, whether the balloon inflation pressure is at least 8 atm during the procedure, whether hypertension is present, and whether the location of coronary artery disease and stenosis is within 10 mm of a branch. How to predict mechanical abnormalities ({PHD}). {\textbar} 6. An electronic device for predicting persistent hemodynamic abnormality ({PHD}) that occurs after carotid artery stent implantation ({CAS}), comprising an input layer, a single hidden layer, and an output layer, wherein each node of the input layer A controller configured to operate the {ANN} to calculate a predicted value of whether {PHD} occurs in an output layer as data is input; Persistent hemodynamic abnormalities ({PHD}), comprising: a storage unit storing weight factor, activation function, learning rate, and patient-specific risk factor data which are input to the {ANN}. Electronic device for predicting. {\textbar} 7. The apparatus of claim 6, wherein the control unit comprises: an {ANN} for receiving a training data and modifying a weighting coefficient, and a test procedure for calculating a predicted value for the {PHD} by processing the input test data after the learning process is completed; And a data input unit, wherein the data input unit controls to input learning data including risk factor data of a patient and actual {PHD} result values ​​of the patient when the {ANN} performs a learning process. Electronic device for predicting hemodynamic abnormalities ({PHD}). {\textbar} 8. The apparatus of claim 6, wherein the control unit comprises a patient data reader, wherein the patient data reader is satisfied whether the risk factor data of the patient satisfies a minimum item of data to be input to a node of an input layer for {PHD} prediction by the {ANN}. The electronic device for predicting persistent hemodynamic abnormality ({PHD}), characterized in that for determining, and requesting input of additional information if it is determined that the content is not satisfied. {\textbar} 9. The method of claim 6, wherein the control unit comprises an accuracy calculator, and the accuracy calculator receives and compares a value input to a False node and a True node of the {ANN} output layer, and compares a difference between a False value and a True value for each patient. Electronic device for predicting persistent hemodynamic abnormalities ({PHD}), characterized in that by calculating the probability of occurrence of {PHD} by calculating. {\textbar} 10. In an electronic device for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent implantation ({CAS}), learning is performed by receiving risk factor data and its result value as learning data that affect the occurrence of {PHD} after {CAS}. And a control unit having an {ANN} for determining whether {PHD} of the target patient is generated by performing calculation after receiving the risk factor data of the patient as test data to predict whether {PHD} occurs after the {CAS} of the target patient. Wherein the risk factor data comprises patient-specific clinical factors and radiological factors, wherein the clinical factors include information on gender and age, wherein the radiological factors are spaced from the location of the lesion and the branch of the lesion. Electronic device for predicting persistent hemodynamic abnormality ({PHD}), characterized in that it comprises information about the distance. {\textbar} 11. In an electronic device for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent implantation ({CAS}), learning is performed by receiving risk factor data and its result value as learning data that affect the occurrence of {PHD} after {CAS}. And a control unit having an {ANN} for determining whether {PHD} of the target patient is generated by performing calculation after receiving the risk factor data of the patient as test data to predict whether {PHD} occurs after the {CAS} of the target patient. The risk factor data includes sex, presence of signs, degree of stenosis of 70\% or more, calcification, ulceration, eccentricity, extensibility, contralaterality, local anesthesia, and balloon swelling duration of 5 seconds during the procedure. Abnormalities, balloon inflation pressure above 8 atm, hypertension, coronary artery disease and stenosis location within 10 mm from the branch. Electronic devices for predicting continuous hemodynamic abnormality ({PHD}) comprises whether. 1. 전자 장치에 의해 수행되는 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 방법에 있어서, 상기 전자 장치의 제어부가, {CAS} 후 {PHD의} 발생에 영향을 미치는 위험인자 데이터 및 그에 대한 결과값을 학습 데이터로 입력받아 {ANN}(Artificial Neural Network)에서 학습을 수행하는 단계; 및 상기 제어부가, 대상 환자의 {CAS} 후 {PHD의} 발생 여부를 예측하기 위해, 학습된 {ANN에} 상기 환자의 위험인자 데이터를 테스트 데이터로 입력하고, 상기 {ANN을} 이용한 연산을 수행하여 대상 환자의 {PHD의} 발생 여부를 판단하는 단계;를 포함하고, 상기 위험인자 데이터는 환자별 임상인자와 방사선학적 인자를 포함하여 구성되되, 상기 임상인자는 성별, 연령에 대한 정보를 포함하고, 상기 방사선학적 인자는 병변의 위치, 병변의 분기로부터 이격된 거리에 대한 정보를 포함하는 것을 특징으로 하는 지속적인 혈류역학적 이상({PHD})를 예측하는 방법. 1. In the method for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent implantation ({CAS}) performed by an electronic device, the control unit of the electronic device, and the risk factor data affecting the generation of {PHD} after {CAS} Receiving the result of the training as learning data and performing learning in {ANN} (Artificial Neural Network); And the control unit inputs risk factor data of the patient as a test data to the learned {ANN} to predict whether the {PHD} occurs after the target patient, and performs calculation using the {ANN} to generate the {PHD} of the target patient. And determining whether the risk factor data includes patient-specific clinical factors and radiological factors, wherein the clinical factors include information on sex and age, and the radiological factors include A method for predicting persistent hemodynamic abnormality ({PHD}) comprising information on location, distance away from the branch of the lesion. 인공신경망({ANN})을 이용하여 지속적 혈류역학적 이상({PHD})를 예측하는 방법 및 장치\{Method and apparatus for predicting persistent hemodynamic depression using artificial neural network\} {\textbar}   {\textbar} 본 발명의 실시 예는 인공신경망({ANN})을 이용하여, 경동맥 스텐트 삽입술({CAS}) 후 지속적인 혈류역학적 이상({PHD})이 발생되는지 여부를 예측하기 위한 방법 및 장치에 관한 것이다.  {\textbar}   {\textbar} 1990년대 후반부터 경동맥 혈관 형성술과 스텐트 삽입술({CAS};carotid artery angioplasty and stenting)은 증후성 또는 무증상 내경동맥 협착 환자에게 빠르게 임상 적용이 이루어져왔다. 이러한 경동맥 혈관 형성술 및 스텐트 삽입술({CAS})은 내막절제술과 비교하면 덜 침습적인 방법이며 내막절제술의 고위험군에서 비교적 안전하게 적용할 수 있다는 점에서 긍정적인 평가를 받고 있다.  {\textbar}   {\textbar} 그러나 {CAS의} 일부 경우에 합병증을 일으킬 수 있는 요인이 존재하며, 특히 경동맥 스텐트를 시술하는 과정에서 혈류역학적 이상이 발생할 수 있어 주의가 요망되는 바이다. 가장 많이 발생되는 증상은 저혈압이며, 이외에도 서맥, 무맥, 실신 등이 발생할 수 있다. 이러한 부작용은 경동맥 스텐트 삽입이 이루어짐에 따라, 동맥의 인위적인 확장과 스텐트에 의한 차폐현상으로 인하여 압수용체의 기능 장애가 발생하면서 일어날 수 있다.  {\textbar}   {\textbar} 임상적 상황에서 일시적인 혈류역학적 이상은 즉각적인 심박 조율이나 의학적 보존적 치료로 인해 합병증 없이 회복될 수 있다. 그러나 지속적인 혈류역학적 이상({PHD};Persistent hemodynamic depression)은 급성 허혈증 뇌졸중, 출혈성 뇌졸중, 심근 경색 및 신장 기능 장애를 야기할 수 있어 주의를 요한다. 따라서 {CAS} 후에 혈류역학적 이상이 발생할 위험이 높은 환자에게는 {CAS} 시술 전 또는 후에 별도의 혈류역학적 안정화를 위한 대책이 요구된다.  {\textbar}   {\textbar} 한편, 종래에 위험 요인을 정의하기 위한 대부분의 연구는 로지스틱 회귀 모델을 사용하여 수행되었다. 최근에 기계 학습 방법이 다중 회귀(multiple logistic regression, {MLR})모델의 대안으로 다양한 의료 분야에서 연구의 진단 정확성을 향상시키는 데 점점 더 많이 사용되고 있다.  {\textbar}   {\textbar} 가장 일반적으로 사용되는 기계 학습 알고리즘 중 두 가지는 인공 신경 네트워크 ({ANN})와 지원 벡터 머신 ({SVM})이다. {ANN은} 입력 레이어, 히든 레이어 및 출력 레이어와 같이 상호 연결된 세 계층으로 구성된다. {ANN} 의 정보 처리 과정은 (i) 감독 및 감독되지 않은 학습 방법을 사용하는 역전파 단계와 (ii) 실제 결과와 계산 된 오류를 비교하는 테스트 단계의 두 단계로 구성된다. 즉, {ANN은} 오류를 근거로 자체교정 또는 학습 능력을 갖는다는 점에서 기존의 다른 분석법과 차이가 있다.  {\textbar}   {\textbar} 이에 따라 {ANN은} 미래 특정 상황이 발생할 확률을 예측하거나 고객이 취할 특정한 값 추정에 적합하며, 질적 변수와 양적 변수에 관계없이 모두 분석이 가능한 점, 입력 변수들 간 비선형 조합이 가능하여 예측력이 우수하다는 장점이 있다.  {\textbar}   {\textbar} 그러나 종래에는 {CAS} 이후 혈류역학적 이상에 대한 종합적인 분석을 위해 {ANN을} 이용한 방법이 존재하지 않았고, 그에 따라 {CAS} 후 발생 가능한 합병증 예측하는 데 있어 정확성이 떨어지는 문제가 있었다.  {\textbar}   {\textbar} 한편, 혈류역학적 이상 여부를 판단하는 것과 관련된 선행특허로는 공개특허공보 10-2017-0090286(유체-구조 상호작용을 고려한 협착 병변 영역의 혈류역학 시뮬레이션 방법)호가 있다. {\textbar}   {\textbar} 본 발명은 기존의 분석 방식인 {MLR} 및 {SVM} 이 아닌 {ANN을} 이용하여 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})에 대하여 보다 높은 정확도로 예측하려는 목적이 있다.  {\textbar}   {\textbar} 본 발명의 실시 예에 따른 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 방법은 {CAS} 후 {PHD의} 발생에 영향을 미치는 위험인자 데이터 및 그에 대한 결과값을 학습 데이터로 입력받아 {ANN}(Artificial Neural Network)에서 학습을 수행하는 단계 및 대상 환자의 {CAS} 후 {PHD의} 발생 여부를 예측하기 위해, 학습된 {ANN에} 상기 환자의 위험인자 데이터를 테스트 데이터로 입력하고, 상기 {ANN을} 이용한 연산을 수행하여 대상 환자의 {PHD의} 발생 여부를 판단하는 단계를 포함하고, 상기 위험인자 데이터는 환자별 임상인자와 방사선학적 인자를 포함하여 구성되되, 상기 임상인자는 성별, 연령에 대한 정보를 포함하고, 상기 방사선학적 인자는 병변의 위치, 병변의 분기로부터 이격된 거리, 병변의 석회화 동반여부 등에 대한 정보를 포함하는 것을 특징으로 할 수 있다.  {\textbar}   {\textbar} 본 발명의 실시 예에 따른 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 전자장치는 입력 레이어, 단일 히든 레이어, 출력 레이어를 포함하여 구성되고, 상기 입력 레이어의 각 노드에 위험인자에 대한 데이터를 입력함에 따라 출력 레이어에서 {PHD의} 발생 여부에 대한 예측값을 산출하도록 {ANN을} 동작하는 제어부, 상기 {ANN의} 학습 및 테스트 동작에 요구되는 가중치 계수, 활성화 함수, 학습률 및 상기 {ANN에} 투입되는 정보인 환자별 위험인자 데이터를 저장하는 저장부를 포함할 수 있다.  {\textbar}   {\textbar} 본 발명의 실시 예에 따른 경동맥 스텐트 삽입술({CAS}) 후 발생하는 지속적인 혈류역학적 이상({PHD})을 예측하는 전자장치는 {CAS} 후 {PHD의} 발생에 영향을 미치는 위험인자 데이터 및 그에 대한 결과값을 학습 데이터로 입력받아 학습을 수행하며, 대상 환자의 {CAS} 후 {PHD의} 발생 여부를 예측하기 위해, 상기 환자의 위험인자 데이터를 테스트 데이터로 입력받은 후 연산을 수행하여 대상 환자의 {PHD의} 발생 여부를 판단하는 {ANN을} 구비하는 제어부를 포함하고, 상기 위험인자 데이터는 환자별 임상인자와 방사선학적 인자를 포함하여 구성되되, 상기 임상인자는 성별, 연령에 대한 정보를 포함하고, 상기 방사선학적 인자는 병변의 위치, 병변의 분기로부터 이격된 거리에 대한 정보를 포함할 수 있다.  {\textbar}   {\textbar} 본 발명의 실시 예에 따른 {ANN을} 이용한 {PHD} 예측 방법은 기존의 분석 방식인 {MLR} 또는 {SVM} 방식에 비해 보다 높은 정확도를 나타낼 수 있다.  {\textbar}   {\textbar} 또한, 본 발명의 실시 예는 역전파 알고리즘을 이용한 학습을 통해 가중치 계수를 산출할 수 있으므로, 위험인자와 실제 {PHD} 발명 여부에 대한 자료만 가지고도 추후 {CAS} 시술 전 환자의 {PHD를} 예측할 수 있게 하는 {ANN모델을} 생성할 수 있다.  {\textbar}   {\textbar} 또한 본 발명의 실시 예는 {PHD} 발병 여부를 예측할 뿐 아니라, 발병 확률을 산출할 수 있다.  {\textbar}   {\textbar} 도 1은 본 발명의 실시 예에 따른 {ANN이} 수행하는 동작에 대한 설명을 위해 도시한 도면이다. 도 2는 본 발명의 실시 예에 따른 {ANN의} 신호 절차를 설명하기 위한 도면이다. 도 3은 본 발명의 실시 예에 따른 {PHD} 발생 예측을 위한 {ANN의} 구성을 도시한 도면이다. 도 4a는 본 발명의 실시 예에 따른 트레이닝 코호트와 테스트 코호트의 비교표를 도시한 도면이다. 도 4b는 본 발명의 실시 예에 따른 테스트 코호트를 {ANN에} 투입하여 얻은 예측 결과값을 표로 나타낸 도면이다. 도 5는 본 발명의 실시 예에 따른 {ANN을} 이용한 {PHD} 예측의 정확성에 대하여 그래프로 도시한 도면이다. 도 6은 본 발명의 실시 예에 따른 {ANN의} 학습 과정을 도시한 순서도이다. 도 7은 본 발명의 실시 예에 따른 {ANN를} 통한 {PHD} 예측 동작의 순서를 도시한 순서도이다. 도 8은 본 발명의 다양한 실시 예에 따른 {ANN을} 이용하여 {PHD의} 발생을 예측하는 전자장치의 구성을 도시한 블록도이다.  {\textbar}   {\textbar} 본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. {\textbar}   {\textbar} 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용하였다.  {\textbar}   {\textbar} 어떤 구성요소가 다른 구성요소에 '연결되어' 있다거나 '접속되어'있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 '직접 연결되어'있다거나 '직접 접속되어'있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. {\textbar}   {\textbar} 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, '포함하다' 또는 '가지다' 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. {\textbar}   {\textbar} 또한, 본 명세서에서, 디바이스는 게이트웨이(gateway)에 연결되어 {IoT}(Internet of Things)에 적용되는 일반적인 장치(또는 사물)일 수 있다. 예를 들어, 디바이스는, 무선 호출기, 스마트폰, 태블릿 {PC}, 컴퓨터, 온도 센서, 습도 센서, 음향 센서, 모션 센서, 근접 센서, 가스 감지 센서, 열 감지 센서, 냉장고, {CCTV}, {TV}, 세탁기, 제습기, 전등, 화재 경보기 등을 포함할 수 있다. 그러나, 이에 제한되지 않는다. {\textbar}   {\textbar} 또한, 본 명세서에서 디바이스(device)는 '기기' 또는 '장치'와 혼용될 수 있으며, '디바이스', '기기' 및 '장치'는 동일한 표현으로 기재되어 있을 수 있다. {\textbar}   {\textbar} 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 이하, 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다.  {\textbar}   {\textbar} 도 1은 본 발명의 실시 예에 따른 {ANN이} 수행하는 동작에 대한 설명을 위해 도시한 도면이다.  {\textbar}   {\textbar} 도 1을 참조하면, 본 발명의 실시 예에 따른 {ANN}(Artificial Neural Network; 인공신경망) 100이 도시되고 있다. 상기 {ANN은} 사람의 두뇌와 비슷한 방식으로 정보를 처리하기 위한 알고리즘을 의미하며, 3계층 레이어인 입력(input) 레이어, 히든(hidden)레이어, 출력(output) 레이어로 구성될 수 있다. 이 때 다양한 실시 예에 따라 상기 히든 레이어는 다수개 설정될 수도 있다. 상기 히든 레이어를 적어도 하나 이상 포함하는 신경망은 다층 신경망으로 정의될 수 있다.  {\textbar}   {\textbar} 또한 {ANN} 100은 연결의 가중치를 갱신하는 학습 과정이 요구된다. 초기의 가중치는 랜덤으로 설정되어 있을 수 있다. 이 때 {ANN} 100을 학습시키기 위해 입력되는 정보는 학습데이터 110이고, 상기 학습 데이터 110이 {ANN} 100 이 구성하는 알고리즘에 투입되어 상기 {ANN} 100이 학습될 수 있다. 학습이 완료되면, 입력 데이터 120가 {ANN} 100에 투입되어 정보처리 동작을 수행한 후 해당 결과를 도출할 수 있게 된다. 본 발명의 실시 예에 따라 {ANN} 100이 투입된 데이터 처리 결과로 산출하는 것은 {PHD}(Persistent hemodynamic depression; 지속적 혈류역학적 이상)의 발생 유무(Yes or No)에 대한 정보일 수 있다. 다양한 실시 예에 따라, 상기 {ANN} 100의 정보처리 과정을 거쳐 도출되는 정보는 {PHD의} 발생 확률에 대한 정보일 수 있다.  {\textbar}   {\textbar} {ANN} 100이 수행하는 학습 및 정보 처리 과정에 대한 설명을 위해 도 2를 참조하도록 한다.  {\textbar}   {\textbar} 도 2는 본 발명의 실시 예에 따른 {ANN의} 신호 절차를 설명하기 위한 도면이다.  {\textbar}   {\textbar} 도 2에서 도시되는 바와 같이 {ANN은} 노드들의 그룹으로 연결되어 있으며, 이는 사람의 뇌에 존재하는 뉴런의 네트워크와 유사하다. 도 2의 각 원모양의 노드는 인공 뉴런을 나타내고 있으며, 화살표는 하나의 뉴런에서 출력되어 다른 하나의 뉴런으로의 입력을 나타내고 있다. 그리고 입력된 데이터는 항목별로 각각 입력 레이어의 I(0), I(1) 노드를 통해 투입될 수 있다.  {\textbar}   {\textbar} 도 2를 참조하면, 입력 값과 가중치 계수의 내적에 바이아스(b) 값을 더한 것을 가중합(즉, net=I0*W0+I1*W1+...In*Wn+b)이라고 하는데, 이 가중합을 활성함수를 통해 가공하면 그 가공된 값이 {ANN의} 출력값이 된다. 활성함수는 어떠한 값을 크게 변화시키기 위한 값이며, 본 발명의 실시 예에 따라 활성함수는 Sigmoid, Tanh, {ReLU} 등이 사용될 수 있다. sigmoid의 정의는 f(x)=1/(1+e{\textasciicircum}(-x))이며, {ReLU의} 정의는 F(x)=max(0,x)이다. 도 2는 입력된 값에 기반한 가중합이 활성함수에 따라 처리된 결과 0이라는 값을 출력한 모습을 도시하고 있다. 그리고 인공 뉴런들의 출력값이 밖으로 드러나지 않음을 이유로 히든 레이어로 정의되는 층은 도 2에서 도시되지 않고 있다. 그러나 본 발명의 실시 예에 따르면, 입력레이어와 출력 레이어 사이에 존재하는 히든 레이어가 적어도 하나 이상 포함될 수 있다.  {\textbar}   {\textbar} 본 발명의 실시 예에 따른 {ANN의} 동작을 보다 자세히 설명하기 위해 도 3을 참조하기로 한다.  {\textbar}   {\textbar} 도 3은 본 발명의 실시 예에 따른 {PHD} 발생 예측을 위한 {ANN의} 구성을 도시한 도면이다.  {\textbar}   {\textbar} 도 3에서 도시되는 바와 같이, {ANN은} 입력 레이어, 하나의 히든 레이어, 출력 레이어로 구성될 수 있다. 입력 레이어의 각 노드에는 {PHD의} 예측에 요구되는 데이터가 항목별로 입력될 수 있다. 이 때 {PHD의} 예측에 요구되는 데이터는 {PHD를} 유발할 수 있는 위험인자로서, 성별, 연령, 고혈압, 당뇨, 관상동맥질환, 고지혈증, 마취 유형({CAS} 시) 등의 임상적 데이터와, 협착 정도(70\% 이상), 유형(편심 또는 동심), 협착 부위(경동맥({CCA}) 분기점으로부터 10mm 이내의 거리에 존재하는지 여부), 대측성(contralateral) 폐색, 석회화 정도(심한 석회와 여부), 궤양, 플라크 분포(광범위한 플라크)를 포함하는 방사선학적 데이터가 해당될 수 있다. 참고로 상기 심한 석회화 여부에 관한 기준은 Rumberger 에 의해 제안된 척도를 사용하여 3등급과 4등급으로 정의될 수 있다.  {\textbar}   {\textbar} 또한 상기 위험인자로는 절차 데이터가 추가로 포함될 수 있다. 상기 절차 데이터에는 풍선 팽창을 유지하는 시간(5초 이상), 최대 대기(8기압 이상), 풍선 크기와 길이, 스텐트 크기와 스텐트 길이에 관한 항목이 포함될 수 있다.  {\textbar}   {\textbar} 본 발명의 실시 예에 따른 {ANN은} 도 3에서 도시되는 바와 같이, 예컨대 14개의 변수가 하나의 입력 레이어를 구성할 수 있다. 도 3의 입력 레이어의 각 노드에 입력되는 변수의 항목을 상단에서부터 순서대로 살펴보면, 성별, 징후가 있는지 여부(협착에 대한), 협착의 정도(70\%이상인지 여부), 석회화(Runberger에 의해 제안된 척도에 따른 3등급 및 4등급 여부), 궤양, 편심 여부(편심인지 또는 동심인지 여부), 확장성(시술에 따른 혈관 확장 정도), 대측성, 마취(국소 마취 여부), 시술시 풍선 팽창 유지 시간(5초 이상인지 여부), 시술 시 풍선 팽창 압력(8기압 이상인지 여부), 고혈압 여부, 관상 동맥 질병, 협착 병변의 위치가 분기로부터 10mm 이내의 거리에 존재하는지 여부가 도시되어 있다. {ANN을} 이용하여 정보를 분석하고자 할 경우 상기 입력 레이어의 각 항목에 맞는 환자별 데이터(예, 성별 값, 1 또는 0로 결정될 수 있음)를 입력할 수 있다.  {\textbar}   {\textbar} 그러나 입력 레이어에 투입되는 데이터 항목은 14개로 제한되지 않고 보다 다양하게 설정될 수도 있고, 상기 언급된 14개 항목 중 일부는 추후 도시되는 도 4a에 나열되는 항목 중 일부(겹치는 항목이 없도록)로 대체될 수 있다.  {\textbar}   {\textbar} 그리고 본 발명의 실시 예에 따라 10개의 뉴런으로 히든 레이어가 구성될 수 있다. 상기 히든 레이어는 다양한 실시 예에 따라 적어도 하나 이상 포함될 수 있으나, 바람직하게는 한 층으로 형성될 수 있다. 또한 상기 히든 레이어의 노드마다 활성화 함수가 적용될 수 있는데, 본 발명의 실시 예에 따른 히든 레이어의 각 노드는 {ReLU} 함수를 적용하는 것이 바람직하다. 또한 본 발명의 실시 예에 따른 {ANN알고리즘은} 매개변수에 대하여 Adam 초기화가 수행되었고, 학습률은 0.1 로 설정됨이 바람직하다. 상기 설정 내용(Adam 초기화, 학습률)에 대하여는 인공신경망 관련 분야의 기술자들이라면 쉽게 알 수 있는 내용이므로 자세한 설명은 생략하기로 한다. 본 발명의 실시 예에 따른 상기 {ANN은} 학습 동작을 수행하기 위해 역전파 학습 알고리즘이 적용될 수 있고, {TensorFlow} 플랫폼상에서 설계 및 구현될 수 있다.  {\textbar}   {\textbar} 도 3의 중간층에 도시되는 히든 레이어의 각 노드는 입력 레이어의 전체 노드와 가중치에 의해 계산된 결과인 값(net=I0*W0+...+In*Wn, W는 가중치 계수)을 수신할 수 있다. 이후 히든 레이어의 각 노드는 활성화 함수에 의해 활성화 여부를 판단할 수 있다. 히든 레이어의 각 노드는 해당 값이 일정 기준치를 만족하여 활성화되거나 혹은 만족하지 못함에 따라 비활성화되는 것을 결정하게 되고 이는 활성화 함수에 기반하여 수행된다. 그리고 히든 레이어의 각 노드에서 출력 레이어의 true 노드와 false 노드로 연결되는 과정에도 각각에 상응하는 가중치 계수(W'n)가 존재할 수 있다. 히든 레이어의 노드가 10개이고 출력 레이어의 노드가 True 노드와 False 노드로 2개이므로, 히든 레이어의 노드에서 출력 레이어 노드로 연결되는 경로는 총 20개가 될 수 있다. 그러므로 본 발명의 실시 예에 따른 {ANN의} 히든 레이어와 출력 레이어 사이 단계에서 적용되는 가중치 계수는 최대 20개의 종류(각각 다르게 설정될 경우)로 설정될 수 있다. 이와 마찬가지로 입력 레이어와 히든 레이어 사이의 노드 간 연결 경로는 (입력 레이어 노드 개수 14개) * (히든 레이어 노드 개수 10개)= 140개가 되고, 이에 따라 입력 레이어와 히든 레이어 사이의 가중치 계수의 최대 종류는 140개가 될 수 있다.  {\textbar}   {\textbar} 도 4a는 본 발명의 실시 예에 따른 트레이닝 코호트와 테스트 코호트의 비교표를 도시한 도면이다.  {\textbar}   {\textbar} 도 4a를 참조하면, 본 발명의 실시 예에 따른 {ANN을} 학습시키기 위한 자료집단인 트레이닝 코호트(training cohort, 학습 데이터에 대응)와, 학습이 완료된 {ANN에} 예측 결과를 얻기 위해 투입하는 입력 자료인 테스트 코호트(test cohort, 테스트 데이터에 대응)에 대하여 도시하고 있다.  {\textbar}   {\textbar} 도 4a는 본 발명의 실시예에 따른 {ANN의} 모델링 및 테스트를 위해, 109명의 자료(트레이닝 코호트에 76명, 테스트 코호트에 33명)가 사용되었음을 도시하고 있다. 다양한 실시 예에 따라, {ANN이} 학습과정을 거쳐 최적의 가중치 계수를 도출하기 위해, 환자의 최소 인원수가 설계자에 의해 설정될 수 있다. 또한 다양한 실시 예에 따라, 최소 인원수가 설정된 경우, 상기 {ANN은} 최소 인원수 이상의 특정 인원수(예, 76명)에 해당하는 자료가 입력되어 학습이 이루어진 경우에 한하여 신뢰할만한 {ANN} 알고리즘이 완성된 것으로 판단할 수 있다.  {\textbar}   {\textbar} 상기 {ANN} 모델링을 위해 트레이닝 코호트(학습 데이터)가 가중치 계수가 완성되지 않은 {ANN} 알고리즘에 입력되는 동안에는, 상기 학습 데이터 중 위험인자 데이터가 {ANN를} 이용하여 연산된 결과로 생성된 예상값과 학습 데이터 중 결과값의 오차를 감소시키기 위해 역전파 학습 알고리즘을 적용하여 가중치 계수를 수정할 수 있다. 다시 말하면, {ANN} 모델링을 완성하기 위하여 {ANN에} 적용되는 가중치 계수를 산출하기 위해 입력되는 자료는 위험인자 데이터(예, {PHD} 발병률에 연관되는 위험인자인 연령, 성별, {CAS} 시술시 풍선 팽창 유지 시간 등에 관한 데이터)와 더불어, 실제 해당 환자들의 {PHD} 발병 여부에 관한 데이터(실제 결과값)가 모두 포함될 수 있다. 이에 따라 {ANN에서} 역전파 단계에서 가중치 계수를 수정할 시 요구되는 오차값(출력 레이어를 통해 산출된 예측값과 실제 결과값의 차이)을 산출할 수 있게 된다.  {\textbar}   {\textbar} 상기 {ANN은} 가중치 계수를 수정하기 위해 기 설정된 분량의 학습이 완료되면, 최후 수정된 가중치 계수를 {ANN} 모델의 가중치 계수로 고정할 수 있다.  {\textbar}   {\textbar} 도 4b는 본 발명의 실시 예에 따른 테스트 코호트를 {ANN에} 투입하여 얻은 예측 결과값을 표로 나타낸 도면이다.  {\textbar}   {\textbar} 본 발명의 실시 예에 따른 {ANN의} 출력 레이어의 True 노드는 각 환자의 데이터를 처리한 결과로 도 4b의 표의 True 열에 기재된 바와 같은 값을 산출할 수 있다. 마찬가지로 본 발명의 실시 예에 따른 {ANN의} False 노드는 각 환자의 데이터를 처리한 결과로 False 열에 기재된 바와 같은 값을 산출할 수 있다. 그리고 {ANN은} False 값과 True 값 중 더 큰 값을 갖는 쪽이 결과로 산출할 수 있다. 예를 들어, True 값이 더 큰 값을 갖는 경우, True에 대응하는 값이 도출될 것이고, 이를 통해 사용자는 해당 환자에게 {PHD의} 발생될 것으로 예측할 수 있게 된다.  {\textbar}   {\textbar} 도 5는 본 발명의 실시 예에 따른 {ANN을} 이용한 {PHD} 예측의 정확성에 대하여 그래프로 도시한 도면이다.  {\textbar}   {\textbar} 도 5를 참조하면, {ANN과} {MLR과} {SVM을} 이용한 {PHD} 예측 결과의 정확도가 그래프로 도시되고 있다.  {\textbar}   {\textbar} 상기 그래프는 {AUROC}(area under the {ROC} curve)로써, 그래프가 좌측상단에 근접하여 그려질수록 정확도가 높은 것으로 인정된다. 실선으로 나타내어진 그래프는 {MLR} 방식의 분석법을 통한 {PHD} 예측의 정확도에 해당하고, 실선 그래프 좌측 바로 옆의 점선으로 나타내어진 그래프는 {SVM방식을} 통해 수행된 {PHD} 예측의 정확도에 대한 그래프이다. 그리고 가장 좌측에 나타내어진 그래프가 바로 {ANN을} 이용하여 분석된 {PHD} 예측의 정확도를 나타내고 있다. 도 5에서 도시되는 바에 따르면 {ANN을} 이용한 {PHD} 예측이 {MLR방식} 및 {SVM방식에} 비해 훨씬 높은 예측률을 보이고 있다.  {\textbar}   {\textbar} 도 6은 본 발명의 실시 예에 따른 {ANN의} 학습 과정을 도시한 순서도이다.  {\textbar}   {\textbar} 본 발명의 실시 예에 따른 {ANN} 알고리즘을 구현하는 전자장치는 학습 데이터를 입력받는 610동작을 수행할 수 있다. 이 때 상기 학습 데이터는 사용자에 의해 개별 입력될 수도 있으나, 별도로 의료기관 서버 컴퓨터에 저장된 환자 데이터로부터 일괄적으로 입력될 수도 있다. 상기 학습 데이터는 위험인자(예, 성별) 각각에 대한 데이터(예, 여성)인 위험인자 데이터와, 실제 {PHD의} 발생 여부인 결과값(예, 발생함)에 대한 데이터를 포함할 수 있다. 상기 학습 데이터는 {ANN의} 학습을 위해 입력되는 데이터이며, 학습을 위해서는 {ANN이} 정보를 처리하여 얻은 예측값과 실제 결과값과의 오차에 대한 정보가 필요하다. 이에 따라 학습 데이터에는 실제 결과값이 필수적으로 포함되어야 한다. 또한 상기 학습 데이터는 {ANN의} 가중치 계수가 충분히 신뢰성을 갖는 수준으로 도출되도록 하기 위해 일정 기준치(예, 70명) 이상의 환자별 데이터가 요구될 수 있다.  {\textbar}   {\textbar} 이후 상기 전자장치는 {ANN을} 이용하여 초기 예측값을 생성하는 615동작을 수행할 수 있다.  {\textbar}   {\textbar} 이후 상기 전자장치는 상기 도출된 초기 예측값과 학습용 결과값(학습 데이터로써 입력된 실제 결과값)과의 오차를 기반으로 가중치 계수를 수정하는 620동작을 수행할 수 있다. 상기 620동작은 역전파 알고리즘을 이용한 동작일 수 있다. 전자장치는 이와 같은 과정을 통해 가중치를 출력 레이어와 가까운 단계에서 적용되는 가중치 계수부터 수정하며, 준비된 학습 데이터의 입력이 모두 완료되면 최종적으로 산출된 계수를 {ANN의} 가중치 계수로 고정하여 {ANN} 모델을 완성할 수 있다.  {\textbar}   {\textbar} 이와 같이 {ANN} 모델이 완성되면, 테스트용 데이터(환자별 위험인자 데이터로만 구성된 데이터)를 {ANN} 알고리즘에 투입하여 정보를 처리할 수 있다. 사용자는 상기 {ANN을} 통해 처리된 정보를 기반으로 {PHD의} 결과를 예측할 수 있다.  {\textbar}   {\textbar} 도 7은 본 발명의 실시 예에 따른 {ANN를} 통한 {PHD} 예측 동작의 순서를 도시한 순서도이다. {\textbar}   {\textbar} 도 7을 참조하면, {ANN} 알고리즘을 수행하는 전자장치는 테스트용 데이터를 입력받는 710동작을 수행할 수 있다. 이 때 상기 테스트용 데이터는 {PHD} 발생여부를 확인할 수 없는 시점의 환자(예, 경동맥 스텐트 삽입술을 앞둔 환자)의 위험인자 데이터를 의미할 수 있다. 그리고 이 때 상기 테스트용 데이터는 각 환자의 {PHD} 발생 여부를 판단하기 위한 목적으로 투입될 수도 있고, 모델링이 완성된 {ANN의} 정확도를 체크하기 위한 목적으로 투입될 수 있다. 본 발명의 실시 예에 따르면 {ANN의} 정보 처리 정확도를 판단하기 위한 테스트용 데이터는 33명에 대한 자료로 구성될 수 있다.  {\textbar}   {\textbar} 이후 상기 전자장치는 입력된 데이터를 수정 완료된 가중치 계수가 적용된 {ANN} 알고리즘에 따라 처리하여 True와 False 에 해당하는 결과값을 각각 생성하는 715동작을 수행할 수 있다. 이후 상기 전자장치는 True 값과 False 값의 결과를 비교하는 720동작을 수행할 수 있다. 만약 True 값이 False 값보다 크게 산출된 경우, 상기 전자장치는 '{PHD} 발생'이라는 결과를 출력하는 725동작을 수행할 수 있다. 반면, True 값보다 False 값이 더 크게 산출된 것으로 판단되면, 상기 전자장치는 '{PHD} 발생하지 않음'과 같은 결과값을 출력하는 730동작을 수행할 수 있다.  {\textbar}   {\textbar} 도 8은 본 발명의 다양한 실시 예에 따른 {ANN을} 이용하여 {PHD의} 발생을 예측하는 전자장치의 구성을 도시한 블록도이다.  {\textbar}   {\textbar} 도 8을 참조하면, 전자장치는 표시부 810, 통신부 820, 입력부 830, 저장부 840, 제어부 850를 포함하여 구성될 수 있다. 그리고 상기 저장부 840는 환자별 위험인자 데이터 841을 포함하여 저장할 수 있다. 그리고 상기 제어부 850는 {ANN} 851, 환자 데이터 판독부 852, 데이터 투입부 853, 정확도 산출부 854를 포함하여 구성될 수 있다.  {\textbar}   {\textbar} 상기 표시부 810는 패널, 홀로그램 장치, 또는 프로젝터를 포함할 수 있다. 패널은, 예를 들면, 유연하게(flexible), 투명하게(transparent), 또는 착용할 수 있게(wearable) 구현될 수 있다. 패널은 터치 패널과 하나의 모듈로 구성될 수도 있다. 홀로그램 장치는 빛의 간섭을 이용하여 입체 영상을 허공에 보여줄 수 있다. 프로젝터는 스크린에 빛을 투사하여 영상을 표시할 수 있다. 스크린은, 예를 들면, 전자 장치의 내부 또는 외부에 위치할 수 있다. 한 실시예에 따르면, 표시부는 패널, 홀로그램 장치, 또는 프로젝터를 제어하기 위한 제어 회로를 더 포함할 수 있다. {\textbar}   {\textbar} 본 발명의 실시 예에 따른 표시부 810는 {ANN} 851에 투입되는 데이터 및 {ANN} 851의 동작 결과 산출된 데이터에 관한 정보(예, {PHD의} 예측 결과; {PHD} 발생, {PHD} 발생하지 않음)를 표시하는 기능을 수행할 수 있다. 또한 상기 표시부 810는 다양한 실시 예에 따라 {ANN} 851가 처리한 결과의 확률에 관한 데이터를 산출할 수 있다. 예컨대, 상기 {ANN은} 다양한 실시 예에 따라, {PHD의} 발생 여부에 관한 예측 뿐 아니라, {PHD가} 발생할 것이라면 그 발생 확률이 얼마인지, 또는 발생하지 않을 것으로 예측된다면 발생하지 않을 확률이 얼마인지에 대한 정보를 함께 산출할 수 있다.  {\textbar}   {\textbar} 상기 통신부 820는 타 사용자 전자장치 또는 타 서버와의 데이터 송수신을 위해 네트워크를 이용할 수 있으며 상기 네트워크의 종류는 특별히 제한되지 않는다. 상기 네트워크는 예를 들어, 인터넷 프로토콜({IP})을 통하여 대용량 데이터의 송수신 서비스를 제공하는 아이피({IP}: Internet Protocol)망 또는 서로 다른 {IP} 망을 통합한 올 아이피(All {IP}) 망 일 수 있다. 또한, 상기 네트워크는 유선망, Wibro(Wireless Broadband)망, {WCDMA를} 포함하는 이동통신망, {HSDPA}(High Speed Downlink Packet Access)망 및 {LTE}(Long Term Evolution) 망을 포함하는 이동통신망, {LTE} advanced({LTE}-A), 5G(Five Generation)를 포함하는 이동통신망, 위성 통신망 및 와이파이(Wi-Fi)망 중 하나 이거나 또는 이들 중 적어도 하나 이상을 결합하여 이루어질 수 있다. {\textbar}   {\textbar} 본 발명의 실시 예에 따른 상기 통신부 820는 타 전자장치 또는 외부 서버로부터 {ANN에} 투입할 데이터인 환자 정보를 수신하기 위한 통신 기능을 지원할 수 있다. 또한 상기 통신부 820는 {ANN의} 정보 처리 결과를 타 전자장치 또는 외부 서버로 전송할 수 있다.  {\textbar}   {\textbar} 상기 입력부 830는 예를 들면, 터치 패널(touch panel), 펜 센서(pen sensor, 키(key), 또는 초음파(ultrasonic) 입력 장치를 포함할 수 있다. 터치 패널(252)은, 예를 들면, 정전식, 감압식, 적외선 방식, 또는 초음파 방식 중 적어도 하나의 방식을 사용할 수 있다. 또한, 터치 패널은 제어 회로를 더 포함할 수도 있다. 터치 패널은 택 타일레이어(tactile layer)를 더 포함하여, 사용자에게 촉각 반응을 제공할 수 있다. {\textbar}   {\textbar} 본 발명의 실시 예에 따른 상기 입력부 830는 학습 데이터(트레이닝 코호트) 또는 테스트 데이터(테스트 코호트)에 대응하는 자료를 직접 입력받을 수 있다. 또한 다양한 실시 예에 따라 상기 입력부 830는 {ANN에} 투입될 데이터의 항목을 변경하기 위한 사용자 조작을 수신할 수 있다. 예컨대, 상기 {ANN의} 입력 레이어에 포함되는 노드의 개수가 기본적으로 14개로 설정되어 있을 수 있는데, 총 위험 인자는 20가지 이상인 것으로 가정할 때, 사용자는 전체 위험 인자의 항목들 중 14개로 선택될 위험인자 항목을 선택하기 위해 상기 입력부 830를 사용할 수 있다.  {\textbar}   {\textbar} 이 밖에도 다양한 실시예에 따른 사용자 입력이 요구될 수 있으며 그 경우 상기 입력부 830가 사용자 입력 신호를 디지털 신호로 변환하여 제어부 850에 전달할 수 있다.  {\textbar}   {\textbar} 상기 저장부는 예를 들면, 내장 메모리 또는 외장 메모리를 포함할 수 있다. 내장메모리는, 예를 들면, 휘발성 메모리(예: {DRAM}(dynamic {RAM}), {SRAM}(static {RAM}), 또는 {SDRAM}(synchronous dynamic {RAM}) 등), 비휘발성 메모리(non-volatile Memory)(예: {OTPROM}(one time programmable {ROM}), {PROM}(programmable {ROM}), {EPROM}(erasable and programmable {ROM}), {EEPROM}(electrically erasable and programmable {ROM}), mask {ROM}, flash {ROM}, 플래시 메모리(예: {NAND} flash 또는 {NOR} flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive({SSD})) 중 적어도 하나를 포함할 수 있다. {\textbar}   {\textbar} 외장 메모리는 플래시 드라이브(flash drive), 예를 들면, {CF}(compact flash), {SD}(secure digital), Micro-{SD}(micro secure digital), Mini-{SD}(mini secure digital), {xD}(extreme digital), {MMC}(multi-media card) 또는 메모리 스틱(memory stick) 등을 더 포함할 수 있다. 외장 메모리는 다양한 인터페이스를 통하여 전자 장치와 기능적으로 및/또는 물리적으로 연결될 수 있다. {\textbar}   {\textbar} 본 발명의 실시 예에 따른 상기 저장부 840는 환자별 위험인자 데이터 841을 포함할 수 있다. 상기 환자별 위험인자 데이터 841는 예컨대, 성별, 징후가 있는지 여부(협착에 대한), 협착의 정도(70\%이상인지 여부), 석회화(Runberger에 의해 제안된 척도에 따른 3등급 및 4등급 여부), 궤양, 편심(편심인지 또는 동심인지 여부), 확장성(시술에 따른 혈관 확장 정도), 대측성, 마취(국소 마취 여부), 시술시 풍선 팽창 유지 시간(5초 이상인지 여부), 시술 시 풍선 팽창 압력(8기압 이상인지 여부), 고혈압 여부, 관상 동맥 질병, 협착 병변의 위치가 분기로부터 10mm 이내의 거리에 존재하는지 여부를 포함할 수 있다. 상기 환자별 위험인자 데이터 841를 기반으로 한 학습 데이터 및 테스트 데이터가 {ANN에} 제공될 수 있다.  {\textbar}   {\textbar} 또한 상기 저장부 840는 본 발명의 실시 예에 따라 {ANN에} 적용되는 활성화함수, 학습률, 가중치 계수 등에 관한 정보를 저장할 수 있다. 그리고 {ANN의} 학습이 완료됨에 따라 상기 저장부 840에 저장되는 가중치 계수 또한 업데이트되어 저장될 수 있다.  {\textbar}   {\textbar} 상기 제어부 850는 프로세서(Processor), 컨트롤러(controller), 마이크로 컨트롤러(microcontroller), 마이크로 프로세서(microprocessor), 마이크로 컴퓨터(microcomputer) 등으로도 호칭될 수 있다. 한편, 제어부는 하드웨어(hardware) 또는 펌웨어(firmware), 소프트웨어, 또는 이들의 결합에 의해 구현될 수 있다.  {\textbar}   {\textbar} 펌웨어나 소프트웨어에 의한 구현의 경우, 본 발명의 일 실시예는 이상에서 설명된 기능 또는 동작들을 수행하는 모듈, 절차, 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리에 저장되어 제어부에 의해 구동될 수 있다. 메모리는 상기 사용자 단말 및 서버 내부 또는 외부에 위치할 수 있으며, 이미 공지된 다양한 수단에 의해 상기 제어부와 데이터를 주고 받을 수 있다. {\textbar}   {\textbar} 본 발명의 실시 예에 따른 상기 제어부 850는 {ANN} 851, 환자데이터 판독부 852, 데이터 투입부 853, 정확도 산출부 854를 포함하여 구성될 수 있다. 먼저 {ANN} 851은 본 발명의 실시 예에 따라, 투입된 학습 데이터를 기반으로 가중합을 구하는 등의 연산을 처리할 수 있다. 그리고 상기 {ANN} 851은 학습 과정 동안에는 역전파 알고리즘을 이용한 정보처리동작을 수행할 수 있다. 상기 {ANN} 851은 역전파 알고리즘을 통해 실제 결과값과 산출된 예측값의 오차가 줄어들도록 출력 레이어로부터 가까운 단계의 가중치 계수부터 수정해나갈 수 있다. 해당 동작을 거쳐 준비된 학습 데이터(예컨대, 76명에 대한 위험인자 데이터)가 모두 투입되어 학습 동작이 완료되면, 상기 {ANN} 851은 최종적으로 산출된 가중치 계수를 적용하여 {ANN} 모델을 완성할 수 있다.  {\textbar}   {\textbar} 이후 상기 {ANN} 851은 투입되는 테스트 데이터를 이용한 정보 처리 과정을 수행할 수 있다. 데이터가 입력되면, {ANN의} 입력 레이어의 각 노드에 위험인자 데이터가 할당되고, 히든 레이어를 거쳐 출력 레이어의 True 노드와 False 노드에 각각 해당 결과 값이 산출될 수 있다. 이후 True 노드와 False노드의 값을 비교하여 큰 값을 갖는 측(True 또는 False)이 최종 예측 결과로서 산출된다.  {\textbar}   {\textbar} 환자 데이터 판독부 852는 본 발명의 실시 예에 따라 상기 통신부 820를 통해 타 전자장치 또는 외부 서버(예, 관련 의료기관 서버)로부터 수집된 정보들 중에서 위험인자에 해당하는 데이터들만을 추출하는 동작을 수행할 수 있다. 예컨대, 통신부 820를 통해 전달되는 정보는 환자의 이름, 생년월일, 흡연 유무 등 검사 결과에 해당하지 않는 정보 및 특정 검사에 대한 결과 정보(예, {HIV} 감염 여부, 혈액형, 혈압, 백혈구 수치 등)가 해당될 수 있다. 그러나 이러한 많은 다양한 항목들 중 {PHD예측과} 관계가 없는 항목들이 존재할 수 있으므로, 상기 환자 데이터 판독부 852는 {ANN에} 투입되어 {PHD의} 예측을 수행하기 위해 요구되는 데이터의 항목만을 추출할 수 있다.  {\textbar}   {\textbar} 또한 상기 환자 데이터 판독부 852는 특정 환자의 테스트 데이터(또는 학습 데이터)가 {PHD} 예측에 요구되는 최소한의 위험인자 항목수(예컨대, 14가지)를 만족하는지 여부를 판단할 수 있다. 만약 환자의 데이터 항목이 {PHD} 예측에 요구되는 최소한의 위험인자 항목수를 만족하지 않는 경우, 상기 환자 데이터 판독부 852는 {PHD예측을} 위해 추가로 요구되는 항목에 대한 정보를 표시부 810에 표시하는 방식으로 요청할 수 있다. 예컨대, 상기 환자 데이터 판독부 852는 특정 환자의 {PHD예측을} 위한 위험인자 항목 중 혈압에 대한 정보가 미입력된 것으로 판단되면, 해당 환자의 혈압 데이터를 입력할 것을 표시부 810에 표시하는 방식으로 요구할 수 있다. 또는 상기 환자 데이터 판독부 852는 추가 정보에 대한 요청을 상기 통신부 820를 통해 타 서버 또는 타 전자장치(예컨대, 환자의 개인단말기)에 전송할 수 있다.  {\textbar}   {\textbar} 상기 데이터 투입부 853는 본 발명의 실시 예에 따라 {ANN} 851의 동작이 학습 단계인지 테스트 단계인지 여부를 판단하고, 학습 단계일 경우, 환자의 위험인자 데이터 및 해당 환자의 실제 결과값(실제 {PHD} 발생 여부에 대한 정보)를 포함하는 학습 데이터를 {ANN} 에 투입하도록 제어할 수 있다. 한편, {ANN의} 동작 단계가 학습 단계가 아닌 테스트 단계일 경우, 투입될 데이터는 환자의 위험인자 데이터만을 포함하도록 설정할 수 있다. 다시 말해, 상기 데이터 투입부 853는 학습 단계에서 투입될 정보에 실제 결과값이 포함되어 있지 않으면 학습 동작을 수행할 수 없으므로 이에 대하여 추가 정보를 요청할 수 있다. 그리고 상기 데이터 투입부 853는 테스트 단계에서 투입될 정보에 실제 결과값이 포함되어 있지 않는 경우, 별다른 문제없이 {ANN에} 데이터를 입력할 수 있다.  {\textbar}   {\textbar} 상기 정확도 산출부 854는 본 발명의 다양한 실시 예에 따라 상기 {ANN} 851의 결과값을 분석하는 보다 구체적으로 분석하는 동작을 수행할 수 있다. 본 발명의 기본 구성은 {ANN의} 결과가 True 혹은 False({PHD의} 발생 예측 또는 발생되지 않을 것을 예측하는 2가지의 결과값만을 산출)로 분류되나, 다양한 실시 예에 따라 정확도 산출부 854에 의한 구체적인 {PHD} 발생 확률 산출이 수행될 수 있다.  {\textbar}   {\textbar} 상기 {ANN} 851은 True 노드와 False 노드의 값을 비교하여 큰 값을 갖는 쪽을 최종 결과로 산출하게 된다. 상기 정확도 산출부 854는 {ANN} 851의 True 노드와 False 노드의 값의 차이의 크기를 비교하거나 True 값이 기준치 이하이거나 또는 False 값이 기준치 이하인 것으로 판단되면, 그에 대응하는 {PHD} 발생 확률을 계산할 수 있다. 따라서, 상기 정확도 산출부 854는 {ANN} 851의 False 값과 True값을 전달받을 수 있고, 해당 값의 차이에 기반하여 {PHD의} 발생확률을 계산할 수 있다. 예를 들어, True 값이 False 값보다 큰 값을 보이나 그 차이가 근소할 경우, 해당 환자의 {PHD} 발생 확률은, True값이 False 값보다 큰 값을 보이면서 그 차이가 현격한 경우에 비하여 낮게 측정될 수 있다 {\textbar}   {\textbar}  또한 다양한 실시 예에 따르면, 상기 전자장치는 {ANN을} 기반으로 {PHD의} 발생 확률을 저하시키기 위해 가장 효과적인 위험인자를 산출할 수 있다. 상기 전자장치는 각 위험인자 데이터들 중 나이, 성별 등의 조절 불가능한 항목을 제외한, 풍선 팽창 유지 시간, 스텐트 사이즈, 혈압 등의 조절가능한 항목을 별도로 선별할 수 있다. 이후 상기 전자장치는 선별된 특정 항목의 값을 일정 간격으로 변경하여 비교 데이터를 생성할 수 있다. 이후, 상기 전자장치는 원 데이터를 {ANN에} 투입하여 생성된 예측값과 비교 데이터를 {ANN에} 투입하여 생성된 예측값을 비교할 수 있으며, 만약, 원 데이터에 의해 생성된 예측값(예컨대, True)이 비교 데이터에 의해 생성된 예측값(예컨대,False)이 서로 다르게 산출되면, 두 값이 다르게 산출되기 시작하는 위험인자 항목별 데이터 수치를 기록할 수 있다. 예를 들어, 원 데이터 분석 결과 {PHD} 예측값이 True로 산출되나, 혈압의 수치를 1만큼 낮춘 비교 데이터를 분석한 결과 {PHD} 예측값이 False로 산출된 경우, 상기 전자장치는 해당 환자의 {PHD} 위험을 낮추기 위해 혈압을 1이상 낮추면 된다는 결과를 생성할 수 있다. 이와 같은 방식으로 본 발명의 다양한 실시 예는 환자의 {CAS후} {PHD의} 발생 여부를 예측할 뿐 아니라, {PHD가} 발생하지 않게 하기 위해 요구되는 위험인자별 수치 정보를 산출하고 이를 사용자에게 제공할 수 있다.  {\textbar}   {\textbar} 참고로, 본 발명의 실시 예에서, 연속 데이터는 평균 ㅁ 표준 편차 ({SD}; standard Deviation)로 표시될 수 있으며, {PHD의} 위험 인자는 트레이닝 코호트의 {MLR} 모델을 사용하여 후향적 데이터로 결정될 수 있다. 테스트 코호트의 전향적 데이터는 {ANN} 모델에 대한 입력으로 사용될 수 있다.  {\textbar}   {\textbar} 또한 다양한 실시 예에 따라, 상기 전자장치에서 {PHD의} 고위험군 환자를 자동으로 식별하기 위해서 {CNN}(Convolutional Neural Network) 기반의 영상 인식이 추가로 수행될 수 있다. 이는 해당 영상을 인식한 의료진이 직접 환자에 대한 자료를 별도로 입력하지 않더라도, 자동으로 영상 인식을 기반으로 관련 자료를 {ANN에} 투입할 수 있게 된다. 예를 들어, 협착부위가 분기로부터 10mm이하의 거리에 존재하는지 여부에 대한 데이터 입력에 있어, {CNN기반의} 영상 인식 기술은 촬영 영상이 입력되는 즉시 해당 환자의 정보가 자동으로 {ANN의} 입력 레이어의 특정 노드에 투입되는 것을 가능하게 할 수 있다.  {\textbar}   {\textbar} 또한, 본 발명의 실시 예에 따르면 76명에 대한 14가지 항목의 트레이닝 데이터를 학습에 이용하였으나, 초과 적용을 방지하기 위해서는 항목 수를 줄이거나 데이터 양을 늘려 적용하는 편이 바람직하다.  {\textbar}   {\textbar} 상술한 예를 참조하여 본 발명을 상세하게 설명하였지만, 당업자라면 본 발명의 범위를 벗어나지 않으면서도 본 예들에 대한 개조, 변경 및 변형을 가할 수 있다. 요컨대 본 발명이 의도하는 효과를 달성하기 위해 도면에 도시된 모든 기능 블록을 별도로 포함하거나 도면에 도시된 모든 순서를 도시된 순서 그대로 따라야만 하는 것은 아니며, 그렇지 않더라도 얼마든지 청구항에 기재된 본 발명의 기술적 범위에 속할 수 있음에 주의한다. {\textbar}   {\textbar} 810 : 표시부 820 : 통신부 830 : 입력부 840 : 저장부 841 : 환자별 위험인자 데이터 850 : 제어부 851 : {ANN} 852 : 환자 데이터 판독부 853 : 데이터 투입부 854 : 정확도 산출부 Method and apparatus for predicting persistent hemodynamic depression using artificial neural network\} {\textbar}   {\textbar} An embodiment of the present invention relates to a method and apparatus for predicting whether persistent hemodynamic abnormality ({PHD}) occurs after carotid artery stent implantation ({CAS}) using an artificial neural network ({ANN}).  {\textbar}   {\textbar} Since the late 1990s, carotid artery angioplasty and stenting ({CAS}) has been rapidly applied to patients with symptomatic or asymptomatic internal carotid artery stenosis. Carotid angioplasty and stent implantation ({CAS}) are a less invasive method compared to endoscopic resection and have been evaluated positively because they can be applied relatively safely in the high risk group of endoscopic resection. {\textbar}   {\textbar} However, some of the {CAS} may cause complications, especially hemodynamic abnormalities may occur during the procedure of carotid artery stents. The most common symptom is hypotension, in addition to bradycardia, arrhythmia, and syncope. This side effect may occur as the carotid artery stent is inserted, resulting in dysfunction of the seizure receptor due to artificial expansion of the artery and shielding by the stent. {\textbar}   {\textbar} In clinical situations, transient hemodynamic abnormalities can be recovered without complications due to immediate pacemaker or medically conservative treatment. Persistent hemodynamic depression ({PHD}), however, can lead to acute ischemic stroke, hemorrhagic stroke, myocardial infarction and renal dysfunction. Therefore, patients who have a high risk of developing hemodynamic abnormality after {CAS} require a separate hemodynamic stabilization measure before or after the {CAS} procedure. {\textbar}   {\textbar} On the other hand, most studies to define risk factors in the past have been performed using logistic regression model. Recently, machine learning methods are increasingly being used as an alternative to multiple logistic regression ({MLR}) models to improve the diagnostic accuracy of research in various medical fields. {\textbar}   {\textbar} Two of the most commonly used machine learning algorithms are artificial neural networks ({ANNs}) and support vector machines ({SVMs}). The {ANN} consists of three interconnected layers: the input layer, the hidden layer, and the output layer. {ANN}'s information processing process consists of two phases: (i) a backpropagation phase using supervised and unsupervised learning methods, and (ii) a test phase comparing actual results with calculated errors. In other words, {ANN} is different from other existing methods in that it has self-calibration or learning ability based on errors. {\textbar}   {\textbar} As a result, {ANN} is suitable for predicting the probability of occurrence of a specific situation in the future or for estimating a specific value to be taken by the customer, and can be analyzed regardless of the qualitative and quantitative variables. There is an advantage.  {\textbar}   {\textbar} However, conventionally, there was no method using {ANN} for comprehensive analysis of hemodynamic abnormality after {CAS}, and thus, there was a problem in that accuracy was low in predicting complications after {CAS}.  {\textbar}   {\textbar} On the other hand, there is a prior patent related to the determination of hemodynamic abnormalities there is published patent publication 10-2017-0090286 (hemodynamic simulation method of the stenosis lesion area considering the fluid-structure interaction). {\textbar}   {\textbar} The present invention aims to predict more accurately the persistent hemodynamic abnormality ({PHD}) that occurs after carotid artery stent implantation ({CAS}) using {ANN} rather than {MLR} and {SVM}, which are conventional analysis methods.  {\textbar}   {\textbar} According to an embodiment of the present invention, a method for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent implantation ({CAS}) may be inputted as learning data of risk factor data and results thereof affecting the development of {PHD} after {CAS}. In order to predict the occurrence of {PHD} after the {CAS} of the target patient and to perform the learning in the {ANN} (Artificial Neural Network), the risk factor data of the patient is input to the learned {ANN} as test data, and the calculation is performed using the {ANN}. And determining whether {PHD} occurs in the target patient, wherein the risk factor data includes patient-specific clinical factors and radiological factors, and the clinical factors include information on gender and age. The radiological factors include information about the location of the lesion, the distance from the branch of the lesion, and whether the lesion is calcified. A it can be characterized. {\textbar}   {\textbar} An electronic device for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent insertion ({CAS}) according to an embodiment of the present invention includes an input layer, a single hidden layer, and an output layer, and each node of the input layer A controller for operating the {ANN} to calculate a predicted value of whether {PHD} is generated in an output layer as data about a risk factor is input to the controller, a weighting factor, an activation function, a learning rate, and a learning rate required for the {ANN}'s learning and test operations. It may include a storage for storing patient-specific risk factor data that is input information.  {\textbar}   {\textbar} According to an embodiment of the present invention, an electronic device for predicting persistent hemodynamic abnormality ({PHD}) occurring after carotid artery stent implantation ({CAS}) may include risk factor data and results thereof that affect {PHD} after {CAS} as learning data. In order to predict whether {PHD} occurs after the {CAS} of the target patient, the {ANN} receives the risk factor data of the patient as test data and performs calculations to determine whether the {PHD} of the target patient is generated. The risk factor data includes a patient-specific clinical factor and a radiological factor, wherein the clinical factor includes information on gender and age, and the radiological factor includes a location of the lesion and a lesion. It may include information about the distance away from the branch of.  {\textbar}   {\textbar} The {PHD} prediction method using the {ANN} according to an embodiment of the present invention may exhibit higher accuracy than the conventional {MLR} or {SVM} method.  {\textbar}   {\textbar} In addition, the embodiment of the present invention can calculate the weight coefficient through the learning using the back-propagation algorithm, {ANN} that can predict the {PHD} of the patient before the next {CAS} procedure even if the data on the risk factor and whether or not the actual {PHD} invented You can create a model.  {\textbar}   {\textbar} In addition, the embodiment of the present invention not only predicts the occurrence of {PHD}, but also calculates the probability of occurrence.  {\textbar}   {\textbar} 1 is a diagram illustrating an operation performed by an {ANN} according to an embodiment of the present invention. 2 is a diagram illustrating a signaling procedure of an {ANN} according to an embodiment of the present invention. 3 is a diagram illustrating a configuration of an {ANN} for predicting {PHD} occurrence according to an embodiment of the present invention. 4A is a diagram illustrating a comparison table between a training cohort and a test cohort according to an exemplary embodiment of the present invention. 4B is a table showing prediction results obtained by injecting a test cohort into an {ANN} according to an embodiment of the present invention. 5 is a graph illustrating the accuracy of {PHD} prediction using {ANN} according to an embodiment of the present invention. 6 is a flowchart illustrating a learning process of an {ANN} according to an embodiment of the present invention. 7 is a flowchart illustrating a procedure of {PHD} prediction operation through an {ANN} according to an embodiment of the present invention. 8 is a block diagram illustrating a configuration of an electronic device that predicts occurrence of {PHD} using an {ANN} according to various embodiments of the present disclosure.  {\textbar}   {\textbar} As the present invention allows for various changes and numerous embodiments, particular embodiments will be illustrated in the drawings and described in detail in the written description. {\textbar}   {\textbar} However, this is not intended to limit the present invention to specific embodiments, it should be understood to include all modifications, equivalents, and substitutes included in the spirit and scope of the present invention. In describing the drawings, similar reference numerals are used for similar elements. {\textbar}   {\textbar} When a component is said to be 'connected' or 'connected' to another component, it may be directly connected to or connected to that other component, but it may be understood that another component may exist in between Should be. On the other hand, when a component is said to be 'directly connected' or 'directly connected' to another component, it should be understood that no other component exists in the middle. {\textbar}   {\textbar} The terminology used herein is for the purpose of describing particular example embodiments only and is not intended to be limiting of the present invention. Singular expressions include plural expressions unless the context clearly indicates otherwise. In this application, the terms 'comprise' or 'have' are intended to indicate that there is a feature, number, step, action, component, part, or combination thereof described in the specification, and one or more other features. It is to be understood that the present invention does not exclude the possibility of the presence or the addition of numbers, steps, operations, components, components, or a combination thereof. {\textbar}   {\textbar} Also, in the present specification, the device may be a general apparatus (or thing) connected to a gateway and applied to the Internet of Things ({IoT}). For example, the device may be a wireless pager, smartphone, tablet {PC}, computer, temperature sensor, humidity sensor, acoustic sensor, motion sensor, proximity sensor, gas sensor, heat sensor, refrigerator, {CCTV}, {TV}, washing machine, dehumidifier , Lights, fire alarms, and the like. However, this is not limitative. {\textbar}   {\textbar} In addition, in the present specification, a device may be used interchangeably with a 'device' or a 'device', and the 'device', the 'device', and the 'device' may be described with the same expression. {\textbar}   {\textbar} Hereinafter, with reference to the accompanying drawings, it will be described in detail a preferred embodiment of the present invention. Hereinafter, the same reference numerals are used for the same components in the drawings, and duplicate descriptions of the same components are omitted. {\textbar}   {\textbar} 1 is a diagram illustrating an operation performed by an {ANN} according to an embodiment of the present invention.  {\textbar}   {\textbar} Referring to {FIG}. 1, an {ANN} (Artificial Neural Network) 100 is shown according to an embodiment of the present invention. The {ANN} refers to an algorithm for processing information in a manner similar to the human brain, and may be composed of three layers, an input layer, a hidden layer, and an output layer. In this case, a plurality of hidden layers may be set according to various embodiments. The neural network including at least one hidden layer may be defined as a multilayer neural network. {\textbar}   {\textbar} In addition, the {ANN} 100 requires a learning process to update the weight of the connection. The initial weight may be set randomly. In this case, the information input for learning the {ANN} 100 is learning data 110, and the learning data 110 may be input to an algorithm configured by the {ANN} 100 to learn the {ANN} 100. When the learning is completed, the input data 120 is input to the {ANN} 100 to perform the information processing operation to derive the corresponding result. According to an embodiment of the present invention, the calculation of the data processing result of {ANN} 100 may be information on whether or not the occurrence of persistent hemodynamic depression ({PHD}) occurs. According to various embodiments of the present disclosure, the information derived through the information processing process of the {ANN} 100 may be information about a probability of occurrence of {PHD}. {\textbar}   {\textbar} See {FIG}. 2 for a description of the learning and information processing performed by the {ANN} 100.  {\textbar}   {\textbar} 2 is a diagram illustrating a signaling procedure of an {ANN} according to an embodiment of the present invention.  {\textbar}   {\textbar} As shown in {FIG}. 2, the {ANN} is connected to a group of nodes, which is similar to a network of neurons in the human brain. Each circular node of {FIG}. 2 represents an artificial neuron, and an arrow represents an output from one neuron and an input to another neuron. The input data may be input through the I (0) and I (1) nodes of the input layer for each item. {\textbar}   {\textbar} Referring to {FIG}. 2, the addition of the bias value (b) to the dot product of the input value and the weighting factor is called a weighted sum (ie, net = I0 * W0 + I1 * W1 + ... In * Wn + b). When the weighted sum is processed through an active function, the processed value becomes the output of the {ANN}. The activity function is a value for greatly changing any value, and the active function may be Sigmoid, Tanh, {ReLU}, etc. according to an embodiment of the present invention. The definition of sigmoid is f (x) = 1 / (1 + e {\textasciicircum} (-x)), and the definition of {ReLU} is F (x) = max (0, x). {FIG}. 2 illustrates a result of outputting a value of 0 as a result of a weighted sum based on an input value processed according to an active function. The layer defined as the hidden layer is not shown in {FIG}. 2 because the output value of the artificial neurons is not exposed to the outside. However, according to an embodiment of the present invention, at least one hidden layer existing between the input layer and the output layer may be included. {\textbar}   {\textbar} In order to describe the operation of the {ANN} according to an embodiment of the present invention in detail, reference is made to {FIG}. 3.  {\textbar}   {\textbar} 3 is a diagram illustrating a configuration of an {ANN} for predicting {PHD} occurrence according to an embodiment of the present invention.  {\textbar}   {\textbar} As shown in {FIG}. 3, the {ANN} may be composed of an input layer, one hidden layer, and an output layer. Data required for prediction of the {PHD} may be input to each node of the input layer for each item. The data required for the prediction of {PHD} are risk factors that can induce {PHD}, including clinical data such as sex, age, hypertension, diabetes, coronary artery disease, hyperlipidemia, anesthesia type (at {CAS}), and degree of stricture (70). \% Or more), type (eccentric or concentric), site of stenosis (whether present within 10 mm from carotid artery ({CCA}) bifurcation), contralateral occlusion, degree of calcification (with or without severe lime), ulcer, plaque distribution Radiological data including (broad plaques) may be relevant. For reference, the criteria for severe calcification can be defined as grades 3 and 4 using the scale proposed by Rumberger. {\textbar}   {\textbar} The risk factor may further include procedural data. The procedure data may include items relating to time to maintain balloon inflation (more than 5 seconds), maximum atmospheric pressure (more than 8 atmospheres), balloon size and length, stent size and stent length. {\textbar}   {\textbar} In the {ANN} according to the embodiment of the present invention, as shown in {FIG}. 3, for example, 14 variables may configure one input layer. Looking at the items of the variable input to each node of the input layer of Figure 3 in order from the top, the gender, whether there are signs (for stenosis), the degree of stenosis (70\% or more), calcification (suggested by Runberger) Grades 3 and 4 according to the measured scale), ulcers, eccentricity (whether eccentric or concentric), dilatability (degree of vessel dilation according to the procedure), contralaterality, anesthesia (local anesthesia), balloon dilation during the procedure It is shown whether the retention time (if more than 5 seconds), the balloon inflation pressure at the procedure (more than 8 atmospheres), the presence of hypertension, coronary artery disease, the location of the stenosis lesions are within a distance of 10 mm from the branch. When information is analyzed using {ANN}, patient-specific data (eg, gender value, which may be determined as 1 or 0) corresponding to each item of the input layer may be input. {\textbar}   {\textbar} However, the number of data items input to the input layer is not limited to 14 and may be set in more various ways, and some of the 14 items mentioned above are replaced by some of the items listed in {FIG}. 4A (to avoid overlapping items). Can be.  {\textbar}   {\textbar} In addition, a hidden layer may be configured of ten neurons according to an exemplary embodiment of the present invention. The hidden layer may be included in at least one according to various embodiments, but preferably may be formed in one layer. In addition, an activation function may be applied to each node of the hidden layer. Preferably, each node of the hidden layer according to an embodiment of the present invention applies a {ReLU} function. In addition, in the {ANN} algorithm according to an embodiment of the present invention, Adam initialization is performed on a parameter, and the learning rate is preferably set to 0.1. The setting contents (Adam initialization, learning rate) are easily understood by those skilled in the art of artificial neural networks, and thus detailed descriptions thereof will be omitted. In the {ANN} according to an embodiment of the present invention, a backpropagation learning algorithm may be applied to perform a learning operation, and may be designed and implemented on a {TensorFlow} platform. {\textbar}   {\textbar} Each node of the hidden layer shown in the middle layer of {FIG}. 3 may receive a value (net = I0 * W0 + ... + In * Wn, where W is a weighting factor), which is a result calculated by the total nodes and weights of the input layer. have. Thereafter, each node of the hidden layer may determine whether to be activated by an activation function. Each node of the hidden layer determines that the corresponding value is activated or not deactivated by satisfying a predetermined reference value, which is performed based on an activation function. In addition, a weighting factor W'n corresponding to each node may also exist in a process of connecting each node of the hidden layer to a true node and a false node of the output layer. Since there are 10 nodes in the hidden layer and 2 nodes in the output layer as true nodes and false nodes, the total paths from the hidden layer nodes to the output layer nodes can be 20 in total. Therefore, weight coefficients applied in the step between the hidden layer and the output layer of the {ANN} according to an embodiment of the present invention may be set to a maximum of 20 types (if differently set). Similarly, the node-to-node connection path between the input layer and the hidden layer is (14 input layer node) * (10 hidden layer node) = 140, which is the maximum kind of weighting coefficient between the input layer and the hidden layer. Can be 140. {\textbar}   {\textbar} 4A is a diagram illustrating a comparison table between a training cohort and a test cohort according to an exemplary embodiment of the present invention.  {\textbar}   {\textbar} Referring to {FIG}. 4A, a training cohort (corresponding to training data) that is a data group for learning {ANN} according to an embodiment of the present invention, and a test that is input data inputted to obtain a prediction result in an {ANN} in which learning is completed The cohort (test cohort, corresponding to test data) is shown.  {\textbar}   {\textbar} 4A shows that 109 data (76 in the training cohort and 33 in the test cohort) were used for modeling and testing the {ANN} according to an embodiment of the present invention. According to various embodiments of the present disclosure, in order for the {ANN} to derive an optimal weight coefficient through the learning process, the minimum number of patients may be set by the designer. According to various embodiments of the present disclosure, when the minimum number of persons is set, the {ANN} may determine that a reliable {ANN} algorithm is completed only when learning is performed by inputting data corresponding to a specific number of persons (eg, 76 persons) having the minimum number of persons. Can be. {\textbar}   {\textbar} While the training cohort (learning data) is input to the {ANN} algorithm for which the weighting factor is not completed for the {ANN} modeling, the result of the predicted value and the learning data generated as a result of the calculation of the risk factor data among the training data using the {ANN}. In order to reduce the error of the value, the weighting coefficient may be modified by applying a backpropagation learning algorithm. In other words, the data input to calculate the weighting coefficient applied to the {ANN} to complete the {ANN} modeling is related to risk factor data (e.g., age, gender, duration of balloon inflation during {CAS} procedure, etc.). In addition to the data), all data (actual results) on whether or not the patient actually develops {PHD} may be included. Accordingly, the {ANN} can calculate an error value (difference between the predicted value calculated through the output layer and the actual result value) required when the weighting coefficient is modified in the back propagation step. {\textbar}   {\textbar} The {ANN} may fix the last modified weight coefficient to the weight coefficient of the {ANN} model when the predetermined amount of learning is completed to correct the weight coefficient.  {\textbar}   {\textbar} 4B is a table showing prediction results obtained by injecting a test cohort into an {ANN} according to an embodiment of the present invention.  {\textbar}   {\textbar} True nodes of the output layer of the {ANN} according to an embodiment of the present invention may calculate a value as described in the True column of the table of {FIG}. 4B as a result of processing the data of each patient. Similarly, the False node of the {ANN} according to an embodiment of the present invention may calculate a value as described in the False column as a result of processing the data of each patient. The {ANN} can be calculated as the result of the larger value of False or True. For example, if the True value has a larger value, a value corresponding to True will be derived, allowing the user to predict that the patient will develop {PHD}. {\textbar}   {\textbar} 5 is a graph illustrating the accuracy of {PHD} prediction using {ANN} according to an embodiment of the present invention.  {\textbar}   {\textbar} Referring to {FIG}. 5, the accuracy of {PHD} prediction results using {ANN}, {MLR}, and {SVM} is illustrated in a graph.  {\textbar}   {\textbar} The graph is an {AUROC} (area under the {ROC} curve), and the more accurate the graph is, the closer it is to the upper left. The graph represented by the solid line corresponds to the accuracy of the {PHD} prediction through the {MLR} method, and the graph indicated by the dotted line to the left of the solid line graph is the graph of the accuracy of the {PHD} prediction performed through the {SVM} method. And the graph shown on the left shows the accuracy of {PHD} prediction analyzed using {ANN}. As shown in {FIG}. 5, {PHD} prediction using {ANN} shows a much higher prediction rate than {MLR} and {SVM}. {\textbar}   {\textbar} 6 is a flowchart illustrating a learning process of an {ANN} according to an embodiment of the present invention.  {\textbar}   {\textbar} An electronic device implementing the {ANN} algorithm according to an embodiment of the present disclosure may perform operation 610 for receiving training data. In this case, the learning data may be individually input by a user, or may be collectively input from patient data stored in a medical institution server computer. The learning data may include risk factor data that is data (eg, women) for each risk factor (eg, gender), and data about a result value (eg, occurring) that is whether actual {PHD} is generated. The learning data is data input for learning of the {ANN}, and information about the error between the predicted value obtained by the {ANN} processing the information and the actual result value is required for the learning. Accordingly, the training data must include the actual result. In addition, the learning data may require patient-specific data of a predetermined reference value (eg, 70) or more so that the weight coefficient of the {ANN} can be derived at a sufficiently reliable level. {\textbar}   {\textbar} Thereafter, the electronic device may perform operation 615 of generating an initial prediction value using the {ANN}.  {\textbar}   {\textbar} Thereafter, the electronic device may perform operation 620 of correcting the weighting factor based on an error between the derived initial prediction value and the learning result value (the actual result value input as the learning data). Operation 620 may be an operation using a backpropagation algorithm. Through this process, the electronic device modifies the weight from the weight coefficient applied at the stage close to the output layer.When all input of the prepared training data is completed, the final calculated coefficient is fixed to the weight coefficient of {ANN} to complete the {ANN} model. can do. {\textbar}   {\textbar} When the {ANN} model is completed as described above, test data (data composed only of patient-specific risk factor data) can be input to the {ANN} algorithm to process information. The user may predict the result of the {PHD} based on the information processed through the {ANN}. {\textbar}   {\textbar} 7 is a flowchart illustrating a procedure of {PHD} prediction operation through an {ANN} according to an embodiment of the present invention. {\textbar}   {\textbar} Referring to {FIG}. 7, an electronic device that performs an {ANN} algorithm may perform operation 710 for receiving test data. In this case, the test data may refer to risk factor data of a patient (eg, a patient ahead of a carotid artery stent implantation) at a time point at which {PHD} is not generated. In this case, the test data may be input for the purpose of determining whether each patient has a {PHD} or may be input for the purpose of checking the accuracy of the {ANN} modeling is completed. According to an embodiment of the present invention, the test data for determining the information processing accuracy of the {ANN} may be composed of data for 33 persons. {\textbar}   {\textbar} Thereafter, the electronic device may perform operation 715 to process the input data according to an {ANN} algorithm to which the modified weight coefficient is applied to generate a result value corresponding to True and False, respectively. Thereafter, the electronic device may perform operation 720 to compare a result of a True value and a False value. If the True value is calculated to be greater than the False value, the electronic device may perform operation 725 outputting a result of '{PHD} generation'. On the other hand, if it is determined that the False value is calculated to be larger than the True value, the electronic device may perform operation 730 for outputting a result value such as 'no {PHD} occurs'. {\textbar}   {\textbar} 8 is a block diagram illustrating a configuration of an electronic device that predicts occurrence of {PHD} using an {ANN} according to various embodiments of the present disclosure.  {\textbar}   {\textbar} Referring to {FIG}. 8, the electronic device may include a display unit 810, a communication unit 820, an input unit 830, a storage unit 840, and a controller 850. The storage unit 840 may store patient-specific risk factor data 841. The controller 850 may include an {ANN} 851, a patient data reader 852, a data input unit 853, and an accuracy calculator 854. {\textbar}   {\textbar} The display unit 810 may include a panel, a hologram device, or a projector. The panel may, for example, be implemented to be flexible, transparent, or wearable. The panel may be composed of a touch panel and one module. The hologram device may show a stereoscopic image in the air by using interference of light. The projector may display an image by projecting light onto a screen. The screen may be located, for example, inside or outside the electronic device. According to an embodiment of the present disclosure, the display unit may further include a control circuit for controlling a panel, a hologram device, or a projector. {\textbar}   {\textbar} The display unit 810 according to an embodiment of the present invention performs a function of displaying information (eg, {PHD} prediction result; {PHD} generation, no {PHD} generation) regarding data input to the {ANN} 851 and data calculated as a result of the operation of the {ANN} 851. can do. In addition, the display unit 810 may calculate data regarding a probability of a result processed by the {ANN} 851 according to various embodiments. For example, according to various embodiments, the {ANN} provides not only prediction about whether {PHD} is generated, but also information about what is the probability of occurrence if {PHD} will occur or if it is not expected to occur. Can be calculated together. {\textbar}   {\textbar} The communication unit 820 may use a network for data transmission and reception with another user electronic device or another server, and the type of the network is not particularly limited. The network may be, for example, an {IP} (Internet Protocol) network providing a transmission / reception service of a large amount of data through an Internet protocol ({IP}), or an All {IP} network integrating different {IP} networks. The network may include a wired network, a wireless broadband network, a mobile communication network including {WCDMA}, a high speed downlink packet access ({HSDPA}) network, and a long term evolution ({LTE}) network, {LTE} advanced ({LTE}-A). ), Or one of a mobile communication network including 5G (Five Generation), a satellite communication network, and a Wi-Fi network, or a combination of at least one of them. {\textbar}   {\textbar} The communication unit 820 according to an embodiment of the present invention may support a communication function for receiving patient information, which is data to be input to the {ANN} from another electronic device or an external server. In addition, the communication unit 820 may transmit the information processing result of the {ANN} to another electronic device or an external server. {\textbar}   {\textbar} The input unit 830 may include, for example, a touch panel, a pen sensor, a key, or an ultrasonic input device The touch panel 252 may be, for example, At least one of capacitive, resistive, infrared, or ultrasonic may be used, and the touch panel may further include a control circuit, and the touch panel may further include a tactile layer. It can provide a tactile response to the user. {\textbar}   {\textbar} The input unit 830 according to an embodiment of the present invention may directly receive data corresponding to training data (training cohort) or test data (test cohort). Also, according to various embodiments of the present disclosure, the input unit 830 may receive a user operation for changing an item of data to be input to the {ANN}. For example, the number of nodes included in the input layer of the {ANN} may be basically set to 14. Assuming that the total risk factor is 20 or more, the user may select 14 of the risk factors. The input unit 830 may be used to select a print item. {\textbar}   {\textbar} In addition, a user input according to various embodiments may be required. In this case, the input unit 830 may convert the user input signal into a digital signal and transmit the converted user input signal to the controller 850.  {\textbar}   {\textbar} The storage unit may include, for example, an internal memory or an external memory. The internal memory may be, for example, volatile memory (for example, dynamic {RAM} ({DRAM}), static {RAM} ({SRAM}), or synchronous dynamic {RAM} ({SDRAM}), etc.), non-volatile memory (for example, {OTPROM} (one). time programmable {ROM} ({PROM}), programmable {ROM} ({PROM}), erasable and programmable {ROM} ({EPROM}), electrically erasable and programmable {ROM} ({EEPROM}), mask {ROM}, flash {ROM}, flash memory (such as {NAND} flash or {NOR} flash), hard drives, Or it may include at least one of a solid state drive ({SSD}). {\textbar}   {\textbar} The external memory may be a flash drive such as compact flash ({CF}), secure digital ({SD}), micro secure digital (Micro-{SD}), mini secure digital (Mini-{SD}), extreme digital ({XD}), It may further include a multi-media card ({MMC}) or a memory stick. The external memory may be functionally and / or physically connected to the electronic device through various interfaces. {\textbar}   {\textbar} The storage unit 840 according to an embodiment of the present invention may include risk factor data 841 for each patient. The patient-specific risk factor data 841 are, for example, gender, signs (for stenosis), degree of stenosis (70\% or more), calcification (grade 3 and 4 according to the scale proposed by Runberger). , Ulcer, eccentricity (whether it is eccentric or concentric), dilatability (degree of vasodilation), contralaterality, anesthesia (local anesthesia), balloon inflation time (5 seconds or more), procedure Balloon inflation pressure (whether greater than 8 atmospheres), hypertension, coronary artery disease, stenosis lesions may include whether within a distance of 10mm from the branch. Training data and test data based on the patient-specific risk factor data 841 may be provided to the {ANN}. {\textbar}   {\textbar} In addition, the storage unit 840 may store information on an activation function, a learning rate, a weighting factor, etc. applied to the {ANN} according to an embodiment of the present invention. As the learning of the {ANN} is completed, the weight coefficient stored in the storage unit 840 may also be updated and stored. {\textbar}   {\textbar} The controller 850 may also be referred to as a processor, a controller, a microcontroller, a microprocessor, a microcomputer, or the like. On the other hand, the control unit may be implemented by hardware (hardware) or firmware (firmware), software, or a combination thereof. {\textbar}   {\textbar} In the case of implementation by firmware or software, an embodiment of the present invention may be implemented in the form of a module, procedure, function, etc. that performs the functions or operations described above. The software code may be stored in a memory and driven by the controller. The memory may be located inside or outside the user terminal and the server, and may exchange data with the controller by various known means. {\textbar}   {\textbar} The controller 850 according to an embodiment of the present invention may include an {ANN} 851, a patient data reader 852, a data input unit 853, and an accuracy calculator 854. First, according to an embodiment of the present invention, the {ANN} 851 may process operations such as obtaining a weighted sum based on inputted training data. The {ANN} 851 may perform an information processing operation using a backpropagation algorithm during a learning process. The {ANN} 851 may modify the weight coefficient of a step close to the output layer so that the error between the actual result value and the calculated prediction value is reduced through the backpropagation algorithm. When all learning data prepared through the corresponding operation (eg, risk factor data for 76 persons) are input and the learning operation is completed, the {ANN} 851 may complete the {ANN} model by applying the finally calculated weight coefficient. {\textbar}   {\textbar} Thereafter, the {ANN} 851 may perform an information processing process using the input test data. When data is input, risk factor data may be allocated to each node of an input layer of the {ANN}, and corresponding result values ​​may be calculated to the true and false nodes of the output layer through the hidden layer. After that, a value having a large value (True or False) is calculated as a final prediction result by comparing the values ​​of the True node and the False node. {\textbar}   {\textbar} The patient data reader 852 extracts only data corresponding to a risk factor from information collected from another electronic device or an external server (eg, a related medical institution server) through the communication unit 820 according to an embodiment of the present invention. can do. For example, the information transmitted through the communication unit 820 may include information that does not correspond to the test result, such as the patient's name, date of birth, smoking status, and result information for a specific test (eg, {HIV} infection, blood type, blood pressure, and white blood cell count). Can be. However, among these various items, there may be items that are not related to {PHD} prediction, so that the patient data reader 852 may extract only the items of data that are input to the {ANN} to perform {PHD} prediction. {\textbar}   {\textbar} Also, the patient data reader 852 may determine whether test data (or learning data) of a specific patient satisfies the minimum number of risk factor items (eg, 14) required for {PHD} prediction. If the patient's data item does not satisfy the minimum number of risk factor items required for {PHD} prediction, the patient data reader 852 displays information on the additionally required item for {PHD} prediction on the display unit 810. You can request For example, if it is determined that information on blood pressure is not input among risk factor items for {PHD} prediction of a specific patient, the patient data reader 852 may request to display the blood pressure data of the corresponding patient on the display unit 810. . Alternatively, the patient data reader 852 may transmit a request for additional information to another server or another electronic device (eg, a patient's personal terminal) through the communication unit 820. {\textbar}   {\textbar} The data input unit 853 determines whether the operation of the {ANN} 851 is a learning phase or a test phase according to an embodiment of the present invention, and in the learning phase, the risk factor data of the patient and the actual result value of the patient (actual {PHD} generation). Learning data, including information on whether or not) can be controlled to be input to the {ANN}. On the other hand, if the operating step of the {ANN} is a test step rather than a learning step, the data to be input may be set to include only the risk factor data of the patient. In other words, the data input unit 853 may not perform the learning operation unless the actual result value is included in the information to be input in the learning step, and thus may request additional information. The data input unit 853 may input data into the {ANN} without any problem when the actual result value is not included in the information to be input in the test step. {\textbar}   {\textbar} The accuracy calculator 854 may perform an operation of analyzing the result value of the {ANN} 851 in more detail according to various embodiments of the present disclosure. The basic configuration of the present invention is classified as True or False (calculates only two result values ​​for predicting the occurrence or no occurrence of {PHD}) of the {ANN}, but according to various embodiments, the specific {PHD} by the accuracy calculator 854 according to various embodiments. An occurrence probability calculation may be performed. {\textbar}   {\textbar} The {ANN} 851 compares the values ​​of the true node and the false node to calculate the final value of the side having the larger value. The accuracy calculator 854 may compare the magnitude of the difference between the values ​​of the True node and the False node of the {ANN} 851, or calculate a corresponding {PHD} occurrence probability when it is determined that the True value is less than the reference value or the False value is less than the reference value. Therefore, the accuracy calculator 854 may receive a False value and a True value of the {ANN} 851 and calculate a probability of occurrence of the {PHD} based on a difference between the corresponding values. For example, if the True value is greater than the False value, but the difference is small, the probability of {PHD} in the patient is measured lower than if the difference is noticeable while the True value is greater than the False value. Can {\textbar}   {\textbar}  According to various embodiments of the present disclosure, the electronic device may calculate the most effective risk factor to reduce the probability of occurrence of {PHD} based on the {ANN}. The electronic device may separately select adjustable items such as balloon inflation holding time, stent size, and blood pressure, except for non-adjustable items such as age and gender among the risk factor data. Thereafter, the electronic device may generate comparison data by changing the value of the selected specific item at predetermined intervals. Thereafter, the electronic device may compare the predicted value generated by inserting the raw data into the {ANN} and the predicted value generated by inserting the comparative data into the {ANN}, and if the predicted value (eg, True) generated by the raw data is If the predicted value generated by the calculation (eg, False) is calculated differently, the data value for each risk factor item in which the two values ​​start to be calculated differently may be recorded. For example, if the {PHD} predicted value is True as a result of analyzing the raw data, but the {PHD} predicted value is False as the result of analyzing the comparative data of lowering the blood pressure value by 1, the electronic device may reduce the risk of {PHD} of the patient. Lowering your blood pressure by one or more can produce results. In this manner, various embodiments of the present invention may not only predict whether {PHD} occurs after the {CAS} of the patient, but also calculate and provide numerical information for each risk factor required to prevent {PHD} from occurring. {\textbar}   {\textbar} For reference, in an embodiment of the present invention, the continuous data may be expressed as mean standard deviation ({SD}), and the risk factor of {PHD} may be determined as retrospective data using the {MLR} model of the training cohort. The prospective data of the test cohort can be used as input to the {ANN} model. {\textbar}   {\textbar} According to various embodiments of the present disclosure, in order to automatically identify a high risk group patient of the {PHD} in the electronic device, image recognition based on a convolutional neural network ({CNN}) may be additionally performed. This means that even if the medical staff who recognizes the image does not input data on the patient, the relevant data can be automatically fed to {ANN} based on the image recognition. For example, in data input on whether or not the stenosis is less than 10mm from the branch, {CNN}-based image recognition technology automatically identifies the patient's input layer as soon as the image is captured. It can be possible to be injected into a node. {\textbar}   {\textbar} In addition, according to an embodiment of the present invention, although training data of 14 items for 76 people was used for learning, it is preferable to reduce the number of items or increase the amount of data in order to prevent over application.  {\textbar}   {\textbar} Although the present invention has been described in detail with reference to the above examples, those skilled in the art can make modifications, changes, and variations to the examples without departing from the scope of the invention. In short, in order to achieve the intended effect of the present invention, it is not necessary to separately include all the functional blocks shown in the drawings or to follow all the orders shown in the drawings in the order shown; Note that it may fall within the scope. {\textbar}   {\textbar} 810: display unit 820: communication unit 830: input unit 840: storage unit 841: Risk Factor Data by Patient 850 control unit 851: {ANN} 852: Patient Data Reader 853: Data input section 854: accuracy calculation unit
Issue: {KR}2009840B1},
}

@patent{dilorenzo16b,
	location = {{US}},
	title = {Methods and systems for determining subject-specific parameters for a neuromodulation therapy},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {A neurological control system for modulating activity of any component or structure comprising the entirety or portion of the nervous system, or any structure interfaced thereto, generally referred to herein as a “nervous system component.” The neurological control system generates neural modulation signals delivered to a nervous system component through one or more neuromodulators to control neurological state and prevent neurological signs and symptoms. Such treatment parameters may be derived from a neural response to previously delivered neural modulation signals sensed by one or more sensors, each configured to sense a particular characteristic indicative of a neurological or psychiatric condition.
A neurological control system for modulating activity of any component or structure comprising the entirety or portion of the nervous system, or any structure interfaced thereto, generally referred to herein as a “nervous system component.” The neurological control system generates neural modulation signals delivered to a nervous system component through one or more neuromodulators to control neurological state and prevent neurological signs and symptoms. Such treatment parameters may be derived from a neural response to previously delivered neural modulation signals sensed by one or more sensors, each configured to sense a particular characteristic indicative of a neurological or psychiatric condition.
A neurological control system for modulating activity of any component or structure comprising the entirety or portion of the nervous system, or any structure interfaced thereto, generally referred to herein as a “nervous system component.” The neurological control system generates neural modulation signals delivered to a nervous system component through one or more neuromodulators to control neurological state and prevent neurological signs and symptoms. Such treatment parameters may be derived from a neural response to previously delivered neural modulation signals sensed by one or more sensors, each configured to sense a particular characteristic indicative of a neurological or psychiatric condition.},
	type = {patent},
	author = {{DiLorenzo}, Daniel John},
	urldate = {2006-12-29},
	date = {2016-04-26},
	note = {Edition: A61N000100 {\textbar} A61N000136 {CPC}  - A61B00054094 {\textbar} A61B00050816 {\textbar} A61B00051101 {\textbar} A61B000524 {\textbar} A61B0005316 {\textbar} A61B0005369 {\textbar} A61B0005389 {\textbar} A61B00054082 {\textbar} A61B00054839 {\textbar} A61N00010529 {\textbar} A61N000136064 {\textbar} A61N000136067 {\textbar} A61N000136082 {\textbar} A61N000136139 {\textbar} A61N0001372 {\textbar} A61B00056852 {\textbar} A61B00056864 {\textbar} A61B00056868 {\textbar} A61B00056882 {\textbar} A61B00057203 {\textbar} A61N00010531 {\textbar} A61N00010539 {\textbar} A61N000136114 {\textbar} A61N00013787 {EP}; {US} {US}
Issue: {US}9320900B2
Number Of Volumes: 001001 10.1016/0887-8994(95)00021-7 {\textbar} 10.1046/j.1528-1157.2002.15702.x {\textbar} 10.1016/S1525-5050(03)00105-7 {\textbar} 10.1002/ana.10323 {\textbar} 10.1097/00004691-200309000-00004 {\textbar} 10.1007/s00422-002-0368-4 {\textbar} 10.1016/S1388-2457(02)00032-9 {\textbar} 10.1097/00004691-200105000-00003 {\textbar} 10.1109/{TBME}.2003.809497 {\textbar} 10.1016/S0167-2789(00)00087-7 {\textbar} 10.1016/S0920-1211(03)00002-0 {\textbar} 10.1016/S1388-2457(01)00712-X {\textbar} 10.1016/j.medengphy.2004.02.006 {\textbar} 10.1007/{BF}02345078 {\textbar} 10.1109/{TBME}.2003.810688 {\textbar} 10.1016/j.physd.2004.02.013 {\textbar} 10.1097/00019052-200204000-00008 {\textbar} 10.1016/S1474-4422(02)00003-0 {\textbar} 10.1016/S0025-5564(03)00100-7 {\textbar} 10.1023/A:1027415927155 {\textbar} 10.1097/00004691-200105000-00002 {\textbar} 10.1016/S0140-6736(03)12780-8 {\textbar} 10.1103/{PhysRevLett}.91.068102 {\textbar} 10.1016/j.crvi.2003.09.011 {\textbar} 10.1016/S1388-2457(02)00344-9 {\textbar} 10.1097/00004691-200105000-00005 {\textbar} 10.1109/{TBME}.2003.810708 {\textbar} 10.1023/A:1009877331765 {\textbar} 10.1109/{TBME}.2003.810693 {\textbar} 10.1109/81.904882 {\textbar} 10.1109/{TBME}.2003.810696 {\textbar} 10.1007/s00422-004-0463-9 {\textbar} 10.1016/S1388-2457(00)00543-5 {\textbar} 10.1385/{NI}:2:3:333 {\textbar} 10.1093/brain/awg265 {\textbar} 10.1109/{TBME}.2004.826642 {\textbar} 10.1016/0167-2789(92)90102-S {\textbar} 10.1111/j.1528-1157.1997.tb01250.x {\textbar} 10.1007/{BF}02524422 {\textbar} 10.1111/j.1528-1157.1998.tb01430.x {\textbar} 10.1038/2667 {\textbar} 10.1016/0013-4694(91)90054-8 {\textbar} 10.1016/0920-1211(94)90081-7 {\textbar} 10.1177/107385849600200213 {\textbar} 10.1109/5254.708428 {\textbar} 10.1016/0013-4694(88)90171-X {\textbar} 10.1046/j.1460-9568.1998.00090.x {\textbar} 10.1016/j.mee.2004.01.026 What is claimed is: {\textbar}   {\textbar} 1. A method of monitoring a subject, the method comprising:  {\textbar} monitoring high frequency head vibration, muscle vibration, or speech production using an acoustic sensor mounted in the subject's head and coupled to a stimulating and recording circuit contained in an enclosure implanted in the subject; {\textbar}   {\textbar} monitoring head movement and position with respect to gravity using an accelerometer mounted in the patient's head and coupled to the stimulating and recording circuit; {\textbar}   {\textbar} delivering a first neuromodulation therapy with the stimulating and recording circuit to manage a neurological symptom of the subject, wherein the first neuromodulation therapy is specified by a first set of parameters derived at least in part from a comparison of a disease state estimate and a reference input corresponding to a target disease state, wherein the disease state estimate is based at least in part on a patient motion signal of the accelerometer and an acoustic signal of the acoustic sensor; {\textbar}   {\textbar} recording the subject's response to the first neuromodulation therapy with the stimulating and recording circuit, the subject's response to the first neuromodulation therapy being calculated from a first set of data received from the accelerometer communicating with the subject and the acoustic sensor; {\textbar}   {\textbar} wirelessly transmitting the subject's response to the first neuromodulation therapy from the stimulating and recording circuit to an external device that is external to the subject's body; {\textbar}   {\textbar} delivering a second neuromodulation therapy with the stimulating and recording circuit, the second neuromodulation therapy specified by a second set of parameters, wherein the second set of parameters is defined by at least one parameter of the first set of parameters being automatically changed to a different value to provide the second set of parameters; {\textbar}   {\textbar} recording the subject's response to the second neuromodulation therapy with the stimulating and recording circuit, the subject's response to the second neuromodulation therapy being calculated from a second set of data received from the accelerometer and the acoustic sensor; {\textbar}   {\textbar} wirelessly transmitting the subject's response to the second neuromodulation therapy from the stimulating and recording circuit to the external device; and {\textbar}   {\textbar} monitoring the responses to the first neuromodulation therapy and the second neuromodulation therapy from the external device. {\textbar}   {\textbar} 2. The method of  {\textbar} claim 1 {\textbar}  wherein the monitoring of the responses comprises analyzing at least the first and second sets of data to determine an optimized set of parameters for a later delivered neuromodulation therapy. {\textbar} 3. The method of  {\textbar} claim 2 {\textbar}  wherein the first neuromodulation therapy and the second neuromodulation therapy are delivered to the subject using an implanted neuromodulation system, the method further comprising:  {\textbar} wirelessly programming the implanted neuromodulation system with the optimized set of parameters. {\textbar}   {\textbar} 4. The method of  {\textbar} claim 2 {\textbar}  wherein the first neuromodulation therapy and the second neuromodulation therapy are delivered to the subject using an implanted neuromodulation system, wherein the implanted neuromodulation system is automatically programmed to use the optimized set of parameters for the later delivered neuromodulation therapy. {\textbar} 5. The method of  {\textbar} claim 1 {\textbar}  wherein the monitoring of the responses comprises analyzing the subject's response to the first neuromodulation therapy and the subject's response to the second neuromodulation therapy to determine an efficacy of at least one of the first neuromodulation therapy and the second neuromodulation therapy. {\textbar} 6. The method of  {\textbar} claim 1 {\textbar}  wherein the monitoring of the responses comprises recording at least one of the first set of parameters, the subject's response to the first neuromodulation therapy, the second set of parameters, and the subject's response to the second neuromodulation therapy, and wherein the recording is performed in a memory of the external device. {\textbar} 7. The method of  {\textbar} claim 1 {\textbar}  wherein the first neuromodulation therapy and/or the second neuromodulation therapy comprises an electrical stimulation delivered via at least one electrode and the different value comprises at least one of electrode configuration, stimulation current, stimulation voltage, stimulation frequency, pulse width, frequency of pulses within a burst, pulses per burst, frequency of bursts, duration of bursts, and pulse train count. {\textbar} 8. The method of  {\textbar} claim 1 {\textbar}  wherein at least one of the first and second neuromodulation therapies comprises vagus nerve stimulation. {\textbar} 9. The method of  {\textbar} claim 1 {\textbar}  wherein the accelerometer is one of a plurality of accelerometers. {\textbar} 10. The method of  {\textbar} claim 1 {\textbar}  wherein the recording of at least the subject's response to the first neuromodulation therapy and the subject's response to the second neuromodulation therapy comprises using a physiological sensor communicating with the subject. {\textbar} 11. The method of  {\textbar} claim 10 {\textbar}  wherein the physiological sensor is configured to sense subject respiration. {\textbar} 12. The method of  {\textbar} claim 1 {\textbar}  wherein the external device is configured to report a neurological state of the subject. {\textbar} 13. The method of  {\textbar} claim 1 {\textbar} , further comprising:  {\textbar} monitoring subject movement using an enclosure mounted accelerometer contained in the enclosure and coupled to the stimulating and recording circuit; and {\textbar}   {\textbar} monitoring muscle vibration using a second acoustic sensor coupled to the stimulating and recording circuit. What is claimed is: {\textbar}   {\textbar} 1. A method of monitoring a subject, the method comprising:  {\textbar} monitoring high frequency head vibration, muscle vibration, or speech production using an acoustic sensor mounted in the subject's head and coupled to a stimulating and recording circuit contained in an enclosure implanted in the subject; {\textbar}   {\textbar} monitoring head movement and position with respect to gravity using an accelerometer mounted in the patient's head and coupled to the stimulating and recording circuit; {\textbar}   {\textbar} delivering a first neuromodulation therapy with the stimulating and recording circuit to manage a neurological symptom of the subject, wherein the first neuromodulation therapy is specified by a first set of parameters derived at least in part from a comparison of a disease state estimate and a reference input corresponding to a target disease state, wherein the disease state estimate is based at least in part on a patient motion signal of the accelerometer and an acoustic signal of the acoustic sensor; {\textbar}   {\textbar} recording the subject's response to the first neuromodulation therapy with the stimulating and recording circuit, the subject's response to the first neuromodulation therapy being calculated from a first set of data received from the accelerometer communicating with the subject and the acoustic sensor; {\textbar}   {\textbar} wirelessly transmitting the subject's response to the first neuromodulation therapy from the stimulating and recording circuit to an external device that is external to the subject's body; {\textbar}   {\textbar} delivering a second neuromodulation therapy with the stimulating and recording circuit, the second neuromodulation therapy specified by a second set of parameters, wherein the second set of parameters is defined by at least one parameter of the first set of parameters being automatically changed to a different value to provide the second set of parameters; {\textbar}   {\textbar} recording the subject's response to the second neuromodulation therapy with the stimulating and recording circuit, the subject's response to the second neuromodulation therapy being calculated from a second set of data received from the accelerometer and the acoustic sensor; {\textbar}   {\textbar} wirelessly transmitting the subject's response to the second neuromodulation therapy from the stimulating and recording circuit to the external device; and {\textbar}   {\textbar} monitoring the responses to the first neuromodulation therapy and the second neuromodulation therapy from the external device. {\textbar}   {\textbar} 2. The method of  {\textbar} claim 1 {\textbar}  wherein the monitoring of the responses comprises analyzing at least the first and second sets of data to determine an optimized set of parameters for a later delivered neuromodulation therapy. {\textbar} 3. The method of  {\textbar} claim 2 {\textbar}  wherein the first neuromodulation therapy and the second neuromodulation therapy are delivered to the subject using an implanted neuromodulation system, the method further comprising:  {\textbar} wirelessly programming the implanted neuromodulation system with the optimized set of parameters. {\textbar}   {\textbar} 4. The method of  {\textbar} claim 2 {\textbar}  wherein the first neuromodulation therapy and the second neuromodulation therapy are delivered to the subject using an implanted neuromodulation system, wherein the implanted neuromodulation system is automatically programmed to use the optimized set of parameters for the later delivered neuromodulation therapy. {\textbar} 5. The method of  {\textbar} claim 1 {\textbar}  wherein the monitoring of the responses comprises analyzing the subject's response to the first neuromodulation therapy and the subject's response to the second neuromodulation therapy to determine an efficacy of at least one of the first neuromodulation therapy and the second neuromodulation therapy. {\textbar} 6. The method of  {\textbar} claim 1 {\textbar}  wherein the monitoring of the responses comprises recording at least one of the first set of parameters, the subject's response to the first neuromodulation therapy, the second set of parameters, and the subject's response to the second neuromodulation therapy, and wherein the recording is performed in a memory of the external device. {\textbar} 7. The method of  {\textbar} claim 1 {\textbar}  wherein the first neuromodulation therapy and/or the second neuromodulation therapy comprises an electrical stimulation delivered via at least one electrode and the different value comprises at least one of electrode configuration, stimulation current, stimulation voltage, stimulation frequency, pulse width, frequency of pulses within a burst, pulses per burst, frequency of bursts, duration of bursts, and pulse train count. {\textbar} 8. The method of  {\textbar} claim 1 {\textbar}  wherein at least one of the first and second neuromodulation therapies comprises vagus nerve stimulation. {\textbar} 9. The method of  {\textbar} claim 1 {\textbar}  wherein the accelerometer is one of a plurality of accelerometers. {\textbar} 10. The method of  {\textbar} claim 1 {\textbar}  wherein the recording of at least the subject's response to the first neuromodulation therapy and the subject's response to the second neuromodulation therapy comprises using a physiological sensor communicating with the subject. {\textbar} 11. The method of  {\textbar} claim 10 {\textbar}  wherein the physiological sensor is configured to sense subject respiration. {\textbar} 12. The method of  {\textbar} claim 1 {\textbar}  wherein the external device is configured to report a neurological state of the subject. {\textbar} 13. The method of  {\textbar} claim 1 {\textbar} , further comprising:  {\textbar} monitoring subject movement using an enclosure mounted accelerometer contained in the enclosure and coupled to the stimulating and recording circuit; and {\textbar}   {\textbar} monitoring muscle vibration using a second acoustic sensor coupled to the stimulating and recording circuit. 1. A method of monitoring a subject, the method comprising:  {\textbar} monitoring high frequency head vibration, muscle vibration, or speech production using an acoustic sensor mounted in the subject's head and coupled to a stimulating and recording circuit contained in an enclosure implanted in the subject; {\textbar}   {\textbar} monitoring head movement and position with respect to gravity using an accelerometer mounted in the patient's head and coupled to the stimulating and recording circuit; {\textbar}   {\textbar} delivering a first neuromodulation therapy with the stimulating and recording circuit to manage a neurological symptom of the subject, wherein the first neuromodulation therapy is specified by a first set of parameters derived at least in part from a comparison of a disease state estimate and a reference input corresponding to a target disease state, wherein the disease state estimate is based at least in part on a patient motion signal of the accelerometer and an acoustic signal of the acoustic sensor; {\textbar}   {\textbar} recording the subject's response to the first neuromodulation therapy with the stimulating and recording circuit, the subject's response to the first neuromodulation therapy being calculated from a first set of data received from the accelerometer communicating with the subject and the acoustic sensor; {\textbar}   {\textbar} wirelessly transmitting the subject's response to the first neuromodulation therapy from the stimulating and recording circuit to an external device that is external to the subject's body; {\textbar}   {\textbar} delivering a second neuromodulation therapy with the stimulating and recording circuit, the second neuromodulation therapy specified by a second set of parameters, wherein the second set of parameters is defined by at least one parameter of the first set of parameters being automatically changed to a different value to provide the second set of parameters; {\textbar}   {\textbar} recording the subject's response to the second neuromodulation therapy with the stimulating and recording circuit, the subject's response to the second neuromodulation therapy being calculated from a second set of data received from the accelerometer and the acoustic sensor; {\textbar}   {\textbar} wirelessly transmitting the subject's response to the second neuromodulation therapy from the stimulating and recording circuit to the external device; and {\textbar}   {\textbar} monitoring the responses to the first neuromodulation therapy and the second neuromodulation therapy from the external device. 1. A method of monitoring a subject, the method comprising:  {\textbar} monitoring high frequency head vibration, muscle vibration, or speech production using an acoustic sensor mounted in the subject's head and coupled to a stimulating and recording circuit contained in an enclosure implanted in the subject; {\textbar}   {\textbar} monitoring head movement and position with respect to gravity using an accelerometer mounted in the patient's head and coupled to the stimulating and recording circuit; {\textbar}   {\textbar} delivering a first neuromodulation therapy with the stimulating and recording circuit to manage a neurological symptom of the subject, wherein the first neuromodulation therapy is specified by a first set of parameters derived at least in part from a comparison of a disease state estimate and a reference input corresponding to a target disease state, wherein the disease state estimate is based at least in part on a patient motion signal of the accelerometer and an acoustic signal of the acoustic sensor; {\textbar}   {\textbar} recording the subject's response to the first neuromodulation therapy with the stimulating and recording circuit, the subject's response to the first neuromodulation therapy being calculated from a first set of data received from the accelerometer communicating with the subject and the acoustic sensor; {\textbar}   {\textbar} wirelessly transmitting the subject's response to the first neuromodulation therapy from the stimulating and recording circuit to an external device that is external to the subject's body; {\textbar}   {\textbar} delivering a second neuromodulation therapy with the stimulating and recording circuit, the second neuromodulation therapy specified by a second set of parameters, wherein the second set of parameters is defined by at least one parameter of the first set of parameters being automatically changed to a different value to provide the second set of parameters; {\textbar}   {\textbar} recording the subject's response to the second neuromodulation therapy with the stimulating and recording circuit, the subject's response to the second neuromodulation therapy being calculated from a second set of data received from the accelerometer and the acoustic sensor; {\textbar}   {\textbar} wirelessly transmitting the subject's response to the second neuromodulation therapy from the stimulating and recording circuit to the external device; and {\textbar}   {\textbar} monitoring the responses to the first neuromodulation therapy and the second neuromodulation therapy from the external device. {CROSS} {REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar}   {\textbar} This application is a continuation of pending application Ser. No. 10/889,844, filed Jul. 12, 2004 now U.S. Pat. No. 7,231,254; which application claims benefit of U.S. Provisional Application No. 60/562,487, filed Apr. 14, 2004, and is a continuation-in-part of U.S. application Ser. No. 10/818,333, filed Apr. 5, 2004 now U.S. Pat. No. 7,277,758, which, in turn, claims benefit of U.S. Provisional Application No. 60/460,140, filed Apr. 3, 2003; U.S. application Ser. No. 10/818,333 is also a continuation-in-part of U.S. application Ser. No. 10/753,205, filed Jan. 6, 2004 now U.S. Pat. No. 7,242,984, which claims the benefit of U.S. Provisional Application No. 60/438,286, filed Jan. 6, 2003; U.S. application Ser. No. 10/753,205 is also a continuation-in-part of U.S. application Ser. No. 10/718,248, filed Nov. 20, 2003 now U.S. Pat. No. 7,209,787; which is a continuation-in-part of U.S. application Ser. No. 10/008,576, filed Nov. 11, 2001, now U.S. Pat. No. 6,819,956; which is a continuation-in-part of U.S. application Ser. No. 09/340,326, filed Jun. 25, 1999, now U.S. Pat. No. 6,366,813; which claims the benefit of U.S. Provisional Application No. 60/095,413, filed Aug. 5, 1998; U.S. application Ser. No. 10/718,248 also claims benefit of U.S. Provisional Application Nos. 60/427,699, filed Nov. 20, 2002, and 60/436,792, filed Dec. 27, 2002. {\textbar}   {\textbar} {BACKGROUND} {OF} {THE} {INVENTION} {\textbar}   {\textbar} 1. Field of the Invention {\textbar}   {\textbar} The present invention relates generally to neurological disease and, more particularly, to intracranial stimulation for optimal control of movement disorders and other neurological disease. {\textbar}   {\textbar} 2. Related Art {\textbar}   {\textbar} There are a wide variety of treatment modalities for neurological disease including movement disorders such as Parkinson's disease, Huntington's disease, and Restless Leg Syndrome, as well as psychiatric disease including depression, bipolar disorder and borderline personality disorders. These treatment modalities are moderately efficacious; however, they suffer from several severe drawbacks. Each of these traditional treatment modalities and their associated limitations are described below. {\textbar}   {\textbar} One common conventional technique for controlling neurological disease includes the use of dopaminergic agonists or anticholinergic agents. Medical management using these techniques requires considerable iteration in dosing adjustments before an “optimal” balance between efficacy and side effect minimization is achieved. Variation, including both circadian and postprandial variations, causes wide fluctuation in symptomatology. This commonly results in alternation between “on” and “off” periods during which the patient possesses and loses motor functionality, respectively. {\textbar}   {\textbar} Another traditional approach for controlling movement disorders is tissue ablation. Tissue ablation is most commonly accomplished through stereotactic neurosurgical procedures, including pallidotomy, thalamotomy, subthalamotomy, and other lesioning procedures. These procedures have been found to be moderately efficacious. However, in addition to posing risks that are inherent to neurosurgical operations, these procedures suffer from a number of fundamental limitations. One such limitation is that tissue removal or destruction is irreversible. As a result, excessive or inadvertent removal of tissue cannot be remedied. {\textbar}   {\textbar} Furthermore, undesirable side effects, including compromise of vision and motor or sensory functions, are likely to be permanent conditions. In particular, bilateral interventions place the patient at considerable risk for developing permanent neurologic side effects, including incontinence, aphasia, and grave psychic disorders. An additional drawback to this approach is that the “magnitude” of treatment is constant. That is, it is not possible to vary treatment intensity over time, as may be required to match circadian, postprandial, and other fluctuations in symptomatology and consequent therapeutic needs. Thus, decrease in treatment “magnitude” is not possible while an increase in treatment “magnitude” necessitates reoperation. Some adjustment is possible through augmentation with pharmacologic treatment; however, these additional treatments are subject to the above-noted limitations related to drug therapy. {\textbar}   {\textbar} Another traditional approach for controlling movement disorders and other neurological disease includes tissue transplantation, typically from animal or human mesencephalic cells. Although tissue transplantation in humans has been performed for many years, it remains experimental and is limited by ethical concerns when performed using a human source. Furthermore, graft survival, as well as subsequent functional connection with intracranial nuclei, are problematic. The yield, or percentage of surviving cells, is relatively small and is not always predictable, posing difficulties with respect to the control of treatment “magnitude.” {\textbar}   {\textbar} Another traditional approach for controlling neurological disease is the continuous electrical stimulation of a predetermined neurological region. Chronic high frequency intracranial electrical stimulation is typically used to inhibit cellular activity in an attempt to functionally replicate the effect of tissue ablation, such as pallidotomy and thalamotomy. Acute electrical stimulation and electrical recording and impedance measuring of neural tissue have been used for several decades in the identification of brain structures for both research purposes as well as for target localization during neurosurgical operations for a variety of neurological diseases. During intraoperative electrical stimulation, reduction in tremor has been achieved using frequencies typically on the order of 75 to 330 Hz. Based on these findings, chronically implanted constant-amplitude electrical stimulators have been implanted in such sites as the thalamus, subthalamic nucleus and globus pallidus. {\textbar}   {\textbar} Chronic constant-amplitude stimulation has been shown to be moderately efficacious. However, it has also been found to be limited by the lack of responsiveness to change in patient system symptomatology and neuromotor function. Following implantation, a protracted phase of parameter adjustment, typically lasting several weeks to months, is endured by the patient while stimulation parameters are interactively adjusted during a series of patient appointments. Once determined, an “acceptable” treatment magnitude is maintained as a constant stimulation level. A drawback to this approach is that the system is not responsive to changes in patient need for treatment. Stimulation is typically augmented with pharmacological treatment to accommodate such changes, causing fluctuation of the net magnitude of treatment with the plasma levels of the pharmacologic agent. {\textbar}   {\textbar} As noted, while the above and other convention treatment modalities offer some benefit to patients with movement disorders, their efficacy is limited. For the above-noted reasons, with such treatment modalities it is difficult and often impossible to arrive at an optimal treatment “magnitude,” that is, an optimal dose or intensity of treatment. Furthermore, patients are subjected to periods of overtreatment and undertreatment due to variations in disease state. Such disease state variations include, for example, circadian fluctuations, postprandial (after meal) and nutrition variations, transients accompanying variations in plasma concentrations of pharmacological agents, chronic progression of disease, and others. {\textbar}   {\textbar} Moreover, a particularly significant drawback to the above and other traditional treatment modalities is that they suffer from inconsistencies in treatment magnitude. For example, with respect to drug therapy, a decrease in responsiveness to pharmacologic agents eventually progresses to eventually preclude effective pharmacologic treatment. With respect to tissue ablation, progression of disease often necessitates reoperation to extend pallidotomy and thalamotomy lesion dimensions. Regarding tissue transplantation, imbalances between cell transplant formation rates and cell death rates cause unanticipated fluctuations in treatment magnitude. For continuous electrical stimulation, changes in electrode position, electrode impedance, as well as patient responsiveness to stimulation and augmentative pharmacologic agents, cause a change in response to a constant magnitude of therapy. {\textbar}   {\textbar} Currently, magnets commonly serve as input devices used by patients with implantable stimulators, including deep brain stimulators, pacemakers, and spinal cord stimulators. Current systems require the patient to manually turn the system off at night time to conserve battery power and use such magnets to maintain system power. This presents considerable difficulty to many patients whose tremor significantly impairs arm function, as they are unable to hold a magnet in a stable manner over the implanted electronics module. Consequently, many patients are unable to turn their stimulators on in the morning without assistance. {\textbar}   {\textbar} What is needed, therefore, is an apparatus and method for treatment of patients with neurological disease in general and movement disorders in particular that is capable of determining and providing an optimal dose or intensity of treatment. Furthermore, the apparatus and method should be responsive to unpredictable changes in symptomatology and minimize alternations between states of overtreatment and undertreatment. The system should also be capable of anticipating future changes in symptomatology and neuromotor functionality, and being responsive to such changes when they occur. {\textbar}   {\textbar} {SUMMARY} {OF} {THE} {INVENTION} {\textbar}   {\textbar} One aspect of the invention is a method of monitoring a subject's response to a plurality of neuromodulation therapies. The method comprises delivering a neuromodulation therapy that is adapted to prevent and/or manage a symptom of a subject suffering from a neurological or psychiatric disorder, wherein the neuromodulation therapy is specified by a set of parameters, recording the set of parameters of the neuromodulation therapy and a subject's response to the neuromodulation therapy, delivering a subsequent neuromodulation therapy to the subject, wherein at least one parameter of the set of parameters of the subsequent neuromodulation therapy is automatically changed relative to the set of parameters of the previously delivered neuromodulation therapy, and recording the set of parameters of the subsequent neuromodulation therapy and a subject's response to the subsequent neuromodulation therapy. {\textbar}   {\textbar} In some embodiments the symptom comprises seizure activity and the neurological disorder comprises epilepsy. {\textbar}   {\textbar} In some embodiments recording the set of parameters of the neuromodulation therapy and the subject's response to the neuromodulation therapy and recording the set of parameters of the subsequent neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy are performed in a memory in an implantable neuromodulation system. The method can further include wirelessly transmitting data that is indicative of the recorded parameters of the neuromodulation therapy and the subject's response to the neuromodulation therapy and data that is indicative of the recorded set of parameters of the subsequent neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy from the memory of the implanted neuromodulation system to a memory of an external device that is external to the subject's body. {\textbar}   {\textbar} In some embodiments the method also includes analyzing the data that is indicative of the subject's response to the neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy to determine a substantially optimal set of parameters for a later delivered neuromodulation therapy. The neuromodulation therapy and the subsequent neuromodulation therapy can be delivered to the subject using an implantable neuromodulation system. In some embodiments the method further comprises wirelessly programming the implantable neuromodulation system with the determined optimal parameters, while in some embodiments the implantable neuromodulation system is automatically programmed to use the substantially optimal set of stimulation parameters for a later delivered neuromodulation therapy. {\textbar}   {\textbar} In some embodiments the method also includes analyzing the subject's response to the neuromodulation therapy and subject's response to the subsequent neuromodulation therapy to determine efficacy of the neuromodulation therapy and efficacy of the subsequent neuromodulation therapy. {\textbar}   {\textbar} In some embodiments the method also includes wirelessly transmitting data that is indicative of the set of parameters of the neuromodulation therapy and the subject's response to the neuromodulation therapy and data that is indicative of the set of parameters of the subsequent neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy from an implantable neuromodulation system to a memory of a device external to the subject's body, where recording the parameters of the neuromodulation therapy and the subject's response to the neuromodulation therapy and recording the parameters of the subsequent neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy are performed in the memory of the device external to the subject's body. {\textbar}   {\textbar} In some embodiments the neuromodulation therapy comprises electrical stimulation delivered via electrodes and the set of parameters comprises at least one of electrode configuration, stimulation current, stimulation voltage, stimulation frequency, pulse width, frequency of pulses within a burst, pulses per burst, frequency of bursts, duration of bursts, and pulse train count. {\textbar}   {\textbar} In some embodiments the neuromodulation therapy comprises intracranial electrical stimulation. In some embodiments the neuromodulation therapy comprises peripheral nerve electrical stimulation such as vagus nerve electrical stimulation. {\textbar}   {\textbar} In some embodiments the neuromodulation therapy comprises delivery of medications. Delivery of medications can be performed with an implanted medication dispenser. {\textbar}   {\textbar} In some embodiments the neuromodulation therapy and subsequent neuromodulation therapy(ies) are delivered when the symptom is detected and/or predicted through analysis of an {EEG} signal from the subject. {\textbar}   {\textbar} In some embodiments the subject's response comprises a brain activity response that is monitored with one or more brain electrodes that are in communication with the implantable neuromodulation system. {\textbar}   {\textbar} Another aspect of the invention is a method of determining patient-specific, substantially optimal stimulation parameters of a stimulation signal for managing a patient with epilepsy. The method includes analyzing an {EEG} signal from a patient to detect and/or predict seizure activity, delivering a first stimulation signal to the patient with an implanted stimulation and recording unit when the analysis of the {EEG} signal detects and/or predicts seizure activity, wherein the stimulation signal comprises a set of stimulation parameters, recording the patient's response to the first stimulation signal, automatically determining parameters for a second stimulation signal, wherein the second stimulation signal comprises at least one changed parameter from the set of predetermined stimulation parameters of the first stimulation signal, delivering the second stimulation signal with the implanted stimulation and recording unit when analysis of the {EEG} signal from the patient detects and/or predicts subsequent seizure activity, recording the patient's response to the second stimulation signal, wirelessly transmitting data that is indicative of the patient's response to the first stimulation signal, the set of parameters of the first stimulation signal, response to the second stimulation signal, and set of parameter of the second stimulation signal to a device that is external to the patient's body, analyzing the patient's response to the first stimulation signal and response to the second stimulation signal to determine substantially optimal stimulation parameters, and programming the implanted stimulation and recording unit with the determined substantially optimal stimulation parameters. {\textbar}   {\textbar} Another aspect of the invention is a system for delivering a neural modulation output to a subject suffering from a neurological or psychiatric disorder. The system includes an assembly adapted to acquire a signal from a subject that is indicative or predictive of a symptom of the neurological or psychiatric disorder and to deliver a neural modulation output to the subject to manage and/or prevent the symptom of the neurological or psychiatric disorder, an implantable device coupled to the assembly, the implantable device configured to automatically sweep through a plurality of neural modulation outputs that comprise different sets of neural modulation parameters, and a memory that is adapted to store the different sets of stimulation parameters and the subject's response to the neural modulation outputs that comprise different sets of neural modulation parameters. {\textbar}   {\textbar} In some embodiments the neurological disorder comprises epilepsy and the symptom comprises seizure activity. {\textbar}   {\textbar} In some embodiments the memory is disposed in an external device and the system further comprises the external device that is configured to be external to the subject's body and is in wireless communication with the implantable device, the wireless communication being used to transmit the different sets of neural modulation parameters and the subject's response to the neural modulation outputs that comprise different sets of neural modulation outputs from the implantable device to the memory of the external device. At least one of the external device and implantable device can be configured to analyze the subject's response to the neural modulation outputs that comprise different sets of neural modulation parameters to determine efficacy of the neural modulation outputs. The implantable device can sweep through the different sets of neural modulation parameters to determine substantially optimal neural modulation parameters of the neural modulation output to treat the subject's neurological or psychiatric disorder. {\textbar}   {\textbar} In some embodiments the substantially optimal neural modulation parameters are manually programmed by a user using an external device that is in wireless communication with the implantable device. In other embodiments the implantable device is programmed to automatically use the substantially optimal neural modulation parameters for later delivered neural modulation outputs. {\textbar}   {\textbar} In some embodiments the neural modulation output comprises electrical stimulation and the assembly comprises a plurality of electrodes, wherein the neural modulation parameters comprise at least one of electrode configuration, stimulation current, stimulation voltage, stimulation frequency, pulse width, frequency of pulses within a burst, pulses per burst, frequency of bursts, duration of bursts, and pulse train count. {\textbar}   {\textbar} In some embodiments the assembly comprises a plurality of electrodes, wherein a subset of electrodes are configured to acquire the physiological signals and a subset of electrodes are configured to deliver the neural modulation output. {\textbar}   {\textbar} In some embodiments the neuromodulation output comprises intracranial electrical stimulation. In some embodiments the neuromodulation output comprises peripheral nerve electrical stimulation such as vagus nerve electrical stimulation. {\textbar}   {\textbar} In some embodiments the neuromodulation output comprises delivery of medications. {\textbar}   {\textbar} Further features and advantages of the present invention, as well as the structure and operation of various embodiments of the present invention, are described in detail below with reference to the accompanying drawings. {\textbar}   {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar}   {\textbar} The present invention is described with reference to the accompanying drawings. In the drawings, like reference numerals indicate identical or functionally similar elements. {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention implanted bilaterally in a human patient. {\textbar} {FIG}. 2 {\textbar}   {\textbar}  is an architectural block diagram of one embodiment of the neurological control system of the present invention. {\textbar} {FIG}. 3 {\textbar}   {\textbar}  is a block diagram of one embodiment of an intracranial recording electrode ({ICRE}) signal processor and an intracranial stimulating electrode ({ICSE}) signal processor each of which are included within the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 4 {\textbar}   {\textbar}  is a schematic diagram of a globus pallidus implanted with stimulating and recording electrodes in accordance with one embodiment of the present invention. {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a block diagram of one embodiment of an {EMG} signal processor that is included in one embodiment of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 6 {\textbar}   {\textbar}  is a block diagram of one embodiment of an {EEG} signal processor module that is included in one embodiment of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 7 {\textbar}   {\textbar}  is a block diagram of one embodiment of an accelerometer signal processor that is incorporated into certain embodiments of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 8 {\textbar}   {\textbar}  is a block diagram of one embodiment of an acoustic signal processor that is included in certain embodiments of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 9 {\textbar}   {\textbar}  is block diagram of one embodiment of a peripheral nerve electrode ({PNE}) signal processor  {\textbar} 237 {\textbar}  that is implemented in certain embodiments of signal processor  {\textbar} 71 {\textbar} . {PNE} signal {\textbar} {FIG}. 10 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 11 {\textbar}   {\textbar}  is a schematic diagram of the patient-neural modulator system illustrated in  {\textbar} {FIG}. 2 {\textbar}  illustrated to show its controller and observer components. {\textbar} {FIG}. 12 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the control circuit illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 13 {\textbar}   {\textbar}  is a schematic diagram of electrical stimulation waveforms for neural modulation. {\textbar} {FIG}. 14 {\textbar}   {\textbar}  is a schematic diagram of one example of the recorded waveforms. {\textbar} {FIG}. 15 {\textbar}   {\textbar}  is a schematic block diagram of an analog switch used to connect one or an opposing polarity pair of Zener diodes across the noninverting and inverting inputs of an intracranial recording electrode amplifier. {\textbar} {FIG}. 16 {\textbar}   {\textbar}  is a diagram of a two coil embodiment of the power delivery unit. {\textbar} {FIG}. 17 {\textbar}   {\textbar}  is a magnification of the configurations of  {\textbar} {FIGS}. 16 and 18 {\textbar}  showing the magnetic flux penetrating the skin. {\textbar} {FIG}. 18 {\textbar}   {\textbar}  is a diagram of a three coil embodiment of the power delivery unit. {\textbar} {FIG}. 19 {\textbar}   {\textbar}  is a diagram of the power delivery unit with coil holder. {\textbar} {FIG}. 20 {\textbar}   {\textbar}  is a diagram of the coil holder. {\textbar} {FIG}. 21 {\textbar}   {\textbar}  is a diagram of the electromagnetic copies in proximity to the head of a patient. {\textbar} {FIG}. 22 {\textbar}   {\textbar}  is a diagram of multiple coil embodiments. {\textbar} {FIG}. 23 {\textbar}   {\textbar}  is a diagram of the paracranial design, with implanted components in close proximity to the patient's head. {\textbar} {FIG}. 24 {\textbar}   {\textbar}  is a diagram of the power conversion unit that includes the electromagnetic coupling element. {\textbar} {FIG}. 25 {\textbar}   {\textbar}  is a diagram of the power conversion circuit. {\textbar} {FIG}. 26 {\textbar}   {\textbar}  is a diagram of the overall system. {\textbar} {FIG}. 27 {\textbar}   {\textbar}  is a diagram of the stimulating and recording unit. {\textbar} {FIG}. 28 {\textbar}   {\textbar}  is a diagram of the system enclosure secured to the calvarium. {\textbar} {FIG}. 29 {\textbar}   {\textbar}  is a diagram of a lower profile design. {\textbar} {FIG}. 30 {\textbar}   {\textbar}  is a diagram of a lower profile design with the system enclosure partially recessed into the calvarium. {\textbar} {FIG}. 31 {\textbar}   {\textbar}  is a diagram of a lower profile design with the system enclosure fully recessed into the calvarium. {\textbar} {FIG}. 32 {\textbar}   {\textbar}  is a diagram of a second lower profile design with the system enclosure fully recessed into the calvarium. {\textbar} {FIG}. 33 {\textbar}   {\textbar}  is a diagram of a neurological control system. {\textbar} {FIG}. 34 {\textbar}   {\textbar}  is a diagram of a second neurological control system. {\textbar} {FIG}. 35 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention implanted unilaterally in a human patient, with the system enclosure recessed in the calvarium, shown as a lateral view. {\textbar} {FIG}. 36 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention implanted unilaterally in a human patient, with the system enclosure recessed in the calvarium, shown as a anteroposterior view. {\textbar} {FIG}. 37 {\textbar}   {\textbar}  is a schematic diagram of a cross section of calvarium with system enclosure shown implanted recessed within the calvarium. {\textbar} {FIG}. 38 {\textbar}   {\textbar}  is a schematic diagram of a cross section of calvarium with drill bit shown in place after completion of process of drilling hole in calvarium. {\textbar} {FIG}. 39 {\textbar}   {\textbar}  is a schematic diagram of a cross section of calvarium with drill bit, with a penetration detection release mechanism, shown in place after completion of process of drilling hole in calvarium. {\textbar} {FIG}. 40 {\textbar}   {\textbar}  is a diagram depicting the path of the intracranial catheter and its connection to the electrical elements. {\textbar} {FIG}. 41 {\textbar}   {\textbar}  depicts one design for the system enclosure for implantation in the calvarium. {\textbar} {FIGS}. 42 and 43 {\textbar}   {\textbar}  depict a dual intracranial catheter design. {\textbar} {FIG}. 44 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention implanted bilaterally in a human patient. {\textbar} {FIG}. 45 {\textbar}   {\textbar}  is a schematic diagram, lateral view, of one embodiment of the present invention implanted unilaterally in a human patient. {\textbar} {FIG}. 46 {\textbar}   {\textbar}  is a schematic diagram, anteroposterior view, of one embodiment of the present invention implanted unilaterally in a human patient, with multiple catheters and neuromodulators. {\textbar} {FIG}. 47 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention, depicting a set of noninvasive and implanted sensors and neuromodulators in a human patient. {\textbar} {FIG}. 48 {\textbar}   {\textbar}  is a schematic diagram of the dermatomal distributions recruited by neuromodulators. {\textbar} {FIG}. 49 {\textbar}   {\textbar}  is a schematic diagram of a noninvasive version of neurological control system, with sensors and neuromodulators overlying dermatomal distributions recruited by neuromodulators. {\textbar} {FIG}. 50 {\textbar}   {\textbar}  is a functional block diagram of neurological control system, with sensors and neuromodulators implanted in the temporal lobe. {\textbar} {FIG}. 51 {\textbar}   {\textbar}  is a functional block diagram of neurological control system, with sensors and neuromodulators implanted a multiplicity of locations, including the temporal lobe and deep brain regions. {\textbar} {FIG}. 52 {\textbar}   {\textbar}  is a functional block diagram of neurological control system, with sensors and neuromodulators implanted a multiplicity of locations, including the temporal lobe and deep brain regions, showing control input and control output waveforms versus time. {\textbar} {FIG}. 53 {\textbar}   {\textbar}  is a functional block diagram of neurological control system, with sensors and neuromodulators implanted a multiplicity of locations, including the temporal lobe and deep brain regions, showing control input and control output waveforms versus time. {\textbar} {FIG}. 54 {\textbar}   {\textbar}  is a timing diagram showing control input and control output waveforms versus time along with five representative elements of neural state vector X over time, during which time control input deviates outside target range. {\textbar} {FIG}. 55 {\textbar}   {\textbar}  is a timing diagram showing control input and control output waveforms versus time along with five representative elements of neural state vector X over time, during which time control input remains within target range. {\textbar} {FIG}. 56 {\textbar}   {\textbar}  is a timing diagram showing control input and control output waveforms versus time along with five representative elements of neural state vector X over time, during which time control input remains within target range, under conditions with and without the application of a perturbation. {\textbar} {FIG}. 57 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with five representative elements of neural state vector X over time, during which time control input remains within target range, under conditions with and without the application of a perturbation. {\textbar} {FIG}. 58 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input remains within normal range, under conditions without the application of a perturbation. Closed-loop neuromodulation control is turned on for a duration during which time control input is more tightly maintained in control range, a subset of normal range. {\textbar} {FIG}. 59 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input deviates outside normal range into borderline range and into critical range, under conditions without the application of a perturbation. Closed-loop neuromodulation control remains off, and there are no {EEG} abnormalities nor neurological sings or symptoms. {\textbar} {FIG}. 60 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input deviates outside normal range into borderline range and into critical range, under conditions without the application of a perturbation. Closed-loop neuromodulation control remains off, and {EEG} abnormalities develop and are followed by neurological sings or symptoms. {\textbar} {FIG}. 61 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input remains within normal range, under conditions without the application of a perturbation. Closed-loop neuromodulation control remains on, and there are no {EEG} abnormalities nor neurological sings or symptoms. {\textbar} {FIG}. 62 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input deviates outside normal range and closed-loop neuromodulation control is turned on, bringing control input back into control range, which is a subset of normal range. There are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 63 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input deviates outside normal range and closed-loop neuromodulation control is turned on, bringing control input back into control range, which is a subset of normal range, following which time closed-loop neuromodulation control is turned back off. There are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 64 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input decreases but remains inside normal range. Closed-loop neuromodulation control remains off, and there are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 65 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input deviates outside normal range into borderline range and critical range and then returns spontaneously to normal range. Closed-loop neuromodulation control remains off, and there are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 66 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input deviates outside normal range into borderline range and critical range, then back into borderline range and normal range and again into borderline range and critical range, following which {EEG} abnormalities develop and which are followed by neurological sings or symptoms. Closed-loop neuromodulation control remains off during this time. {\textbar} {FIG}. 67 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input decreases but remains inside control range, which is a subset of normal range. Closed-loop neuromodulation control remains on, and there are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 68 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input deviates outside control range yet remains within normal range. Closed-loop neuromodulation control is turned on, and control input is brought back within control range. Control input remains within normal range and there are no {EEG} abnormalities nor neurological signs or symptoms during this time. {\textbar} {DETAILED} {DESCRIPTION} {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the intracranial stimulator of the present invention implanted bilaterally in a human patient. In the embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , two neurological control systems  {\textbar} 999 {\textbar}  are shown implanted bilaterally. Each system  {\textbar} 999 {\textbar}  includes a stimulating and recording unit  {\textbar} 26 {\textbar}  and one or more intracranial components described below. As described in this illustrative embodiment, the intracranial components preferably include a stimulating electrode array  {\textbar} 37 {\textbar} . However, it should become apparent to those of ordinary skill in the relevant art after reading the present disclosure that the stimulating electrodes may also be extracranial; that is, attached to a peripheral nerve in addition to or in place of being located within the cranium. As shown in  {\textbar} {FIG}. 1 {\textbar} , stimulating and recording unit  {\textbar} 26 {\textbar}  of each neurological control system  {\textbar} 999 {\textbar}  is preferably implanted contralateral to the intracranial components of the device. {\textbar} As one skilled in the relevant art would find apparent from the following description, the configuration illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar}  is just one example of the present invention. Many other configurations are contemplated. For example, in alternative embodiments of the present invention, the stimulating and recording unit  {\textbar} 26 {\textbar}  is implanted ipsilateral or bilateral to the intracranial components. It should also be understood that the stimulating and recording unit  {\textbar} 26 {\textbar}  can receive ipsilateral, contralateral or bilateral inputs from sensors and deliver ipsilateral, contralateral, or bilateral outputs to a single or a plurality of intracranial stimulating electrode arrays  {\textbar} 37 {\textbar} . Preferably, these inputs are direct or preamplified signals from at least one of {EMG} electrode array  {\textbar} 50 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , Accelerometer Array  {\textbar} 52 {\textbar} , Acoustic Transducer Array  {\textbar} 53 {\textbar} , Peripheral Nerve Electrode Array  {\textbar} 54 {\textbar} , and Intracranial Recording Electrode Array  {\textbar} 38 {\textbar} . The signals input from these sensors will be referred to herein as “sensory input modalities”  {\textbar} 247 {\textbar} . The outputs include but are not limited to one or more stimulating current signals or stimulating voltage signals to Intracranial Stimulating Electrode Array  {\textbar} 37 {\textbar} . {\textbar} In the embodiment illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , the two unilateral systems  {\textbar} 26 {\textbar}  are shown to receive sensory inputs from the side contralateral as well as the intracranial stimulating electrode arrays  {\textbar} 37 {\textbar} . In the illustrative embodiment, systems  {\textbar} 26 {\textbar}  also receive sensory inputs from intracranial recording electrode arrays  {\textbar} 38 {\textbar} . As will become apparent from the following description, intracranial recording electrode arrays  {\textbar} 38 {\textbar}  may provide valuable feedback information. {\textbar} It should be understood that this depiction is for simplicity only, and that any combination of ipsilateral, contralateral or bilateral combination of each of the multiple sensory input modalities and multiple stimulation output channels may be employed. In addition, stimulating and recording units  {\textbar}   {\textbar} 26 {\textbar}  may be a single device, two communicating devices, or two independent devices. Accordingly, these and other configurations are considered to be within the scope of the present invention. It is anticipated that stimulating and recording units  {\textbar} 26 {\textbar} , if implemented as distinct units, would likely be implanted in separate procedures (soon after clinical introduction) to minimize the likelihood of drastic neurological complications. {\textbar} In the exemplary embodiment illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , the intracranial stimulating electrode array  {\textbar} 37 {\textbar}  includes a plurality of intracranial stimulating electrodes  {\textbar} 1 {\textbar} ,  {\textbar} 2 {\textbar} ,  {\textbar} 3 {\textbar}  and  {\textbar} 4 {\textbar} . Array  {\textbar} 37 {\textbar}  may, of course, have more or fewer electrodes than that depicted in  {\textbar} {FIG}. 1 {\textbar} . These intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar}  may be used to provide stimulation to a predetermined nervous system component. The electrical stimulation provided by the intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar}  may be excitatory or inhibitory, and this may vary in a manner which is preprogrammed, varied in real-time, computed in advance using a predictive algorithm, or determined using another technique now or latter developed. {\textbar} The intracranial recording electrode arrays  {\textbar}   {\textbar} 38 {\textbar}  includes intracranial recording electrodes  {\textbar} 5 {\textbar}  and  {\textbar} 6 {\textbar} . In accordance with one embodiment of the present invention, the intracranial recording electrodes  {\textbar} 5 {\textbar} ,  {\textbar} 6 {\textbar}  are used to record cortical activity as a measure of response to treatment and as a predictor of impeding treatment magnitude requirements. In the illustrative embodiment, intracranial recording electrodes  {\textbar} 5 {\textbar}  and  {\textbar} 6 {\textbar}  are depicted in a location superficial to the intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar} . However, this positioning may be reversed or the intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar}  and intracranial recording electrodes  {\textbar} 5 {\textbar}  and  {\textbar} 6 {\textbar}  may be interspersed in alternative embodiments. For example, these electrodes may be placed in at least one of motor cortex, premotor cortex, supplementary motor cortex, other motor cortical areas, somatosensory cortex, other sensory cortical areas, Wernicke's area, Broca's area, other cortical region, other intracranial region, and other extracranial region. {\textbar} In the illustrative embodiment, an intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  is provided to mechanically support and facilitate electrical connection between intracranial and extracranial structures. In this embodiment, intracranial catheter  {\textbar} 7 {\textbar}  contains one or more wires connecting extracranial stimulating and recording circuit  {\textbar} 26 {\textbar}  to the intracranial electrodes, including but not limited to, intracranial stimulating electrodes  {\textbar} 14 {\textbar}  and intracranial recording electrodes  {\textbar} 5 {\textbar} ,  {\textbar} 6 {\textbar} . The wires contained within intracranial catheter  {\textbar} 7 {\textbar}  transmit stimulating electrode output signal ({SEOS}) to intracranial stimulating electrode array  {\textbar} 37 {\textbar} . Such wires additionally transmit stimulating electrode input signal ({SEIS}) and recording electrode input signal ({REIS}), from intracranial stimulating electrode array  {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar}  respectively, to stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} Stimulating and recording circuit  {\textbar}   {\textbar} 26 {\textbar}  is protected within a circuit enclosure  {\textbar} 44 {\textbar} . Circuit enclosure  {\textbar} 44 {\textbar}  and contained components, including stimulating and recording circuit  {\textbar} 26 {\textbar}  comprise stimulating and recording unit  {\textbar} 43 {\textbar} . It should be understood that more or fewer of either type of electrode as well as additional electrode types and locations may be incorporated or substituted without departing from the spirit of the present invention. Furthermore, stimulating and recording circuit  {\textbar} 26 {\textbar}  can be placed extra cranially in a subclavian pocket as shown in  {\textbar} {FIG}. 1 {\textbar} , or it may be placed in other extracranial or intracranial locations. {\textbar} Connecting cable  {\textbar}   {\textbar} 8 {\textbar}  generally provides electrical connection between intracranial or intracranial locations. A set of electrical wires provides the means for communication between the intracranial and extracranial components; however, it should be understood that alternate systems and techniques such as radiofrequency links, optical (including infrared) links with transcranial optical windows, magnetic links, and electrical links using the body components as conductors, may be used without departing from the present invention. Specifically, in the illustrative embodiment, connecting cable  {\textbar} 8 {\textbar}  provides electrical connection between intracranial components  {\textbar} 246 {\textbar}  and stimulating and recording circuit  {\textbar} 26 {\textbar} . In embodiments wherein stimulating and recording circuit  {\textbar} 26 {\textbar}  has an intracranial location, connecting cable  {\textbar} 8 {\textbar}  would likely be entirely intracranial. Alternatively, connecting in embodiments wherein stimulating and recording circuit  {\textbar} 26 {\textbar}  is implanted under scalp  {\textbar} 10 {\textbar}  or within or attached to calvarium  {\textbar} 9 {\textbar} , connecting cable  {\textbar} 8 {\textbar}  may be confined entirely to subcutaneous region under the scalp  {\textbar} 10 {\textbar} . {\textbar} A catheter anchor  {\textbar}   {\textbar} 29 {\textbar}  provides mechanical connection between intracranial catheter  {\textbar} 7 {\textbar}  and caldarium  {\textbar} 9 {\textbar} . Catheter anchor  {\textbar} 29 {\textbar}  is preferably deep to the overlying scalp  {\textbar} 10 {\textbar} . Such a subcutaneous connecting cable  {\textbar} 8 {\textbar}  provides electrical connection between intracranial electrodes  {\textbar} 246 {\textbar}  and stimulating and recording circuit  {\textbar} 26 {\textbar} . Cable  {\textbar} 8 {\textbar}  may also connect any other sensors, including but not limited to any of sensory input modalities  {\textbar} 247 {\textbar} , or other stimulating electrodes, medication dispensers, or actuators with stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} Sensory feedback is provided to recording and stimulating unit  {\textbar}   {\textbar} 26 {\textbar}  from a multiplicity of sensors, collectively referred to as sensory input modalities  {\textbar} 247 {\textbar} . Intracranial recording electrode array  {\textbar} 38 {\textbar} , previously described, is intracranial in location. Additional sensors, most of which are located extracranially in the preferred embodiment, comprise the remainder of sensory input modalities  {\textbar} 247 {\textbar} . Sensory input modalities  {\textbar} 247 {\textbar}  provide information to stimulating and recording unit  {\textbar} 26 {\textbar} . As will be described in greater detail below, such information is processed by stimulating and recording unit  {\textbar} 26 {\textbar}  to deduce the disease state and progression and its response to therapy. {\textbar} In one embodiment of the invention, a head-mounted acoustic sensor  {\textbar}   {\textbar} 11 {\textbar}  is used to monitor any number of vibratory characteristics such as high frequency head vibration, muscle vibration, and/or speech production. Head-mounted acoustic sensor  {\textbar} 11 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  with an acoustic sensor connecting cable  {\textbar} 30 {\textbar} . {\textbar} A head-mounted accelerometer  {\textbar}   {\textbar} 12 {\textbar}  is implemented in certain embodiments of the present invention to monitor head movement and position with respect to gravity. Head-mounted accelerometer  {\textbar} 12 {\textbar}  may be mounted to any structure or structures that enables it to accurately sense a desired movement. Such structures include, for example, the skull base, caldarium, clavicle, mandible, extraocular structures, soft tissues and vertebrae. Head-mounted accelerometer  {\textbar} 12 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  with an accelerometer connecting cable  {\textbar} 31 {\textbar} . {\textbar} A proximal electromyography ({EMG}) electrode array  {\textbar}   {\textbar} 45 {\textbar}  is also included in certain preferred embodiments of the invention. Proximal {EMG} electrode array  {\textbar} 45 {\textbar}  includes a positive proximal {EMG} electrode  {\textbar} 13 {\textbar} , a reference proximal {EMG} electrode  {\textbar} 14 {\textbar} , and a negative proximal {EMG} electrode  {\textbar} 15 {\textbar} . As one skilled in the relevant art would find apparent, proximal {EMG} electrode array  {\textbar} 45 {\textbar}  may include any number of type of electrodes. Proximal {EMG} electrode array  {\textbar} 45 {\textbar}  is implanted in or adjacent to muscle tissue. In the embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , proximal {EMG} electrode array  {\textbar} 45 {\textbar}  is shown implanted within the neck of the human patient. However, it should be understood that this location is illustrative only and that proximal {EMG} electrode array  {\textbar} 45 {\textbar}  may be implanted in or adjacent to any muscle without departing from the spirit of the present invention. {\textbar} A proximal acoustic sensor  {\textbar}   {\textbar} 27 {\textbar}  may also be implemented in the present invention. Proximal acoustic sensor  {\textbar} 27 {\textbar}  senses muscle vibration and may be used to augment, supplement or replace {EMG} recording. Also, a proximal accelerometer  {\textbar} 28 {\textbar}  may be used to sense movement, including tremor and voluntary activity, and orientation with respect to gravity. Proximal connecting cable  {\textbar} 16 {\textbar}  provides electrical connection from the proximal {EMG} electrodes  {\textbar} 14 {\textbar}  and  {\textbar} 15 {\textbar} , proximal acoustic sensor  {\textbar} 27 {\textbar} , and proximal accelerometer  {\textbar} 28 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} . In the illustrative embodiment, these sensors are shown connected to a common proximal connecting cable  {\textbar} 16 {\textbar} . However, in alternative embodiments, this configuration may include the use of multiple connecting cables or implement other types of communication media without departing from the present invention. It should also be understood from the preceding description that the number of each type of sensor may also be increased or decreased, some sensor types may be eliminated, and other sensor types may be included without departing from the spirit of the present invention. {\textbar} A distal {EMG} electrode array  {\textbar}   {\textbar} 47 {\textbar}  may also be included in certain embodiments of the present invention. In such embodiments, distal {EMG} electrode array  {\textbar} 47 {\textbar}  typically includes a positive distal {EMG} electrode  {\textbar} 17 {\textbar} , a reference distal {EMG} electrode  {\textbar} 42 {\textbar} , and a negative distal {EMG} electrode  {\textbar} 18 {\textbar} . Positive distal {EMG} electrode  {\textbar} 17 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by positive distal {EMG} connecting cable  {\textbar} 20 {\textbar} . Negative distal {EMG} electrode  {\textbar} 18 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by negative distal {EMG} connecting cable  {\textbar} 21 {\textbar} . Reference distal {EMG} electrode  {\textbar} 42 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by reference distal {EMG} connecting cable  {\textbar} 48 {\textbar} . {\textbar} In other embodiments, a distal acoustic sensor  {\textbar}   {\textbar} 19 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by distal acoustic connecting cable  {\textbar} 22 {\textbar} . Distal accelerometer  {\textbar} 33 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by distal accelerometer connecting cable  {\textbar} 34 {\textbar} . Distal accelerometer  {\textbar} 33 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by distal accelerometer connecting cable  {\textbar} 34 {\textbar} . {\textbar} In the embodiment illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , distal {EMG} electrode array  {\textbar} 47 {\textbar} , distal acoustic sensor  {\textbar} 19 {\textbar} , and distal accelerometer  {\textbar} 33 {\textbar}  are shown located in the shoulder region. However, the distal {EMG} electrode array  {\textbar} 47 {\textbar}  may be located in other locations, including, for example, the masseter, temporalis, sternocleidomastoid, other portion of the head and neck, pectoralis, torso, abdomen, upper extremities, lower extremities, and other locations. The number of each type of sensor may be increased or decreased, some sensor types may be eliminated, and other sensor types may be included without departing from the spirit of the present invention. {\textbar} An enclosure-mounted {EMG} electrode array  {\textbar}   {\textbar} 46 {\textbar}  is illustrated in  {\textbar} {FIG}. 1 {\textbar} . Enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar}  includes enclosure-mounted positive {EMG} electrode  {\textbar} 23 {\textbar} , enclosure-mounted negative {EMG} electrode  {\textbar} 24 {\textbar}  and enclosure-mounted reference {EMG} electrode  {\textbar} 25 {\textbar} , all of which are attached to the circuit enclosure  {\textbar} 44 {\textbar}  that encloses stimulating and recording unit  {\textbar} 26 {\textbar} . The circuit enclosure  {\textbar} 44 {\textbar}  is preferably included to provide robustness against potential lead entanglement and fracture. In one particular embodiment, circuit enclosure  {\textbar} 44 {\textbar}  is constructed of titanium and epoxy, or other single or combination of bio-compatible materials. Enclosure-mounted acoustic sensor  {\textbar} 35 {\textbar}  and enclosure-mounted accelerometer  {\textbar} 36 {\textbar}  are mounted to stimulating and recording unit  {\textbar} 43 {\textbar} . The number of each type of sensor may be increased or decreased, their locations changed, some sensor types eliminated, and other sensor types included without departing from the spirit of the present invention. {\textbar} In the embodiment illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , {EEG} electrodes  {\textbar} 39 {\textbar} ,  {\textbar} 40 {\textbar} ,  {\textbar} 41 {\textbar}  are provided. The {EEG} electrodes may be mounted directly to connecting cable  {\textbar} 8 {\textbar}  or may be connected via intermediate cables. Any one of the numerous standard and new electrode configurations, or montages, may be employed in {EEG} electrodes  {\textbar} 39 {\textbar} - {\textbar} 41 {\textbar}  without departing from the present invention. {\textbar} In one embodiment, a proximal peripheral nerve electrode array  {\textbar}   {\textbar} 98 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by proximal peripheral nerve electrode array connecting cable  {\textbar} 100 {\textbar} . Proximal peripheral nerve electrode array  {\textbar} 98 {\textbar}  is shown located in the neck region. In this location proximal peripheral nerve electrode array  {\textbar} 98 {\textbar}  can interface with the vagus nerve, spinal accessory nerve, or nerve arising from cervical roots. {\textbar} A distal peripheral nerve electrode array  {\textbar}   {\textbar} 99 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by distal peripheral nerve electrode array connecting cable  {\textbar} 32 {\textbar} . Distal peripheral nerve electrode array  {\textbar} 99 {\textbar}  is shown located by the proximal arm, in position to interface with the brachial plexus or proximal arm nerve. One or more of these peripheral nerve electrode arrays may be implanted in these or other locations, including but not limited to the head, cranial nerves, neck, torso, abdomen, upper extremities, and lower extremities, without departing from the present invention. {\textbar} In one preferred embodiment, the peripheral nerve electrode arrays are each comprised of three epineural platinum-iridium ring electrodes, each in with an internal diameter approximately 30\% larger than that of the epineurium, longitudinally spaced along the nerve. Electrodes of differing dimensions and geometries and constructed from different materials may alternatively be used without departing from the present invention. Alternative electrode configurations include but are not limited to epineural, intrafascicular, or other intraneural electrodes; and materials include but are not limited to platinum, gold, stainless steel, carbon, and other element or alloy. {\textbar}   {\textbar} {FIG}. 2 {\textbar}   {\textbar}  is an architectural block diagram of one embodiment of the neurological control system  {\textbar} 999 {\textbar}  of the present invention for modulating the activity of at least one nervous system component in a patient. As used herein, a nervous system component includes any component or structure comprising an entirety or portion of the nervous system, or any structure interfaced thereto. In one preferred embodiment, the nervous system component that is controlled by the present invention includes the globus pallidus internus. In another preferred embodiment, the controlled nervous system component is the subthalamic nucleus. {\textbar} The neurological control system  {\textbar}   {\textbar} 999 {\textbar}  includes one or more implantable components  {\textbar} 249 {\textbar}  including a plurality of sensors each configured to sense a particular characteristic indicative of a neurological or psychiatric condition. One or more intracranial ({IC}) stimulating electrodes in an {IC} stimulating electrode array  {\textbar} 37 {\textbar}  delivers a neural modulation signal to the same or other nervous system component as that being monitored by the system  {\textbar} 26 {\textbar} . One or more sensors  {\textbar} 38 {\textbar} ,  {\textbar} 51 {\textbar} ,  {\textbar} 52 {\textbar} ,  {\textbar} 53 {\textbar} , and  {\textbar} 54 {\textbar}  sense the occurrence of neural responses to the neural modulation signals. Stimulating and recording unit  {\textbar} 26 {\textbar}  generates the neural modulation signal based on the neural response sensed by the sensors. {\textbar} The neurological control system  {\textbar}   {\textbar} 999 {\textbar}  preferably also includes a patient interface module  {\textbar} 55 {\textbar}  and a supervisory module  {\textbar} 56 {\textbar} . A control circuit  {\textbar} 72 {\textbar}  (described below) is communicably coupled to the patient interface module  {\textbar} 55 {\textbar}  and receives signal inputs from and provides signal outputs to patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . In one preferred embodiment, patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  remain external to the body of the patient. However either of these devices may be connected via percutaneous leads or be partially or totally implanted without departing from the present invention. {\textbar} Patient interface module  {\textbar}   {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  facilitate adjustment of control parameters, monitoring of disease state, monitoring of response to therapy, monitoring of stimulating and recording circuit  {\textbar} 26 {\textbar} , monitoring of impedance and other characteristics of intracranial stimulating electrode array  {\textbar} 37 {\textbar} , monitoring of physiologic parameters, monitoring of vital signs, monitoring of any other characteristic or function of components of the present invention, including but not limited to the stimulating and recording circuit  {\textbar} 26 {\textbar} , stimulating and recording unit  {\textbar} 43 {\textbar} , circuit enclosure  {\textbar} 44 {\textbar} , {EMG} electrode array  {\textbar} 50 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , accelerometer array  {\textbar} 52 {\textbar} , acoustic transducer array  {\textbar} 53 {\textbar} , peripheral nerve electrode array  {\textbar} 54 {\textbar} , and intracranial recording electrode array  {\textbar} 38 {\textbar} . Such monitoring and adjustment is accomplished through the use of any well known bi-directional communication between control circuit  {\textbar} 72 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . In one preferred embodiment, a radio frequency link is employed. In alternative embodiments, other communication technologies, including but not limited to optical, percutaneous, or electromagnetic, may be used. {\textbar} In one preferred embodiment, patient interface module  {\textbar}   {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  are placed adjacent to the patients garments overlying the implanted stimulating and recording unit  {\textbar} 43 {\textbar} . When neurological control system  {\textbar} 999 {\textbar}  is turned on in this position, a communications handshaking protocol is executed. Communication handshaking routines are known to those or ordinary skill in the art, and they enable establishment of a communication rate and protocol and facilitate mutual identification of devices. Patient interface module  {\textbar} 55 {\textbar}  automatically downloads parameters from stimulating and recording circuit  {\textbar} 26 {\textbar}  and stores values of such parameters in a memory. When the transfer of these parameter values is complete, patient interface module  {\textbar} 55 {\textbar}  emits a audible signal such as a series of beeps, and the patient turns off patient interface module  {\textbar} 55 {\textbar}  and removes it from its position overlying the implanted stimulating and recording unit  {\textbar} 43 {\textbar} . Parameter values may then be retrieved by the patient by a routine including but not limited to a menu driven interface, and the values may be transmitted via telephone conversation or other communication method to a health care professional. Supervisory module  {\textbar} 56 {\textbar}  operates in the same manner with one addition; a step is provided during which the health care professional may upload parameters to stimulating and recording circuit  {\textbar} 26 {\textbar}  to alter its function including by means of changing parameters including but not limited to control laws gains and thresholds, filter parameters, signal processing parameters, stimulation waveform modes (including at least one of current regulated, voltage regulated, frequency regulated, or pulse width regulated), and stimulation waveform parameters. {\textbar} Control laws, well known to those of ordinary skill in the field of control theory, are defined by a set of parameters specific to the particular control law. Common parameters include preset gains, threshold levels, saturation amplitudes, sampling rates, and others. Adaptive controllers change in response to the behavior of the system being controlled; as such, in addition to preset parameters, adaptive controllers possess a set of varying parameters. These varying parameters contain information indicative of the behavior of the system being controlled; downloading of these parameters provides one set of measures of the disease state and its response to therapy. {\textbar}   {\textbar} Such monitoring includes observation of time history of disease state, stimulation parameters, response to therapy, and control law parameters, including time-varying adaptive controller parameters. Such adjustments includes modification of actual stimulation parameters and allowable ranges thereof, including but not limited to pulse width, pulse amplitude, interpulse interval, pulse frequency, number of pulses per burst frequency. Adjustments can further include modification of actual control law parameters and allowable ranges thereof, including but not limited to gains, thresholds and sampling rates of said stimulation waveforms. Signal processor  {\textbar}   {\textbar} 71 {\textbar}  contains signal processor modules for each of the sensory input modalities  {\textbar} 247 {\textbar} . Signal processing algorithms for each of the said sensory input modalities  {\textbar} 247 {\textbar}  may be independent. Additionally, signal processing algorithms the said sensory input modalities  {\textbar} 247 {\textbar}  may be coupled, such that the processing of one of the sensory input modalities  {\textbar} 247 {\textbar}  is dependent on another of the sensory input modalities  {\textbar} 247 {\textbar} . Adjustments may additionally include modification of actual signal processor parameters and allowable ranges thereof, including but not limited to gains, filter cutoff frequencies, filter time constants, thresholds, and sampling rates. In a preferred embodiment, the stimulation and control law parameters are stored in at least one of random access memory and central processing unit registers (not shown). {\textbar} It is anticipated that patient interface module  {\textbar}   {\textbar} 55 {\textbar}  is to be used by the patient, a family member or associate, or home health care personnel to monitor the functions and performance of neurological control system  {\textbar} 999 {\textbar} . In such an embodiment, the use of the patient interface module  {\textbar} 55 {\textbar}  is restricted to monitoring operations; adjustment of stimulation and control parameters is not enabled. However, adjustment of all or a subset of stimulation and control parameters (described below) may be facilitated by patient interface module  {\textbar} 55 {\textbar}  without departing from the present invention. Supervisory module  {\textbar} 56 {\textbar} , on the other hand, is used by a physician or other health care personnel to monitor function and performance of neurological control system  {\textbar} 999 {\textbar}  and to adjust stimulation and control parameters. Control parameters controlled by patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  include allowable stimulation magnitude range, such as maximum combination of stimulation voltage, current, pulse width, pulse frequency, train frequency, pulse train count, pulse train duration. Control parameters may also include variables and constants used to define control laws implemented in control circuit  {\textbar} 72 {\textbar} . Such control parameters include, but are not limited to, control law gains  {\textbar} 197 {\textbar} - {\textbar} 203 {\textbar} , and other parameters for control laws, including but not limited to proportional controller  {\textbar} 230 {\textbar} , differential controller  {\textbar} 204 {\textbar} , integral controller  {\textbar} 205 {\textbar} , nonlinear controller  {\textbar} 206 {\textbar} , adaptive controller  {\textbar} 207 {\textbar} , sliding controller  {\textbar} 208 {\textbar} , model reference controller  {\textbar} 209 {\textbar} , and other controllers. In addition, amplitudes for other controller parameters, including but not limited to amplitudes for controller weights  {\textbar} 210 {\textbar} - {\textbar} 216 {\textbar}  may be set by supervisory module  {\textbar} 56 {\textbar} . Additionally, the parameters specifying the maximum amplitudes, or saturation values, may be set by supervisory module  {\textbar} 56 {\textbar} . Control circuit  {\textbar} 72 {\textbar}  ( {\textbar} {FIG}. 12 {\textbar} ) will be described in detail below. {\textbar} The majority of the computation accomplished by stimulating and recording circuit  {\textbar}   {\textbar} 26 {\textbar}  is performed in signal conditioning circuit  {\textbar} 76 {\textbar} , signal processor  {\textbar} 71 {\textbar} , and control circuit  {\textbar} 72 {\textbar} ; the algorithms and behavior of which are determined by corresponding sets of control parameters, of which some may be set by the supervisory module  {\textbar} 56 {\textbar}  and a typically more restricted set by patient interface module  {\textbar} 55 {\textbar} . In one embodiment, control parameters further includes signal conditioning parameters. Signal conditioning parameters may include, for example, amplifier gains, filter gains and bandwidths, threshold values, and other parameters. In certain embodiments, control parameters additionally include signal processing parameters, including envelope determinator gains and time constants, filter passbands, filter gains, threshold values, integrator gains, analyzer parameters, disease state estimator parameters, artifact rejecter thresholds, envelope determinator time constants, rectifier parameters, spectral analyzer parameters and timer parameters. {\textbar} In the illustrative embodiment described herein, control parameters further include spike detector  {\textbar}   {\textbar} 188 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, spike characterizer  {\textbar} 189 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, spike analyzer  {\textbar} 190 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, spectral energy characterizer  {\textbar} 192 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, spectral energy analyzer  {\textbar} 193 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, aggregate disease state estimator  {\textbar} 195 {\textbar}  ( {\textbar} {FIG}. 10 {\textbar} ) parameters. {\textbar} In accordance with the present invention, tremor are quantified and monitored by any sensors over time as indicators of disease state. Such sensors include but are not limited to {EMG} electrode array  {\textbar}   {\textbar} 50 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , accelerometer array  {\textbar} 52 {\textbar} , acoustic transducer array  {\textbar} 53 {\textbar} , peripheral nerve electrode array  {\textbar} 54 {\textbar} , intracranial recording electrode array  {\textbar} 38 {\textbar} , and intracranial stimulating electrode array  {\textbar} 37 {\textbar} . In one particular embodiment, the sensed tremor characteristics include, but are not limited to, magnitude, frequency, duration and frequency of occurrence of tremors. Changes in these and other parameters are compared to current levels of, and changes in, treatment parameters. These changes are then used by aggregate disease state estimator  {\textbar} 195 {\textbar}  to estimate the response to therapy as functions of various electrical stimulation treatment parameters. Electrical stimulation treatment parameters are adjusted by control circuit  {\textbar} 72 {\textbar}  in real-time to provide optimal control of disease state. {\textbar} Modulation parameters are optimized to achieve at least one of minimization of disease state, minimization of symptoms of disease, minimization of stimulation magnitude, minimization of side effects, and any constant or time-varying weighted combination of these. Patient interface module  {\textbar}   {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  also preferably monitor the function and operation of other components of neurological control system  {\textbar} 999 {\textbar} , including stimulating and recording unit  {\textbar} 26 {\textbar}  and implanted components  {\textbar} 249 {\textbar} . {\textbar} Stimulating and recording unit  {\textbar}   {\textbar} 26 {\textbar}  receives and processes signals generated by implanted components  {\textbar} 249 {\textbar}  to provide conditioned signals  {\textbar} 78 {\textbar} - {\textbar} 84 {\textbar}  to a signal processor  {\textbar} 71 {\textbar} . For each type of implanted components  {\textbar} 249 {\textbar}  coupled to stimulating and recording unit  {\textbar} 26 {\textbar} , signal conditioning circuit  {\textbar} 76 {\textbar}  preferably includes an associated amplifier and filter. Each amplifier and associated filter is configured to receive and process the signal generated by the associated one of the set of sensors  {\textbar} 38 {\textbar} ,  {\textbar} 51 {\textbar} ,  {\textbar} 52 {\textbar} ,  {\textbar} 53 {\textbar} , and  {\textbar} 54 {\textbar} . {\textbar} In the illustrative embodiment, implanted components  {\textbar}   {\textbar} 249 {\textbar}  include an electromyography ({EMG}) electrode array  {\textbar} 50 {\textbar}  which generate {EMG} signals. Preferably, {EMC} electrode array  {\textbar} 50 {\textbar}  comprises of all {EMG} electrodes implemented in the particular embodiment of the present invention. These include, in the exemplary embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , proximal {EMG} electrode array  {\textbar} 45 {\textbar} , enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar}  and distal {EMG} electrode array  {\textbar} 47 {\textbar} . Array  {\textbar} 50 {\textbar}  may also include, for example, {EMG} electrodes implanted in the head or other location, and surface {EMG} electrodes. {\textbar} Implanted components  {\textbar}   {\textbar} 249 {\textbar}  also include an electroencephalography ({EEG}) electrode array  {\textbar} 51 {\textbar}  which generate {EEG} signals and accelerometer array  {\textbar} 52 {\textbar}  which generates acceleration signals. {EEG} electrodes  {\textbar} 39 {\textbar} ,  {\textbar} 40 {\textbar} ,  {\textbar} 41 {\textbar}  illustrated in  {\textbar} {FIG}. 1 {\textbar}  are representative of {EEG} electrode array  {\textbar} 51 {\textbar} . {EEG} electrodes  {\textbar} 39 {\textbar} - {\textbar} 41 {\textbar}  may be mounted directly to connecting cable  {\textbar} 8 {\textbar}  or connected via intermediate cables. {EEG} electrode array  {\textbar} 51 {\textbar}  may include more or fewer elements than {EEG} electrodes  {\textbar} 39 {\textbar} - {\textbar} 41 {\textbar}  depicted; and any of numerous standard and new electrode configurations, or montages, may be employed without departing from the present invention. {\textbar} Accelerometer array  {\textbar}   {\textbar} 52 {\textbar} , which produces well-known acceleration signals, preferably includes all accelerometers implemented in the patient associated with the present invention. For example, in the embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , accelerometer array  {\textbar} 52 {\textbar}  includes head-mounted accelerometer  {\textbar} 12 {\textbar} , proximal accelerometer  {\textbar} 28 {\textbar} , enclosure-mounted accelerometer  {\textbar} 36 {\textbar}  and distal accelerometer  {\textbar} 33 {\textbar} . Accelerometer array  {\textbar} 52 {\textbar}  may include more or fewer accelerometers than these accelerometers, and accelerometers of any types and locations may be employed without departing from the present invention. {\textbar} Acoustic transducer array  {\textbar}   {\textbar} 53 {\textbar}  includes all acoustic sensors utilized by the present invention. In the exemplary embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , acoustic transducer array  {\textbar} 53 {\textbar} , includes head-mounted acoustic sensor  {\textbar} 11 {\textbar} , proximal acoustic sensor  {\textbar} 27 {\textbar} , enclosure-mounted acoustic sensor  {\textbar} 35 {\textbar}  and distal acoustic sensor  {\textbar} 19 {\textbar} . It should be understood that acoustic transducer array  {\textbar} 53 {\textbar}  may include more or fewer elements than said acoustic sensors listed above; and any of numerous acoustic sensor types and locations may be employed without departing from the present invention. {\textbar} Peripheral nerve electrode array  {\textbar}   {\textbar} 54 {\textbar}  generates peripheral neural signals, including but not limited to efferent and afferent axonal signals. Preferably, peripheral nerve electrode array  {\textbar} 54 {\textbar}  includes all peripheral nerve electrodes implemented in present invention. For example, in the illustrative embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , peripheral nerve electrode array  {\textbar} 54 {\textbar}  includes proximal peripheral nerve electrode array  {\textbar} 98 {\textbar}  and distal peripheral nerve electrode array  {\textbar} 99 {\textbar} . The single or plurality of individual peripheral nerve electrode arrays which comprise peripheral nerve electrode array  {\textbar} 54 {\textbar}  may be implanted in the illustrated or other locations, as noted above. {\textbar} Intracranial ({IC}) recording electrode array  {\textbar}   {\textbar} 38 {\textbar}  generates central neural signals, including but not limited to cortical, white matter, and deep brain nuclear signals. Neural activity to be sensed includes but is not limited to that found in the primary motor cortex, premotor cortex, supplementary motor cortex, somatosensory cortex, white matter tracts associated with these cortical areas, the globus pallidus internal segment, the globus pallidus external segment, the caudate, the putamen, and other cortical and subcortical areas. As one of ordinary skill in the relevant art will find apparent, the present invention may include additional or different types of sensors that sense neural responses for the type and particular patient. Such sensors generate sensed signals that may be conditioned to generate conditioned signals, as described below. One example of the placement of these electrodes is described above with reference to the embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} . Many others are contemplated by the present invention. {\textbar} As noted, for each of the different types of sensors included in implanted components  {\textbar}   {\textbar} 249 {\textbar} , signal conditioning circuit  {\textbar} 76 {\textbar}  includes an associated amplifier and filter in the illustrative embodiment. Accordingly, signal conditioning circuit  {\textbar} 76 {\textbar}  includes an {EMG} amplifier  {\textbar} 59 {\textbar}  and filter  {\textbar} 66 {\textbar} , each constructed and arranged to amplify and filter, respectively, the {EMG} signals received from {EMG} electrode array  {\textbar} 50 {\textbar} . Similarly, signal conditioning circuit  {\textbar} 76 {\textbar}  also includes an {EEG} amplifier  {\textbar} 60 {\textbar}  and filter  {\textbar} 67 {\textbar} , accelerometer ({ACC}) amplifier  {\textbar} 61 {\textbar}  and filter  {\textbar} 68 {\textbar} , acoustic ({ACO}) amplifier  {\textbar} 62 {\textbar}  and filter  {\textbar} 69 {\textbar} , peripheral nerve electrode ({PNE}) amplifier  {\textbar} 63 {\textbar}  and filter  {\textbar} 70 {\textbar}  and intracranial ({IC}) recording electrode ({ICRE}) amplifier  {\textbar} 58 {\textbar}  and filter  {\textbar} 65 {\textbar} . {\textbar} Simplifiers  {\textbar}   {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  may be single or multi-channel amplifiers depending upon the number of electrodes with which it interfaces. In one preferred embodiment, amplifiers  {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  are physically located in the same enclosure as filters  {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar} ; that is, in a single signal conditioning circuit  {\textbar} 76 {\textbar} . Preferably, signal conditioning circuit  {\textbar} 76 {\textbar}  is physically contained within stimulating and recording unit  {\textbar} 102 {\textbar} . However, amplifiers  {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  may be located separately from stimulating recording unit  {\textbar} 102 {\textbar} . For example, amplifiers  {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  may be affixed to or situated proximate to their associated electrode arrays  {\textbar} 38 {\textbar} ,  {\textbar} 50 {\textbar} - {\textbar} 54 {\textbar} . This arrangement facilitates the preamplification of the associated signals generated by the associated electrode arrays  {\textbar} 38 {\textbar} ,  {\textbar} 50 {\textbar} - {\textbar} 54 {\textbar} , increasing the signal-to-noise ratio of the signals. Amplifiers  {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  may be any known voltage amplifier now or later developed suitable for amplifying the particular signals generated by their associated electrodes. {\textbar} As noted, the amplified signals are passed to their associated filters  {\textbar}   {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar}  as shown in  {\textbar} {FIG}. 2 {\textbar} . As with amplifiers  {\textbar} 57 {\textbar} - {\textbar} 59 {\textbar} , filters  {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar}  may be physically separate from or incorporated into signal conditioning circuit  {\textbar} 76 {\textbar}  and stimulating and recording unit  {\textbar} 26 {\textbar} . In one preferred embodiment, filters  {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar}  are low pass filters having a cut-off frequency of, for example, 3,000 Hz. In alternative embodiments, filters  {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar}  may include a notch filter to remove, for example, 60 Hz noise, or other types of filters appropriate for the type of signals generated by the associated sensors  {\textbar} 38 {\textbar} ,  {\textbar} 51 {\textbar} ,  {\textbar} 52 {\textbar} ,  {\textbar} 53 {\textbar} , and  {\textbar} 54 {\textbar} . Selection of the appropriate frequencies for the cut-off and notch filter frequencies is considered to be well known in the relevant art and within the scope of the present invention. Filters  {\textbar} 66 {\textbar} - {\textbar} 70 {\textbar} ,  {\textbar} 65 {\textbar}  and  {\textbar} 64 {\textbar}  generate conditioned sensed signals  {\textbar} 84 {\textbar} ,  {\textbar} 83 {\textbar}  and  {\textbar} 78 {\textbar} - {\textbar} 82 {\textbar} , respectively. {\textbar} Signal processor  {\textbar}   {\textbar} 71 {\textbar}  processes the conditioned sensed neural response signals  {\textbar} 78 {\textbar} - {\textbar} 84 {\textbar}  generated by signal conditioning circuit  {\textbar} 76 {\textbar}  in accordance with the present invention to determine neural system states. Signal processor  {\textbar} 71 {\textbar}  generally performs well known filtering operations in the time and frequency domains. In one preferred embodiment, the neural system states include one or more physiologic or disease states. Signal processor  {\textbar} 71 {\textbar} , which can be implemented in a fast microprocessor, a {DSP} (digital signal processor) chip, or as analog circuitry, for example, is described in detail below. {\textbar} Control circuit  {\textbar}   {\textbar} 72 {\textbar} , responsive to the signal processor  {\textbar} 71 {\textbar} , patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} , adjusts the magnitude of a neural modulation signal in response to the sensed neural response. Signal processor  {\textbar} 71 {\textbar}  extracts relevant information from the sensed condition signals, and control circuit  {\textbar} 72 {\textbar}  uses this extracted information in the calculation of an output neuromodulation signal ({NMS})  {\textbar} 998 {\textbar} . Neuromodulation signal  {\textbar} 998 {\textbar}  subsequently travels along stimulator output path  {\textbar} 111 {\textbar}  to {IC} stimulating electrode array  {\textbar} 37 {\textbar} . In one embodiment, control circuit  {\textbar} 72 {\textbar}  is a state machine, utilizing current and past system behavior in the calculation of a control signal. In an alternative embodiment, control circuit  {\textbar} 72 {\textbar}  includes an embedded microprocessor to process nonlinear control laws. Alternative embodiments of the control circuit  {\textbar} 72 {\textbar}  appropriate for the particular application may be also be used. {\textbar} Control circuit  {\textbar}   {\textbar} 72 {\textbar}  receives control law selection information, control law parameter information, stimulation waveform parameter range information, stimulation modulation mode, output stage regulation mode, and medication dose and timing information from patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . The waveform parameter or parameters which are modulated by control law output signal U  {\textbar} 997 {\textbar}  are determined by the stimulation modulation mode; these parameters include but are not limited to pulse amplitude, pulse width, pulse frequency, pulses per burst, and burst frequency. Selection between regulation of pulse voltage or pulse current as the regulated pulse amplitude is determined by the output stage regulation mode. {\textbar} Control circuit  {\textbar}   {\textbar} 72 {\textbar}  provides stimulation waveform parameter history information, disease state history information, control law state variable history information, control law error history information, control law input variable history information, control law output variable history information, stimulating electrode impedance history information, sensory input history information, battery voltage history information, and power consumption history information to patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . {\textbar} Provision of stimulating electrode impedance history information allows monitoring of stimulating electrode performance and functionality. If an electrode is determined to be fractured, shorted, or encapsulated by fibrotic tissue, any of various control law parameters, output stage parameters, and waveform range parameters may be adjusted to allow compensation for these changes. Additionally, the Neuromodulation Signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  may be delivered to different sets of electrodes to insure that it reaches neural tissue  {\textbar} 250 {\textbar} . Sensory input history information allows evaluation of validity of any given sensory input. This is useful in determining the functionality of a given sensor and serves as an indicator for sensor replacement or adjustment of the signal processing parameters or algorithm or the control law parameters or algorithm to continue to generate reliable disease state estimate signals X and control law outputs U despite the loss of any particular individual or set of sensory signals. {\textbar} Signal processor  {\textbar}   {\textbar} 71 {\textbar}  receives amplifier gain setting information, filter parameter information, weighting information, and disease state estimator parameter and algorithm information from patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . The function and operation of patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  are described above. As noted, patient interface module  {\textbar} 55 {\textbar}  may be used by the patient or home health care personnel to monitor disease state, stimulation parameters, and response to therapy. Limited adjustment of stimulation parameters and ranges is facilitated. Patient interface module  {\textbar} 55 {\textbar}  may be used by the patient or home health care personnel to provide information to the physician, avoiding the need for an office visit for the obtainment of said information. {\textbar} Patient information module  {\textbar}   {\textbar} 55 {\textbar}  queries signal processor  {\textbar} 71 {\textbar}  for present and time histories of monitored values. Time histories of selected variables in signal processor  {\textbar} 71 {\textbar}  and control circuit  {\textbar} 72 {\textbar}  are stored in memory module  {\textbar} 240 {\textbar}  for subsequent retrieval by patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . Selected variables include but are not limited to disease state, tremor frequency, tremor magnitude, {EMG} magnitude, {EMG} frequency spectra ({EMG} magnitude within frequency ranges), and acceleration of limb, head, mandible, or torso. Selected variables may also include disease state, frequency spectra of limb, torso, and head movements, as determined by {EMG} and accelerometer signals. {\textbar} Stimulating and recording unit  {\textbar}   {\textbar} 26 {\textbar}  also includes an output stage circuit  {\textbar} 77 {\textbar} . Output stage circuit  {\textbar} 77 {\textbar}  takes for an input the control law output signal U, which may be comprised of a single or multiplicity of channels or signals, from control circuit  {\textbar} 72 {\textbar} . This control law output signal U  {\textbar} 997 {\textbar}  modulates the magnitude of the sequence of waveforms comprising the desired output neuromodulation signal ({NMS}.sub.D) which is produced by output stage circuit  {\textbar} 77 {\textbar}  and delivered via intracranial stimulating electrode array  {\textbar} 37 {\textbar}  to neural tissue  {\textbar} 250 {\textbar} . {\textbar} Output stage circuit  {\textbar}   {\textbar} 77 {\textbar}  generates a neuromodulation signal ({NMS}.sub.D)  {\textbar} 998 {\textbar}  with a magnitude specified by control law output signal U  {\textbar} 997 {\textbar}  received from control circuit  {\textbar} 72 {\textbar} . In one preferred embodiment, the waveform parameter of the desired output neuromodulation signal ({NMS}.sub.D) which is modulated by control law output signal U is the stimulation current magnitude. The capability to specifically modulate the stimulation current confers efficacy resistance to perturbations or changes in electrode impedance. Presently implanted systems suffer from a decline in efficacy which results from an increase in electrode impedance which accompanies the normal tissue response to a foreign body, that is fibrotic encapsulation of the electrode. In this design taught in the present invention, a the magnitude of the current delivered to the neural tissue  {\textbar} 250 {\textbar}  will not vary as the electrode becomes encapsulated with fibrotic tissue or its impedance otherwise changes over time. A further advantage conferred by current modulation is the ability to monitor electrode impedance. If a current-modulated waveform, preferably a sinusoid, is delivered to the electrodes, and the resultant voltage potential waveform is concurrently monitored, the relative magnitudes and phase shifts of these waveforms may be computed. From these magnitudes and phases, the complex impedance and hence the resistive and capacitive components of the electrode impedance may be calculated. {\textbar} In an alternative embodiment, the waveform parameter of the desired output neuromodulation signal ({NMS}.sub.D) which is modulated by control law output signal U  {\textbar}   {\textbar} 997 {\textbar}  is the stimulation voltage magnitude. This design would not enjoy the independence of the stimulation current and efficacy from impedance variation enjoyed by the embodiment described above. If fibrosis was uneven around the surface of the electrode, this embodiment would avoid potentially undesirably large current densities along narrow tracts of remaining low resistance unfibrosed regions of neural tissue  {\textbar} 250 {\textbar} . {\textbar} Alternatively, regulation of stimulus pulse width may be desired. In certain circuit implementations, the available resolution or bits for specifying the magnitude of pulse width may be greater than that for specifying the pulse voltage or current. In such a case, if finer control of the magnitude of Neuromodulation signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  is desired than is provided by the control of pulse current or pulse voltage, then it may be desirable to modulate the pulse width. Furthermore, the spatial neuron recruitment characteristics of a pulse width modulated neuromodulation signal ({NMS})  {\textbar} 998 {\textbar}  may provide a more linear, predictable, or controllable response than that obtained with current or voltage modulation. Selection between regulation of pulse voltage, pulse current, or pulse width as the regulated pulse amplitude parameter is determined by the output stage regulation mode, which may be set using supervisory module  {\textbar} 56 {\textbar} . In alternative embodiments, the modulation of pulse frequency and the modulation of the number of pulses per burst are regulated. As one of ordinary skill in the relevant art would find apparent. Other such characteristics may be regulated in addition to or instead of the ones noted above. {\textbar} Output stage circuit  {\textbar}   {\textbar} 77 {\textbar}  includes a pulse generator  {\textbar} 73 {\textbar} , an output amplifier  {\textbar} 74 {\textbar}  and a multiplexor  {\textbar} 75 {\textbar} . Pulse generator  {\textbar} 73 {\textbar}  generates one or more stimulus waveforms, each of which is characterized by several parameters, including but not limited to pulse amplitude, pulse width, pulse frequency, number of pulses per burst, and burst frequency. As noted above, pulse amplitude may comprise pulse voltage or pulse current. Preferably, each of these parameters may be independently varied, as specified by control law output signal U  {\textbar} 997 {\textbar}  generated by control circuit  {\textbar} 72 {\textbar} . As noted, the stimulus waveforms comprising the neuromodulation signal ({NMS}) generated by output stage circuit  {\textbar} 77 {\textbar}  are applied to patient through intracranial ({IC}) stimulating electrode array  {\textbar} 37 {\textbar} . Pulse generator  {\textbar} 73 {\textbar}  generates a single waveform when single channel stimulation is to be used, and a plurality of waveforms when multiple channel stimulation is to be used. It may generate monophasic or biphasic waveforms. {\textbar} In one preferred embodiment, charge balanced biphasic waveforms are produced. Those skilled in the art are aware that the net charge contained in a given pulse is given by the time integral of the stimulus current over the duration of the pulse. In a biphasic configuration, a pair of pulses of opposite polarity is generated, and the pulse current amplitude and pulse width are chosen such that the charge amplitude is equal in magnitude and opposite in polarity. In some cases, it is desirable for the pulses comprising the biphasic pulse pair to have different amplitudes; in this case, the pulse widths are chosen to insure equal and opposite charges so the pulse par introduces zero net charge to the neural tissue  {\textbar}   {\textbar} 250 {\textbar} . The capability to deliver pulse pairs with balanced charges is yet a further advantage conferred by the current regulation mode described above. {\textbar} Even though the waveform parameters of the pulse pairs are calculated to deliver a zero net charge, in practice, noise and precision limitations in computation and resolution limitations and nonlinearities in the digital to analog conversion and amplification stages may result in slight imbalances in the pulse pair charges. Over time, this can result in the delivery of a substantial accumulated net charge to the neural tissue. To eliminate this potential for net charge delivery to neural tissue, a direct current ({DC}) blocking capacitor is employed. This is a technique that is well known to those or ordinary skill in the art. In one preferred embodiment, a {DC} blocking capacitor is included within multiplexor  {\textbar}   {\textbar} 75 {\textbar}  in series with stimulator output path  {\textbar} 111 {\textbar} . {\textbar} Typically, multi-channel stimulation is used in the case of bilateral stimulation. Since the disease progression is typically asymmetrical, and the normal motor control systems governing movement on the left and right side of the body are also highly independent of each other, the delivery of treatment to the left and right sides of the body should be controlled separately. This represents one need for a multiple channel neuromodulation signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar} . Multichannel stimulation is also expected to be beneficial in treating patients with variable involvement of different limbs. For example, the magnitude neuromodulation of a portion of the globus pallidus required to achieve optimal controls of arm tremor may be different from the optimal level of neuromodulation of separate portion of the globus pallidus to achieve optimal control of leg tremor. In this case, separate electrodes or electrode pairs are required to deliver optimal levels of neuromodulation to control tremor in these two regions of the body. Correspondingly, these separate electrodes or electrode pairs will be driven by separate neuromodulation signal ({NMS}) channels, necessitating a multichannel system. {\textbar} A further need for multichannel neuromodulation signal ({NMS}) is the control of multiple symptoms of the movement disorder and the side effects arising from pharmacologic treatment. Optimal control of tremor, dyskinesias, and rigidity are not achieved by modulation of the same site at the same intensity. For this reason, multiple and separately controlled channels of neuromodulation are required to simultaneously achieve optimal control of these multiple symptoms and side effects. Each of these symptoms and side effects may be considered to comprise one or more element in a multivariable disease state. A multivariable control system will be required to optimally drive each of these disease state elements to its desired value, ideally toward a target minimum level and thus achieve optimal control of this multiplicity of disease states. This multivariable control system may be implemented as multiple independent control laws each with separate though potentially overlapping sensory inputs or as a multivariable control law matrix. {\textbar}   {\textbar} Stimulation via each of the multiple channels comprising the neuromodulation signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  is characterized by separate though possibly overlapping sets of one or more of the following parameters: stimulation voltage, stimulation current stimulation frequency of pulses within the same burst, frequency of bursts, pulse width, pulses per burst, duration of burst, and interpulse interval. The stimulus waveforms are amplified by output amplifier  {\textbar} 74 {\textbar}  to generate an amplified stimulus waveform. Specifically, pulse generator  {\textbar} 73 {\textbar}  transfers information to output amplifier  {\textbar} 74 {\textbar}  which includes information that uniquely specifies the desired stimulation waveform. In a preferred embodiment, the information is in the form of an analog signal which represents a scaled version of the voltage or current waveform to be delivered to the tissue. It should be understood that other forms of the signal generated by pulse generator  {\textbar} 73 {\textbar}  may be used, including combinations of at least one of analog and digital representations. Output amplifier  {\textbar} 74 {\textbar}  performs amplification and regulation of the received stimulus waveform generated by the pulse generator  {\textbar} 73 {\textbar} . This may be regulation of electrical current to achieve desired voltage or regulation of electrical voltage to achieve desired current, depending on whether a voltage or current waveform is to be delivered to the nervous system component. {\textbar} As one skilled in the relevant art would find apparent, voltage regulation is simpler to implement, and is a technique which is commonly used by many conventional stimulators. Current regulation, on the other hand, is more complex but allows for more precise control of the applied stimulation. Current regulation insures that a specified amount of current is delivered, regardless of the impedance of the electrode. Current regulation is advantageous in that it allows for precise control of stimulation level despite changes in electrode impedance which invariably occur over time. Since electrode impedances often change, typically increasing as they become encapsulated by fibrosis, current regulation is preferred to avoid the decrease in current which would occur if voltage regulation were to be used in such circumstances. {\textbar}   {\textbar} The amplified stimulus waveform generated by output amplifier  {\textbar}   {\textbar} 74 {\textbar}  is conducted along stimulator amplifier output path  {\textbar} 112 {\textbar}  to multiplexor  {\textbar} 75 {\textbar} . Multiplexor  {\textbar} 75 {\textbar}  allows for delivery of a stimulating electrode output signal ({SEOS}) to the intracranial stimulating electrode array  {\textbar} 37 {\textbar} , multiplexed with sensing of a stimulating electrode input signal ({SEIS}). Specifically, multiplexor  {\textbar} 75 {\textbar}  serves to alternately connect intracranial stimulating electrode ({ICSE}) array  {\textbar} 37 {\textbar}  to output amplifier  {\textbar} 74 {\textbar}  and intracranial stimulating electrode amplifier  {\textbar} 57 {\textbar} . Connection of intracranial stimulating electrode ({ICSE}) array  {\textbar} 37 {\textbar}  to output amplifier  {\textbar} 74 {\textbar}  facilitates delivery of neural modulation signal to neural tissue, while connection of intracranial stimulating electrode ({ICSE}) array  {\textbar} 37 {\textbar}  to intracranial stimulating electrode amplifier  {\textbar} 57 {\textbar}  facilitates monitoring of neural activity in the region being stimulated. {\textbar} Multiplexor  {\textbar}   {\textbar} 75 {\textbar}  allows delivery of neural modulation signals to neural tissue concurrent with monitoring of activity of same neural tissue; this facilitates real-time monitoring of disease state and response to treatment. Stimulating electrode output signal ({SEOS}) from output amplifier  {\textbar} 74 {\textbar}  is conducted along stimulator amplifier output path  {\textbar} 112 {\textbar}  to multiplexor  {\textbar} 75 {\textbar} . Multiplexor  {\textbar} 75 {\textbar}  conducts output from output amplifier  {\textbar} 74 {\textbar}  to stimulator output path  {\textbar} 111 {\textbar}  which conducts the stimulating electrode output signal to intracranial stimulating electrode array  {\textbar} 37 {\textbar} . To facilitate periodic sampling of neural activity in tissue being stimulated, multiplexor  {\textbar} 75 {\textbar}  alternatively conducts signal arising from stimulated tissue via intracranial stimulating electrode array ({ICSE})  {\textbar} 37 {\textbar}  and stimulator output path  {\textbar} 111 {\textbar}  to multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  and intracranial stimulating electrode amplifier  {\textbar} 57 {\textbar} . {\textbar} Multiplexor  {\textbar}   {\textbar} 75 {\textbar}  selectively conducts the signal on multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  to amplifier  {\textbar} 57 {\textbar} . Multiplexor  {\textbar} 75 {\textbar}  may alternate conduction between path  {\textbar} 111 {\textbar}  and path  {\textbar} 112 {\textbar}  or path  {\textbar} 113 {\textbar}  using temporal multiplexing, frequency multiplexing or other techniques to allow concurrent access to the intracranial stimulating electrode ({ICSE}) array  {\textbar} 37 {\textbar}  for modulation of tissue activity and monitoring of tissue activity. Temporal multiplexing is a well known technique and frequency multiplexing of stimulation and recording signals in known to those skilled in the art. In this embodiment, temporal multiplexing is accomplished by alternately connecting stimulator output path  {\textbar} 111 {\textbar}  to stimulator amplifier output path  {\textbar} 112 {\textbar}  and multiplexed stimulator recording input path  {\textbar} 113 {\textbar} . In one embodiment, frequency multiplexing is accomplished by passing a band-limited portion of stimulating electrode output signal {SEOS} via the stimulator output path  {\textbar} 111 {\textbar}  to intracranial stimulating electrode array  {\textbar} 37 {\textbar}  while simultaneously monitoring activity on intracranial stimulating electrode array  {\textbar} 37 {\textbar}  within a separate frequency band, thereby generating a stimulating electrode input signal {SEIS}. Thus, stimulating electrode input signal {SEIS} is conducted from the intracranial stimulating electrode array  {\textbar} 37 {\textbar}  to stimulator output path  {\textbar} 111 {\textbar}  to multiplexor  {\textbar} 75 {\textbar}  and via multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  to intracranial stimulating electrode array amplifier  {\textbar} 57 {\textbar} . {\textbar} Multiplexor  {\textbar}   {\textbar} 75 {\textbar}  facilitates conduction between stimulator amplifier output path  {\textbar} 112 {\textbar}  and multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  to allow automated calibration. In this mode, a calibration signal of known amplitude is generated by pulse generator  {\textbar} 73 {\textbar}  and amplified by output amplifier  {\textbar} 74 {\textbar}  which, for calibration purposes, delivers a voltage regulated signal via stimulator amplifier output path  {\textbar} 112 {\textbar}  to multiplexor  {\textbar} 75 {\textbar} . Multiplexor  {\textbar} 75 {\textbar}  conducts amplified calibration signal to multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  which conducts signal to intracranial stimulating electrode amplifier  {\textbar} 57 {\textbar} . {\textbar} Although not included in the illustrative embodiment, multiplexed or intermittent connection of stimulator amplifier output path  {\textbar}   {\textbar} 112 {\textbar}  to the inputs of at least on of the other amplifiers, including {EMG} amplifier  {\textbar} 59 {\textbar} , {EEG} amplifier  {\textbar} 60 {\textbar} , accelerometer amplifier  {\textbar} 61 {\textbar} , acoustic amplifier  {\textbar} 62 {\textbar} , peripheral nerve electrode amplifier  {\textbar} 63 {\textbar} , and intracranial recording electrode amplifier  {\textbar} 58 {\textbar} , may be implemented without departing from the present invention. The same multiplexed connections may be used to calibrate the pulse generator  {\textbar} 73 {\textbar}  and output amplifier  {\textbar} 74 {\textbar} . {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 15 {\textbar} , an analog switch may be used to connect one or an opposing polarity pair of Zener diodes across the noninverting and inverting inputs of intracranial recording electrode amplifier  {\textbar} 58 {\textbar} . In this configuration, the Zener diodes would limit the maximal amplitude of the calibration signal in one or both polarities to known values, allowing for accurate calibration of intracranial recording electrode amplifier  {\textbar} 58 {\textbar} . The analog switch may then be deactivated, removing the cathode of the single or pair of Zener diodes from the input of intracranial recording electrode amplifier  {\textbar} 58 {\textbar}  to allow measurement of stimulating electrode output signal ({SEOS}) for calibration of pulse generator  {\textbar} 73 {\textbar}  and output amplifier  {\textbar} 74 {\textbar} . This is described in greater detail below. {\textbar} Multiplexor  {\textbar}   {\textbar} 75 {\textbar}  also facilitates conduction between stimulator amplifier output path  {\textbar} 112 {\textbar} , multiplexed stimulator recording input path  {\textbar} 113 {\textbar} , and stimulator output path  {\textbar} 111 {\textbar}  to allow measurement of impedances of components of intracranial stimulating electrode array  {\textbar} 37 {\textbar} . In this electrode impedance measurement mode, a three way connection between stimulator amplifier output path  {\textbar} 112 {\textbar} , multiplexed stimulator recording input path  {\textbar} 113 {\textbar} , and stimulator output path  {\textbar} 111 {\textbar}  is created. When output amplifier  {\textbar} 74 {\textbar}  is operated in current regulated mode, it delivers an {SEOS} of known current via stimulator output path  {\textbar} 111 {\textbar}  to intracranial stimulating electrode array  {\textbar} 37 {\textbar} . The voltages generated across the elements of intracranial stimulating electrode array  {\textbar} 37 {\textbar}  generally are the products of the electrode impedances and the known stimulating currents. These voltages are sensed as the stimulating electrode input signal {SEIS} by the intracranial stimulating electrical amplifier  {\textbar} 57 {\textbar} . {\textbar} Reference module  {\textbar}   {\textbar} 1116 {\textbar}  contains memory registers in which control law reference values are stored. Such reference values include but are not limited to target disease state levels, target symptom levels, including target tremor level, and threshold levels. Threshold levels include but are not limited to disease and symptom levels, including tremor threshold levels. Neural modulation amplitude may be increased when at least one of disease state and symptom level exceed the corresponding threshold. Similarly neural modulation amplitude may be decreased or reduced to zero when either the disease state or symptom level falls below the corresponding threshold. {\textbar} Reference module  {\textbar}   {\textbar} 116 {\textbar}  is connected to patient interface module  {\textbar} 55 {\textbar} , facilitating both monitoring and adjustment of reference values by patient. Reference module  {\textbar} 116 {\textbar}  is also connected to supervisory module  {\textbar} 56 {\textbar} , facilitating both monitoring and adjustment of reference values by physician or other health care provider. Supervisory module  {\textbar} 56 {\textbar}  may be used by the neurologist, neurosurgeon, or other health care professional, to adjust disease state reference R values for the one or more control laws implemented in control circuit  {\textbar} 72 {\textbar} . The disease state reference R values specify the target level at which the corresponding disease states are to be maintained, as quantified by the disease state estimate X values, providing reference values for control laws implemented in control law circuit block  {\textbar} 231 {\textbar}  ( {\textbar} {FIG}. 11 {\textbar} ; discussed below) and contained within control circuit  {\textbar} 72 {\textbar} . Reference module  {\textbar} 116 {\textbar}  may also receive input from control circuit  {\textbar} 72 {\textbar} , facilitating the dynamic adjustment of reference disease state “r” (discussed below). Reference module  {\textbar} 116 {\textbar}  may additionally receive input from disease state estimator module array ({DSEMA})  {\textbar} 229 {\textbar}  ( {\textbar} {FIG}. 11 {\textbar} ; discussed below) and aggregate disease state estimator  {\textbar} 195 {\textbar}  ( {\textbar} {FIG}. 11 {\textbar}  discussed below) and components of signal processor  {\textbar} 71 {\textbar} , for use in dynamically determining reference disease state “r”. {\textbar} {FIG}. 10 {\textbar}   {\textbar}  is a schematic diagram of signal processor  {\textbar} 71 {\textbar} . In this illustrative embodiment, signal processor  {\textbar} 71 {\textbar}  includes a disease state estimator module array  {\textbar} 229 {\textbar}  that includes one or more signal processor modules that generate a quantitative estimate of at least one disease state or parameter thereof based upon its respective input. For example, magnitude of tremor in the 3 to 5 Hz range represents one possible representation of a disease state. This could be an absolute or normalized quantification of limb acceleration in meters per second squared. This component of the disease state would be calculated almost exclusively from sensory feedback from accelerometer array  {\textbar} 52 {\textbar} . Another possible disease state is the frequency of occurrence of episodes of tremor activity per hour. This element of the disease state may be estimated from any of several of the sensory feedback signals. In this case, the most accurate representation of this disease state element is obtained by applying a filter such as a Kalman filter to calculate this parameter based upon a weighted combination of the sensory feedback signals. Such weighting coefficients are calculated from quantified measures of the accuracy of and noise present upon each sensory feedback channel. {\textbar} In the illustrative embodiment, disease state estimator module array  {\textbar}   {\textbar} 229 {\textbar}  includes an {EMG} signal processor  {\textbar} 233 {\textbar} , {EEG} signal processor  {\textbar} 234 {\textbar} , accelerometer signal processor  {\textbar} 235 {\textbar} , acoustic signal processor  {\textbar} 236 {\textbar} , peripheral nerve electrode ({PNE}) signal processor  {\textbar} 237 {\textbar} , intracranial recording electrode ({ICRE}) signal processor  {\textbar} 238 {\textbar} , and intracranial stimulating electrode ({ICSE}) signal processor  {\textbar} 239 {\textbar} . It should be understood that other signal processors may also be included in the array  {\textbar} 229 {\textbar} . Inputs to these modules include conditioned {EMG} signal path  {\textbar} 78 {\textbar} , conditioned {EEG} signal path  {\textbar} 79 {\textbar} , conditioned accelerometer signal path  {\textbar} 80 {\textbar} , conditioned acoustic signal path  {\textbar} 81 {\textbar} , conditioned peripheral nerve electrode ({PNE}) signal path  {\textbar} 82 {\textbar} , conditioned intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar} , and conditioned intracranial stimulating electrode ({ICSE}) signal path  {\textbar} 84 {\textbar} , respectively. Communication between these modules is facilitated. The output(s) of each of the modules is connected to an aggregate disease state estimator  {\textbar} 195 {\textbar} . Aggregate disease state estimator  {\textbar} 195 {\textbar}  generates a single or plurality of disease state estimates “X” indicative of state of disease and response to treatment. {\textbar} In the preferred embodiment, the acceleration of at least one of the affected limb and the head, each of which is sensed as a sensory feedback channel by an element of the accelerometer array  {\textbar}   {\textbar} 52 {\textbar} , serves as respective elements in the disease state estimate X. These elements of disease state estimate X are inputs to respective control laws implemented in control circuit  {\textbar} 72 {\textbar} . of input to the control law. A control law governing the function of a proportional controller using acceleration as its single sensory feedback channel is given by equation (1):  {\textbar} u {\textbar}   {\textbar} 1 {\textbar} =0.3166( {\textbar} V*S {\textbar} 2 {\textbar} /m {\textbar} )* {\textbar} {ACC} {\textbar}   (1) {\textbar} and if {\textbar}   {\textbar} u {\textbar}   {\textbar} 2 {\textbar} =0.6333( {\textbar} V*S {\textbar} 2 {\textbar} /m {\textbar} )* {\textbar} {ACC} {\textbar}   (2) {\textbar}  where u {\textbar}   {\textbar} 1  {\textbar} and u {\textbar} 1  {\textbar} are the stimulation voltage given in volts; and {ACC} is the limb, mandible, or head acceleration given in meters per second squared (m/s {\textbar} 2 {\textbar} ). {\textbar} In equation (1), the stimulation site is the ventroposterolateral pallidum, the output stage mode is voltage regulated, the waveform is a continuous train of square waves, the amplitude u {\textbar}   {\textbar} 1  {\textbar} is given in volts (typically approximately 1 volt), and the remaining stimulation parameters include a pulse width of 210 microseconds, and a stimulation frequency of 130 Hz. In equation (2), the stimulation site is the ventral intermediate thalamic nucleus (Vim), the output stage mode is voltage regulated, the waveform is an intermittent train of square waves with an on time of 5 minutes and an off time of 45 seconds, the amplitude u {\textbar} 2  {\textbar} is given in volts (typically approximately 3 volts), and the remaining stimulation parameters include a pulse width of 60 microseconds, and a stimulation frequency of 130 Hz. {\textbar} In one preferred embodiment, the {ACC} signal represents the average acceleration over a finite time window, typically 15 to 60 seconds. This effective lowpass filtering provides a stable sensory feedback signal for which a proportional control law is appropriate. If stability and performance requirements dictate, as is familiar to those practiced in the art of feedback control, other components, including an integrator and a differentiator may be added to the control law to produce a proportional-integral-differential ({PID}) controller, as needed. {\textbar}   {\textbar} One preferred embodiment also includes electromyographic ({EMG}) signals as sensory feedback in the calculation of at least one element of the disease state estimate X which is an input to the control law. As discussed in the section describing {EMG} signal processor  {\textbar}   {\textbar} 233 {\textbar} , the {EMG} signals are rectified by full wave rectifier  {\textbar} 123 {\textbar} , passed through envelope determiner  {\textbar} 124 {\textbar} , passed through several bandpass filters  {\textbar} 125 {\textbar} ,  {\textbar} 127 {\textbar} ,  {\textbar} 129 {\textbar} ,  {\textbar} 131 {\textbar} ,  {\textbar} 133 {\textbar}  and associated threshold discriminators  {\textbar} 126 {\textbar} ,  {\textbar} 128 {\textbar} ,  {\textbar} 130 {\textbar} ,  {\textbar} 132 {\textbar} ,  {\textbar} 134 {\textbar}  and then passed in parallel to each of integrator  {\textbar} 135 {\textbar}  and counter  {\textbar} 136 {\textbar} . Integrator  {\textbar} 135 {\textbar}  generates an output which is a weighted function of it inputs and represents the average magnitude of tremor activity over a given time window −w/2 to +w/2. A simplified representation of this is given by equation (3): {\textbar} u {\textbar}   {\textbar} 3 {\textbar} = {\textbar} ∫ {\textbar} - {\textbar} w {\textbar} / {\textbar} 2 {\textbar} w {\textbar} / {\textbar} 2 {\textbar} ⁢ {\textbar} X {\textbar} {EMG} {\textbar} - {\textbar} ⁢ {\textbar} ⅆ {\textbar} t {\textbar} ( {\textbar} 3 {\textbar} ) {\textbar}  over a given time window −w/2 to +w/2. A simplified representation of this is given by the equation: {\textbar}   {\textbar} As is familiar to those skilled in the art of control theory, an integral controller is marginally stable. To confer stability to this control law, the equivalent of a finite leak of the output magnitude u.sub.4 to zero is added to maintain stability. A more general form of this equation is given by equation (4):  {\textbar}   {\textbar} − {\textbar}   {\textbar} C {\textbar} 1 {\textbar} ∂C {\textbar} 4 {\textbar} /dt+C {\textbar} 2 {\textbar} ·u {\textbar} 4 {\textbar} =B {\textbar} 1 {\textbar} ·∂X {\textbar} {EMG} {\textbar} /dt+B {\textbar} 2 {\textbar} ·X {\textbar} {EMG} {\textbar}   (4) {\textbar} Shown as a system function, the control law output U is given as the product of a transfer function H(s) and the disease estimate X, the input to the control law:  {\textbar}   {\textbar} u {\textbar}   {\textbar} ( {\textbar} s {\textbar} )( {\textbar} C {\textbar} 1 {\textbar} ∘s+C {\textbar} 2 {\textbar} )= {\textbar} X {\textbar} {EMG} {\textbar} ( {\textbar} s {\textbar} )( {\textbar} B {\textbar} 1 {\textbar} ∘s+B {\textbar} 2 {\textbar} )  (5) {\textbar} u {\textbar}   {\textbar} ( {\textbar} s {\textbar} )/ {\textbar} X {\textbar} {EMG} {\textbar} ( {\textbar} s {\textbar} )=( {\textbar} B {\textbar} 1 {\textbar} ∘s+B {\textbar} 2 {\textbar} )/( {\textbar} C {\textbar} 1 {\textbar} ∘s+C {\textbar} 2 {\textbar} )  (6) {\textbar} H {\textbar}   {\textbar} ( {\textbar} s {\textbar} )= {\textbar} U {\textbar} ( {\textbar} s {\textbar} )/ {\textbar} X {\textbar} {EMG} {\textbar} ( {\textbar} s {\textbar} )=( {\textbar} B {\textbar} 1 {\textbar} ∘s+B {\textbar} 2 {\textbar} )/( {\textbar} C {\textbar} 1 {\textbar} ∘s+C {\textbar} 2 {\textbar} )  (7) {\textbar}  One such control law with an appropriate time response is given by:  {\textbar}   {\textbar} H {\textbar}   {\textbar} ( {\textbar} s {\textbar} )= {\textbar} u {\textbar} ( {\textbar} s {\textbar} )/ {\textbar} X {\textbar} {EMG} {\textbar} ( {\textbar} s {\textbar} )= {\textbar} G {\textbar} {VIEMG} {\textbar} (0.1 {\textbar} ∘s+ {\textbar} 1)/(2 {\textbar} ∘s+ {\textbar} 1)  (8) {\textbar}  where G {\textbar}   {\textbar} V/{EMG}  {\textbar} is the gain in neuromodulation signal ({NMS}) (volts per volt of {EMG} signal). {\textbar} For intramuscular {EMG} electrodes, signal amplitudes are on the order of 100 microvolts. For neuromodulation signal ({NMS}) parameters of 2 volts amplitude, 60 microseconds pulse width, 130 Hz stimulation frequency, the appropriate overall gain G′ {\textbar}   {\textbar} v/{EMG}  {\textbar} is 20,000 volts {\textbar} {NMS} {\textbar} /volts {\textbar} {EMG} {\textbar} . Since the preamplifier stage performs amplification,  {\textbar} 1000 {\textbar} , in the preferred embodiment, the actual value for G {\textbar} v {\textbar} /{EMG} as implemented in the control law is 20 volts {\textbar} {NMS} {\textbar} /volts {\textbar} {PREAMPL} {EMG} {\textbar} . {\textbar} Disease state estimator  {\textbar}   {\textbar} 195 {\textbar}  determines estimates of disease state including but not limited to long-term, or baseline, components, circadian components, postprandial components, medication induced alleviation of components, medication induced components, and future predicted behavior of said components. Output of disease state estimator  {\textbar} 195 {\textbar}  includes output of observer  {\textbar} 228 {\textbar} , depicted in  {\textbar} {FIG}. 11 {\textbar} , which makes use of an adaptive model of disease behavior to estimate disease states which are not directly detectable from sensors. Such sensors provide input to the adaptive model to correct state estimates and model parameters. Each of the signal processor modules in disease state estimator module array  {\textbar} 229 {\textbar}  are described below. {\textbar} {FIG}. 3 {\textbar}   {\textbar}  is a block diagram of intracranial recording electrode ({ICRE}) signal processor  {\textbar} 238 {\textbar}  and intracranial stimulating electrode ({ICSE}) signal processor  {\textbar} 239 {\textbar} , each of which are included within signal processor  {\textbar} 71 {\textbar}  in the illustrative embodiment illustrated in  {\textbar} {FIGS}. 2 and 10 {\textbar} . {ICRE} signal processor module  {\textbar} 238 {\textbar}  and {ICSE} signal processor module  {\textbar} 239 {\textbar}  process signals from one or more intracranial electrodes, including but not limited to those comprising intracranial recording electrode array  {\textbar} 38 {\textbar}  and intracranial stimulating electrode array  {\textbar} 37 {\textbar} . As noted, intracranial stimulating electrode array  {\textbar} 37 {\textbar}  is comprised of one or more intracranial stimulating electrodes while intracranial recording electrode array  {\textbar} 38 {\textbar}  is comprised of one or more intracranial recording electrodes. {\textbar} Input to {ICRE} signal processor  {\textbar}   {\textbar} 238 {\textbar}  is conditioned intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar}  noted above. This input is connected to a spike detector  {\textbar} 85 {\textbar}  which identifies action potentials. Spike detection techniques are well known to those skilled in the art and generally employ low and high amplitude thresholds. Waveforms having amplitudes greater than the low threshold and lower than the high threshold are determined to be action potentials. These thresholds may be predetermined or adjusted manually using supervisory module  {\textbar} 56 {\textbar}  or may be adapted in real-time by an algorithm which sweeps the threshold through a range of values to search for values at which action potential spikes are consistently recorded. The low amplitude threshold is set above the amplitude of background noise and that of nearby cells not of interest, and the high amplitude threshold is set above the amplitude of the desired action potentials to allow their passage while eliminating higher amplitude noise spikes, such as artifacts arising from electrical stimulation currents. Bandpass, notch, and other filtering techniques may also be used to improve signal to noise ratio and the sensitivity and specificity of spike detectors. Individual neuron action potentials are usually recorded using fine point high-impedance electrodes, with impedances typically ranging from 1 to 5 megohms. Alternatively, larger lower-impedance electrodes may be used for recording, in which case the signals obtained typically represent aggregate activity of populations of neurons rather than action potentials from individual neurons. Spike detector  {\textbar} 85 {\textbar}  passes the waveform(s) to a spike characterizer  {\textbar} 86 {\textbar} . Spike characterizer  {\textbar} 86 {\textbar}  determines firing patterns of individual neurons. The patterns include, for example, tonic activity, episodic activity, and burst firing. Spike characterizer  {\textbar} 86 {\textbar}  calculates parameters that characterize the behavior of the individual and groups of neurons, the activity of which is sensed by intracranial recording electrode array  {\textbar} 38 {\textbar} . In one embodiment, the characterization includes parameterization of recorded action potentials, also referred to as spikes, bursts of spikes, and overall neural activity patterns. This parameterization includes, but is not limited to, calculation of frequencies of spikes, frequencies of bursts of spikes, inter-spike intervals, spike amplitudes, peak-to-valley times, valley-to-peak times, spectral composition, positive phase amplitudes, negative phase amplitudes, and positive-negative phase differential amplitudes. These parameters are depicted in  {\textbar} {FIG}. 14 {\textbar}  and are discussed below. Based on these parameterization, spike characterizer  {\textbar} 86 {\textbar}  discriminates individual spikes and bursts originating from different neurons. This discrimination facilitates serial monitoring of activity of individual and groups of neurons and the assessment and quantification of activity change, reflective of change in disease state and of response to therapy. {\textbar} A spike analyzer  {\textbar}   {\textbar} 87 {\textbar}  receives as input the parameters from spike characterizer  {\textbar} 86 {\textbar} . Spike analyzer  {\textbar} 87 {\textbar}  extracts higher level information, including but not limited to average spike frequencies, average interspike intervals, average amplitudes, standard deviations thereof, trends, and temporal patterning. By comparing current spike frequency rates to historical spike frequency data, spike analyzer  {\textbar} 87 {\textbar}  additionally calculates the rates of change of spike parameters. Prior trends and current rates of change may then be used to predict future behaviors. Rates of change of the parameters include but are not limited to autocorrelation and digital filtering. {\textbar} Spike analyzer  {\textbar}   {\textbar} 87 {\textbar}  may receive additional input from accelerometers, including but not limited to at least one of head mounted accelerometer  {\textbar} 12 {\textbar} , proximal accelerometer  {\textbar} 28 {\textbar} , enclosure mounted accelerometer- {\textbar} 36 {\textbar} , and distal accelerometer  {\textbar} 33 {\textbar} . Spike analyzer  {\textbar} 87 {\textbar}  may receive indirect input from accelerometers, such as from conditioned or processed signals arising therefrom. This may include, for example, the signal transmitted by conditioned accelerometer signal path  {\textbar} 80 {\textbar} . {\textbar} Spike analyzer  {\textbar}   {\textbar} 87 {\textbar}  may also receive additional input from {EMG} arrays  {\textbar} 50 {\textbar} , such as a proximal {EMG} electrode array  {\textbar} 45 {\textbar} , enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar} , or distal {EMG} electrode array  {\textbar} 47 {\textbar} . Spike analyzer  {\textbar} 87 {\textbar}  may receive indirect input from such {EMG} electrode arrays  {\textbar} 50 {\textbar} , such as from conditioned or processed signals arising therefrom, including but not limited to the signal transmitted by conditioned {EMG} signal path  {\textbar} 78 {\textbar} . {\textbar} These additional inputs from accelerometers and {EMG} arrays facilitates the characterization of neuronal firing patterns relative to activity of muscle groups and movement of joints, including but not limited to characterization of neuronal spike amplitudes and tuning of firing to movement, including but not limited to movement velocity and direction. The characterization may be used to assess functioning of the sensorimotor system, including but not limited to motor response time, and to measure the disease state and response to therapy. {\textbar}   {\textbar} Intracranial recording electrode ({ICRE}) single unit-based ({SU}) disease state estimator  {\textbar}   {\textbar} 88 {\textbar}  receives input from spike characterizer  {\textbar} 86 {\textbar}  and/or spike analyzer  {\textbar} 87 {\textbar} . Spike analyzer  {\textbar} 87 {\textbar}  provides higher level information, including but not limited to average spike frequencies, average interspike intervals, average amplitudes, standard deviations thereof, trends, and temporal patterning to disease state estimator  {\textbar} 88 {\textbar} . These inputs are representative of the current neuronal activity in the tissue from which the intracranial recording electrodes ({ICRE}) are recording. {ICRE} {SU} disease state estimator  {\textbar} 88 {\textbar}  may also receive input representative of one or more signals, including desired neuronal activity, from control circuit  {\textbar} 72 {\textbar} . The {ICRE} {SU} disease state estimate X {\textbar} {ICRE} {\textbar} \_ {\textbar} su  {\textbar} calculated by {ICRE} {SU} disease state estimator  {\textbar} 88 {\textbar} , may be comprised of a single or a plurality of signals, consistent with a representation of the disease state by a single or a multitude of state variables, respectively. The {ICRE} {MU} disease state estimate X {\textbar} {ICRE} {\textbar} \_ {\textbar} {MU}  {\textbar} calculated by {ICRE} {MU} disease state estimator  {\textbar} 88 {\textbar} , may be comprised of a single or a plurality of signals, each representative of multiunit neurophysiological signals, i.e. reflective of concurrent activity of numerous neurons. Both {ICRE} {SU} disease state estimate X {\textbar} {ICRE} {\textbar} \_ {\textbar} {SU}  {\textbar} and {ICRE} {MU} disease state estimate X {\textbar} {ICRE} {\textbar} \_ {\textbar} {MU}  {\textbar} are output to aggregate disease state estimator  {\textbar} 195 {\textbar} . {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 3 {\textbar} , conditioned intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar}  additionally connects to filter  {\textbar} 101 {\textbar} . Filter  {\textbar} 101 {\textbar}  is preferably of the bandpass type filter. In one embodiment, the bandpass filter  {\textbar} 101 {\textbar}  has a passband of 0.1 to 100 Hz, although other ranges may be used. Output of filter  {\textbar} 101 {\textbar}  connects to spectral energy characterizer  {\textbar} 102 {\textbar} , which may be implemented in any of several hardware or software forms. For example, in one embodiment, the spectral energy characterizer  {\textbar} 102 {\textbar}  is implemented using real-time fast Fourier transform ({FFT}) techniques. Alternatively, other digital or analog techniques may also be used. {\textbar} It should be understood that inputs and outputs from spike detector  {\textbar}   {\textbar} 85 {\textbar} , spike characterizer  {\textbar} 86 {\textbar} , spike analyzer  {\textbar} 87 {\textbar} , disease state estimator  {\textbar} 88 {\textbar} , filter  {\textbar} 101 {\textbar} , spectral energy characterizer  {\textbar} 102 {\textbar} , spectral energy analyzer  {\textbar} 103 {\textbar} , and disease state estimator  {\textbar} 104 {\textbar}  may be comprised of individual signals or a plurality of signals. Further, spike detector  {\textbar} 85 {\textbar} , spike characterizer  {\textbar} 86 {\textbar} , spike analyzer  {\textbar} 87 {\textbar} , disease state estimator  {\textbar} 88 {\textbar} , filter  {\textbar} 101 {\textbar} , spectral energy characterizer  {\textbar} 102 {\textbar} , spectral energy analyzer  {\textbar} 103 {\textbar} , and disease state estimator  {\textbar} 104 {\textbar}  may each have different parameters and signal processing characteristics for each of the multiple signals processed. Because baseline neuronal firing rates differ among various anatomical and functional regions of the brain, and their involvement in disease states and susceptibility to change in firing patterns varies, the respective signal processing circuitry and logic will vary correspondingly. For example, baseline firing rates among neurons in the globus pallidus externus are approximately 43 Hz and those in the globus pallidus internus are 59 Hz. {\textbar} The input to intracranial stimulating electrode {ICSE} signal processor  {\textbar}   {\textbar} 239 {\textbar} , referred to above as conditioned intracranial stimulating electrode ({ICSE}) signal path  {\textbar} 84 {\textbar} , connects to spike detector  {\textbar} 89 {\textbar} . Spike detector  {\textbar} 89 {\textbar}  identifies action potentials in a manner similar to that described above with reference to spike detector  {\textbar} 85 {\textbar} . Intracranial stimulating electrode {ICSE} signal processor  {\textbar} 239 {\textbar}  performs a similar set of functions as intracranial recording electrode {ICRE} signal processor  {\textbar} 238 {\textbar}  on a different set of sensory feedback signals. As noted above, spike detection techniques are well known to those skilled in the art. {\textbar} Spike detector  {\textbar}   {\textbar} 89 {\textbar}  passes waveforms to spike characterizer  {\textbar} 90 {\textbar} , which uses well known techniques to calculate parameters than characterize the behavior of the individual and groups of neurons, the activity of which is sensed by intracranial stimulating electrode array  {\textbar} 37 {\textbar} . As noted above with respect to spike characterizer  {\textbar} 86 {\textbar} , this characterization may include parameterization of spikes, bursts of spikes, and overall neural activity patterns. Similarly, the parameterization may include calculation of spike frequencies, burst frequencies, inter-spike intervals, amplitudes, peak-to-valley times, valley-to-peak times, spectral composition, positive phase amplitudes, negative phase amplitudes, and positive-negative phase differential amplitudes. Such characterization of neural spikes is known to those skilled in the art of neurophysiology. Based on this parameterization, spike characterizer  {\textbar} 90 {\textbar}  discriminates individual spikes and bursts originating from different neurons. As noted, such discrimination facilitates serial monitoring of activity of individual and groups of neurons and the assessment and quantification of activity change, reflective of change in disease state and of response to therapy. {\textbar} Spike analyzer  {\textbar}   {\textbar} 91 {\textbar}  receives the parameters from spike characterizer  {\textbar} 90 {\textbar} , and extracts higher level information, including average spike frequencies, average interspike intervals, average amplitudes, standard deviations thereof, trends, and temporal patterning. The function and operation of spike analyzer  {\textbar} 91 {\textbar}  is similar to that described herein with reference to spike analyzer  {\textbar} 87 {\textbar} . Similarly, spike analyzer  {\textbar} 91 {\textbar}  may receive additional input directly or indirectly from accelerometers and/or {EMG} arrays to facilitate the characterization of neuronal firing patterns relative to activity of muscle groups and movement of joints. This may include, for example, characterization of neuronal spike amplitudes and tuning of firing to movement, including but not limited to movement velocity and direction. Such characterization may be used to asses functioning of the sensorimotor system, including but not limited to motor response time, and to measure the disease state and response to therapy. {\textbar} Intracranial stimulating electrode ({ICSE}) single unit-based ({SU}) disease state estimator  {\textbar}   {\textbar} 92 {\textbar}  receives input from either or both spike characterizer  {\textbar} 90 {\textbar}  and spike analyzer  {\textbar} 91 {\textbar} . {ICSE} {SU} disease state estimator  {\textbar} 92 {\textbar}  receives input representative of the current neuronal activity from spike characterizer  {\textbar} 90 {\textbar} . {ICSE} {SU} disease state estimator  {\textbar} 92 {\textbar}  may receive input representative of at least one of several signals, including desired neuronal activity, actual neuronal activity, and the difference between these quantities. The {ICSE} {SU} disease state estimate, calculated by {ICSE} {SU} disease state estimator  {\textbar} 92 {\textbar} , may be comprised of a single or a plurality of signals, consistent with a representation of the disease state by a single or a multitude of state variables, respectively. {\textbar} As with intracranial recording electrode signal processor  {\textbar}   {\textbar} 238 {\textbar} , inputs and outputs from spike detector  {\textbar} 89 {\textbar} , spike characterizer  {\textbar} 90 {\textbar} , spike analyzer  {\textbar} 91 {\textbar} , disease state estimator  {\textbar} 92 {\textbar} , filter  {\textbar} 106 {\textbar} , spectral energy characterizer  {\textbar} 107 {\textbar} , spectral energy analyzer  {\textbar} 108 {\textbar} , and disease state estimator  {\textbar} 109 {\textbar}  may include individual or a plurality of signals, and each may have different parameters and signal processing characteristics for each of the multiple signals processed. Because baseline neuronal firing rates differ among various anatomical and functional regions of the brain, and their involvement in disease states and susceptibility to change in firing patters varies, the respective signal processing circuitry and logic varies correspondingly. {\textbar} {FIG}. 4 {\textbar}   {\textbar}  is a schematic diagram of a globus pallidus  {\textbar} 119 {\textbar}  implanted with stimulating and recording electrodes. Intracranial catheter  {\textbar} 7 {\textbar}  is shown in place with electrode of the intracranial stimulating electrode array  {\textbar} 37 {\textbar}  located within the globus pallidus internus (Gpi)  {\textbar} 120 {\textbar} , including globus pallidus internus internal segment ({GPi},i)  {\textbar} 94 {\textbar}  and globus pallidus internus external segment ({GPi},e)  {\textbar} 95 {\textbar} , and globus pallidus externus ({GPe})  {\textbar} 96 {\textbar} . {\textbar} Intracranial stimulating electrodes  {\textbar}   {\textbar} 1 {\textbar}  and  {\textbar} 2 {\textbar}  are shown implanted in the globus pallidus internus internal segment ({GPi},i)  {\textbar} 94 {\textbar} ; and intracranial stimulating electrodes  {\textbar} 3 {\textbar}  and  {\textbar} 4 {\textbar}  are shown implanted in the globus pallidus internus external segment ({GPi},e)  {\textbar} 95 {\textbar}  and globus pallidus externus ({GPe})  {\textbar} 96 {\textbar} , respectively. It should be understood that this arrangement is illustrative of one preferred embodiment, and other stimulating and recording electrode configurations may be employed without departing from the present invention. {\textbar} The optic tract  {\textbar}   {\textbar} 97 {\textbar}  is shown in its close anatomical relationship to the globus pallidus internus (Gpi)  {\textbar} 120 {\textbar} . The risk inherent in treatment modalities involving irreversible tissue ablation should be apparent; stereotactic errors of only one to several millimeters during lesioning of the globus pallidus internus (Gpi)  {\textbar} 120 {\textbar}  may result in irreversible damage or complete destruction of the optic tract  {\textbar} 97 {\textbar} . Furthermore, the advantage of a system which dynamically adjusts the amplitude of inhibitory electrical stimulus to the globus pallidus  {\textbar} 119 {\textbar}  to minimize said amplitude offers the potential advantage of minimization of side effects including interference with visual signals of the optic tract  {\textbar} 97 {\textbar}  and prevention of overtreatment. {\textbar} Intracranial stimulating electrodes  {\textbar}   {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} , {\textbar} 4 {\textbar}  are shown implanted in the {GPi},i  {\textbar} 94 {\textbar} , {GPi},e  {\textbar} 95 {\textbar} , {GPe}  {\textbar} 96 {\textbar} , respectively. This is one preferred embodiment. Numerous permutations of electrode stimulation site configuration may be employed, including more or fewer electrodes in each of these said regions, without departing from the present invention. Electrodes may be implanted within or adjacent to other regions in addition to or instead of those listed above without departing from the present invention, said other reasons including but not limited to the ventral medial Vim thalamic nucleus, other portion of the thalamus, subthalamic nucleus ({STN}), caudate, putamen, other basal ganglia components, cingulate gyrus, other subcortical nuclei, nucleus locus ceruleus, pedunculopontine nuclei of the reticular formation, red nucleus, substantia nigra, other brainstem structure, cerebellum, internal capsule, external capsule, corticospinal tract, pyramidal tract, ansa lenticularis, white matter tracts, motor cortex, premotor cortex, supplementary motor cortex, other motor cortical regions, somatosensory cortex, other sensory cortical regions, Broca's area, Wernickie's area, other cortical regions, other central nervous system structure, other peripheral nervous system structure, other neural structure, sensory organs, muscle tissue, or other non-neural structure. {\textbar} Referring to  {\textbar}   {\textbar} {FIGS}. 3 and 4 {\textbar} , a small percentage of cells in the globus pallidus internus internal segment  {\textbar} 94 {\textbar}  and globus pallidus internus external segment  {\textbar} 95 {\textbar}  exhibit tremor-synchronous discharges. As noted, at least one of single unit recordings from individual cells and multiple unit recordings from a plurality of cells are processed by signal processor  {\textbar} 71 {\textbar} . The single and multiple unit recordings may be derived from signals arising from intracranial stimulating electrode array  {\textbar} 37 {\textbar} , intracranial recording electrode array  {\textbar} 38 {\textbar} , or other sources. The output from signal processor  {\textbar} 71 {\textbar}  is connected to control circuit  {\textbar} 72 {\textbar}  and the output may represent at least one of disease state, magnitude of symptomatology, response to therapy, other parameter, and combination thereof. {\textbar} Individual electrodes comprising intracranial stimulating electrode array  {\textbar}   {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar}  may each be of the microelectrode type for single unit recordings, macroelectrode type for multiple unit recordings, other electrode type, or a combination thereof, without departing from the spirit of the present invention. In one preferred embodiment, intracranial stimulating electrode array  {\textbar} 37 {\textbar}  consists of macroelectrodes. The macroelectrodes facilitate delivery of stimulation current at a lower charge density (coulombs per unit of electrode surface area) than microelectrodes of the same chemistry and surface treatment. The dimensions of intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar}  are selected such that the current density, or electrical current divided by electrode surface area, is below the threshold of reversible charge injection for the given electrode material. {\textbar} Standard single cell recording technique, using an electrode with an impedance of typically 1-2 Megohms, involves bandpass filtering with −6 decibel ({dB}) points at 300 and 10,000 Hertz. This filtering, or a modification thereof, may be accomplished by {ICRE} filter  {\textbar}   {\textbar} 65 {\textbar}  and {ICSE} filter  {\textbar} 64 {\textbar} ; alternatively, it may be performed in spike detector  {\textbar} 85 {\textbar}  and spike detector  {\textbar} 89 {\textbar} , respectively, or other portion of stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a block diagram of one embodiment of an {EMG} signal processor  {\textbar} 233 {\textbar}  which is included in a preferred embodiment of signal processor  {\textbar} 71 {\textbar} . {EMG} signal processor  {\textbar} 233 {\textbar}  processes signals from {EMG} electrode array  {\textbar} 50 {\textbar} , performing functions including but not limited to full wave rectification, envelope determination, bandpass filtering, threshold discrimination, and others described in more detail below, to produce signals indicative of the overall magnitude of tremor as well as the frequency at which tremor episodes occur. As noted, {EMG} electrode array  {\textbar} 50 {\textbar}  includes, but is not limited to, proximal {EMG} electrode array  {\textbar} 45 {\textbar} , enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar} , and distal {EMG} electrode array  {\textbar} 47 {\textbar} . {EMG} electrodes may be located in any implanted or external location without departing from the present invention. For example, electrodes may be located within or in proximity to the hand, forearm, arm foot, calf, leg, abdomen, torso, neck, head, haw, lip, eyelid, larynx, vocal cords, and tongue. {\textbar} Conditioned {EMG} signal path  {\textbar}   {\textbar} 78 {\textbar}  is also connected to a well-known full wave rectifier  {\textbar} 123 {\textbar}  now or later developed. Output from the full wave rectifier  {\textbar} 123 {\textbar}  is coupled to an input of an envelope determiner  {\textbar} 124 {\textbar} . Determination of the envelope of a modulated signal is well known to those skilled in the art of electronics; this may be readily implemented in analog or digital hardware or in software. Output of envelope determiner  {\textbar} 124 {\textbar}  is connected to inputs of filters  {\textbar} 125 {\textbar} ,  {\textbar} 127 {\textbar} ,  {\textbar} 129 {\textbar} ,  {\textbar} 131 {\textbar}  and  {\textbar} 133 {\textbar} . In one embodiment, filters  {\textbar} 125 {\textbar} ,  {\textbar} 127 {\textbar} ,  {\textbar} 129 {\textbar} ,  {\textbar} 131 {\textbar} ,  {\textbar} 133 {\textbar}  implement passbands of approximately 0.1-2 Hz, 2-3 Hz, 3-5 Hz, 7-8 Hz, and 8-13 Hz, respectively. Outputs of filters  {\textbar} 125 {\textbar} ,  {\textbar} 127 {\textbar} ,  {\textbar} 129 {\textbar} ,  {\textbar} 131 {\textbar}  and  {\textbar} 133 {\textbar}  are connected to threshold discriminators  {\textbar} 126 {\textbar} ,  {\textbar} 128 {\textbar} ,  {\textbar} 130 {\textbar} ,  {\textbar} 132 {\textbar} ,  {\textbar} 134 {\textbar} , respectively. {\textbar} Threshold discriminators  {\textbar}   {\textbar} 126 {\textbar} ,  {\textbar} 128 {\textbar} ,  {\textbar} 130 {\textbar} ,  {\textbar} 132 {\textbar} , and  {\textbar} 134 {\textbar}  generate outputs representing episodes of normal voluntary movement (Mv), low frequency intention tremor (Til) resting tremor (Tr), high frequency intention tremor (Tih), and physiologic tremor (Tp), respectively. These outputs are each connected to both of integrator  {\textbar} 135 {\textbar}  and counter  {\textbar} 136 {\textbar} . Integrator  {\textbar} 135 {\textbar}  generates outputs representative of the total activity of each of the above types of movement over at least one period of time. One such time period may be, for example, time since implantation, time since last visit to physician or health care provider, month internal, week interval, day interval, interval since last medication dose, interval since last change in stimulation parameters, weighted average of multiple time windows, and convolution of said activity with arbitrary time window function. {\textbar} Counter  {\textbar}   {\textbar} 136 {\textbar}  generates outputs representative of the number of episodes of each of the above types of movement over at least one period of time. Such period of time may be, for example, time since implantation, time since last visit to physician or health care provider, month interval, week internal, day interval, interval since last medication dose, interval since last change in stimulation parameters, and weighted average of said number of episodes over multiple time windows. Outputs from integrator  {\textbar} 135 {\textbar}  and counter  {\textbar} 136 {\textbar}  are connect to {EMG} analyzer  {\textbar} 137 {\textbar} . {EMG} analyzer  {\textbar} 137 {\textbar}  performs a number of functions including, for example, calculation of proportions of tremor activity which are of the rest and the intention type, ratios of different types of tremor activity, the level of suppression of resting tremor activity with voluntary movement, assessment of temporal patterns of {EMG} activity. {EMG} disease state estimator  {\textbar} 138 {\textbar}  receives inputs from {EMG} analyzer  {\textbar} 137 {\textbar}  and generates output representative of disease state based upon said input. In one preferred embodiment, two disease states are calculated, including a signal representative of the overall magnitude of tremor activity and a signal representative of the frequency of occurrence of tremor events. It should be understood that all signals paths may transmit one or more signals without departing from the present invention. {\textbar} {EMG} signals may be sensed from any individual or group of muscles and processed in a manner including but not limited to the determination of severity and frequency of occurrence of various tremor types. Normal or physiologic tremor includes movement in the 8-13 Hz range and may be used as a normalization for the other types of sensed tremor. The predominant pathological form of tremor exhibited in Parkinson's disease patients is the classical “resting” tremor which includes movements in the 3-5 Hz range which are present at rest and suppressed in the presence of voluntary movement. In the present invention, quantification of this tremor type serves as a heavily weighted sensory input in the assessment of disease state and response to therapy. Parkinson's disease patients may also exhibit intention tremor, of which there are two types. The first type of intention tremor is referred to as “low frequency intention tremor” (Til in the present invention) and consists of movements in the 2-3 Hz range. A second type of intention tremor is referred to as “high frequency intention tremor” Tih in the present invention and consists of irregular movements in the 7-8 Hz range which persist throughout voluntary movement. Other types of tremor having associated movement in other ranges may be sensed and represented by the {EMG} signals. {\textbar}   {\textbar} {EMG} signals from at least one of orbicularis oculi (effecting eye closure), levator palpebrae (effecting eye opening), and other muscles contributing to eyelid movement, may be sensed and processed to determine frequency of eye blinking. Patients with Parkinson's disease exhibit a reduction in eyeblinking frequency from the normal of 20 per minute to 5 to 10 per minute, and this parameter is sensed as a measure of disease severity and response to treatment. Additionally, said {EMG} signals may be sensed and processed for detection and quantification of blepharoclonus, or rhythmic fluttering of the eyelids, and used as a measure of disease state and response to therapy. {EMG} signals, including baseline levels thereof, may be used to quantify rigidity and hypertonus as measures of disease state and response to therapy. Discharge patterns of individual motor units, including but not limited to synchronization of multiple units and distribution of intervals preceding and following discharge, may be used as measures of disease state and response to therapy. {\textbar}   {\textbar} {FIG}. 6 {\textbar}   {\textbar}  is a block diagram of one embodiment of an {EEG} signal processor module  {\textbar} 234 {\textbar}  which is included in embodiments of signal processor  {\textbar} 71 {\textbar} . The {EEG} signal processor module  {\textbar} 234 {\textbar}  processes signals from {EEG} electrode array  {\textbar} 51 {\textbar} . Conditioned {EEG} signal path  {\textbar} 79 {\textbar}  connects to an input of artifact rejecter  {\textbar} 139 {\textbar}  which rejects signals with amplitudes above a threshold. In one embodiment, this threshold is 0.1 {mV}. An output from artifact rejecter  {\textbar} 139 {\textbar}  connects to an input of each of supplementary motor area signal extractor  {\textbar} 140 {\textbar}  and filters  {\textbar} 143 {\textbar} ,  {\textbar} 146 {\textbar} ,  {\textbar} 149 {\textbar} ,  {\textbar} 152 {\textbar} ,  {\textbar} 219 {\textbar} . Filters  {\textbar} 143 {\textbar} ,  {\textbar} 146 {\textbar} ,  {\textbar} 149 {\textbar} ,  {\textbar} 152 {\textbar} , and  {\textbar} 219 {\textbar}  are preferably of the bandpass type with passbands of 13-30 Hz, 8-13′ Hz, 4-7 Hz, 0.1-4 Hz, and 0.1-0.3 Hz, respectively. Each filter output is connected to an input of an associated full wave rectifier  {\textbar} 141 {\textbar} ,  {\textbar} 144 {\textbar} ,  {\textbar} 147 {\textbar} ,  {\textbar} 150 {\textbar} ,  {\textbar} 153 {\textbar} ,  {\textbar} 220 {\textbar} . Each full wave rectifier  {\textbar} 141 {\textbar} ,  {\textbar} 144 {\textbar} ,  {\textbar} 147 {\textbar} ,  {\textbar} 150 {\textbar} ,  {\textbar} 153 {\textbar} ,  {\textbar} 220 {\textbar}  is connected to an input of an associated envelope determiner  {\textbar} 142 {\textbar} ,  {\textbar} 145 {\textbar} ,  {\textbar} 148 {\textbar} ,  {\textbar} 151 {\textbar} ,  {\textbar} 154 {\textbar} , and  {\textbar} 221 {\textbar} , respectively. The envelope determiners generate a signal representative of the envelope of the input signal, typically performed by lowpass filtering with a time constant of 5 seconds. Finally, outputs of envelope determiners  {\textbar} 142 {\textbar} ,  {\textbar} 145 {\textbar} ,  {\textbar} 148 {\textbar} ,  {\textbar} 151 {\textbar} ,  {\textbar} 154 {\textbar} , and  {\textbar} 221 {\textbar}  are connected to {EEG} disease state estimator  {\textbar} 155 {\textbar} . {\textbar} Signal {SMA} generated by supplementary motor area signal extractor  {\textbar}   {\textbar} 140 {\textbar}  represents activity in the supplementary motor area ipsilateral to the intracranial stimulating electrode array ({ISEA})  {\textbar} 37 {\textbar} . Supplementary motor area signal extractor  {\textbar} 140 {\textbar}  amplifies signals which are unique to elements of the {EEG} electrode array  {\textbar} 51 {\textbar}  which overlie the supplementary motor area. The supplementary motor area receives neural signals via neural projections from the basal ganglia and exhibits decreased activity in patients with Parkinson disease. The {SMA} is essential for sequential movements, which are often impaired in Parkinson's disease patients. The {SMA} signal provides a quantitative measure of disease state and response to therapy. The {SMA} signal is extracted from the anterior {EEC} leads, predominantly from those in the vicinity of the frontal cortex, and provides a quantitative measure of disease state and response to therapy. Signals beta, alpha, theta, and delta consist of 13-30 Hz, 8-13 Hz, 4-7 Hz, and 0.14 Hz activity, respectively. {\textbar} Signal “resp” consists of 0.1-0.3 Hz activity and reflects respiration. Parkinson's disease patients exhibit irregular respiratory patterns characterized by pauses and by abnormally deep breathing while at rest and preceding speech. Assessment of respiratory irregularity as well as other parameters derived from such resp signal serve as quantitative measures of disease state and response to therapy. {\textbar}   {\textbar} Anterior {EEG} electrodes are also used to sense {EMG} signals, and the {EMG} signals are processed to determine activity of muscles including but not limited to those related to eye blinking activity. Processing of the {EMG} signals is included in the  {\textbar}   {\textbar} {FIG}. 6 {\textbar}  circuit block diagram which contains the {EEC} signal processing component of signal processor  {\textbar} 71 {\textbar} . However, the processing could be incorporated into {EMG} signal processing component of signal processor  {\textbar} 71 {\textbar}  without departing from scope of the present invention. Conditioned {EEG} signal path  {\textbar} 79 {\textbar}  is additionally connected to input of full wave rectifier  {\textbar} 222 {\textbar} , the output of which is connected to the input of an envelope determiner  {\textbar} 223 {\textbar} . Envelope determiner  {\textbar} 223 {\textbar}  includes an output connected to input of filter  {\textbar} 224 {\textbar} . Filter  {\textbar} 224 {\textbar}  is preferably of the bandpass type with a passband range of 0.1 to 20 Hz. Filter  {\textbar} 224 {\textbar}  has an output connected to input of threshold discriminator  {\textbar} 225 {\textbar} , the output of which is connected to {EEG} disease state estimator  {\textbar} 155 {\textbar} . {\textbar} Preferably, {EMG} signals arising from activity of at least one of orbicularis oculi (effecting eye closure), levator palpebrae (effecting eye opening), and other muscles the activity of which is associated with eyelid movement are sensed by anterior {EEG} electrodes. These {EMG} signals are processed to determine eye blink events, and the rates and regularity of eye blinking activity are calculated. Frequency and irregularity of eyeblinking as well as blepharoclonus, or rhythmic fluttering of the eyelids, are quantified as measures of disease state and response to therapy. {\textbar}   {\textbar} {FIG}. 7 {\textbar}   {\textbar}  is a block diagram of one embodiment of an accelerometer signal processor  {\textbar} 235 {\textbar}  which is incorporated into certain embodiments of signal processor  {\textbar} 71 {\textbar} . The accelerometer signal processor  {\textbar} 235 {\textbar}  processes signals from accelerometer array  {\textbar} 52 {\textbar} . Conditioned accelerometer signal path  {\textbar} 80 {\textbar}  is connected to an input of each of a plurality of filters  {\textbar} 156 {\textbar} ,  {\textbar} 160 {\textbar} ,  {\textbar} 164 {\textbar} ,  {\textbar} 168 {\textbar} ,  {\textbar} 172 {\textbar} . The filters are preferably of the bandpass type with passbands of 0.1-2 Hz, 2-3 Hz, 3-5 Hz, 7-8 Hz, and 8-13 Hz, respectively. Other passband frequency ranges may also be used. The output of each filter  {\textbar} 156 {\textbar} ,  {\textbar} 160 {\textbar} ,  {\textbar} 164 {\textbar} ,  {\textbar} 168 {\textbar} ,  {\textbar} 172 {\textbar}  is connected to an associated full wave rectifiers  {\textbar} 157 {\textbar} ,  {\textbar} 161 {\textbar} ,  {\textbar} 165 {\textbar} ,  {\textbar} 169 {\textbar} , and  {\textbar} 173 {\textbar} , respectively. The output of each rectifier  {\textbar} 157 {\textbar} ,  {\textbar} 161 {\textbar} ,  {\textbar} 165 {\textbar} ,  {\textbar} 169 {\textbar} , and  {\textbar} 173 {\textbar}  is connected to an associated envelope determiners  {\textbar} 158 {\textbar} ,  {\textbar} 162 {\textbar} ,  {\textbar} 166 {\textbar} ,  {\textbar} 170 {\textbar} , and  {\textbar} 174 {\textbar} , respectively. Outputs of envelope determiners  {\textbar} 158 {\textbar} ,  {\textbar} 162 {\textbar} ,  {\textbar} 166 {\textbar} ,  {\textbar} 170 {\textbar} , and  {\textbar} 174 {\textbar}  are connected to inputs of an associated threshold discriminators  {\textbar} 159 {\textbar} ,  {\textbar} 163 {\textbar} ,  {\textbar} 167 {\textbar} ,  {\textbar} 171 {\textbar} , and  {\textbar} 175 {\textbar} , respectively. {\textbar} Outputs of threshold discriminators  {\textbar}   {\textbar} 159 {\textbar} ,  {\textbar} 163 {\textbar} ,  {\textbar} 167 {\textbar} ,  {\textbar} 171 {\textbar} ,  {\textbar} 175 {\textbar}  represent episodes of normal voluntary movement (Mv), low frequency intention tremor (Til), resting tremor (Tr), high frequency intention tremor (Tih), and physiologic tremor (Tp), respectively. These outputs are each connected to an integrator  {\textbar} 176 {\textbar}  and a counter  {\textbar} 177 {\textbar} . Integrator  {\textbar} 176 {\textbar}  generates outputs representative of the total activity of each of the above types of movement over at least one period of time. As noted, such a time period may be, for example, time since implementation, time since last visit to physician or health care provider, or some other time interval, weighted average of multiple time windows, or convolution of selected activities with an arbitrary time window function. {\textbar} Counter  {\textbar}   {\textbar} 177 {\textbar}  generates outputs representative of the number of episodes of each of the above types of movements over at least one such period of time. Outputs from integrator  {\textbar} 176 {\textbar}  and counter  {\textbar} 177 {\textbar}  are connect to an acceleration analyzer  {\textbar} 178 {\textbar} . Acceleration analyzer  {\textbar} 178 {\textbar}  calculates proportions of tremor types, such as the rest and intention types, ratios of different types of tremor activity, the level of suppression of resting tremor activity with voluntary movement, and assessment of temporal patterns of movement and acceleration. Acceleration analyzer  {\textbar} 178 {\textbar}  may perform some or all of these calculations, as well as other calculations, on alternative embodiments of the present invention. Acceleration-based disease state estimator  {\textbar} 179 {\textbar}  receives input from acceleration analyzer  {\textbar} 178 {\textbar}  and generates output representative of disease state based upon such input. {\textbar} It should be understood that accelerometer signals may be sensed from any individual or group of body components. For example, such signals may be sensed from joints, bones, and muscles. Furthermore, such signals may be processed in any well known manner, including the determination of severity and frequency of occurrence of various tremor types. The types of tremor have been described above with respect to  {\textbar}   {\textbar} {FIG}. 5 {\textbar} . {\textbar} {FIG}. 8 {\textbar}   {\textbar}  is a block diagram of one embodiment of an acoustic signal processor  {\textbar} 236 {\textbar}  which is included in certain embodiments of signal processor  {\textbar} 71 {\textbar} . Acoustic signal processor  {\textbar} 236 {\textbar}  processes signals from acoustic transducer array  {\textbar} 53 {\textbar} . Conditioned acoustic signal path  {\textbar} 81 {\textbar}  is connected to a full wave rectifier  {\textbar} 180 {\textbar}  and a spectral analyzer  {\textbar} 185 {\textbar} . The output of full wave rectifier  {\textbar} 180 {\textbar}  is connected to an input of an envelope determiner  {\textbar} 181 {\textbar} , an output of which is connected to an input of a low threshold discriminator  {\textbar} 182 {\textbar}  and a high threshold discriminator  {\textbar} 183 {\textbar} . Low threshold discriminator  {\textbar} 182 {\textbar}  and high threshold discriminator  {\textbar} 183 {\textbar}  each have an output connected to an input of timer  {\textbar} 184 {\textbar} . Timer  {\textbar} 184 {\textbar}  generates an output signal representing latency (Lat) and is connected to acoustic analyzer  {\textbar} 186 {\textbar} . An output of acoustic analyzer  {\textbar} 186 {\textbar}  is connected to an input of acoustic-based disease state estimator  {\textbar} 187 {\textbar} . Latency (Lat) represents the latency between initiation of vocal utterance and the subsequent achievement of a threshold level of vocal amplitude. Such a vocal amplitude level is set by high threshold discriminator  {\textbar} 183 {\textbar}  and may represent steady state vocal amplitude or a preset or dynamically varying threshold. Latency from voice onset to achievement of steady state volume may be delayed in patients with Parkinson's disease and is calculated as a measure of disease state and response to therapy. {\textbar} Acoustic analyzer  {\textbar}   {\textbar} 186 {\textbar}  receives input from spectral analyzer  {\textbar} 185 {\textbar} . The respiratory pattern is determined from rhythmic modulation of voice and breathing sounds, sensed by elements of the acoustic transducer array  {\textbar} 53 {\textbar} . Irregularity and pauses in respiration as well as abnormally deep breathing patterns at rest and preceding speech are exhibited in Parkinson's disease patients. Such parameters are quantified and used as estimates of disease state and response to therapy. Respiration durations are quantified; abnormally deep respiration both during rest and preceding speech are identified and used as indicators of disease state and response to therapy. Pauses in speech and decline in speech amplitude, or fading, are additionally monitored as indicators of disease state and response to therapy. Spectral composition of speech is monitored and the change in spectral composition, reflective of changes of pharyngeal and laryngeal geometry, are quantified. Additionally, the fundamental vocal frequency; that is, the frequency at which the epiglottis vibrates, is extracted an that standard deviation of the fundamental vocal frequency is calculated over various time intervals as a quantified measure of the monotonic quality of speech characteristic of Parkinson's disease. This serves as yet another indicator of disease state and response to therapy. {\textbar} {FIG}. 9 {\textbar}   {\textbar}  is block diagram of one embodiment of a peripheral nerve electrode ({PNE}) signal processor  {\textbar} 237 {\textbar}  which is implemented in certain embodiments of signal processor  {\textbar} 71 {\textbar} . {PNE} signal processor  {\textbar} 237 {\textbar}  processes signals from peripheral nerve electrode array  {\textbar} 54 {\textbar} . These signals provided by peripheral nerve electrode array  {\textbar} 54 {\textbar}  are provided to {PNE} signal processor  {\textbar} 237 {\textbar}  via conditioned {PNE} signal path  {\textbar} 82 {\textbar} . Conditioned {PNE} signal path  {\textbar} 82 {\textbar}  is connected to an input of a spike detector  {\textbar} 188 {\textbar}  and a filter  {\textbar} 191 {\textbar} . {\textbar} Spike detector  {\textbar}   {\textbar} 188 {\textbar}  identifies action potentials. As noted, spike detection techniques are well known to those skilled in the art, and generally employ low and high amplitude thresholds. Waveforms with amplitudes greater than the low threshold and lower than the high threshold are determined to be action potentials. These thresholds may be adjusted in real-time, and the low amplitude threshold is set above the amplitude of background noise and that of nearby cells not of interest, and the high amplitude threshold is set above the amplitude of the desired action potentials to allow their passage while eliminating higher amplitude noise spikes, such as artifacts arising from electrical stimulation currents. It should be understood that bandpass, notch, and other filtering techniques may also used to improve signal to noise ratio and the sensitivity and specific of spike detectors. Individual neuron action potentials are usually recorded using fine point high-impedance electrodes, with impedances typically ranging from 1 to 5 megohms. Alternatively, larger lower-impedance electrodes may be used for recording, in which case the signals obtained typically represent aggregate activity of populations of neurons rather than action potentials from individual neurons. As noted above, peripheral nerve electrode array  {\textbar} 54 {\textbar}  may include such electrodes as single unit recording microelectrodes, multiple unit recording microelectrodes, intrafascicular electrodes, other intraneural electrodes, epineural electrodes, and any combination thereof. {\textbar} A spike characterizer  {\textbar}   {\textbar} 189 {\textbar}  determines firing patterns of individual neurons, including, for example, tonic activity, episodic activity and burst firing. Spike characterizer  {\textbar} 189 {\textbar}  receives the signals passed by spike detector  {\textbar} 188 {\textbar}  and calculates parameters that characterize the behavior of the individual and groups of neurons, the activity of which is sensed by peripheral nerve electrode array  {\textbar} 54 {\textbar} . Such characterization includes but is not limited to parameterization of spikes, bursts of spikes, and overall neural activity patterns. Parameterization includes but is not limited to calculation of frequencies of spikes, frequencies of bursts of spikes, inter-spike intervals, spike amplitudes, peak-to-valley times, valley-to-peak times, spectral composition, positive phase amplitudes, negative phase amplitudes, and positive-negative phase differential amplitudes. These parameters are described in further detail below with reference to  {\textbar} {FIG}. 14 {\textbar} . Based on this parameterization, spike characterizer  {\textbar} 189 {\textbar}  discriminates individual spikes and bursts originating from different neurons. The discrimination facilitates aerial monitoring of activity of individual and groups of neurons and the assessment and quantification of activity change, reflective of change in disease state and of response to therapy. {\textbar} A spike analyzer  {\textbar}   {\textbar} 190 {\textbar}  receives as input the parameters from spike characterizer  {\textbar} 189 {\textbar} , and extracts higher level information, including but not limited to average spike frequencies, average frequencies o bursts of spikes, average interspike intervals, average spike amplitudes, standard deviations thereof, trends, and temporal patterning. {\textbar} Preferably, spike analyzer  {\textbar}   {\textbar} 190 {\textbar}  additionally calculates the rates of change of spike parameters. From prior and current rates of change, future behaviors may be predicted. Rates of change of the parameters include but are not limited to first, second, and third time derivatives. In alternative embodiments, spike analyzer  {\textbar} 190 {\textbar}  additionally calculates weighted combinations of spike characteristics and performs convolutions of spike waveforms with other spike waveforms, and other preset and varying waveforms. Such operations may be performed, for example, for purposes including but not limited to autocorrelation and digital filtering. {\textbar} Spike analyzer  {\textbar}   {\textbar} 190 {\textbar}  may receive additional input from accelerometers, such as those described above, including head mounted accelerometer  {\textbar} 12 {\textbar} , proximal accelerometer  {\textbar} 28 {\textbar} , enclosure mounted accelerometer  {\textbar} 36 {\textbar} , and distal accelerometer  {\textbar} 33 {\textbar} . Spike analyzer  {\textbar} 190 {\textbar}  may receive indirect input from these or other accelerometers, as well as from conditioned or processed signals arising therefrom. Such conditioned or processed signals include, for example, the signal transmitted by conditioned accelerometer signal path  {\textbar} 80 {\textbar}  ( {\textbar} {FIG}. 7 {\textbar} ). {\textbar} Spike analyzer  {\textbar}   {\textbar} 190 {\textbar}  may receive additional input from {EMG} arrays. As noted, such {EMG} arrays may include, for example, proximal {EMG} electrode array  {\textbar} 4 {\textbar} S, enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar} , and distal {EMG} electrode array  {\textbar} 47 {\textbar} . Spike analyzer  {\textbar} 190 {\textbar}  may also receive indirect input from these or other {EMG} electrode arrays, as well as from conditioned or processed signals arising therefrom. Such conditioned or processed signals include but are not limited to the signal transmitted by conditioned {EMG} signal path  {\textbar} 78 {\textbar}  ( {\textbar} {FIG}. 5 {\textbar} ). These additional inputs from accelerometers and {EMG} arrays facilitates the characterization of neuronal firing patterns relative to activity of muscle groups and movement of joints. Such characterization may include, for example, characterization of neuronal spike amplitudes and tuning of neuronal spike frequencies to movement, including but not limited to the signal transmitted by conditioned {EMG} signal path  {\textbar} 78 {\textbar} . {\textbar} The additional input from accelerometers and {EMG} arrays also facilitates the characterization of neuronal firing patterns relative to activity of muscle groups and movement of joints, including but not limited to characterization of neuronal spike amplitudes and tuning of neuronal spike frequencies to movement, including but not limited to movement velocity and direction. These characterizations may be used to assess functioning of the sensorimotor system, including but not limited to motor response time, and to measure the disease state and response to therapy. {\textbar}   {\textbar} Peripheral nerve electrode ({PNE})-based single unit ({SU}) disease state estimator  {\textbar}   {\textbar} 194 {\textbar}  receives an input representative of the current neuronal activity from spike characterizer  {\textbar} 189 {\textbar} . {PNE}-based single unit disease state estimator  {\textbar} 194 {\textbar}  may receive input representative of at least one of several signals, including desired neuronal activity, actual neuronal activity, and the difference between these quantities. The output from estimator  {\textbar} 194 {\textbar}  may carry a single or a plurality of signals, consistent with a representation of the disease state by a single or a multitude of state variables, respectively. {\textbar} Filter  {\textbar}   {\textbar} 191 {\textbar}  has an output connected to an input of spectral energy characterizer  {\textbar} 192 {\textbar} . Spectral energy characterizer  {\textbar} 192 {\textbar}  calculates the spectral composition of the signals sensed by the peripheral nerve electrode array  {\textbar} 54 {\textbar} . Spectral energy characterizer  {\textbar} 192 {\textbar}  provides outputs to each of spectral energy analyzer  {\textbar} 193 {\textbar}  and peripheral nerve electrode ({PNE})-based multiple unit disease state estimator  {\textbar} 232 {\textbar} . Output of spectral energy analyzer  {\textbar} 193 {\textbar}  is connected to an input of {PNE}-based multiple unit ({MU}) disease state estimator  {\textbar} 232 {\textbar} . {PNE} {SU} disease state estimator  {\textbar} 194 {\textbar}  both receives input from and provides output to {PNE} {MU} disease state estimator  {\textbar} 232 {\textbar} . {\textbar} {PNE} {MU} disease state estimator  {\textbar}   {\textbar} 232 {\textbar}  receives as an input signals representative of the current neuronal activity from spectral energy characterizer  {\textbar} 192 {\textbar} . {PNE} {MU} disease state estimator  {\textbar} 232 {\textbar}  may receive input representative of at least one of several signals, including desired neuronal activity, actual neuronal activity, and the difference between these quantities. The output from {PNE} {MU} disease state estimator  {\textbar} 232 {\textbar}  may carry a single or a plurality of signals, consistent with a representation of the disease state by a single or a multitude of state variables, respectively. {\textbar} It should be understood that inputs and outputs from each spike detector  {\textbar}   {\textbar} 188 {\textbar} , spike characterizer  {\textbar} 189 {\textbar} , spike analyzer  {\textbar} 190 {\textbar} , filter  {\textbar} 191 {\textbar} , spectral energy characterizer  {\textbar} 192 {\textbar} , spectral energy analyzer  {\textbar} 193 {\textbar} , and {PNE}-based single unit disease state estimator  {\textbar} 194 {\textbar} , and {PNE}-based multiple unit disease state estimator  {\textbar} 232 {\textbar}  may each be comprised of individual signals or a plurality of signals. It should also be understood that each of these the units, spike detector  {\textbar} 188 {\textbar} , spike characterizer  {\textbar} 189 {\textbar} , spike analyzer  {\textbar} 190 {\textbar} , filter  {\textbar} 191 {\textbar} , spectral energy characterizer  {\textbar} 192 {\textbar} , spectral energy analyzer  {\textbar} 193 {\textbar} , and {PNE}-based single unit disease state estimator  {\textbar} 194 {\textbar} , and {PNE} {MU} disease state estimator  {\textbar} 232 {\textbar}  may each have different parameters and signal processing characteristics for each of the multiple signals processed. Modifications of this processing circuitry may be made to accommodate various combinations of intraneural electrodes, used for single and multiple unit recordings, and epineural electrodes, used for compound action potential recordings, without departing from the present invention. {\textbar} {FIG}. 11 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of a patient-neural modulator system  {\textbar} 999 {\textbar}  illustrated in  {\textbar} {FIG}. 2 {\textbar}  with feedback control. Patient-neural modulator system  {\textbar} 999 {\textbar}  primarily includes an observer  {\textbar} 228 {\textbar}  and a controller  {\textbar} 229 {\textbar} . An observer is a component of a control system that is known to those or ordinary skill in the art of control systems. An observer is a functional block in which variables, typically represented in software as parameter values or in hardware as electrical signal amplitudes, represent states of the controlled system. Such a component is used in controlling systems in which one or more of the state variables are not directly observable from the sensed signals. An observer essentially includes a simulated version of the controlled system. Its input are the same control law output signals delivered to the controlled system, and its outputs are desired to match those sensed outputs of the controlled system. The difference between the outputs of the observer and the measured outputs of the controlled system, that is, the outputs of a motor control portion of the patient's nervous system in this case, are used to calculate an observer error signal which may then be used to correct the observer error. Since the observer is implemented in software or hardware, all of its signals, including all state variables, are accessible. In a system such as the complex neural circuitry of the patient, one or more of the state variables may not be “observable”, that is directly measurable or calculatable based on measured values. In such a case, the state variables present in the observer may be used as “estimates” of the actual state variables and included in the control law. The general use of “observers” for estimation of “unobservable” state variables is known to those skilled in the art of control theory. The use of observers for the estimation of neural state variables, disease states, and responses to therapy is one of the teachings of the present invention. {\textbar} Observer  {\textbar}   {\textbar} 228 {\textbar}  includes signal conditioning circuit  {\textbar} 76 {\textbar}  ( {\textbar} {FIG}. 2 {\textbar} ) and signal processor  {\textbar} 71 {\textbar}  ( {\textbar} {FIGS}. 2, 10 {\textbar} ). Signal processor  {\textbar} 71 {\textbar} , as noted, includes disease state estimator module array ({DSEMA})  {\textbar} 229 {\textbar}  and aggregate disease state estimator  {\textbar} 195 {\textbar} . Observer  {\textbar} 228 {\textbar}  receives patient output “y” from patient  {\textbar} 227 {\textbar} . Patient output “y” is comprised of one or more signals arising from patient  {\textbar} 227 {\textbar} . In one preferred embodiment patient output “y” includes one or more signals from {EMG} electrode array  {\textbar} 50 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , accelerometer array  {\textbar} 52 {\textbar} , acoustic transducer array  {\textbar} 53 {\textbar} , peripheral nerve electrode array  {\textbar} 54 {\textbar} , intracranial recording electrode array  {\textbar} 38 {\textbar} , and intracranial stimulating electrode array  {\textbar} 37 {\textbar} . It should be understood that additional signals f the same or different type may also be included. {\textbar} Control circuit  {\textbar}   {\textbar} 72 {\textbar}  ( {\textbar} {FIG}. 2 {\textbar} ) includes summator  {\textbar} 226 {\textbar}  which receives an input from reference module  {\textbar} 116 {\textbar} , and a control law circuit block  {\textbar} 231 {\textbar} . Controller  {\textbar} 229 {\textbar}  includes the control law circuit lock  {\textbar} 231 {\textbar}  and output stage circuit  {\textbar} 77 {\textbar} . Controller  {\textbar} 229 {\textbar}  generates a neural modulation waveforms “u”, described in detail below with reference to  {\textbar} {FIG}. 13 {\textbar} . The function and operation of each of these modules is described in detail below. {\textbar} Reference disease state “r”, generated by reference module  {\textbar}   {\textbar} 116 {\textbar} , is a non-inverting input to summator  {\textbar} 226 {\textbar} , providing disease state and target reference values for the single or plurality of control laws implemented in control law circuit block  {\textbar} 231 {\textbar}  introduced above with reference to  {\textbar} {FIG}. 2 {\textbar} . Reference module  {\textbar} 116 {\textbar}  may also receive input from control circuit  {\textbar} 72 {\textbar} , facilitating the dynamic adjustment of reference values. Reference disease state “r” may comprise a single or plurality of signals, each of which may be zero, constant, or time-varying independent of the other. Disease state error “e” is output from summator  {\textbar} 226 {\textbar}  and input to controller  {\textbar} 229 {\textbar} . Disease state error “e”, which may comprise a single or plurality of signals, represents a difference between a desired disease state (represented by reference disease state “r”) and an actual disease state (represented by disease state estimate “x”). Other methods of calculating disease state estimate “x”, including but not limited to linear or nonlinear combinations of reference disease state “r” and disease state estimate “x”, may be employed without departing from the present invention. Controller  {\textbar} 229 {\textbar}  is comprised of control law circuit block  {\textbar} 231 {\textbar}  and output stage circuit  {\textbar} 77 {\textbar} . {\textbar} Disease state error “e” is input to control law circuit block  {\textbar}   {\textbar} 231 {\textbar}  which generates a control circuit output “uc.” Control law circuit block  {\textbar} 231 {\textbar}  is connected to an input of output stage circuit  {\textbar} 77 {\textbar} . The output of the controller  {\textbar} 229 {\textbar} , which is generated by the output stage circuit  {\textbar} 77 {\textbar} , “u”, is delivered to patient  {\textbar} 227 {\textbar}  in the form of neural modulation waveforms, described in detail below with reference to  {\textbar} {FIG}. 13 {\textbar} . {\textbar} Patient output “y” is input to signal conditioning circuit  {\textbar}   {\textbar} 76 {\textbar} , the output of which is connected to the input of {DSEMA}  {\textbar} 229 {\textbar} . The output of {DSEMA}  {\textbar} 229 {\textbar}  is provided to an aggregate disease state estimator  {\textbar} 195 {\textbar} , the output of which is the disease state estimate x. Disease state estimate x, which may be comprised of a single or plurality of signals, is an inverting input to summator  {\textbar} 226 {\textbar} . {\textbar} Control law circuit block  {\textbar}   {\textbar} 231 {\textbar}  receives disease state estimate x as an additional input, for use in nonlinear, adaptive and other control laws. Reference module  {\textbar} 116 {\textbar}  receives input from {DSEMA}  {\textbar} 229 {\textbar}  and aggregate disease state estimator  {\textbar} 195 {\textbar}  for use in dynamically determining reference disease state r. Other modifications, including substitutions, additions, and deletions, may be made to the control loop without departing from the present invention. {\textbar} Control law circuit block  {\textbar}   {\textbar} 231 {\textbar}  has an autocalibration mode in which multivariable sweeps through stimulation parameters and stimulating electrode configurations are performed to automate and expedite parameter and configuration optimization. This autocalibration feature enables rapid optimization of treatment, eliminating months of iterations of trial and error in optimizing stimulation parameters and electrode configuration necessitated by the prior technique of constant parameter stimulation. Additionally, this autocalibration feature permits real-time adjustment and optimization of stimulation parameters and electrode configuration. This is particularly useful to overcome increases in electrode impedance which result from the body's normal response to implanted foreign bodies in which a fibrotic capsule is commonly formed around the electrodes. Effects of shifts in electrode position relative to a target structures may be minimized by said autocalibration feature. Detection of changes in electrode impedance and position are facilitated by autocalibration feature. The autocalibration feature facilitates detection of changes in electrode impedance and position. Notification of patient and health care provider allows proactive action, including automated or manual adjustment of treatment parameters and advance knowledge of impending electrode replacement needs. {\textbar} {FIG}. 12 {\textbar}   {\textbar}  is a schematic diagram of control circuit  {\textbar} 72 {\textbar} . As noted, control circuit  {\textbar} 72 {\textbar}  comprises control laws circuit block  {\textbar} 231 {\textbar}  and summator  {\textbar} 226 {\textbar} . Disease state error “e” is input to gain stages of control laws, including but not limited to at least one of proportional gain  {\textbar} 197 {\textbar} , differential gain  {\textbar} 198 {\textbar} , integral gain  {\textbar} 199 {\textbar} , nonlinear gain  {\textbar} 200 {\textbar} , adaptive gain  {\textbar} 201 {\textbar} , sliding gain  {\textbar} 202 {\textbar} , and model reference gain  {\textbar} 203 {\textbar} . {\textbar} An output of each of these gain stages is connected to what is referred to herein as control law stages. In the illustrative embodiment, control law stages includes proportional controller  {\textbar}   {\textbar} 230 {\textbar} , differential controller  {\textbar} 204 {\textbar} , integral controller  {\textbar} 205 {\textbar} , nonlinear controller  {\textbar} 206 {\textbar} , adaptive controller  {\textbar} 207 {\textbar} , sliding controller  {\textbar} 208 {\textbar} , and model reference controller  {\textbar} 209 {\textbar} , respectively. {\textbar} Outputs of these control law stages are connected to weight stages, including proportional controller weight  {\textbar}   {\textbar} 210 {\textbar} , differential controller weight  {\textbar} 211 {\textbar} , integral controller weight  {\textbar} 212 {\textbar} , nonlinear controller weight  {\textbar} 213 {\textbar} , adaptive controller weight  {\textbar} 214 {\textbar} , sliding controller weight  {\textbar} 215 {\textbar} , and model reference controller weight  {\textbar} 216 {\textbar} . Outputs of the weight stages are noninverting inputs to summator  {\textbar} 217 {\textbar} , the output of which is control circuit output “uc”. The weight stages may be any combination of at least one of constant, time varying, and nonlinear without departing from the present invention. {\textbar} Disease state estimate x is input to nonlinear controller  {\textbar}   {\textbar} 206 {\textbar} , adaptive controller  {\textbar} 207 {\textbar} , sliding controller  {\textbar} 208 {\textbar} , and model reference controller  {\textbar} 209 {\textbar} . The control laws depicted are representative of one possible implementation; numerous variations, including substitutions, additions, and deletions, may be made without departing from the present invention. {\textbar} The present invention optimizes the efficiency of energy used in the treatment given to the patient by minimizing to a satisfactory level the stimulation intensity to provide the level of treatment magnitude necessary to control disease symptoms without extending additional energy delivering unnecessary overtreatment. In the definition of the control law, a command input or reference input (denoted as r in  {\textbar}   {\textbar} {FIGS}. 11 and 12 {\textbar} ) specifies the target disease state. In the preferred embodiment, r specifies the target amplitude of tremor. The control law generates an electrical stimulation magnitude just sufficient to reduce the patient's tremor to the target value. With this apparatus and method, the precise amount of electrical energy required is delivered, and overstimulation is avoided. In present stimulation systems, a constant level of stimulation is delivered, resulting in either of two undesirable scenarios when disease state and symptoms fluctuate: (1) undertreatment, i.e. tremor amplitude exceeds desirable level or (2) overtreatment or excess stimulation, in which more electrical energy is delivered than is actually needed. In the overtreatment case, battery life is unnecessarily reduced. The energy delivered to the tissue in the form of a stimulation signal represents a substantial portion of the energy consumed by the implanted device; minimization of this energy substantially extends battery life, with a consequent extension of time in between reoperations to replace expended batteries. {\textbar} {FIG}. 13 {\textbar}   {\textbar}  is a schematic diagram of electrical stimulation waveforms for neural modulation. The illustrated ideal stimulus waveform is a charge balanced biphasic current controlled electrical pulse train. Two cycles of this waveform are depicted, each of which is made of a smaller cathodic phase followed, after a short delay, by a larger anodic phase. In one preferred embodiment, a current controlled stimulus is delivered; and the “Stimulus Amplitude” represents stimulation current. A voltage controlled or other stimulus may be used without departing from the present invention. Similarly, other waveforms, including an anodic phase preceding a cathodic phase, a monophasic pulse, a triphasic pulse, or the waveform may be used without departing from the present invention. {\textbar} The amplitude of the first phase, depicted here as cathodic, is given by pulse amplitude  {\textbar}   {\textbar} 1 {\textbar}  {PA} {\textbar} 1 {\textbar} ; the amplitude of the second phase, depicted here as anodic, is given by pulse amplitude  {\textbar} 2 {\textbar}  {PA} {\textbar} 2 {\textbar} . The durations of the first and second phases are pulse width  {\textbar} 1 {\textbar}  {PW} {\textbar} 1 {\textbar}  and pulse width  {\textbar} 1 {\textbar}  {PW} {\textbar} 2 {\textbar} , respectively. Phase I and phase  {\textbar} 2 {\textbar}  are separated by a brief delay d. Waveforms repeat with a stimulation period T, defining the stimulation frequency as f=1/T. {\textbar} The area under the curve for each phase represents the charge Q transferred, and in the preferred embodiment, these quantities are equal and opposite for the cathodic (Q1) and anodic (Q2) pulses, i.e. Q=Q1=Q2. For rectangular pulses, the charge transferred per pulse is given by Q1={PA} {\textbar}   {\textbar} 1 {\textbar} *{PW} {\textbar} 1 {\textbar}  and Q2={PA} {\textbar} 2 {\textbar} *{PW} {\textbar} 2 {\textbar} . The charge balancing constraint given by −Q1=Q2 imposes the relation {PA} {\textbar} 1 {\textbar} *{PW} {\textbar} 1 {\textbar} =−{PA} {\textbar} 2 {\textbar} *{PW} {\textbar} 2 {\textbar} . Departure from the charge balancing constraint, as is desired for optimal function of certain electrode materials, in included in the present invention. {\textbar} The stimulus amplitudes {PA} {\textbar}   {\textbar} 1 {\textbar}  and {PA} {\textbar} 2 {\textbar} , durations {PW} {\textbar} 1 {\textbar}  and {PW} {\textbar} 2 {\textbar} , frequency f, or a combination thereof may be varied to modulate the intensity of the said stimulus. A series of stimulus waveforms may be delivered as a burst, in which case the number of stimuli per burst, the frequency of waveforms within the said burst, the frequency at which the bursts are repeated, or a combination thereof may additionally be varied to modulate the stimulus intensity. {\textbar} Typical values for stimulation parameters include f=100-300 Hz, {PA} {\textbar}   {\textbar} 1 {\textbar}  and {PA} {\textbar} 2 {\textbar}  range from 10 microamps to 10 milliamps, {PW} {\textbar} 1 {\textbar}  and {PW} {\textbar} 2 {\textbar}  range from 50 microseconds to 100 milliseconds. These values are representative, and departure from these ranges is included in the apparatus and method of the present invention. {\textbar} {FIG}. 14 {\textbar}   {\textbar}  is a schematic diagram of one example of the recorded waveforms. This represents an individual action potential from a single cell recording, typically recorded from intracranial microelectrodes. Aggregates of multiple such waveforms are recorded from larger intracranial electrodes. The action potentials may be characterized according t a set of parameters including but not limited to time to valley  {\textbar} 1 {\textbar}  {TV} {\textbar} 1 {\textbar} , time to peak  {\textbar} 1 {\textbar}  {TP} {\textbar} 1 {\textbar} , time to valley  {\textbar} 2 {\textbar}  {TV} {\textbar} 2 {\textbar} , amplitude of valley  {\textbar} 1 {\textbar}  {AV} {\textbar} 1 {\textbar} , amplitude of peak  {\textbar} 1 {\textbar}  {AP} {\textbar} 1 {\textbar} , amplitude of valley  {\textbar} 2 {\textbar}  {AV} {\textbar} 2 {\textbar} , and algebraic combinations and polarity reversals thereof. {\textbar} When recording activity from more than one cell, said characterization facilitates discrimination of waveforms by individual recorded cell. The discrimination allows activity of a plurality of cells to be individually followed over time. The parameterization may be performed separately on signals recorded from different electrodes. Alternatively, said parameterization may be performed on signals pooled from multiple electrodes. {\textbar}   {\textbar} Following is a description of a general form for representing disease state. {\textbar}   {\textbar} Disease State {DS} is a vector of individual disease states, including intrinsic disease states {DSI} and extrinsic disease states {DSE}:  {\textbar}   {\textbar} {DS}=[{DS} {\textbar}   {\textbar} I {\textbar} {DS} {\textbar} E {\textbar} ] {\textbar} Intrinsic disease states and extrinsic disease states are, themselves vectors of individual disease states:  {\textbar}   {\textbar} {DS} {\textbar}   {\textbar} I {\textbar} =[{DS} {\textbar} I1 {\textbar} {DS} {\textbar} I2 {\textbar} {DS} {\textbar} I3  {\textbar} . . . {DS} {\textbar} {IN} {\textbar} ] {\textbar} {DS} {\textbar}   {\textbar} E {\textbar} =[{DS} {\textbar} E1 {\textbar} {DS} {\textbar} E2 {\textbar} {DS} {\textbar} E3  {\textbar} . . . {DS} {\textbar} {EM} {\textbar} ] {\textbar} Intrinsic Disease States include those disease states which characterize the state of disease at a given point in time. Extrinsic Disease States include variations of intrinsic disease states, including but not limited to cyclical variations in Intrinsic Disease States, variations in Intrinsic Disease States which occur in response to external events, and variations in Intrinsic Disease States which occur in response to levels of and changes in levels of electrical stimulation. Said external events include but are not limited to pharmacologic dosing, consumption of meals, awakening, falling asleep, transitioning from Parkinsonian “on” state to Parkinsonian “off” state, transitioning from Parkinsonian “off” state to Parkinsonian “on” state. {\textbar}   {\textbar} Each of Intrinsic Disease States and Extrinsic Disease States include but are not limited to those defined herein; additional disease states and definitions thereof may be added without departing from the present invention. {\textbar}   {\textbar} The first intrinsic disease state {DS} {\textbar}   {\textbar} I1  {\textbar} represents the level of resting tremor  {\textbar} {DS} {\textbar}   {\textbar} I1 {\textbar} ={RT} {\textbar} N  {\textbar} Where Normalized Resting Tremor Magnitude {RT}.sub.N is given by:  {\textbar}   {\textbar} {RT} {\textbar}   {\textbar} N {\textbar} =T {\textbar} A,3-5 {\textbar} *W {\textbar} {TA},3-5 {\textbar} +T {\textbar} E,3-5 {\textbar} *W {\textbar} {TE},3-5 {\textbar} +T {\textbar} P,3-5 {\textbar} *W {\textbar} {PE},3-5 {\textbar} +T {\textbar} C,3-5 {\textbar} +W {\textbar} {TC},3-5 {\textbar} +T {\textbar} N,3-5 {\textbar} *W {\textbar} {TN},3-5 {\textbar} +T {\textbar} S,3-5 {\textbar} *W {\textbar} {TS},3-5 {\textbar} +T {\textbar} E,3-5 {\textbar} *W {\textbar} {TE},3-5  {\textbar} Where the factors from which the Resting Tremor Magnitude {RT}.sub.N is determined, representing estimates of the magnitude of 3-5 Hertz movement of selected body segments, including but not limited to limbs, torso, and head are: {\textbar}   {\textbar} T {\textbar}   {\textbar} A,3-5 {\textbar} =Tremor level determined by acceleration monitoring {\textbar} W {\textbar}   {\textbar} {TA},3-5 {\textbar} =Weighting factor for tremor T {\textbar} A,3-5  {\textbar} T {\textbar}   {\textbar} E,3-5 {\textbar} =Tremor level determined by electromyographic ({EMG}) monitoring {\textbar} W {\textbar}   {\textbar} {TE},3-5 {\textbar} =Weighting factor for tremor T {\textbar} E,3-5  {\textbar} T {\textbar}   {\textbar} P,3-5 {\textbar} =Tremor level determined by peripheral nerve electrode monitoring {\textbar} W {\textbar}   {\textbar} {TP},3-5 {\textbar} =Weighting factor for tremor T {\textbar} P,3-5  {\textbar} T {\textbar}   {\textbar} C,3-5 {\textbar} =Tremor level determined by cortical electrode monitoring {\textbar} W {\textbar}   {\textbar} {TC},3-5 {\textbar} =Weighting factor for tremor T {\textbar} C,3-5  {\textbar} T {\textbar}   {\textbar} N,3-5 {\textbar} =Tremor level determined by neural monitoring, including subcortical nuclei, white matter tracts, and spinal cord neurons {\textbar} W {\textbar}   {\textbar} {TN},3-5 {\textbar} =Weighting factor for tremor T {\textbar} N,3-5  {\textbar} T {\textbar}   {\textbar} S,3-5 {\textbar} =Tremor level determined by acoustic sensor monitoring {\textbar} W {\textbar}   {\textbar} {TS},3-5 {\textbar} =Weighting factor for tremor T {\textbar} S,3-5  {\textbar} Weighting factors are adjusted after implantation to achieve normalization of {RT} {\textbar}   {\textbar} N  {\textbar} and to allow for selective weighting of tremor levels as determined from signals arising from various sensors, including but not limited to those listed. {\textbar} These calculations may be implemented in analog hardware, digital hardware, software, or other form. In the preferred embodiment, values are implemented as 16-bit variables; ranges for said weighting factors and tremor levels are 0 to 65535. These ranges may be changed or implemented in analog form without departing from the present invention. {\textbar}   {\textbar} The second intrinsic disease state {DS} {\textbar}   {\textbar} I2  {\textbar} represents the level of dyskinesia:  {\textbar} {DS} {\textbar}   {\textbar} I2 {\textbar} =D {\textbar} N  {\textbar} Where Normalized Dyskinesia Magnitude D {\textbar}   {\textbar} N  {\textbar} is given by:  {\textbar} D {\textbar}   {\textbar} N {\textbar} =D {\textbar} A {\textbar} *W {\textbar} {DA} {\textbar} +T {\textbar} E {\textbar} *W {\textbar} {TE} {\textbar} +T {\textbar} P {\textbar} *W {\textbar} {PE} {\textbar} +T {\textbar} C {\textbar} +W {\textbar} {TC} {\textbar} +T {\textbar} N {\textbar} *W {\textbar} {TN} {\textbar} +T {\textbar} S {\textbar} *W {\textbar} {TS} {\textbar} +T {\textbar} E {\textbar} *W {\textbar} {TE}  {\textbar} Where {\textbar}   {\textbar} D {\textbar}   {\textbar} A,3-5 {\textbar} =Dyskinesia level determined by acceleration monitoring {\textbar} W {\textbar}   {\textbar} {DA},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} A,3-5  {\textbar} D {\textbar}   {\textbar} E,3-5 {\textbar} =Dyskinesia level determined by electromyographic ({EMG}) monitoring {\textbar} W {\textbar}   {\textbar} {DE},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} E,3-5  {\textbar} D {\textbar}   {\textbar} P,3-5 {\textbar} =Dyskinesia level determined by peripheral nerve electrode monitoring {\textbar} W {\textbar}   {\textbar} {DP},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} P,3-5  {\textbar} D {\textbar}   {\textbar} C,3-5 {\textbar} =Dyskinesia level determined by cortical electrode monitoring {\textbar} W {\textbar}   {\textbar} {DC},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} C,3-5  {\textbar} D {\textbar}   {\textbar} N,3-5 {\textbar} =Dyskinesia level determined by neural monitoring, including subcortical nuclei, white matter tracts, and spinal cord neurons {\textbar} W {\textbar}   {\textbar} {DN},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} N,3,5  {\textbar} D {\textbar}   {\textbar} S,3-5 {\textbar} =Dyskinesia level determined by acoustic sensor monitoring {\textbar} W {\textbar}   {\textbar} {DS},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} S,3,5  {\textbar} The third intrinsic disease state {DS} {\textbar}   {\textbar} I3  {\textbar} represents the level of rigidity.  {\textbar} {DS} {\textbar}   {\textbar} I3 {\textbar} =R {\textbar} N  {\textbar} Where Normalized Rigidity Magnitude R {\textbar}   {\textbar} N  {\textbar} is given by:  {\textbar} R {\textbar}   {\textbar} N {\textbar} =R {\textbar} A {\textbar} *W {\textbar} {RA} {\textbar} +R {\textbar} E {\textbar} *W {\textbar} {RE} {\textbar} +R {\textbar} P {\textbar} *W {\textbar} {RE} {\textbar} +R {\textbar} C {\textbar} +W {\textbar} {RC} {\textbar} +R {\textbar} N {\textbar} *W {\textbar} {RN} {\textbar} +R {\textbar} S {\textbar} *W {\textbar} {RS} {\textbar} +R {\textbar} E {\textbar} *W {\textbar} {RE}  {\textbar} Where {\textbar}   {\textbar} R {\textbar}   {\textbar} A,3-5 {\textbar} =Rigidity level determined by acceleration monitoring {\textbar} W {\textbar}   {\textbar} {RA},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} A,3-5  {\textbar} R {\textbar}   {\textbar} E,3-5 {\textbar} =Rigidity level determined by electromyographic ({EMG}) monitoring {\textbar} W {\textbar}   {\textbar} {RE},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} F,3-5  {\textbar} R {\textbar}   {\textbar} P,3-5 {\textbar} =Rigidity level determined by peripheral nerve electrode monitoring {\textbar} W {\textbar}   {\textbar} {RP},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} P,3-5  {\textbar} R {\textbar}   {\textbar} C,3-5 {\textbar} =Rigidity level determined by cortical electrode monitoring {\textbar} W {\textbar}   {\textbar} {RC},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} C,3-5  {\textbar} R {\textbar}   {\textbar} N,3-5 {\textbar} =Rigidity level determined by neural monitoring, including subcortical nuclei, white matter tracts, and spinal cord neurons {\textbar} W {\textbar}   {\textbar} {RN},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} N,3-5  {\textbar} R {\textbar}   {\textbar} S,3-5 {\textbar} =Rigidity level determined by acoustic sensor monitoring {\textbar} W {\textbar}   {\textbar} {RS},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} S,3-5  {\textbar} The fourth intrinsic disease state {DS} {\textbar}   {\textbar} I4  {\textbar} represents the level of bradykinesia.  {\textbar} {DS} {\textbar}   {\textbar} I4 {\textbar} =B {\textbar} N  {\textbar} Where Normalized Bradykinesia Magnitude {BN} is given by:  {\textbar}   {\textbar} B {\textbar}   {\textbar} N {\textbar} =B {\textbar} A {\textbar} *W {\textbar} {BA} {\textbar} +B {\textbar} E {\textbar} *W {\textbar} {BE} {\textbar} +B {\textbar} P {\textbar} *W {\textbar} {PE} {\textbar} +B {\textbar} C {\textbar} +W {\textbar} {BC} {\textbar} +B {\textbar} N {\textbar} *W {\textbar} {BN} {\textbar} +B {\textbar} S {\textbar} *W {\textbar} {BS} {\textbar} +B {\textbar} E {\textbar} *W {\textbar} {BE}  {\textbar} Where {\textbar}   {\textbar} R {\textbar}   {\textbar} A {\textbar} =Bradykinesia level determined by acceleration monitoring {\textbar} W {\textbar}   {\textbar} {RA} {\textbar} =Weighting factor for Bradykinesia R {\textbar} A  {\textbar} R {\textbar}   {\textbar} E {\textbar} =Bradykinesia level determined by electromyographic ({EMG}) monitoring {\textbar} W {\textbar}   {\textbar} {RE} {\textbar} =Weighting factor for Bradykinesia R {\textbar} E  {\textbar} R {\textbar}   {\textbar} P {\textbar} =Bradykinesia level determined by peripheral nerve electrode monitoring {\textbar} W {\textbar}   {\textbar} {RP} {\textbar} =Weighting factor for Bradykinesia R {\textbar} P  {\textbar} R {\textbar}   {\textbar} C {\textbar} =Bradykinesia level determined by cortical electrode monitoring {\textbar} W {\textbar}   {\textbar} {RC} {\textbar} =Weighting factor for Bradykinesia R {\textbar} C  {\textbar} R {\textbar}   {\textbar} N {\textbar} =Bradykinesia level determined by neural monitoring, including subcortical nuclei, white matter tracts, and spinal cord neurons {\textbar} W {\textbar}   {\textbar} {RN} {\textbar} =Weighting factor for Bradykinesia R {\textbar} N  {\textbar} R {\textbar}   {\textbar} S {\textbar} =Bradykinesia level determined by acoustic sensor monitoring {\textbar} W {\textbar}   {\textbar} {RS} {\textbar} =Weighting factor for Bradykinesia R {\textbar} S  {\textbar} The control law drives these disease states toward their reference values, nominally 0, according to a vector of weights, establishing a prioritization. {\textbar}   {\textbar} Side effects and other parameters, such as power consumption and current magnitude, are also quantified and minimized according to a cost function. {\textbar}   {\textbar} One advantage of the present invention is that it provides prediction of future symptomatology, cognitive and neuromotor functionality, and treatment magnitude requirements. Such predictions may be based on preset, learned and real-time sensed parameters as well as input from the patient, physician or other person or system. The prediction of future symptomatology is based upon any of several weighted combination of parameters. Based upon prior characterization of the circadian fluctuation in symptomatology (that is, tremor magnitude for deep brain stimulation or level of depression for stimulation of other sites including locus ceruleus), future fluctuations may be predicted. An estimate, or model, of fluctuation may be based upon a combination of preset, learned, and real-time sensed parameters. Preset parameters are derived from clinical studies designed specifically for the purpose of gathering such data, or from estimates extracted from data gleaned from published literature. Real-time sensed parameters are derived from the current states (and changes, i.e. derivatives and other processed signals, thereof) of sensed and processed signals. Learned parameters are based upon the time histories of previously sensed signals. For example, the circadian fluctuation in tremor amplitude may be sensed; a weighted average of this data collected over numerous prior days provides as estimate of the expected tremor amplitude as well as a standard deviation and other statistical parameters to characterize the anticipated tremor amplitude. Similarly, in the presence of closed-loop feedback, the level of stimulation required to reduce or eliminate tremor may be used as an estimate of the “amplitude” or state of the underlying disease. {\textbar}   {\textbar} Another advantage of the present invention is that it performs automated determination of the optimum magnitude of treatment—by sensing and quantifying the magnitude and frequency of tremor activity in the patient, a quantitative representation of the level or “state” of the disease is determined. The disease state is monitored as treatment parameters are automatically varied, and the local or absolute minimum in disease state is achieved as the optimal set of stimulation parameters is converged upon. The disease state may be represented as a single value or a vector or matrix of values; in the latter two cases, a multivariable optimization algorithm is employed with appropriate weighting factors. {\textbar}   {\textbar} Having now described several embodiments of the invention, it should be apparent to those skilled in the art that the foregoing is merely illustrative and not limiting, having been presented by way of example only. For example, all signal paths may transmit a single or plurality of signals without departing from the present invention. Numerous modifications and other embodiments are within the scope of one of ordinary skill in the art and are contemplated as falling within the scope of the invention as defined by the appended claims. {\textbar}   {\textbar} Current implanted neurostimulators suffer from limited battery life necessitating replacement. The original filing of this invention teaches a closed-loop technique which allows lower average power delivery, providing extended batter life. A further improvement is taught in the present invention. The present invention teaches a novel form of power delivery, in which electromagnetic power is provided externally and radiated transcutaneously through the skin  {\textbar}   {\textbar} 382 {\textbar}  to the implanted circuit. {\textbar} A multiplicity of electromagnetic coils is used, to provide electromagnetic fields of multiple non-collinear orientations. The purpose of this design is to overcome fluctuations and interruptions in power that otherwise occur when the implanted circuit moves along with the body parts relative to electromagnetic coils. {\textbar}   {\textbar} An additional improvement is taught in the application of time multiplexing of signals delivered by said multiplicity of electromagnetic coils. Multiplexing signals in time from a multiplicity of coils allows electromagnetic energy to be delivered at a multiplicity of spatial orientations without mutual interference between fields. In one embodiment, three coils are positioned such that they are mutually orthogonal. Regardless of the orientation of the implanted circuit, mutual coupling between the implanted circuit and at least one element of the coil array will facilitate power transmission. {\textbar}   {\textbar} The present invention further includes an embodiment in which the coils are embedded in a flexible cloth assembly, including but not limited to a pillow, bandana, hat, or other accessory or piece of apparel. {\textbar}   {\textbar} Additionally, low profile mounting of the neurological control system  {\textbar}   {\textbar} 999 {\textbar}  is taught, including a design in which the device is implanted entirely adjacent to the head, avoiding the subcutaneous cables plaguing current designs with high failure and fracture rates. Additionally, a low-profile design is taught in which the neurological control system is implanted beneath the skin and recessed in the caldarium. {\textbar} {FIG}. 16 {\textbar}   {\textbar}  and  {\textbar} {FIG}. 18 {\textbar}  show two coil and three coil embodiments, respectively, of power delivery unit  {\textbar} 413 {\textbar} . Different numbers of coils may be used without departing from the present invention. Each of electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  radiates electromagnetic power, represented by magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar} , which radiates through the skin  {\textbar} 382 {\textbar}  and is then converted to electrical energy by power conversion unit  {\textbar} 378 {\textbar} . Power is then transmitted from power conversion unit  {\textbar} 378 {\textbar}  via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of the neurological control system  {\textbar} 999 {\textbar} . {\textbar} A single or multiplicity of coil holder  {\textbar}   {\textbar} 380 {\textbar}  holds electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  in place. Coil holder  {\textbar} 380 {\textbar}  may be placed atop bedding  {\textbar} 381 {\textbar} , which may include a pillow, blanket, or mattress. Alternatively, coil holder  {\textbar} 380 {\textbar}  may be placed below bedding  {\textbar} 381 {\textbar} , which may include a pillow, blanket, mattress, or other element. {\textbar} {FIG}. 17 {\textbar}   {\textbar}  shows this configuration at greater magnification, in which magnetic flux  {\textbar} 375 {\textbar}  is seen to penetrate skin  {\textbar} 382 {\textbar} . {\textbar} {FIG}. 19 {\textbar}   {\textbar}  depicts power delivery unit  {\textbar} 413 {\textbar}  with coil holder  {\textbar} 380 {\textbar}  shown holding electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  in place, as seen from above. In this design, all electromagnetic coils  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  are contained within coil holder  {\textbar} 380 {\textbar} . For illustrative purposes, coil holder  {\textbar} 380 {\textbar}  is shown in this embodiment as a convex shape. Other shapes may be used without departing from the present invention. {\textbar} {FIG}. 20 {\textbar}   {\textbar}  shows coil holder  {\textbar} 380 {\textbar}  with electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  in place, as seen from above. In this design, all electromagnetic coils  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  are contained within coil holder  {\textbar} 380 {\textbar} . For illustrative purposes, coil holder  {\textbar} 380 {\textbar}  is shown in this embodiment as a multi-lobed shape, with electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  contained within coil pockets  {\textbar} 383 {\textbar} ,  {\textbar} 384 {\textbar} ,  {\textbar} 385 {\textbar} , respectively. Other shapes may be used without departing from the present invention. {\textbar} Electromagnetic coils  {\textbar}   {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  may be permanently affixed within coil holder  {\textbar} 380 {\textbar} . Alternatively, electromagnetic coils  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  may be removable form coil holder  {\textbar} 380 {\textbar}  to facilitate cleaning or laundering of coil holder  {\textbar} 380 {\textbar} . {\textbar} Further, use of electromagnetic fields, as direct modulators of neural activity is taught in the present invention. [This also references provisional application filed Jul. 29, 2002.] {\textbar}   {\textbar} As shown in  {\textbar}   {\textbar} {FIG}. 21 {\textbar} , electromagnetic coils  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  may be positioned by coil holder  {\textbar} 380 {\textbar}  to lie in close proximity to the head  {\textbar} 398 {\textbar}  of a patient. Magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar} , which radiate through the skin  {\textbar} 382 {\textbar}  penetrate into underlying brain  {\textbar} 251 {\textbar} , or other neural tissue  {\textbar} 354 {\textbar} , and generate electrical currents. Said electrical currents serve to stimulate or inhibit neural activity. Other neural tissue includes but is not limited to brain  {\textbar} 251 {\textbar} , brainstem, spinal cord, peripheral nerves, cranial nerves, neurosensory organs, and other structures. {\textbar} {FIG}. 22 {\textbar}   {\textbar}  shows multiple coil embodiments. Different numbers of coils may be used without departing from the present invention.  {\textbar} {FIG}. 22 {\textbar}  shows a distributed arrangement of coils, to facilitate strong signal coupling with a minimum of tissue heating or sensory stimulation. Brain  {\textbar} 251 {\textbar}  is shown underlying skin  {\textbar} 382 {\textbar}  in head  {\textbar} 398 {\textbar} . Temporal cortex  {\textbar} 255 {\textbar}  and thalamus  {\textbar} 270 {\textbar}  are shown. {\textbar} Headband coil holder  {\textbar}   {\textbar} 386 {\textbar}  is in mechanical connection with each of electromagnetic coils  {\textbar} 387 {\textbar} ,  {\textbar} 388 {\textbar} ,  {\textbar} 389 {\textbar} ,  {\textbar} 390 {\textbar} ,  {\textbar} 391 {\textbar} ,  {\textbar} 392 {\textbar} ,  {\textbar} 393 {\textbar} , which radiate electromagnetic power through the skin  {\textbar} 382 {\textbar} . This is then converted to electrical energy by power conversion unit  {\textbar} 378 {\textbar} , which is implanted in any of several locations, shown in  {\textbar} {FIG}. 17 {\textbar}  and  {\textbar} {FIG}. 18 {\textbar} , omitted here for diagram clarity. As shown in  {\textbar} {FIG}. 17 {\textbar} , power is then transmitted from power conversion unit  {\textbar} 378 {\textbar}  via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of the neurological control system  {\textbar} 999 {\textbar} . {\textbar} Power source  {\textbar}   {\textbar} 397 {\textbar}  provides power to power modulator  {\textbar} 396 {\textbar} , which modulates power on a carrier frequency and is electrically connected via electromagnetic coil cable  {\textbar} 394 {\textbar}  to electromagnetic coils  {\textbar} 387 {\textbar} ,  {\textbar} 388 {\textbar} ,  {\textbar} 389 {\textbar} ,  {\textbar} 390 {\textbar}  which radiate power through skin  {\textbar} 382 {\textbar} . Power modulator  {\textbar} 396 {\textbar}  is also electrically connected via electromagnetic coil cable  {\textbar} 395 {\textbar}  to electromagnetic coils  {\textbar} 391 {\textbar} ,  {\textbar} 392 {\textbar} ,  {\textbar} 393 {\textbar}  which radiate power through skin  {\textbar} 382 {\textbar} . Electromagnetic coils  {\textbar} 387 {\textbar} ,  {\textbar} 388 {\textbar} ,  {\textbar} 389 {\textbar} ,  {\textbar} 390 {\textbar} ,  {\textbar} 391 {\textbar} ,  {\textbar} 392 {\textbar} ,  {\textbar} 393 {\textbar}  can be arranged in a different geometrical or anatomical configuration, with the same, a higher or a lower number of electromagnetic coils, without departing from the present invention. Electromagnetic coils  {\textbar} 387 {\textbar} ,  {\textbar} 388 {\textbar} ,  {\textbar} 389 {\textbar} ,  {\textbar} 390 {\textbar} ,  {\textbar} 391 {\textbar} ,  {\textbar} 392 {\textbar} ,  {\textbar} 393 {\textbar}  may alternatively be affixed to a different form of apparel, clothing, or fixture without departing from the present invention. Such embodiments include a hat, cap, bandana, or other device. {\textbar} {FIG}. 23 {\textbar}   {\textbar}  shows the paracranial design, with implanted components in close proximity to the head  {\textbar} 398 {\textbar} . This design eliminates the pervasive problem of moving parts, inherent in all current technology devices. All cabling is in close approximation to the caldarium, a rigid structure; therefore all implanted parts remain stationary. Since no implanted parts are subjected to movement, they are at greatly reduced risk for mechanical fatigue, the single highest failure mode for current implanted neuromodulators. This innovation dramatically reduces the frequency and likelihood for re-operation to repair broken implanted components, a major concern in all patients and particularly the elderly, who are often poor operative candidates, and who are at highest risk for many of the neurological and neurodegenerative diseases amenable to treatment by neuromodulation. {\textbar} {FIG}. 23 {\textbar}   {\textbar}  depicts an embodiment in which the head  {\textbar} 398 {\textbar}  of the patient lies atop coil holder  {\textbar} 380 {\textbar} , placing the power conversion unit  {\textbar} 378 {\textbar}  within at least one of magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar} . Power conversion unit  {\textbar} 378 {\textbar}  converts power transmitted as magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar}  into electrical energy, which is transmitted by power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of the neurological control system  {\textbar} 999 {\textbar} . Stimulating and recording circuit  {\textbar} 26 {\textbar}  generates neuromodulation signal that is transmitted via connecting cable  {\textbar} 8 {\textbar}  to intracranial stimulating electrode array  {\textbar} 37 {\textbar} , depicted in more detail in  {\textbar} {FIG}. 1 {\textbar} , which deliver neuromodulation signal to brain  {\textbar} 251 {\textbar} . or other neural tissue  {\textbar} 354 {\textbar} . Connecting cable  {\textbar} 8 {\textbar}  furthermore provides bi-directional electrical connection between intracranial electrodes  {\textbar} 246 {\textbar}  and stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of neurological control system  {\textbar} 999 {\textbar} . {\textbar} Catheter anchor  {\textbar}   {\textbar} 29 {\textbar}  is in mechanical communication with intracranial catheter  {\textbar} 7 {\textbar} . and secures it to caldarium  {\textbar} 9 {\textbar} . Intracranial electrodes  {\textbar} 246 {\textbar}  are mounted on or incorporated into intracranial catheter  {\textbar} 7 {\textbar} . {\textbar} {FIG}. 24 {\textbar}   {\textbar}  shows power conversion unit  {\textbar} 378 {\textbar}  includes electromagnetic coupling element  {\textbar} 399 {\textbar} , such as a wire coil, circuit board tracing coil, or equivalent implementation. In one embodiment, power conversion unit  {\textbar} 378 {\textbar}  also includes power conversion circuit  {\textbar} 400 {\textbar} , which converts electrical signal induced by any of magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar} , on electromagnetic coupling element  {\textbar} 399 {\textbar} , into at least one of electrical power and electrical signal, which are transmitted via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , which generates neuromodulation signal  {\textbar} 412 {\textbar} , which is transmitted on connecting cable  {\textbar} 8 {\textbar}  to intracranial catheter  {\textbar} 7 {\textbar} . {\textbar} Power conversion circuit  {\textbar}   {\textbar} 400 {\textbar}  includes rectifier  {\textbar} 401 {\textbar} , energy storage element  {\textbar} 402 {\textbar} , regulator  {\textbar} 403 {\textbar} , filter  {\textbar} 404 {\textbar} , demodulator  {\textbar} 405 {\textbar} , and amplifier  {\textbar} 406 {\textbar} . Electromagnetic coupling element  {\textbar} 399 {\textbar}  is electrically connected via electromagnetic coupling element cable  {\textbar} 407 {\textbar}  to power conversion circuit  {\textbar} 400 {\textbar} . {\textbar} Either of magnetic flux  {\textbar}   {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar}  passing through electromagnetic coupling element  {\textbar} 399 {\textbar}  induces induced current  {\textbar} 408 {\textbar} , which is transmitted via electromagnetic coupling element cable  {\textbar} 407 {\textbar}  to power conversion circuit  {\textbar} 400 {\textbar} . Induced current  {\textbar} 408 {\textbar}  is rectified by rectifier  {\textbar} 401 {\textbar}  to a direct current form and is stored or lowpass filtered by energy storage element  {\textbar} 402 {\textbar}  and regulated by regulator  {\textbar} 403 {\textbar}  and then transmitted as regulated power  {\textbar} 409 {\textbar}  by power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of neurological control system  {\textbar} 999 {\textbar} . {\textbar} {FIG}. 25 {\textbar}   {\textbar}  shows the communication circuit. This circuit also provides bi-directional communication with external devices, including power delivery unit  {\textbar} 413 {\textbar}  as well as with patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} , shown in  {\textbar} {FIG}. 1 {\textbar} . {\textbar} Either of magnetic flux  {\textbar}   {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar}  passing through electromagnetic coupling element  {\textbar} 399 {\textbar}  induces induced current  {\textbar} 408 {\textbar} , which is transmitted via electromagnetic coupling element cable  {\textbar} 407 {\textbar}  to power conversion circuit  {\textbar} 400 {\textbar} . Induced current  {\textbar} 408 {\textbar}  is filtered by filter  {\textbar} 404 {\textbar} , then demodulated by  {\textbar} 405 {\textbar} , then amplified by amplifier  {\textbar} 406 {\textbar} , then transmitted as incoming data stream  {\textbar} 410 {\textbar}  via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} . At least one of digital to analog or analog to digital conversion may also be performed without departing from the present invention. {\textbar} Outgoing data stream  {\textbar}   {\textbar} 411 {\textbar}  is transmitted from stimulating and recording circuit  {\textbar} 26 {\textbar}  via power cable  {\textbar} 379 {\textbar}  to power conversion circuit  {\textbar} 400 {\textbar}  where it is modulated by modulator  {\textbar} 414 {\textbar}  and then amplified by amplifier  {\textbar} 415 {\textbar}  and transmitted as inducing current  {\textbar} 416 {\textbar}  along electromagnetic coupling element cable  {\textbar} 407 {\textbar}  to electromagnetic coupling element  {\textbar} 399 {\textbar}  where it generated magnetic flux that is detected and decoded by external devices, including power delivery unit  {\textbar} 413 {\textbar}  as well as with patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} , shown in  {\textbar} {FIG}. 1 {\textbar} . At least one of digital to analog or analog to digital conversion may also be performed without departing from the present invention. {\textbar} {FIG}. 26 {\textbar}   {\textbar}  depicts the overall system, with power conversion unit  {\textbar} 378 {\textbar}  connected via power cable  {\textbar} 379 {\textbar}  to power management unit  {\textbar} 417 {\textbar} , a component of stimulating recording and power circuit  {\textbar} 419 {\textbar} . Power management unit  {\textbar} 417 {\textbar}  is in electrical connection with energy storage unit  {\textbar} 418 {\textbar}  and in electrical connection with stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} In one preferred embodiment, energy storage unit  {\textbar}   {\textbar} 418 {\textbar}  is implemented as a capacitor. Power management unit  {\textbar} 417 {\textbar}  converts regulated power  {\textbar} 409 {\textbar}  into charge, which is stored in energy storage unit  {\textbar} 418 {\textbar} . {\textbar} In another preferred embodiment, energy storage unit  {\textbar}   {\textbar} 418 {\textbar}  is implemented as a rechargeable battery. Power management unit  {\textbar} 417 {\textbar}  converts regulated power  {\textbar} 409 {\textbar}  into current, which recharges energy storage unit  {\textbar} 418 {\textbar} . {\textbar} When regulated power  {\textbar}   {\textbar} 409 {\textbar}  is insufficient to power stimulating and recording circuit  {\textbar} 26 {\textbar} , power management unit  {\textbar} 417 {\textbar}  withdrawals energy from energy storage unit  {\textbar} 418 {\textbar}  and delivers energy to stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} An embodiment of this invention further includes novel geometrical features to enhance form and function of this neuromodulation system as well as any neural stimulation system. One invention taught is the refinement of the implanted case such that one side is concave. An additional invention taught is the refinement of the implanted case such that one side is convex. A further extension of this invention includes the use of at least one concave side and at least one convex side. Advantages of this design include the close positioning of the casing against the intact outer table of the skull of the patient. {\textbar}   {\textbar} {FIG}. 27 {\textbar}   {\textbar}  shows stimulating and recording unit  {\textbar} 43 {\textbar}  enclosed within system enclosure  {\textbar} 434 {\textbar} , implanted beneath the scalp  {\textbar} 10 {\textbar} , overlying the caldarium  {\textbar} 9 {\textbar} . System enclosure  {\textbar} 434 {\textbar}  is designed with an enclosure inner surface  {\textbar} 427 {\textbar}  and enclosure outer surface  {\textbar} 426 {\textbar} . In one preferred embodiment, enclosure inner surface  {\textbar} 427 {\textbar}  and enclosure outer surface  {\textbar} 426 {\textbar}  are concave and convex, respectively. {\textbar} By designing enclosure inner surface  {\textbar}   {\textbar} 427 {\textbar}  to be concave, system enclosure  {\textbar} 434 {\textbar}  may be placed tightly and securely against caldarium  {\textbar} 9 {\textbar} . This represents a substantial innovation over flat machined enclosures, the designs currently implanted elsewhere and that are based upon established pacemaker technology. This innovation reduces of eliminates movement of the implant that would otherwise occur with existing devices. {\textbar} By designing enclosure outer surface  {\textbar}   {\textbar} 426 {\textbar}  to be convex, system enclosure  {\textbar} 434 {\textbar}  may be placed against calvarium  {\textbar} 9 {\textbar}  with a substantially improved cosmetic result and less displacement of scalp  {\textbar} 10 {\textbar}  or other skin  {\textbar} 382 {\textbar} . This represents a substantial innovation over flat machined enclosures, the designs currently implanted elsewhere and that are based upon established pacemaker technology. This innovation reduces or eliminates movement of the implant that would otherwise occur with existing devices. {\textbar} Furthermore, each of enclosure inner surface  {\textbar}   {\textbar} 427 {\textbar}  and enclosure outer surface  {\textbar} 426 {\textbar}  serve to reduce the profile of system enclosure  {\textbar} 434 {\textbar}  and to improve the cosmetic appearance of the overlying skin  {\textbar} 382 {\textbar}  or scalp  {\textbar} 10 {\textbar} . {\textbar} In this embodiment, system enclosure  {\textbar}   {\textbar} 434 {\textbar}  overlies the intact pericranium  {\textbar} 420 {\textbar} . This facilitates attachment of System enclosure  {\textbar} 434 {\textbar}  to the pericranium  {\textbar} 420 {\textbar}  by means of mechanical attachment  {\textbar} 424 {\textbar} , providing mechanical attachment between mechanical attachment mount  {\textbar} 425 {\textbar}  and at least one of pericranium  {\textbar} 420 {\textbar} , skin  {\textbar} 382 {\textbar} , scalp  {\textbar} 10 {\textbar} , or other tissue of the patient. Mechanical attachment  {\textbar} 424 {\textbar} , may be implemented as sutures, wires, clips, or other attachment means. In this embodiment, the caldarium outer table  {\textbar} 421 {\textbar} , caldarium marrow layer  {\textbar} 422 {\textbar} , and caldarium inner table  {\textbar} 423 {\textbar}  remain intact. {\textbar} Alternatively, System enclosure  {\textbar}   {\textbar} 434 {\textbar}  is implanted beneath the scalp  {\textbar} 10 {\textbar}  and beneath the pericranium  {\textbar} 420 {\textbar} , directly overlying the caldarium  {\textbar} 9 {\textbar} . In this embodiment, the pericranium  {\textbar} 420 {\textbar}  serves to secure System enclosure  {\textbar} 434 {\textbar}  in place against the caldarium  {\textbar} 9 {\textbar} . {\textbar} {FIG}. 28 {\textbar}   {\textbar}  depicts system enclosure  {\textbar} 434 {\textbar}  secured to the calvarium  {\textbar} 9 {\textbar}  using screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  which are shown inserted through screw mounts  {\textbar} 428 {\textbar} ,  {\textbar} 430 {\textbar} , respectively, into calvarium  {\textbar} 9 {\textbar} . Additional or fewer screws and screw mounts may be used without departing form the present invention. Screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  may penetrate in depth to the level of the calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow layer  {\textbar} 422 {\textbar} , or calvarium inner table  {\textbar} 423 {\textbar} . {\textbar} {FIG}. 29 {\textbar}   {\textbar}  depicts a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is partially recessed into the calvarium  {\textbar} 9 {\textbar} . Protruding component  {\textbar} 432 {\textbar}  lies above the outer surface of calvarium  {\textbar} 9 {\textbar} , and recessed component  {\textbar} 433 {\textbar}  lies below the outer surface of calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  is shown occupying volume previously occupied by calvarium outer table  {\textbar} 421 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  may also occupying volume previously occupied by calvarium marrow layer without departing from the present invention. {\textbar} {FIG}. 30 {\textbar}   {\textbar}  depicts a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is partially recessed into the calvarium  {\textbar} 9 {\textbar} . Protruding component  {\textbar} 432 {\textbar}  lies above the outer surface of calvarium  {\textbar} 9 {\textbar} , and recessed component  {\textbar} 433 {\textbar}  lies below the outer surface of calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  is shown occupying volume previously occupied by calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow  {\textbar} 422 {\textbar} , and calvarium inner table  {\textbar} 423 {\textbar} . System enclosure  {\textbar} 434 {\textbar}  is shown secured to the calvarium outer table  {\textbar} 421 {\textbar}  portion of calvarium  {\textbar} 9 {\textbar}  using screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  which are shown inserted through screw mounts  {\textbar} 428 {\textbar} ,  {\textbar} 430 {\textbar} , respectively. Additional or fewer screws and screw mounts may be used without departing form the present invention. Screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  may penetrate in depth to the level of the calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow layer  {\textbar} 422 {\textbar} , or calvarium inner table  {\textbar} 423 {\textbar} . {\textbar} {FIG}. 31 {\textbar}   {\textbar}  depicts a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is fully recessed into the calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  lies below the outer surface of calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  is shown occupying volume previously occupied by calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow  {\textbar} 422 {\textbar} , and calvarium inner table  {\textbar} 423 {\textbar} . System enclosure  {\textbar} 434 {\textbar}  is shown secured to the calvarium outer table  {\textbar} 421 {\textbar}  portion of calvarium  {\textbar} 9 {\textbar}  using screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  which are shown inserted through screw mounts  {\textbar} 428 {\textbar} ,  {\textbar} 430 {\textbar} , respectively. Additional or fewer screws and screw mounts may be used without departing form the present invention. Screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  may penetrate in depth to the level of the calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow layer  {\textbar} 422 {\textbar} , or calvarium inner table  {\textbar} 423 {\textbar} . {\textbar} {FIG}. 32 {\textbar}   {\textbar}  depicts a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is fully recessed into the calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  lies below the outer surface of calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  is shown occupying volume previously occupied by calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow  {\textbar} 422 {\textbar} , and calvarium inner table  {\textbar} 423 {\textbar} . In one embodiment shown, enclosure inner surface  {\textbar} 427 {\textbar}  is shown extending below the level of calvarium inner table  {\textbar} 423 {\textbar} . This design facilitates close proximity of stimulating and recording unit  {\textbar} 43 {\textbar}  to underlying neural tissue  {\textbar} 354 {\textbar}  and brain  {\textbar} 251 {\textbar} , valuable in sensing neural activity and in delivering an output neuromodulation signal ({NMS})  {\textbar} 998 {\textbar}  via intracranial stimulating electrode array  {\textbar} 37 {\textbar} , shown in  {\textbar} {FIG}. 1 {\textbar}  and  {\textbar} {FIG}. 2 {\textbar} . {\textbar} System enclosure  {\textbar}   {\textbar} 434 {\textbar}  is shown secured to the calvarium inner table  {\textbar} 423 {\textbar}  portion of calvarium  {\textbar} 9 {\textbar}  using screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  which are shown inserted through screw mounts  {\textbar} 428 {\textbar} ,  {\textbar} 430 {\textbar} , respectively. Additional or fewer screws and screw mounts may be used without departing form the present invention. Alternate means of mechanically attaching system enclosure  {\textbar} 434 {\textbar}  to calvarium  {\textbar} 9 {\textbar}  may be employed without departing from the present invention. {\textbar} {FIG}. 33 {\textbar}   {\textbar}  depicts the neurological control system  {\textbar} 999 {\textbar}  employing a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is recessed into the calvarium  {\textbar} 9 {\textbar} . Power delivery unit  {\textbar} 413 {\textbar} , via generated magnetic flux, transmits power to power conversion unit  {\textbar} 378 {\textbar} , which transmits power via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , part of stimulating and recording unit  {\textbar} 43 {\textbar} , contained within system enclosure  {\textbar} 434 {\textbar} . Stimulating and recording circuit  {\textbar} 26 {\textbar}  is electrically connected via connecting cable  {\textbar} 8 {\textbar}  to intracranial catheter  {\textbar} 7 {\textbar}  which provides electrical connection to intracranial stimulating electrode array  {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar} . Intracranial catheter is mechanically secured via catheter anchor  {\textbar} 29 {\textbar}  to calvarium  {\textbar} 9 {\textbar} . {\textbar} {FIG}. 34 {\textbar}   {\textbar}  depicts the neurological control system  {\textbar} 999 {\textbar}  employing a lower profile and more compact design in which the system enclosure  {\textbar} 434 {\textbar}  is recessed into the calvarium  {\textbar} 9 {\textbar} . Power delivery unit  {\textbar} 413 {\textbar} , via generated magnetic flux, transmits power to power conversion unit  {\textbar} 378 {\textbar} , which transmits power via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , part of stimulating and recording unit  {\textbar} 43 {\textbar} , contained within system enclosure  {\textbar} 434 {\textbar} . {\textbar} Stimulating and recording circuit  {\textbar}   {\textbar} 26 {\textbar}  is in close proximity to intracranial catheter  {\textbar} 7 {\textbar} , this includes but is not limited to a preferred embodiment in which stimulating and recording circuit  {\textbar} 26 {\textbar}  is recessed into calvarium at the site surrounding the entry point at which intracranial catheter  {\textbar} 7 {\textbar}  passes from outside the calvarium to inside the calvarium. Stimulating and recording circuit  {\textbar} 26 {\textbar}  is electrically connected directly or via connecting cable  {\textbar} 8 {\textbar}  to intracranial catheter  {\textbar} 7 {\textbar}  which provides electrical connection to intracranial stimulating electrode array  {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar} . Intracranial catheter is mechanically secured via catheter anchor  {\textbar} 29 {\textbar}  to calvarium  {\textbar} 9 {\textbar} . {\textbar} An advantage of the closed-loop system includes the natural variability of the output signal. The nervous system exhibits a natural tendency to attenuate responses to continuous stimuli, such as continuous background noises. A natural example includes imperceptibility of stationary visual images on frog retina. A related example is electrical stimulation of peripheral nerves, such as stimulation of the tibial or peroneal nerves for use in eliciting the flexion withdrawal reflex to facilitate gait restoration in paraplegics. With time, these reflexes attenuate or habituate, reducing their effectiveness. {\textbar}   {\textbar} The time-varying nature of a closed-loop signal, responding to environmental and system fluctuations and noise, the natural neural process of habituation to constant signals will be reduced. {\textbar}   {\textbar} Furthermore, by specifically and intentionally altering the output signal, such as intermittently reducing the amplitude of the stimulus, and allowing the closed-loop system to compensate in between these intentional amplitude restrictions, further reduction and prevention of habituation is achieved. {\textbar}   {\textbar} As shown previously, ventricular electrode catheter  {\textbar}   {\textbar} 1 {\textbar}  is shown positioned within the lateral ventricle  {\textbar} 2 {\textbar} , with ventricular electrode  {\textbar} 17 {\textbar}  in contact with the {CSF} fluid  {\textbar} 18 {\textbar}  in lateral ventricle  {\textbar} 2 {\textbar} . Cortical electrode  {\textbar} 3 {\textbar}  is in contact with the {CSF} fluid overlying the cerebral cortex  {\textbar} 19 {\textbar} . Cortical electrode  {\textbar} 3 {\textbar}  may be placed over any portion of the cerebral or cerebellar cortex without departing from the present invention. Hippocampal electrode  {\textbar} 4 {\textbar}  is shown underlying the hippocampal regions of the cerebrum. {\textbar} The parenchyma of the nervous system is used as a dielectric to establish a voltage potential gradient between any of the {CSF} reservoirs, including the lateral ventricles, third ventricle, cerebral aqueduct, fourth ventricle, foramen of lushke, foramen of magende, basal cisterns, {CSF} overlying the cerebellar hemispheres, {CSF} overlying the cerebral hemispheres, central spinal canal, {CSF} overlying the spinal cord, and {CSF} overlying the spinal nerves and roots. {\textbar}   {\textbar} Patients currently implanted with neuromodulation devices must undergo repeat surgery to replace implanted pulse generators every 3-5 years to replace units when batteries fail. Tradeoffs between acceptable implanted device size and limited energy density with current battery technology are responsible for this pervasive problem. Many of these patients are older, and the risks of general anesthesia and surgery are not insignificant. Subjecting these patents to these large risks is a pervasive problem in the field of neuromodulation. The present invention overcomes these limitations with a clever design employing a novel external radiofrequency power delivery system. {\textbar}   {\textbar} The present embodiment of the invention includes an external coil use of Limited energy density because technology is limited. {\textbar}   {\textbar} The present embodiment of this invention teaches a device, method of implantation, and surgical tools for the rapid implantation of a neuromodulation system. Current devices suffer form the need to implant a pulse generator in the subclavicular pocket or other site remote form the site of electrode implantation. Because of this, subcutaneous cables must be implanted to connect the implanted circuit to the implanted stimulating electrode. The present invention teaches a device and method for implanting the circuit in close proximity to the site of stimulation. The design taught herein obviates the need for any subcutaneous cables. Additionally, it teaches a compact design that allows placement of the implanted circuit and the implantation of the intracranial electrode catheter through a single hole. This is a substantial improvement, facilitating much more rapid implantation and eliminating the need for subcutaneous cable implantation. As a result, surgical procedures are much faster and may be performed under local anesthesia, no longer requiring general anesthesia. This substantially increases the market size, allowing implantation in older and frail patients who might otherwise not benefit from neuromodulation technology because of their being poor surgical candidates, due to their inability to safely tolerate general anesthesia and long surgical procedures. {\textbar}   {\textbar} {FIGS}. 35 and 36 {\textbar}   {\textbar}  depict the neurological control system  {\textbar} 999 {\textbar}  employing a lower profile and more compact design in which the system enclosure  {\textbar} 434 {\textbar}  is recessed into the calvarium  {\textbar} 9 {\textbar} , shown in the anteroposterior and lateral projections, respectively. Power delivery unit  {\textbar} 413 {\textbar} , is included within system enclosure  {\textbar} 434 {\textbar} ; however, power delivery unit  {\textbar} 413 {\textbar}  may also be external to system enclosure  {\textbar} 434 {\textbar}  without departing from the present invention. {\textbar} Stimulating and recording circuit  {\textbar}   {\textbar} 26 {\textbar}  is in close proximity to intracranial catheter  {\textbar} 7 {\textbar} , this includes but is not limited to a preferred embodiment in which stimulating and recording circuit  {\textbar} 26 {\textbar}  is recessed into calvarium at the site surrounding the entry point at which intracranial catheter  {\textbar} 7 {\textbar}  passes from outside the calvarium to inside the calvarium. Stimulating and recording circuit  {\textbar} 26 {\textbar}  is electrically connected to intracranial catheter  {\textbar} 7 {\textbar}  which provides electrical connection to intracranial stimulating electrode array  {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar} . Intracranial catheter is mechanically secured to system enclosure  {\textbar} 434 {\textbar} . System enclosure  {\textbar} 434 {\textbar}  is secured to calvarium  {\textbar} 9 {\textbar}  via mechanical attachment  {\textbar} 424 {\textbar} , which is attached to system enclosure  {\textbar} 434 {\textbar}  via machine screw  {\textbar} 439 {\textbar}  or equivalent means and to calvarium  {\textbar} 9 {\textbar}  via bone screw  {\textbar} 438 {\textbar}  or equivalent means. Catheter recess  {\textbar} 441 {\textbar}  provides space for establishment of electrical and mechanical connection of stimulating and recording circuit  {\textbar} 26 {\textbar}  to intracranial catheter  {\textbar} 7 {\textbar} . Catheter mount socket  {\textbar} 437 {\textbar}  and catheter mount ball  {\textbar} 436 {\textbar} . {\textbar} {FIG}. 37 {\textbar}   {\textbar}  shows an expanded view of the neurological control system  {\textbar} 999 {\textbar}  also shown in  {\textbar} {FIGS}. 35 and 36 {\textbar} . {\textbar} {FIGS}. 38 and 39 {\textbar}   {\textbar}  depict a Caldarium drill bit is used to create a circular hole in the calvarium. The present invention teaches a major advance in the expeditiousness of the implantation procedure for creating a craniotomy, with particular relevance to the implantation of a neuromodulation device recessed in the calvarium. In a single pass, a drill bit creates a hole of a diameter similar to that of the implanted device. The outer diameter portion is created by calvarium bit outer diameter segment  {\textbar} 443 {\textbar} . Attached to and deep to calvarium bit outer diameter segment  {\textbar} 443 {\textbar}  is the calvarium bit inner diameter segment  {\textbar} 442 {\textbar} , which creates a hole in the calvarium of a smaller diameter. The resulting geometry, as seen in  {\textbar} {FIG}. 38 {\textbar}  and  {\textbar} {FIG}. 39 {\textbar} , produces bone ledge  {\textbar} 447 {\textbar} . Bone ledge  {\textbar} 447 {\textbar}  serves to provide mechanical support to system enclosure  {\textbar} 434 {\textbar} , preventing system enclosure  {\textbar} 434 {\textbar}  from becoming displaced and impinging upon brain  {\textbar} 251 {\textbar} . {\textbar} Intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  is secured to system enclosure  {\textbar} 434 {\textbar}  by means of catheter mount ball  {\textbar} 436 {\textbar} . A compressible material is either adjacent to or comprises catheter mount ball  {\textbar} 436 {\textbar} . {\textbar} {FIG}. 40 {\textbar}   {\textbar}  depicts the path of the intracranial catheter  {\textbar} 7 {\textbar}  and its connection to the electrical elements of stimulating and recording circuit  {\textbar} 26 {\textbar} , which is contained within system enclosure  {\textbar} 434 {\textbar}  and in close proximity to intracranial catheter  {\textbar} 7 {\textbar} . Intracranial Catheter Proximal End  {\textbar} 451 {\textbar}  is largely contained within or at least has a component that occupies a portion of the catheter recess  {\textbar} 441 {\textbar} . Intracranial Catheter Proximal Electrode  {\textbar} 452 {\textbar}  and Intracranial Catheter Proximal Electrode  {\textbar} 453 {\textbar}  are shown. Additional electrodes or alternate connection means may be employed without departing from the present invention. {\textbar} In one embodiment, set screws are used to electrically connect electrodes on intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  to contacts mounted on system enclosure  {\textbar} 434 {\textbar} . Electrode contacts and set screw are recessed in catheter recess  {\textbar} 441 {\textbar}  in system enclosure  {\textbar} 434 {\textbar} . {\textbar} System enclosure is constructed from a castable material, such as potted epoxy, methylmethacrylate, or other plastic, silicone, or polymer. {RF} electrodes are included within the system enclosure. A titanium or stainless steel shield may be included into eh center of the system enclosure  {\textbar}   {\textbar} 434 {\textbar} . The outer surface of system enclosure  {\textbar} 434 {\textbar}  may have a convex shape, to better approximate the shape of the calvarium removed and replaced by system enclosure  {\textbar} 434 {\textbar} , and the convex shape of outer surface of system enclosure  {\textbar} 434 {\textbar}  minimized stress concentrations on the overlying scalp  {\textbar} 10 {\textbar} . {\textbar} Disease state is estimated using a measure or estimate of chaos of neural activity. Such measures include Lyupanov functions and other measures of chaos or system synchronicity or correlation. {\textbar}   {\textbar} Bottom surface of system enclosure  {\textbar}   {\textbar} 434 {\textbar}  may include electrodes used for at least one of recording, stimulation, ground, or reference electrode functions. {\textbar} An array of at least one {EEG} electrode is used for recording electroencephalographic signals. Said {EEG} electrode may be placed in at least one of a subgaleal location, subcutaneous location, epidural location, subdural location, intracerebral location, or other location enabling {EEG} electrode to sense neural activity. {\textbar}   {\textbar} An advancement in intracranial catheter design is taught in the present invention. Intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  includes a microelectrode channel  {\textbar} 448 {\textbar} . Microelectrode  {\textbar} 449 {\textbar}  is inserted through microelectrode channel  {\textbar} 448 {\textbar} , with microelectrode tip  {\textbar} 450 {\textbar}  protruding beyond tip of intracranial catheter  {\textbar} 7 {\textbar} . Microelectrode tip  {\textbar} 450 {\textbar}  is used to record single cell activity to identify neural structures during advancement of intracranial catheter  {\textbar} 7 {\textbar}  through brain  {\textbar} 251 {\textbar} . At the completion of the insertion of intracranial catheter  {\textbar} 7 {\textbar}  through brain  {\textbar} 251 {\textbar} , microelectrode  {\textbar} 449 {\textbar}  may be removed from intracranial catheter  {\textbar} 7 {\textbar} . {\textbar} This allows microelectrode recording and implantation of intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  during a single pass, saving substantial time during the implantation procedure. {\textbar} During and Following implantation, closed-loop optimization of electrical field shaping is performed by control circuit  {\textbar}   {\textbar} 72 {\textbar} . {\textbar} Disease state is characterized by a measure of correlation between neural signals measured from neural tissue. Disease State {DS} is a vector of individual disease states, including intrinsic disease states {DSI} and extrinsic disease states {DSE}:  {\textbar}   {\textbar} {DS}=[{DS} {\textbar}   {\textbar} I {\textbar} {DS} {\textbar} E {\textbar} ] {\textbar} Intrinsic disease states and extrinsic disease states are, themselves vectors of individual disease states:  {\textbar}   {\textbar} {DS} {\textbar}   {\textbar} I {\textbar} =[{DS} {\textbar} I1 {\textbar} {DS} {\textbar} I2 {\textbar} {DS} {\textbar} I3  {\textbar} . . . {DS} {\textbar} {IN} {\textbar} ] {\textbar} {DS} {\textbar}   {\textbar} E {\textbar} =[{DS} {\textbar} E1 {\textbar} {DS} {\textbar} E2 {\textbar} {DS} {\textbar} E3  {\textbar} . . . {DS} {\textbar} {EM} {\textbar} ] {\textbar} Intrinsic Disease States include those disease states which characterize the state of disease at a given point in time. Extrinsic Disease States include variations of intrinsic disease states, including but not limited to cyclical variations in Intrinsic Disease States, variations in Intrinsic The fifth intrinsic disease state {DS} {\textbar}   {\textbar} I5  {\textbar} represents the level of correlation between neural activity in multiple areas of the nervous system.  {\textbar} {DS} {\textbar}   {\textbar} I5 {\textbar} =C {\textbar} N  {\textbar} Where Normalized Correlation Magnitude matrix C {\textbar}   {\textbar} N  {\textbar} is given by: {\textbar} C {\textbar}   {\textbar} N {\textbar} = {\textbar} [ {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 1 {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 1 {\textbar} , {\textbar} M {\textbar} : {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 1 {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 2 {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 2 {\textbar} , {\textbar} M {\textbar} : {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 1 {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 2 {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 3 {\textbar} , {\textbar} M {\textbar} : {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⁢ {\textbar} : {\textbar} C {\textbar} M {\textbar} , {\textbar} 1 {\textbar} C {\textbar} M {\textbar} , {\textbar} 2 {\textbar} C {\textbar} M {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} M {\textbar} , {\textbar} M {\textbar} ] {\textbar}  Which becomes: {\textbar}   {\textbar} C {\textbar}   {\textbar} N {\textbar} = {\textbar} [ {\textbar} 1 {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 1 {\textbar} , {\textbar} M {\textbar} : {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 1 {\textbar} 1 {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 2 {\textbar} , {\textbar} M {\textbar} : {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 1 {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 2 {\textbar} 1 {\textbar} ⋯ {\textbar} C {\textbar} 3 {\textbar} , {\textbar} M {\textbar} : {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⁢ {\textbar} : {\textbar} C {\textbar} M {\textbar} , {\textbar} 1 {\textbar} C {\textbar} M {\textbar} , {\textbar} 2 {\textbar} C {\textbar} M {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} 1 {\textbar} ] {\textbar} This matrix or a weighted sum of its components represents an additional measure of disease state. This has broad applications in neurological disease quantification and also has particular relevance to measurement of tremor and assessment of seizure activity as well as prediction of likelihood and onset of seizure activity. {\textbar}   {\textbar} C {\textbar}   {\textbar} N {\textbar} = {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} * {\textbar} W {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} + {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 3 {\textbar} * {\textbar} W {\textbar} 1 {\textbar} , {\textbar} 3 {\textbar} + {\textbar} … {\textbar} + {\textbar} C {\textbar} 1 {\textbar} , {\textbar} M {\textbar} * {\textbar} W {\textbar} 1 {\textbar} , {\textbar} M {\textbar} + {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 1 {\textbar} * {\textbar} W {\textbar} 2 {\textbar} , {\textbar} 1 {\textbar} + {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} * {\textbar} W {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} + {\textbar} … {\textbar} + {\textbar} C {\textbar} 2 {\textbar} , {\textbar} M {\textbar} * {\textbar} W {\textbar} 2 {\textbar} , {\textbar} M {\textbar} + {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 1 {\textbar} * {\textbar} W {\textbar} 3 {\textbar} , {\textbar} 1 {\textbar} + {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 2 {\textbar} * {\textbar} W {\textbar} 3 {\textbar} , {\textbar} 2 {\textbar} + {\textbar} … {\textbar} + {\textbar} C {\textbar} 3 {\textbar} , {\textbar} M {\textbar} * {\textbar} W {\textbar} 3 {\textbar} , {\textbar} M {\textbar} + {\textbar} ⋯ {\textbar} C {\textbar} M {\textbar} , {\textbar} 1 {\textbar} * {\textbar} W {\textbar} M {\textbar} , {\textbar} 1 {\textbar} + {\textbar} C {\textbar} M {\textbar} , {\textbar} 2 {\textbar} * {\textbar} W {\textbar} M {\textbar} , {\textbar} 2 {\textbar} + {\textbar} C {\textbar} M {\textbar} , {\textbar} 3 {\textbar} * {\textbar} W {\textbar} M {\textbar} , {\textbar} 3 {\textbar} + {\textbar} … {\textbar}  Where {\textbar}   {\textbar} C {\textbar}   {\textbar} I,J {\textbar} =Correlation between signal I and signal J {\textbar} W {\textbar}   {\textbar} I,J {\textbar} =Weighting factor for Correlation between signal I and signal J {\textbar} The sixth intrinsic disease state {DS} {\textbar}   {\textbar} I6  {\textbar} represents the level of chaos in neural activity in a single or multiplicity of areas of the nervous system. This may be implemented as any measure of entropy or chaos, including variance, standard deviation, Lyupanov exponent values, maximum Lyupanov exponent value, or other measure of entropy or chaos without departing from the present invention.  {\textbar} {DS} {\textbar}   {\textbar} I6 {\textbar} =S {\textbar} N  {\textbar} {DS} {\textbar}   {\textbar} I6 {\textbar} =S {\textbar} 1 {\textbar} *W {\textbar} S1 {\textbar} +S {\textbar} 2 {\textbar} *W {\textbar} S2 {\textbar} +S {\textbar} 3 {\textbar} *W {\textbar} S3 {\textbar} + . . . +S {\textbar} N {\textbar} *W {\textbar} {SN}  {\textbar}  Where {\textbar}   {\textbar} S {\textbar}   {\textbar} 1 {\textbar} =Entropy measure for signal I, which may be implemented in any of several ways outlined above, some of which are detailed below. {\textbar} W {\textbar}   {\textbar} {SI} {\textbar} =Weighting factor for Entropy measure for signal {\textbar} Chaos measurement implemented and quantified as Entropy:  {\textbar}   {\textbar} S {\textbar}   {\textbar} I {\textbar} =Entropy measure for signal  {\textbar} I {\textbar} =− {\textbar}   {\textbar} k∫J[{dX}]P[X {\textbar} I {\textbar} ] log  {\textbar} P[X {\textbar} I {\textbar} ] {\textbar} Where {\textbar}   {\textbar} k=a constant, i.e. Boltzmann's constant as in thermodynamics, or by convention a dimensionless constant in information theory; {\textbar}   {\textbar} X {\textbar}   {\textbar} I {\textbar} =Signal I, such as {EEG} voltage signal I or implanted electrode signal I or microelectrode voltage signal {\textbar} P[X {\textbar}   {\textbar} I {\textbar} ]=Probability distribution of Signal I {\textbar} {dX}=integration variable {\textbar}   {\textbar} In a typical implementation in digital hardware, based upon a base 2 digitization scheme, chaos measurement implemented and quantified as Entropy becomes:  {\textbar}   {\textbar} S {\textbar}   {\textbar} I {\textbar} =−Σp {\textbar} i  {\textbar} log {\textbar} 2  {\textbar} p {\textbar} i  {\textbar} bits {\textbar}  Where {\textbar}   {\textbar} S {\textbar}   {\textbar} I {\textbar} =Entropy measure for signal I {\textbar} p {\textbar}   {\textbar} i {\textbar} =probability of outcome i, for example of sensed voltage being within a particular discretization bin window or value range. {\textbar} log {\textbar}   {\textbar} 2  {\textbar} p {\textbar} i {\textbar} =Log base 2 of p {\textbar} i {\textbar} , alternative bases could be used, but 2 is typically chosen to be consistent with digital hardware, which is implemented using the binary (base 2) system. {\textbar} Chaos measurement implemented and quantified as Lyupanov exponent, which is defined as: {\textbar}   {\textbar} S {\textbar}   {\textbar} l {\textbar} = {\textbar} L {\textbar} = {\textbar} ( {\textbar} 1 {\textbar} / {\textbar} ∑ {\textbar} k {\textbar} = {\textbar} 1 {\textbar} M {\textbar} ⁢ {\textbar} Dt {\textbar} k {\textbar} ) {\textbar} * {\textbar} ∑ {\textbar} k {\textbar} = {\textbar} 1 {\textbar} M {\textbar} ⁢ {\textbar} L {\textbar} k {\textbar} ⁢ {\textbar} ⁢ {\textbar} bits {\textbar} ⁢ {\textbar} ⁢ {\textbar} per {\textbar} ⁢ {\textbar} ⁢ {\textbar} second {\textbar}  Where {\textbar}   {\textbar} L=Lyupanov Exponent {\textbar}   {\textbar} L {\textbar}   {\textbar} k  {\textbar} Satisfies the condition: L(t {\textbar} k {\textbar} )=L(t {\textbar} k-1 {\textbar} )*2 {\textbar} Lk*Dtk  {\textbar} Dt {\textbar}   {\textbar} k {\textbar} =t {\textbar} k {\textbar} −t {\textbar} k-1  {\textbar} is the evolution time of L(t {\textbar} k {\textbar} ) {\textbar} L(t {\textbar}   {\textbar} k {\textbar} ) is the distance between two close points in phase space at time t {\textbar} k  {\textbar} S {\textbar}   {\textbar} I {\textbar} =Entropy measure for signal I, calculated with Lypoanov Exponent {\textbar} Other measures of chaos, including variations of these and other measures or estimates for chaos, may be used without departing from the present invention. {\textbar}   {\textbar} {FIGS}. 37 and 40 {\textbar}   {\textbar}  show system enclosure in cross section, in which intracranial catheter  {\textbar} 7 {\textbar}  traverses catheter mount ball  {\textbar} 436 {\textbar} , which rotates within catheter mount socket  {\textbar} 437 {\textbar} , providing a swivel mechanism to facilitate the selection of a continuum of potential intracranial target sites for intracranial electrode array and intracranial catheter using a single mounted position for system enclosure  {\textbar} 434 {\textbar}  on caldarium  {\textbar} 9 {\textbar} . {\textbar} The reader is requested to note the following labels on  {\textbar}   {\textbar} {FIG}. 37 {\textbar} : {\textbar} Catheter mount ball  {\textbar}   {\textbar} 436 {\textbar} Catheter mount socket  {\textbar}   {\textbar} 437 {\textbar} stimulating and recording unit  {\textbar}   {\textbar} 43 {\textbar} {FIG}. 41 {\textbar}   {\textbar}  depicts one design for the system enclosure for implantation in the calvarium. Mechanical attachment  {\textbar} 424 {\textbar}  is shown in plurality, facilitating mechanical attachment of system enclosure  {\textbar} 434 {\textbar}  to calvarium  {\textbar} 9 {\textbar} , including calvarium outer table  {\textbar} 421 {\textbar}  or calvarium inner table  {\textbar} 423 {\textbar} , calvarium stabilization lip  {\textbar} 501 {\textbar} , or other portion of calvarium without departing from the present invention. Alternatively, other attachment means may be fashioned to perform the equivalent function of attaching system enclosure  {\textbar} 434 {\textbar}  to calvarium  {\textbar} 9 {\textbar}  without departing from the present invention. A single or plurality of screw  {\textbar} 429 {\textbar}  is used to perform the attachment of mechanical attachment  {\textbar} 424 {\textbar}  to calvarium  {\textbar} 9 {\textbar}  and to system enclosure  {\textbar} 434 {\textbar} . Mechanical attachment may be implemented as a cranial plate, craniofacial plate, or other form well known to neurosurgeons, or it may be implemented in another equivalent fashion without departing form the present invention. {\textbar} Electrode  {\textbar}   {\textbar} 452 {\textbar} ,  {\textbar} 453 {\textbar} ,  {\textbar} 454 {\textbar} ,  {\textbar} 455 {\textbar} ,  {\textbar} 456 {\textbar} ,  {\textbar} 457 {\textbar} ,  {\textbar} 458 {\textbar} ,  {\textbar} 459 {\textbar} , are shown on the end of intracranial catheter  {\textbar} 7 {\textbar} , said electrode facilitate contact between intracranial electrodes  {\textbar} 246 {\textbar} , and circuitry enclosed within system enclosure  {\textbar} 434 {\textbar} , including but not limited to output stage, signal conditioning circuit, signal processing circuit, control circuit, and other circuit components. {\textbar} {FIGS}. 42 and 43 {\textbar}   {\textbar}  depict a dual intracranial catheter design, shown from above and shown in cross section profile implanted in a patient, respectively. Mechanical attachment  {\textbar} 424 {\textbar}  are as described in  {\textbar} {FIG}. 41 {\textbar} . Intracranial catheter  {\textbar} 7 {\textbar}  and Electrode  {\textbar} 452 {\textbar} ,  {\textbar} 453 {\textbar} ,  {\textbar} 454 {\textbar} ,  {\textbar} 455 {\textbar} ,  {\textbar} 456 {\textbar} ,  {\textbar} 457 {\textbar} ,  {\textbar} 458 {\textbar} ,  {\textbar} 459 {\textbar}  are as described in  {\textbar} {FIG}. 41 {\textbar} . Electrode  {\textbar} 476 {\textbar} ,  {\textbar} 477 {\textbar} ,  {\textbar} 478 {\textbar} ,  {\textbar} 479 {\textbar} ,  {\textbar} 480 {\textbar} ,  {\textbar} 481 {\textbar} ,  {\textbar} 482 {\textbar} ,  {\textbar} 483 {\textbar}  are shown on the end of intracranial catheter  {\textbar} 500 {\textbar} . A multiplicity of intracranial catheter y or intracranial catheter  {\textbar} 500 {\textbar}  may be employed without departing from the spirit of the present invention. In  {\textbar} {FIG}. 43 {\textbar} , a plurality of bone screw  {\textbar} 438 {\textbar}  is shown facilitating mechanical attachment of mechanical attachment  {\textbar} 424 {\textbar}  to caldarium  {\textbar} 9 {\textbar} . In  {\textbar} {FIG}. 43 {\textbar} , a plurality of machine screw  {\textbar} 439 {\textbar}  is shown facilitating mechanical attachment of mechanical attachment  {\textbar} 424 {\textbar}  to system enclosure  {\textbar} 434 {\textbar} . In  {\textbar} {FIG}. 43 {\textbar} , catheter recess  {\textbar} 441 {\textbar}  is seen in cross section, providing space for intracranial catheter  {\textbar} 7 {\textbar}  and intracranial catheter  {\textbar} 500 {\textbar}  to minimize the profile or height of system enclosure and avoid surface protuberances that could cause ulceration of overlying portions of scalp  {\textbar} 10 {\textbar} . {\textbar} {FIG}. 44 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the intracranial stimulator of the present invention implanted bilaterally in a human patient. In the embodiment illustrated in  {\textbar} {FIG}. 44 {\textbar} , two neurological control systems  {\textbar} 999 {\textbar}  are shown implanted bilaterally. Each system  {\textbar} 999 {\textbar}  includes a stimulating and recording unit  {\textbar} 26 {\textbar}  and one or more intracranial components described below. As described in this illustrative embodiment, the intracranial components preferably include a stimulating electrode array  {\textbar} 37 {\textbar} . However, it should become apparent to those of ordinary skill in the relevant art after reading the present disclosure that the stimulating electrodes may also be extracranial; that is, attached to a peripheral nerve in addition to or in place of being located within the cranium. {\textbar} {FIG}. 45 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the neurological control system  {\textbar} 999 {\textbar}  implanted unilaterally in a human patient. A multiplicity of components or multiplicity of entire systems may be implanted unilaterally or bilaterally without departing from the present invention. In the embodiment illustrated in  {\textbar} {FIG}. 45 {\textbar} , one neurological control systems  {\textbar} 999 {\textbar}  is shown implanted unilaterally in the temporal lobe, shown in an orientation intersecting the hippocampus  {\textbar} 277 {\textbar} . Each system  {\textbar} 999 {\textbar}  includes a stimulating and recording unit  {\textbar} 26 {\textbar}  and one or more intracranial components described in detail above in parent cases. As described in this illustrative embodiment, the intracranial components preferably include an intracranial catheter  {\textbar} 7 {\textbar}  with at least one of a sensor array  {\textbar} 560 {\textbar}  or neuromodulator array  {\textbar} 561 {\textbar} . Sensor array  {\textbar} 560 {\textbar}  may be implemented as a intracranial recording electrode array  {\textbar} 38 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , or other form of sensory input including sensory input modalities  {\textbar} 247 {\textbar}  shown in  {\textbar} {FIG}. 1 {\textbar}  or other form, including optical, metabolic, chemical, or other sensor, without departing form the present invention. Neuromodulator array  {\textbar} 561 {\textbar} , shown on intracranial catheter  {\textbar} 7 {\textbar} , serve to stimulate, inhibit, or both, neural activity. Neuromodulator array  {\textbar} 561 {\textbar}  may be on the same intracranial catheter  {\textbar} 7 {\textbar}  as sensor array  {\textbar} 560 {\textbar}  or on a second intracranial catheter  {\textbar} 500 {\textbar} , as shown in  {\textbar} {FIG}. 46 {\textbar} , on a multiplicity of intracranial catheter  {\textbar} 7 {\textbar} , or on other structure, without departing from the present invention. There may be partial or complete overlap in elements that comprise neuromodulator array  {\textbar} 561 {\textbar}  and sensor array  {\textbar} 560 {\textbar} . For example, neural interface array  {\textbar} 562 {\textbar}  may be implemented as electrode array  {\textbar} 563 {\textbar} , some or all of elements of intracranial recording electrode array  {\textbar} 38 {\textbar}  and elements of intracranial stimulating electrode array  {\textbar} 37 {\textbar}  may be shared. Various forms of multiplexing, in various dimensions, including time, space, frequency, phase, or other dimension, may be employed to facilitate dual or multiple function of elements of sensor array  {\textbar} 560 {\textbar}  and neuromodulator array  {\textbar} 561 {\textbar} , to one skilled in the art, without departing form the present invention. It should become apparent to those of ordinary skill in the relevant art after reading the present disclosure that the stimulating electrodes may also be extracranial; that is, attached to a peripheral nerve or other location such as on the surface of the skin in addition to or in place of being located within the cranium. {\textbar} {FIG}. 46 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the neurological control system  {\textbar} 999 {\textbar}  implanted unilaterally in a human patient. A multiplicity of components or multiplicity of entire systems may be implanted unilaterally or bilaterally without departing from the present invention. In the embodiment illustrated in the sagittal view diagram in  {\textbar} {FIG}. 46 {\textbar} , one neurological control systems  {\textbar} 999 {\textbar}  is shown implanted unilaterally, with two intracranial catheters, intracranial catheter  {\textbar} 7 {\textbar}  and intracranial catheter  {\textbar} 500 {\textbar} , in the right thalamus  {\textbar} 335 {\textbar}  and the right hippocampus  {\textbar} 564 {\textbar} , respectively. The same or a multiplicity of neurological control systems  {\textbar} 999 {\textbar}  may be placed in contralateral structures, including left thalamus  {\textbar} 336 {\textbar}  and left hippocampus  {\textbar} 565 {\textbar} , and other structures including the right anterior nucleus of the thalamus, left anterior nucleus of the thalamus, right subthalamic nucleus, left subthalamic nucleus, right substantia nigra, left substantia nigra, other single structures, or other multiplicity of structures. {\textbar} Modulation of right hippocampus  {\textbar}   {\textbar} 564 {\textbar}  is also accomplished via hippocampal modulator  {\textbar} 534 {\textbar}  and hippocampal modulator  {\textbar} 535 {\textbar} . Modulation of left hippocampus  {\textbar} 565 {\textbar}  is also accomplished via hippocampal modulator  {\textbar} 536 {\textbar}  and hippocampal modulator  {\textbar} 357 {\textbar} . Cortex  {\textbar} 252 {\textbar}  is modulated via cortical modulator  {\textbar} 530 {\textbar} , cortical modulator  {\textbar} 531 {\textbar} , cortical modulator  {\textbar} 532 {\textbar} , and cortical modulator  {\textbar} 533 {\textbar} . {\textbar} {FIG}. 46 {\textbar}   {\textbar}  also shows cortical modulator  {\textbar} 530 {\textbar} , cortical modulator  {\textbar} 531 {\textbar} , cortical modulator  {\textbar} 532 {\textbar} , cortical modulator  {\textbar} 533 {\textbar} , hippocampal modulator  {\textbar} 534 {\textbar} , hippocampal modulator  {\textbar} 535 {\textbar} , hippocampal modulator  {\textbar} 536 {\textbar} , and hippocampal modulator  {\textbar} 537 {\textbar} , which facilitate modulation of multiple regions of cortex  {\textbar} 252 {\textbar} , right hippocampus  {\textbar} 564 {\textbar} , and left hippocampus  {\textbar} 565 {\textbar} . {\textbar} {FIG}. 46 {\textbar}   {\textbar}  and  {\textbar} {FIG}. 47 {\textbar}  are sagittal and lateral view diagrams, respectively, depicting a multiplicity of neural interfacing nodes. Neural interfacing is accomplished with olfactory nerve  {\textbar} 525 {\textbar}  via at least one of olfactory nerve modulator  {\textbar} 527 {\textbar}  and with trigeminal nerve  {\textbar} 368 {\textbar}  via at least one of trigeminal nerve modulator  {\textbar} 528 {\textbar} . {\textbar} {FIG}. 47 {\textbar}   {\textbar}  depicts neural interfacing with vagus nerve  {\textbar} 369 {\textbar}  via at least one of vagus nerve modulator  {\textbar} 529 {\textbar} , with baroreceptor  {\textbar} 370 {\textbar}  via baroreceptor modulator  {\textbar} 566 {\textbar} , with sympathetic ganglion  {\textbar} 371 {\textbar}  via sympathetic modulator  {\textbar} 567 {\textbar} . Modulation of these structures is used for control of neurological state in the treatment of neurological disease as well as hypertension and hypotension. {\textbar} {FIG}. 47 {\textbar}   {\textbar}  also depicts several noninvasive techniques for the treatment of neurological disease. Orbitofrontal modulator  {\textbar} 279 {\textbar} , prefrontal modulator  {\textbar} 280 {\textbar} , precentral modulator  {\textbar} 281 {\textbar} , postcentral modulator  {\textbar} 282 {\textbar} , parietal modulator  {\textbar} 283 {\textbar} , parietooccipital modulator  {\textbar} 284 {\textbar} , occipital modulator  {\textbar} 285 {\textbar} , cerebellar modulator  {\textbar} 286 {\textbar}  are shown overlying the scalp  {\textbar} 10 {\textbar} . These may be implemented as electromagnetic coils or as electrodes, to produce electromagnetic waves for the induction of current or to directly produce currents, respectively. There may also be implemented optically or using other modality for the modulation of neurological activity. These neuromodulators may be located at any anatomical depth, including superficial to the scalp, implanted at any level including but not limited to within the scalp, under the scalp, recessed in the caldarium, deep to the caldarium, in the epidural space, in the subdural space, overlying the cortex, within the cortex, or deep to the cortex, without departing from the present invention. Neuromodulators may take the form of macroelectrodes, macroelectrode arrays, microelectrodes, microelectrode arrays, nerve cuffs, other designs described in the present invention, other electrode designs known in the art, and other neural interfaces to be developed, without departing form the present invention. {\textbar} Neural chaos is modulated by the controlled introduction of energy into a single or multiplicity of neural structures including but not limited to olfactory nerve  {\textbar}   {\textbar} 525 {\textbar} , trigeminal nerve  {\textbar} 368 {\textbar} , vagus nerve  {\textbar} 369 {\textbar} , cutaneous nerves, other cranial nerves, subcutaneous nerve endings, cortex  {\textbar} 252 {\textbar} , cerebral cortex, cerebellar cortex  {\textbar} 257 {\textbar} , deep brain structures  {\textbar} 349 {\textbar} , thalamus  {\textbar} 121 {\textbar} , subthalamic nucleus  {\textbar} 122 {\textbar} , basal ganglia, locus ceruleus, any portion or portions of Papez' circuit, hippocampus, amygdala, fornix, subthalamic nucleus, anterior nucleus of the thalamus, prepyriform cortex, solitary nucleus, dorsal column nucleus, cerebellar nuclei, caudate, putamen, corpus callosum, other nuclei, other tracts, other nerves, other nuclei, other neural structures, and other non-neural structures. {\textbar} {FIG}. 48 {\textbar}   {\textbar}  shows dermatomal zones, revealing specific areas of innervation of skin  {\textbar} 382 {\textbar}  by underlying nerves. Dermatomal zone  {\textbar} 538 {\textbar} , dermatomal zone  {\textbar} 539 {\textbar} , and dermatomal zone  {\textbar} 540 {\textbar}  are innervated by trigeminal nerve branches  {\textbar} 1 {\textbar} ,  {\textbar} 2 {\textbar} , and  {\textbar} 3 {\textbar} , respectively. Dermatomal zone  {\textbar} 541 {\textbar} , dermatomal zone  {\textbar} 542 {\textbar} , and dermatomal zone  {\textbar} 543 {\textbar}  are innervated by cervical nerve roots C {\textbar} 2 {\textbar} , C {\textbar} 2 {\textbar} , and C {\textbar} 3 {\textbar} , respectively. {\textbar} {FIG}. 49 {\textbar}   {\textbar}  depicts two implementations of noninvasive versions of neurological control system  {\textbar} 999 {\textbar} ; these are shown as neurological control system  {\textbar} 994 {\textbar}  which is preferably mounted on the had and neurological control system  {\textbar} 995 {\textbar}  which is preferably mounted on the neck. {\textbar} Neurological control system  {\textbar}   {\textbar} 994 {\textbar}  comprises head band  {\textbar} 568 {\textbar} , recording and stimulating unit  {\textbar} 555 {\textbar} , connecting cable  {\textbar} 556 {\textbar} , connecting cable  {\textbar} 557 {\textbar} , and neuromodulator  {\textbar} 545 {\textbar} , neuromodulator  {\textbar} 546 {\textbar} , neuromodulator  {\textbar} 547 {\textbar} , neuromodulator  {\textbar} 548 {\textbar} , neuromodulator  {\textbar} 549 {\textbar} , neuromodulator  {\textbar} 550 {\textbar} , neuromodulator  {\textbar} 551 {\textbar} , neuromodulator  {\textbar} 552 {\textbar} , and an additional set, which may be symmetrical or asymmetrical, on the contralateral side. {\textbar} Neurological control system  {\textbar}   {\textbar} 995 {\textbar}  comprises head band  {\textbar} 569 {\textbar} , recording and stimulating unit  {\textbar} 570 {\textbar} , connecting cable  {\textbar} 558 {\textbar} , connecting cable  {\textbar} 559 {\textbar} , and neuromodulator  {\textbar} 553 {\textbar} , neuromodulator  {\textbar} 554 {\textbar} , and an additional set, which may be symmetrical or asymmetrical, on the contralateral side. {\textbar} Any single or plurality of said dermatomal zone  {\textbar}   {\textbar} 538 {\textbar} ,  {\textbar} 539 {\textbar} ,  {\textbar} 540 {\textbar} ,  {\textbar} 541 {\textbar} ,  {\textbar} 542 {\textbar} ,  {\textbar} 543 {\textbar}  may be modulated using implanted nerve cuff electrode disclosed in pending patent application Ser. No. 10/198,871 ({GISTIM}) and the cited provisional Appln. No. 60/307,124. Other techniques for modulating innervation to these regions may be employed without departing from the present invention. These include surface electrical stimulation, magnetic stimulation, transcranial magnetic stimulation, vibrotactile stimulation, thermal stimulation, pressure stimulation, optical stimulation, or other stimulation modality. {\textbar} {FIG}. 50 {\textbar}   {\textbar}  depicts a functional block diagram of the neurological control system  {\textbar} 999 {\textbar} , connected to intracranial catheter  {\textbar} 7 {\textbar} , shown implanted in the temporal lobe  {\textbar} 571 {\textbar} , intersecting the hippocampus  {\textbar} 277 {\textbar} . In this diagram, signal from sensor array  {\textbar} 560 {\textbar}  is conditioned, conducted along intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar}  to signal processor  {\textbar} 71 {\textbar} , which generates control input (Y)  {\textbar} 996 {\textbar} , which is conducted to control circuit  {\textbar} 72 {\textbar} , which generates control output (U)  {\textbar} 997 {\textbar} , which is conducted to Output stage circuit  {\textbar} 77 {\textbar} , which generates neuromodulating signal ({NMS})  {\textbar} 998 {\textbar} , which is conducted along stimulator output path  {\textbar} 111 {\textbar}  to neuromodulator array  {\textbar} 561 {\textbar} . Neuromodulator array  {\textbar} 561 {\textbar}  and sensor array  {\textbar} 560 {\textbar}  are implemented as intracranial recording electrode array ({ICREA})  {\textbar} 38 {\textbar}  and intracranial stimulating electrode array ({ICSEA})  {\textbar} 37 {\textbar} , in one preferred embodiment. In the present invention, control input (Y)  {\textbar} 996 {\textbar}  is a function of at least one of neural chaos, T-index, neural signal correlation, neural signal cross-correlation, and neural synchronization. Control output (U)  {\textbar} 997 {\textbar}  and neuromodulatory signal ({NMS})  {\textbar} 998 {\textbar}  are selected to modulate at least one of neural chaos, neural signal correlation, neural signal cross-correlation, and neural synchronization. {\textbar} {FIG}. 51 {\textbar}   {\textbar}  depicts the same functional block diagram as in  {\textbar} {FIG}. 50 {\textbar}  with the addition of a second intracranial catheter  {\textbar} 500 {\textbar}  positioned to intersect at least one of the thalamus  {\textbar} 121 {\textbar} , subthalamic nucleus  {\textbar} 122 {\textbar} , or other anatomical target, including at least one of the centromedian nucleus, substantia nigra, locus ceruleus, reticular activating center, nucleus solitarus, or other neural structure or non-neural structure. {\textbar} {FIG}. 52 {\textbar}   {\textbar}  depicts the same functional block diagram as in  {\textbar} {FIG}. 51 {\textbar}  with the addition of a time diagram of the control input (Y)  {\textbar} 996 {\textbar}  and control output (U)  {\textbar} 997 {\textbar}  shown versus time. The control input (Y)  {\textbar} 996 {\textbar}  is shown to vary with time and to remain within the bounds delimited by threshold  {\textbar} 572 {\textbar}  and threshold  {\textbar} 575 {\textbar} . Control output (U)  {\textbar} 997 {\textbar}  is shown to vary with time in a manner designed to maintain control input (Y)  {\textbar} 996 {\textbar}  within the range specified, below threshold  {\textbar} 572 {\textbar}  and above threshold  {\textbar} 575 {\textbar} . Any of the control laws specified in this patent as well as any others may be used without departing form the present invention. In  {\textbar} {FIG}. 52 {\textbar} , signals form a nonlinear control law is shown; as the disease state varies and approaches threshold  {\textbar} 575 {\textbar}  toward the center of the diagram, control output (U)  {\textbar} 997 {\textbar}  is seen to increase and drive control input (Y)  {\textbar} 996 {\textbar}  back toward the center of the range delimited by threshold  {\textbar} 572 {\textbar}  and threshold  {\textbar} 575 {\textbar} . {\textbar} {FIG}. 53 {\textbar}   {\textbar}  depicts the same functional block diagram and time diagram as in  {\textbar} {FIG}. 52 {\textbar}  with the addition of a threshold  {\textbar} 573 {\textbar} , threshold  {\textbar} 574 {\textbar} , and target value  {\textbar} 576 {\textbar} . In this time diagram, control output (U)  {\textbar} 997 {\textbar}  is shown to vary in accordance with a more complex nonlinear control law. The variation is representative of a piecewise linear control law, which response differently when the control input (Y) is in different regions as defined by threshold  {\textbar} 572 {\textbar} , threshold  {\textbar} 573 {\textbar} , threshold  {\textbar} 574 {\textbar} , threshold  {\textbar} 575 {\textbar} , and target value  {\textbar} 576 {\textbar} . In this embodiment, as control input (Y)  {\textbar} 996 {\textbar}  diverges farther from target value  {\textbar} 576 {\textbar} , the absolute value of the magnitude of control output (U)  {\textbar} 997 {\textbar}  becomes larger. The vertical center of the time diagram for control output (U) may be interpreted as being zero, though other offsets and baseline values may be used without departing form the present invention. As disease state enters the range delimited by threshold  {\textbar} 572 {\textbar}  and threshold  {\textbar} 573 {\textbar} , the gain of control law is seen to increase, as reflected by the incremental increase in magnitude of control output (U)  {\textbar} 997 {\textbar} . As disease state enters the range delimited by threshold  {\textbar} 574 {\textbar}  and threshold  {\textbar} 575 {\textbar} , the gain of control law is seen to increase, as reflected by the incremental increase, in the opposite polarity, in magnitude of control output (U)  {\textbar} 997 {\textbar} . This behavior demonstrates a control law designed to maintain control input (Y)  {\textbar} 996 {\textbar}  within the operating range defined by threshold  {\textbar} 573 {\textbar}  and threshold  {\textbar} 574 {\textbar} , shown as target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} , which are above and below target value  {\textbar} 576 {\textbar} , respectively. As is shown subsequently, state (X)  {\textbar} 991 {\textbar}  is a scalar or vector of value representative of neurological state and disease state. Components of state (X)  {\textbar} 991 {\textbar}  may be identical to or functions of control input (Y). Furthermore, the same, similar, or different control laws and systems may be employed to control the behavior of state (X)  {\textbar} 991 {\textbar} . f control input (Y)  {\textbar} 996 {\textbar}  diverges outside this range and into critical range  {\textbar} 579 {\textbar}  or critical range  {\textbar} 580 {\textbar} , a different control scheme is used. This may be implemented as the same control law with different gains or as a different control law. {\textbar} In  {\textbar}   {\textbar} {FIG}. 53 {\textbar} , the signal path is shown along with the system block diagram, detailed in  {\textbar} {FIG}. 2 {\textbar} , which is from the original filing of the parent case of this patent. Neural recording signal ({NRS})  {\textbar} 993 {\textbar}  is sensed by sensor array  {\textbar} 560 {\textbar} , and is transmitted to signal conditioning circuit  {\textbar} 76 {\textbar} . Feedback signal (F)  {\textbar} 992 {\textbar}  is generated by signal conditioning circuit  {\textbar} 76 {\textbar}  from neural recording signal ({NRS})  {\textbar} 993 {\textbar}  and transmitted to signal processor  {\textbar} 71 {\textbar} . Feedback signal (F) is shown transmitted on Conditioned Intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar} , though for a non-implanted neurological control system  {\textbar} 999 {\textbar} , a different transmission means would be used, without departing form the present invention. Signal conditioning circuit  {\textbar} 76 {\textbar} , may have a unity gain, and equivalently be omitted from neurological control system  {\textbar} 999 {\textbar} , without departing from the present or parent case invention. {\textbar} In  {\textbar}   {\textbar} {FIG}. 54 {\textbar} , a time diagram of the control input (Y)  {\textbar} 996 {\textbar}  and control output (U)  {\textbar} 997 {\textbar}  shown versus time. In addition, a time diagram of state vector (X)  {\textbar} 991 {\textbar} , with components state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar} , state  {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar} , state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar} , and state  {\textbar} 5 {\textbar}  (X {\textbar} 5 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 5 {\textbar} , are shown. More or fewer states, comprising the range of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  to state N ({XN})  {\textbar} 991 {\textbar} -N, as shown in  {\textbar} {FIG}. 56 {\textbar} , may be defined without departing from the present invention. {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  is identical to control input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  is a function of neural chaos. This may be used to facilitate a proportional control law component in the control of neural chaos. In one preferred embodiment the function of neural chaos includes the disentrainment of neural chaos, inversely related to the synchronization of neural chaos among at least 1 recording electrode or other neural signal transducer. {\textbar} There are a multiplicity of methods and designs in which this can be implemented in the present invention. In one such preferred embodiment, one state may be allocated to represent the measure of neural chaos for each element of neural recording signal ({NRS})  {\textbar}   {\textbar} 993 {\textbar} , as recorded from each recording electrode or signal transducer, including at least one of intracranial recording electrode  {\textbar} 5 {\textbar} , intracranial recording electrode  {\textbar} 6 {\textbar} , elements of intracranial recording electrode array  {\textbar} 38 {\textbar} , elements of neural interface array  {\textbar} 562 {\textbar}  (shown in  {\textbar} {FIG}. 45 {\textbar} ), or other neural signal transducer. At least one additional state is defined as a function of these states, specifically the disentrainment of neural chaos, inversely related to the correlation or synchronization of neural chaos, which is a measure of the correlation between these measures of neural chaos derived from elements of neural recording signal ({NRS})  {\textbar} 993 {\textbar} . These measures of neural chaos and the correlation between neural chaos measurements may be alternatively calculated within signal processor  {\textbar} 71 {\textbar}  as a neural state or disease state estimate, without departing from the present invention. {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar}  is a time derivative of control input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar}  is a measure of the first derivative with respect to time of neural chaos or function thereof, which is used to facilitate a differential control law component in the control of said function of neural chaos. {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is a time integral of control Input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is a measure of the first integral with respect to time of neural chaos or function thereof, which is used to facilitate an integral control law component in the control of said function of neural chaos. {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar}  is a nonlinear function of control input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is a measure of a nonlinear function of neural chaos, which is used to facilitate a nonlinear control law component in the control of neural chaos or function thereof, including disentrainment of neural chaos or of synchronization of neural chaos. As shown, state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar}  depicts a nonlinear function which is approximately zero during the condition in which control input (Y)  {\textbar} 996 {\textbar}  is within target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar}  and increases in magnitude as control input (Y) deviates from the region defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar}  and migrates into at least one of critical range  {\textbar} 579 {\textbar}  and critical range  {\textbar} 580 {\textbar} . State  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar}  is shown to represent “target range deviation”, a continuous function which is shown as the amount by which state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ) deviates outside the limits defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 5 {\textbar}  (X {\textbar} 5 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 5 {\textbar}  is an error signal representing the difference between a constant or time varying reference value and control input (Y)  {\textbar} 996 {\textbar} . As such it represents an error signal. It may also be processed to generate additional states, such as a combination of first, second, and higher order derivatives and integrals with respect to time, to produce control laws of arbitrary complexity to facilitate tracking of any or all components of state (X)  {\textbar} 991 {\textbar}  to a desired reference signal. In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 5 {\textbar}  (X {\textbar} 5 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 5 {\textbar}  is a measure of the difference between the actual level of neural chaos and the desired level of neural chaos, such as target value  {\textbar} 576 {\textbar}  or other signal. {\textbar} These components of state (X)  {\textbar}   {\textbar} 991 {\textbar} , and other signals and functions thereof, are used to drive the neural chaos to a desired level, such as within the normal level seen during inter-ictal periods, and to prevent the neural chaos form entering critical range  {\textbar} 579 {\textbar}  or critical range  {\textbar} 580 {\textbar} . When neural chaos decreases to a value within critical range  {\textbar} 580 {\textbar} , the probability of a seizure is increased. Generation of neuromodulatory signal ({NMS})  {\textbar} 998 {\textbar}  is performed to drive neural chaos out of this region into either of target range  {\textbar} 577 {\textbar}  or target range  {\textbar} 578 {\textbar} , to reduce the probability of a seizure and thereby prevent the occurrence of a seizure. {\textbar} This control system is also used to prevent occurrence of other neurological events, including mania, depression, psychosis, rage, narcolepsy, desire for addicting agents (i.e. opiates, cocaine, nicotine, alcohol, or other drug), or other undesirable neurological state, condition, perception, or symptom. {\textbar}   {\textbar} Neuromodulatory signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  is transmitted to neuromodulator array  {\textbar} 561 {\textbar} . Neuromodulator array  {\textbar} 561 {\textbar} , encompasses any single or plurality of neuromodulator elements, including neuromodulator  {\textbar} 545 {\textbar} , neuromodulator  {\textbar} 546 {\textbar} , neuromodulator  {\textbar} 547 {\textbar} , neuromodulator  {\textbar} 548 {\textbar} , neuromodulator  {\textbar} 549 {\textbar} , neuromodulator  {\textbar} 550 {\textbar} , neuromodulator  {\textbar} 551 {\textbar} , neuromodulator  {\textbar} 552 {\textbar} , neuromodulator  {\textbar} 553 {\textbar} , neuromodulator  {\textbar} 554 {\textbar} , intracranial stimulating electrode  {\textbar} 1 {\textbar} , intracranial stimulating electrode  {\textbar} 2 {\textbar} , intracranial stimulating electrode  {\textbar} 3 {\textbar} , and intracranial stimulating electrode  {\textbar} 4 {\textbar} . Any of said neuromodulator elements may be implemented as a singularity or combination of an electrode for the delivery of electrical energy, a drug delivery catheter for the delivery of drug or chemical agent, a microcatheter for the intraparenchymal delivery of drug or agent, an optical element for the delivery of optical energy, a coil or other transceiver for the delivery of electromagnetic energy, ultrasonic transducer for the delivery of ultrasound energy, thermal source for the introduction of thermal energy, thermal sink for the removal of thermal energy, microdialysis device for the introduction or control of chemical concentrations, or other device for the modulation of neural activity. {\textbar} Neuromodulatory signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  is transmitted to neuromodulator array  {\textbar} 561 {\textbar} , according to closed-loop control laws described above, to control state (X)  {\textbar} 991 {\textbar}  in any of several manners or combinations thereof, including control laws to: (1) maintain state (X)  {\textbar} 991 {\textbar}  at or near a target value (scalar or vector), (2) maintain state (X)  {\textbar} 991 {\textbar}  within a single or plurality of target ranges, including but not limited to target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} , (3) prevent state (X)  {\textbar} 991 {\textbar}  from entering any critical range, including but not limited to critical range  {\textbar} 579 {\textbar}  and critical range  {\textbar} 580 {\textbar} , (4) to maintain state (X)  {\textbar} 991 {\textbar}  at or near any constant or time-varying reference value, (scalar or vector), (5) maintain state (X)  {\textbar} 991 {\textbar}  within a single or plurality of constant or time-varying target ranges, (6) prevent state (X)  {\textbar} 991 {\textbar}  from entering any constant or time-varying critical range, and (7) other form of closed-loop control. {\textbar} As is typical of control systems, the farther any single or plurality of component of state (X)  {\textbar}   {\textbar} 991 {\textbar}  is from a critical range, such as critical range  {\textbar} 579 {\textbar}  and critical range  {\textbar} 580 {\textbar} , the lower the probability of entering said critical range by said single or plurality of component of state (X)  {\textbar} 991 {\textbar} . The larger the difference between a single or plurality of component of state (X)  {\textbar} 991 {\textbar}  from said critical range, the larger the system dynamic effect, external perturbation, or noise magnitude would be required to drive said single or plurality of component of state (X)  {\textbar} 991 {\textbar}  into said critical range. For a neurological condition that has an elevated probability of occurring when said single or plurality of component of state (X)  {\textbar} 991 {\textbar}  are in critical range, the probability of said neurological condition occurring can be minimized if said single or plurality of component of state (X)  {\textbar} 991 {\textbar}  is kept outside or as far in value as possible from of said critical range. {\textbar} When the present invention is applied to the treatment of epilepsy, at least one component, i.e. state  {\textbar}   {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , of state (X)  {\textbar} 991 {\textbar} , is decreases as the probability of a seizure occurring increases. Through the introduction of chaos into the nervous system, the neural chaos is increased, thereby reducing the probability of a seizure occurring. With sufficient control gain, the probability of a seizure occurring can be driven to small values approaching zero; resulting in the prevention of a seizure. {\textbar} State (X)  {\textbar}   {\textbar} 991 {\textbar}  comprises disease state estimate as shown in  {\textbar} {FIG}. 12 {\textbar} . As taught in the parent case, and is shown in  {\textbar} {FIG}. 12 {\textbar} , a control error (e) is calculated as the difference between the disease reference state (r) and the disease state estimate (X). Control circuit  {\textbar} 72 {\textbar}  operates to drive this control error (e) toward zero, such that the disease state estimate (X) follows the disease state reference (r). This same invention, taught in the parent case, is used to control state (X) as also shown in  {\textbar} {FIG}. 52 {\textbar} , to follow a desired disease reference state. This same invention, taught in the parent case, is also used to control state (X) as also shown in  {\textbar} {FIG}. 52 {\textbar} , to remain within a desired target range. This same invention, taught in the parent case, is also used to control state (X) as also shown in  {\textbar} {FIG}. 52 {\textbar} , to remain outside of a critical range. Control law circuit block  {\textbar} 231 {\textbar}  teaches a configuration for accomplishing each of these control schemes. {\textbar} In the control of neurological state to prevent seizures, the control circuit  {\textbar}   {\textbar} 72 {\textbar}  shown in the parent invention may be employed to perform at least one of (1) maintenance of neurological chaos or function thereof at a reference value, typically defined within the normal inter-ictal range; (2) maintenance of neurological chaos or function thereof within a target range, typically representative of normal inter-ictal chaos range; (3) maintenance of neurological chaos or function thereof outside of a critical range, typically outside of the normal inter-ictal chaos range, (4) maintenance of neurological chaos or function thereof as far as possible from a critical range which is associated with an increased probability of seizure; (5) maintenance of neurological chaos or function thereof at a constant value, (6), maintenance of neurological chaos at a time varying value. Functions of neurological chaos included in the present invention comprise disentrainment of neural chaos, entrainment of neural chaos, synchronization of neural chaos, correlation of neural chaos, differences between actual and reference values of neural chaos, and functions thereof. {\textbar} In  {\textbar}   {\textbar} {FIG}. 55 {\textbar} , a time diagram of the control input (Y)  {\textbar} 996 {\textbar}  and control output (U)  {\textbar} 997 {\textbar}  shown versus time. In addition, a time diagram of state vector (X)  {\textbar} 991 {\textbar} , with components state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar} , state  {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar} , state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar} , and state N ({XN})  {\textbar} 991 {\textbar} -N, are shown. More or fewer states may be defined without departing from the present invention. {\textbar} In this figure, state  {\textbar}   {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  is shown to be the same as control input  {\textbar} 1 {\textbar}  (Y- {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , which represents disentrainment of neural chaos among elements of neural recording signal ({NRS})  {\textbar} 993 {\textbar} , calculated in this preferred embodiment as a disease state estimate by signal processor  {\textbar} 71 {\textbar}  and transmitted to control circuit  {\textbar} 72 {\textbar} . The calculations may be allocated differently among signal processor  {\textbar} 71 {\textbar}  and control circuit  {\textbar} 72 {\textbar}  without departing form the present invention. State  {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar}  is shown as the first derivative with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} . State  {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is shown as the first integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} As seen in  {\textbar}   {\textbar} {FIG}. 55 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  remains within target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . State  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 9914 {\textbar}  represents a function of the amount by which state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ) deviates outside the limits defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . In state time diagram shown, state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar}  is a nonlinear function of control input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is a measure of a nonlinear function of the disentrainment of neural chaos. As seen in related  {\textbar} {FIG}. 54 {\textbar} , state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  depicts a nonlinear function which is approximately zero during the condition in which control input (Y)  {\textbar} 996 {\textbar}  is within target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar}  and increases in magnitude as control input (Y) deviates from the region defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar}  and migrates into at least one of critical range  {\textbar} 579 {\textbar}  and critical range  {\textbar} 580 {\textbar} . State  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 9914 {\textbar}  is shown to represent “target range deviation”, a continuous function which is shown as the amount by which state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ) deviates outside the limits defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . In  {\textbar} {FIG}. 55 {\textbar} , state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 9914 {\textbar}  remains approximately zero during the time span shown, since control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  remains within the union of union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} , suggesting satisfactory closed-loop control performance, specifically in the regulation of the disentrainment of neural chaos. {\textbar} In  {\textbar}   {\textbar} {FIG}. 56 {\textbar} , a time diagram of the unperturbed control input (Y′)  {\textbar} 988 {\textbar}  and perturbed control input (Y″)  {\textbar} 989 {\textbar} , unperturbed control output (U′)  {\textbar} 983 {\textbar}  and perturbed control output (U″)  {\textbar} 984 {\textbar} , unperturbed state (X′)  {\textbar} 986 {\textbar} , and perturbed state (X″)  {\textbar} 987 {\textbar}  in response to perturbation (P)  {\textbar} 990 {\textbar} . This figure shows the effect of perturbation (P)  {\textbar} 990 {\textbar}  on the neurophysiology of patient  {\textbar} 227 {\textbar}  and signals processed by neurological control system  {\textbar} 999 {\textbar} . {\textbar} Unperturbed control input  {\textbar}   {\textbar} 1 {\textbar}  (Y- {\textbar} 1 {\textbar} ′)  {\textbar} 988 {\textbar} , unperturbed control output  {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ′)  {\textbar} 983 {\textbar} , and unperturbed state  {\textbar} 1 {\textbar}  (X- {\textbar} 1 {\textbar} ′)  {\textbar} 986 {\textbar}  represent the neurophysiology of patient  {\textbar} 227 {\textbar}  and signals processed by neurological control system  {\textbar} 999 {\textbar}  in the absence of perturbation (P)  {\textbar} 990 {\textbar} . Additional elements of any values, including but not limited to unperturbed control input (Y′)  {\textbar} 988 {\textbar} , unperturbed control output (U′)  {\textbar} 983 {\textbar} , and unperturbed state (X′)  {\textbar} 986 {\textbar}  are included in the present invention, in a multivariable implementation of a preferred embodiment of the present invention. {\textbar} Perturbed control input  {\textbar}   {\textbar} 1 {\textbar}  (Y- {\textbar} 1 {\textbar} ″)  {\textbar} 989 {\textbar} - {\textbar} 1 {\textbar} , perturbed control output  {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ″)  {\textbar} 984 {\textbar} - {\textbar} 1 {\textbar} , and perturbed state  {\textbar} 1 {\textbar}  (X- {\textbar} 1 {\textbar} ″)  {\textbar} 987 {\textbar} - {\textbar} 1 {\textbar}  represent the neurophysiology of patient  {\textbar} 227 {\textbar}  and signals processed by neurological control system  {\textbar} 999 {\textbar}  in the presence of perturbation (P)  {\textbar} 990 {\textbar} , such as the application of flashing lights. Additional elements of any values, including but not limited to perturbed control input (Y″)  {\textbar} 989 {\textbar} , perturbed control output (U″)  {\textbar} 984 {\textbar} , and perturbed state (X″)  {\textbar} 987 {\textbar}  are included in the present invention, in a multivariable implementation of a preferred embodiment of the present invention. {\textbar} Independence of neural chaos and disentrainment of neural chaos are seen to decrease, reflective of an increase in synchronization of neural chaos, in response to perturbation (P)  {\textbar}   {\textbar} 990 {\textbar} ; and other state variables, including perturbed state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ″)  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , through perturbed state N ({XN}″)  {\textbar} 991 {\textbar} -N, as described in detail in  {\textbar} {FIG}. 54 {\textbar}  and  {\textbar} {FIG}. 55 {\textbar} , are shown to respond accordingly. {\textbar} Perturbed control output  {\textbar}   {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ″)  {\textbar} 984 {\textbar} - {\textbar} 1 {\textbar}  is seen to increase relative to unperturbed control output  {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ′)  {\textbar} 983 {\textbar} - {\textbar} 1 {\textbar} , as determined by control law implemented in control circuit  {\textbar} 72 {\textbar} , in response to the increase in perturbed state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ″)  {\textbar} 987 {\textbar} - {\textbar} 1 {\textbar} . This incremental increase in perturbed control output  {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ″)  {\textbar} 984 {\textbar} - {\textbar} 1 {\textbar}  causes a corresponding incremental increase in neuromodulating signal ({NMS})  {\textbar} 998 {\textbar} , which causes an incremental increase in the level of neural disentrainment to compensate for the effects of perturbation (P)  {\textbar} 990 {\textbar} , driving the level of disentrainment of neural chaos back into the desired range, comprising the region defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . {\textbar} In  {\textbar}   {\textbar} {FIG}. 57 {\textbar} , a time diagram of the {EEG} signal (E)  {\textbar} 985 {\textbar} , unperturbed control input (Y′)  {\textbar} 988 {\textbar}  and perturbed control input (Y″)  {\textbar} 989 {\textbar} , unperturbed control output (U′)  {\textbar} 983 {\textbar}  and perturbed control output (U″)  {\textbar} 984 {\textbar} , unperturbed state (X′)  {\textbar} 986 {\textbar}  and perturbed state (X″)  {\textbar} 987 {\textbar}  in response to perturbation (P)  {\textbar} 990 {\textbar} . This figure shows the effect of perturbation (P)  {\textbar} 990 {\textbar}  on the neurophysiology of patient  {\textbar} 227 {\textbar}  and signals processed by neurological control system  {\textbar} 999 {\textbar} . {\textbar} In addition to the values shown in  {\textbar}   {\textbar} {FIG}. 56 {\textbar} ,  {\textbar} {FIG}. 57 {\textbar}  further shows {EEG} signal  {\textbar} 985 {\textbar} , including {EEG} signal  {\textbar} 1 {\textbar}  (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and {EEG} signal  {\textbar} 2 {\textbar}  (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during which time span there are no {EEG} abnormalities  {\textbar} 599 {\textbar} . Neurological control system  {\textbar} 999 {\textbar}  maintains perturbed control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 989 {\textbar} - {\textbar} 1 {\textbar}  within the desired range, comprising the region defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} , preventing any neurological signs or symptoms and preventing any {EEG} abnormalities which may precede or be concurrent with such neurological signs or symptoms. {\textbar} In  {\textbar}   {\textbar} {FIG}. 58 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y)  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the normal unperturbed state. This diagram shows normal {EEG} signals, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , with no {EEG} abnormalities  {\textbar} 599 {\textbar}  nor neurological signs or symptoms  {\textbar} 600 {\textbar}  during this time span {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . Additional states (X)  {\textbar} 991 {\textbar}  may be defined or used without departing from the present invention. In one embodiment, for the treatment of seizures, state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  represent the level of correlation of neural chaos between {EEG} signals (E {\textbar} 1 {\textbar}  to E-N)  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  to  {\textbar} 985 {\textbar} -N. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  may occupy a range of values that are subdivided into specific ranges shown in  {\textbar} {FIG}. 58 {\textbar} . {\textbar} Under normal baseline conditions, as shown for baseline nonperturbed nontreated period  {\textbar}   {\textbar} 592 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary within normal range  {\textbar} 587 {\textbar} . This demonstrated variation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  occurs throughout the day under normal conditions and in the absence of any signs or symptoms of disease. This represents a normal range of disease state. In one preferred embodiment for the treatment of epilepsy, this represents the normal range of a metric of disentrainment of neural chaos and during which there are no signs and no symptoms of seizure. {\textbar} Under normal conditions and during which time the present invention is in operation (“Closed-Loop Neuromodulator Control {ON}”), shown as nonperturbed treated period  {\textbar}   {\textbar} 593 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary within control range  {\textbar} 586 {\textbar} . Control range  {\textbar} 586 {\textbar}  is a subset of normal range  {\textbar} 587 {\textbar} . This demonstrates variation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  that occurs throughout the day under conditions in which the present invention is active (“Closed-Loop Neuromodulator Control {ON}”) and in the absence of any signs or symptoms of disease. This represents a normal range of disease state. In one preferred embodiment for the treatment of epilepsy, this represents the normal range of a metric of neural chaos during which there are no signs and no symptoms of seizure. During nonperturbed treated period  {\textbar} 593 {\textbar} , the Closed-Loop Neuromodulator Control is {ON} and control output (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is active. Due to the action of control output (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar} , implemented as electrical current or voltage pulses, flow of pharmacological or chemical agent, emission of light, delivery of vibratory or ultrasound energy, production of electromagnetic energy, application of pressure or other neuromodulating energy form, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is maintained within control range  {\textbar} 586 {\textbar} . {\textbar} Under normal conditions and during which time the present invention is inactive (“Closed-Loop Neuromodulator Control {OFF}”), shown as nonperturbed nontreated period  {\textbar}   {\textbar} 594 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary within normal range  {\textbar} 587 {\textbar} . This demonstrated variation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  occurs throughout the day under normal conditions and in the absence of any signs or symptoms of disease. This represents a normal range of disease state. In one preferred embodiment for the treatment of epilepsy, this represents the normal range of a metric of neural chaos during which there are no signs and no symptoms of seizure. There may be some aftereffects that persist following the deactivation of the present invention (Closed-Loop Neuromodulator Control {OFF}); these are anticipated in the present invention. The persistence of beneficial effects for some period following the use of the present invention allows the duty cycle of operation to be reduced, thereby minimizing tissue stimulation, drug or other agent delivery. {\textbar} There are no {EEG} abnormalities  {\textbar}   {\textbar} 599 {\textbar}  and no neurological signs or symptoms  {\textbar} 600 {\textbar} , including seizures, during the time periods depicted in  {\textbar} {FIG}. 58 {\textbar} . As shown during nonperturbed nontreated period  {\textbar} 594 {\textbar} , the action of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  provides a continuous stabilizing influence on control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , preventing it from deviating outside of control range  {\textbar} 586 {\textbar} . At no point in time in  {\textbar} {FIG}. 58 {\textbar}  does control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  indicate any adverse neurological conditions that would be reflective of a seizure, and aura, or associated event. Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  does not enter borderline range  {\textbar} 588 {\textbar} , borderline range  {\textbar} 589 {\textbar} , critical range  {\textbar} 590 {\textbar} , or critical range  {\textbar} 591 {\textbar} . {\textbar} In  {\textbar}   {\textbar} {FIG}. 59 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the normal unperturbed state. This diagram shows normal {EEG} signals, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying interictal period  {\textbar} 603 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of normal range  {\textbar} 587 {\textbar}  and into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar}  without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or signs or symptoms of neurological disease  {\textbar} 600 {\textbar} . {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . Additional states (X)  {\textbar} 991 {\textbar} , including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other elements of state (X)  {\textbar} 991 {\textbar}  and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary first within the normal range  {\textbar} 587 {\textbar}  and to have multiple excursions into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} . During this time, there are no episodes of abnormal {EEG} nor episodes of neurological signs or symptoms. Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , as well as corresponding elements of state (X)  {\textbar} 991 {\textbar} , exhibit excursions outside of normal range  {\textbar} 587 {\textbar} , and corresponding ranges likewise for elements of state (X)  {\textbar} 991 {\textbar} , and return to normal range  {\textbar} 587 {\textbar}  without event. {\textbar} In  {\textbar}   {\textbar} {FIG}. 60 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the unperturbed state in which the present invention is not activated and a seizure spontaneously develops. This diagram shows the development of {EEG} abnormalities  {\textbar} 599 {\textbar} , shown in (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, followed by the progression of the seizure to be manifest by neurological signs or symptoms  {\textbar} 600 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of normal range  {\textbar} 587 {\textbar}  and into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} , during which time {EEG} abnormalities  {\textbar} 599 {\textbar}  subsequently develop, followed by neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . Additional states (X)  {\textbar} 991 {\textbar} , including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other elements of state (X)  {\textbar} 991 {\textbar}  and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary first within the normal range  {\textbar} 587 {\textbar}  and to have multiple excursions into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} . During the first such excursion, which occurs in interictal period  {\textbar} 595 {\textbar} , there are no episodes of {EEG} abnormalities  {\textbar} 599 {\textbar}  nor episodes of neurological signs or symptoms  {\textbar} 600 {\textbar} . Sometime during the second such excursion into critical range  {\textbar} 591 {\textbar} , {EEG} abnormalities  {\textbar} 599 {\textbar}  develop, as seen during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar} . The {EEG} abnormalities  {\textbar} 599 {\textbar}  that appears during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar}  then progresses to involve a larger portion of the brain and is manifest as neurological signs or symptoms  {\textbar} 600 {\textbar}  which define the clinical seizure  {\textbar} 597 {\textbar} . Following clinical seizure  {\textbar} 597 {\textbar} , neurological signs or symptoms  {\textbar} 600 {\textbar}  cease and {EEG} abnormalities  {\textbar} 599 {\textbar}  cease. During and Following clinical seizure  {\textbar} 597 {\textbar} , Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  progressively moves back to normal range  {\textbar} 587 {\textbar} . {\textbar} In  {\textbar}   {\textbar} {FIG}. 61 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the unperturbed state in which the present invention is activated and providing a continuous stabilizing influence on the nervous system, during controlled interictal period  {\textbar} 604 {\textbar} . This diagram shows the persistence of normal {EEG} signals, shown in (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying controlled interictal period  {\textbar} 604 {\textbar} , accompanied by no neurological signs or symptoms  {\textbar} 600 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , within the control range  {\textbar} 586 {\textbar} . A single or multiplicity of additional states may be used without departing from the present invention. {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . Additional states (X)  {\textbar} 991 {\textbar} , including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other elements of state (X)  {\textbar} 991 {\textbar}  and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} In one preferred embodiment for the treatment of epilepsy, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is calculated as a measure of the disentrainment of neural chaos. Other measures of neural chaos, functions of neural chaos, or other function of at least one of neural chaos or neural entropy may be used without departing from the present invention. Neural chaos may be measured using a Lyapunov exponent, Kolmogorov entropy, or other measure of chaos. These measures of neural chaos, disentrainment of neural chaos, entrainment of neural chaos, synchronization of neural chaos, and other functions of neural chaos may be calculated using any of the methods taught in the present invention or using other measures, including those in which information rate, neural signal correlations or cross-correlations, or other measure of entropy, chaos, or equivalent measure, or other function of neural or physiological signals are employed. Other functions include metrics of neural signal overall energy levels, energy levels within a single or multiplicity frequency bands or ratios thereof, changes in spike and wave frequencies, or other parameters. {\textbar} Control output  {\textbar}   {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is used to generate Neuromodulatory signal ({NMS})  {\textbar} 998 {\textbar} , which is transmitted to at least one of the implementations neural modulator described herein or to other neuromodulator; these include but are not limited to neuromodulator array  {\textbar} 561 {\textbar} , hippocampal modulator  {\textbar} 534 {\textbar}  and hippocampal modulator  {\textbar} 535 {\textbar} , hippocampal modulator  {\textbar} 536 {\textbar}  and hippocampal modulator  {\textbar} 357 {\textbar} , cortical modulator  {\textbar} 530 {\textbar} , cortical modulator  {\textbar} 531 {\textbar} , cortical modulator  {\textbar} 532 {\textbar} , and cortical modulator  {\textbar} 533 {\textbar} , olfactory nerve modulator  {\textbar} 527 {\textbar} , trigeminal nerve modulator  {\textbar} 528 {\textbar} , vagus nerve modulator  {\textbar} 529 {\textbar} , sympathetic modulator  {\textbar} 567 {\textbar} , crbitofrontal modulator  {\textbar} 279 {\textbar} , prefrontal modulator  {\textbar} 280 {\textbar} , precentral modulator  {\textbar} 281 {\textbar} , postcentral modulator  {\textbar} 282 {\textbar} , parietal modulator  {\textbar} 283 {\textbar} , parietooccipital modulator  {\textbar} 284 {\textbar} , occipital modulator  {\textbar} 285 {\textbar} , cerebellar modulator  {\textbar} 286 {\textbar} , neuromodulator  {\textbar} 545 {\textbar} , neuromodulator  {\textbar} 546 {\textbar} , neuromodulator  {\textbar} 547 {\textbar} , neuromodulator  {\textbar} 548 {\textbar} , neuromodulator  {\textbar} 549 {\textbar} , neuromodulator  {\textbar} 550 {\textbar} , neuromodulator  {\textbar} 551 {\textbar} , neuromodulator  {\textbar} 552 {\textbar} , neuromodulator  {\textbar} 553 {\textbar} , neuromodulator  {\textbar} 554 {\textbar} , neuromodulator array  {\textbar} 561 {\textbar} , contralateral implementations of any of these, and other neuromodulators. Other variations of these neuromodulator designs or locations may be envisioned by one skilled in the art, and these are included in the present invention. Other anatomical locsaiotns or electrode designs or configurations may be used without departing form the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to remain within control range  {\textbar} 586 {\textbar} , while responding to the continuous stabilizing influence provided by control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar} . There are no {EEG} abnormalities  {\textbar} 599 {\textbar}  and no neurological signs or symptoms  {\textbar} 600 {\textbar}  during the action provided by the feedback driven controller embodied in the present invention. The present invention encompasses the use of any single or multiplicity of elements of control input Y  {\textbar} 996 {\textbar} , representing any single or multiplicity of disease state. One preferred state used in the treatment of epilepsy is the use of at least one measure of disentrainment of neural chaos. These and other measures of neural activity, chaos, disentrainment of neural chaos, entrainment of neural chaos, synchronization of chaos are also used in the treatment of psychosis, depression, schizophrenia, mania, bipolar disorder, rage, anxiety, and other neurological and psychiatric conditions. {\textbar} In  {\textbar}   {\textbar} {FIG}. 62 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the unperturbed state in which the control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) is initially {OFF} during uncontrolled interictal period  {\textbar} 605 {\textbar}  and is subsequently activated and begins providing a continuous stabilizing influence on the nervous system, during controlled interictal period  {\textbar} 606 {\textbar} . {\textbar} The transition from control output  {\textbar}   {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) in the {OFF} state during uncontrolled interictal period  {\textbar} 605 {\textbar}  to the {ON} state during controlled interictal period  {\textbar} 606 {\textbar}  occurs at an arbitrary time and under normal conditions. In the diagram shown, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has deviated from arbitrarily defined control range  {\textbar} 586 {\textbar}  and is still within normal range  {\textbar} 587 {\textbar} . As has been shown in  {\textbar} {FIG}. 59 {\textbar} , this does not represent a precursor to a seizure, and even if control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  were to enter orderline range  {\textbar} 588 {\textbar} , borderline range  {\textbar} 589 {\textbar} , critical range  {\textbar} 590 {\textbar} , or critical range  {\textbar} 591 {\textbar} , this condition would not represent a precursor to a seizure. At the point shown, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has deviated by an arbitrary amount from target value  {\textbar} 576 {\textbar} , at which point control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is activated to apply closed-loop feedback control to stabilize control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  and bring control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  into control range  {\textbar} 586 {\textbar} . {\textbar} This diagram shows the persistence of normal {EEG} signals, shown in (E {\textbar}   {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying controlled interictal period  {\textbar} 604 {\textbar} , accompanied by no neurological signs or symptoms  {\textbar} 600 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , within the control range  {\textbar} 586 {\textbar} . A single or multiplicity of additional states may be used without departing from the present invention. {\textbar} In  {\textbar}   {\textbar} {FIG}. 63 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the unperturbed state in which the control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) is initially {OFF} during uncontrolled interictal period  {\textbar} 607 {\textbar} , is subsequently activated and begins providing a continuous stabilizing influence on the nervous system during controlled interictal period  {\textbar} 608 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) is subsequently {OFF} in uncontrolled interictal period  {\textbar} 609 {\textbar} . {\textbar} The transition from control output  {\textbar}   {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) in the {OFF} state during uncontrolled interictal period  {\textbar} 605 {\textbar}  to the {ON} state during controlled interictal period  {\textbar} 606 {\textbar}  occurs at an arbitrary time and under normal conditions. In the diagram shown, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has deviated from arbitrarily defined control range  {\textbar} 586 {\textbar}  and is still within normal range  {\textbar} 587 {\textbar} . As has been shown in  {\textbar} {FIG}. 59 {\textbar} , this does not represent a precursor to a seizure, and even if control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  were to enter borderline range  {\textbar} 588 {\textbar} , borderline range  {\textbar} 589 {\textbar} , critical range  {\textbar} 590 {\textbar} , or critical range  {\textbar} 591 {\textbar} , this condition would not represent a precursor to a seizure. At the point shown, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has deviated by an arbitrary amount from target value  {\textbar} 576 {\textbar} , at which point control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is activated to apply closed-loop feedback control to stabilize control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  and bring control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  into control range  {\textbar} 586 {\textbar} . Once control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has been stabilized into an arbitrary range, such as control range  {\textbar} 586 {\textbar}  or other range, control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) is turned {OFF}, as shown in uncontrolled interictal period  {\textbar} 609 {\textbar} . The turning of control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) {OFF} is performed to conserve battery power, minimize electrical current induced tissue damage, minimize {pH} changes at the tissue-electrode interface, to further minimize neural habituation, which is itself a benefit of closed-loop feedback driven neuromodulation, and other benefits. {\textbar} This diagram shows the persistence of normal {EEG} signals, shown in (E {\textbar}   {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying controlled interictal period  {\textbar} 604 {\textbar} , accompanied by no neurological signs or symptoms  {\textbar} 600 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , within the control range  {\textbar} 586 {\textbar} . A single or multiplicity of additional states may be used without departing from the present invention. {\textbar} In  {\textbar}   {\textbar} {FIG}. 64 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights. This diagram shows normal {EEG} signals, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying uncontrolled baseline period  {\textbar} 610 {\textbar}  preceding the application of perturbation (P)  {\textbar} 990 {\textbar} , uncontrolled perturbation period  {\textbar} 611 {\textbar}  during the application of perturbation (P)  {\textbar} 990 {\textbar} , and uncontrolled post-perturbation period  {\textbar} 612 {\textbar}  following the application of perturbation (P)  {\textbar} 990 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , within normal range  {\textbar} 587 {\textbar} , and without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar} . Despite the application of perturbation (P)  {\textbar} 990 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , a measure of disease state, remains in normal range  {\textbar} 587 {\textbar} ; and corresponding elements of state (X)  {\textbar} 991 {\textbar}  remain in their corresponding normal ranges. {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . In a preferred embodiment for the treatment of seizures, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is a function of disentrainment of neural chaos, for which neural chaos is calculated using Lyapunov exponents, Kolmogorov entropy or other measure of chaos. Additional elements of state (X)  {\textbar} 991 {\textbar} , including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other elements of state (X)  {\textbar} 991 {\textbar}  and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} In  {\textbar}   {\textbar} {FIG}. 65 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights. This diagram shows normal {EEG} signals, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying uncontrolled baseline period  {\textbar} 610 {\textbar}  preceding the application of perturbation (P)  {\textbar} 990 {\textbar} , uncontrolled perturbation period  {\textbar} 611 {\textbar}  during the application of perturbation (P)  {\textbar} 990 {\textbar} , and uncontrolled post-perturbation period  {\textbar} 612 {\textbar}  following the application of perturbation (P)  {\textbar} 990 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of normal range  {\textbar} 587 {\textbar}  and into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar}  without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . In a preferred embodiment for the treatment of seizures, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is a function of disentrainment of neural chaos, for which neural chaos is calculated using Lyapunov exponents, Kolmogorov entropy or other measure of chaos. Additional elements of state (X)  {\textbar} 991 {\textbar}  may be used, including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other variables or constants and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary first within the normal range  {\textbar} 587 {\textbar}  and to have multiple excursions into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} . During this time, there are no episodes of {EEG} abnormalities  {\textbar} 599 {\textbar}  nor episodes of neurological signs or symptoms  {\textbar} 600 {\textbar} . Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , as well as corresponding elements of state (X)  {\textbar} 991 {\textbar} , exhibit excursions outside of normal range  {\textbar} 587 {\textbar} , and corresponding ranges likewise for elements of state (X)  {\textbar} 991 {\textbar} , and return to normal range  {\textbar} 587 {\textbar}  without event. {\textbar} In  {\textbar}   {\textbar} {FIG}. 66 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y)  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights, during which time the present invention is not activated and a seizure subsequently develops. {\textbar} This diagram shows {EEG} signals, (E {\textbar}   {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , which are initially normal during uncontrolled baseline period  {\textbar} 613 {\textbar} , preceding the application of perturbation (P)  {\textbar} 990 {\textbar} , and which remain normal during uncontrolled perturbation period  {\textbar} 614 {\textbar}  during the application of perturbation (P)  {\textbar} 990 {\textbar} , and remain normal for some time thereafter during uncontrolled post-perturbation period  {\textbar} 615 {\textbar}  following the application of perturbation (P)  {\textbar} 990 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of normal range  {\textbar} 587 {\textbar}  and into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar}  without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar}  during uncontrolled baseline period  {\textbar} 613 {\textbar} , uncontrolled perturbation period  {\textbar} 614 {\textbar} , and uncontrolled post-perturbation period  {\textbar} 615 {\textbar} . {\textbar} During the second excursion of control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  into critical range  {\textbar} 591 {\textbar} , {EEG} abnormalities  {\textbar} 599 {\textbar}  develop, shown in (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , defining the beginning of sustained organized paroxysmal discharge period  {\textbar} 616 {\textbar} , which is followed by the progression of {EEG} abnormalities  {\textbar} 599 {\textbar}  into clinical seizure  {\textbar} 617 {\textbar} , which is manifest by neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . In a preferred embodiment for the treatment of seizures, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is a function of disentrainment of neural chaos, for which neural chaos is calculated using Lyapunov exponents, Kolmogorov entropy or other measure of chaos. Additional elements of state (X)  {\textbar} 991 {\textbar}  may be used, including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other variables or constants and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary first within the normal range  {\textbar} 587 {\textbar}  and to have multiple excursions into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} . During the first such excursion, which occurs in uncontrolled post-perturbation period  {\textbar} 615 {\textbar} , there are no episodes of {EEG} abnormalities  {\textbar} 599 {\textbar}  nor episodes of neurological signs or symptoms  {\textbar} 600 {\textbar} . Sometime during the second such excursion into critical range  {\textbar} 591 {\textbar} , {EEG} abnormalities  {\textbar} 599 {\textbar}  develop, as seen during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar} . The {EEG} abnormalities  {\textbar} 599 {\textbar}  that appears during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar}  then progresses to involve a larger portion of the brain and is manifest as neurological signs or symptoms  {\textbar} 600 {\textbar}  which define the clinical seizure  {\textbar} 597 {\textbar} . Following clinical seizure  {\textbar} 597 {\textbar} , neurological signs or symptoms  {\textbar} 600 {\textbar}  cease and {EEG} abnormalities  {\textbar} 599 {\textbar}  cease; and this remains the case during uncontrolled interictal period  {\textbar} 618 {\textbar} . During and Following clinical seizure  {\textbar} 597 {\textbar} , Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , reflective of disease state, progressively moves back to normal range  {\textbar} 587 {\textbar} . {\textbar} In  {\textbar}   {\textbar} {FIG}. 67 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights. The present invention is shown continuously activated, producing control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  to provide a continuous stabilizing influence, and the potential for a neurological signs or symptoms  {\textbar} 600 {\textbar}  is prevented. Furthermore, the very potential for even a precursor, i.e. {EEG} abnormalities  {\textbar} 599 {\textbar} , is prevented, because the nervous system is prevented from entering a state in which such neurological signs or symptoms  {\textbar} 600 {\textbar}  or their precursors may develop and progress. Said neurological signs or symptoms  {\textbar} 600 {\textbar}  include but are not limited to a seizure, status epilepticus, headache, manic episode, depressive episode, anxiety episode, panic attack, rage episode, psychotic episode. {\textbar} In  {\textbar}   {\textbar} {FIG}. 68 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights. The present invention is shown conditionally activated, when control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  moves outside of control range, to resume the production of control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  to provide a continuous stabilizing influence and prevent the potential for a neurological signs or symptoms  {\textbar} 600 {\textbar}  or their precursors. There are no {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar}  present and no potential for them to occur at any point in this figure. {\textbar} This diagram shows {EEG} signals, (E {\textbar}   {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , which remain normal during uncontrolled baseline period  {\textbar} 622 {\textbar} , preceding the application of perturbation (P)  {\textbar} 990 {\textbar} , and which remain normal during uncontrolled perturbation period  {\textbar} 623 {\textbar}  during which time perturbation (P)  {\textbar} 990 {\textbar}  is applied, and remain normal thereafter during uncontrolled post-perturbation period  {\textbar} 624 {\textbar}  and controlled post-perturbation period  {\textbar} 625 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of control range  {\textbar} 586 {\textbar}  without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} When control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  moves outside of control range  {\textbar} 586 {\textbar}  but remains within normal range  {\textbar} 587 {\textbar} , then control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is delivered to maintain the nervous system in a stable state and thereby prevent even the possibility of undesirable neurological signs or symptoms  {\textbar} 600 {\textbar}  or their precursors, i.e. {EEG} abnormalities  {\textbar} 599 {\textbar} , from developing. The precise time of initiation of delivery of control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is somewhat arbitrary, as the action is taken no t in response to any event but as a measure to prevent a neural state, as quantified by control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , from exiting normal range  {\textbar} 587 {\textbar}  and progressing into a critical range  {\textbar} 591 {\textbar}  in which neurological signs or symptoms  {\textbar} 600 {\textbar}  may subsequently develop. {\textbar} By this action of control output  {\textbar}   {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar} , the very potential for even a precursor, i.e. {EEG} abnormalities  {\textbar} 599 {\textbar} , is prevented, because the nervous system is prevented from entering a state in which such neurological signs or symptoms  {\textbar} 600 {\textbar}  or their precursors may develop and progress. Said neurological signs or symptoms  {\textbar} 600 {\textbar}  include but are not limited to a seizure, status epilepticus, headache, manic episode, depressive episode, anxiety episode, panic attack, rage episode, psychotic episode. {\textbar} {SUMMARY} {\textbar}   {\textbar} In one preferred embodiment, the control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is calculated as a measure of disentrainment of neural chaos among regions of the nervous system. This representation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  then reflects degree of neural entrainment, which is inversely related to entrainment of neural chaos and synchronization of neural chaos. During normal interictal states, when no seizure or other neurological signs or symptoms  {\textbar} 600 {\textbar}  are present, the nervous system possesses a normal degree of neural entrainment, that is, the various neural regions exhibit some correlation in their level of chaos. A seizure occurs as a significant portion of neural tissue exhibits synchronization of activity. By minimizing neural entrainment and maximizing disentrainment, seizures and their precursors may be prevented. {\textbar} This is fundamentally different from and a dramatic improvement over the system described by but not enabled by Fischell U.S. Pat. No. 6,016,449. Fischell describes a system that detects and terminates a seizure. The patent then claims but does not enable a system to detect and terminate a precursor to a seizure, by detecting {EEG} thresholds. Precursors are not defined and their detection no described nor enabled. In either of these two cases of terminating seizures or precursors to seizures, the aberrant neural condition has already occurred and its progression t seizure is imminent and inevitable without intervention. At this point, terminating the process, which has already begun, is difficult and may not be possible. In the Fischell designs, an event detection signal is generated upon detection of a seizure or its precuror, in either case of which, progression to clinical seizure has begun or is imminent, as manifest by {EEG} abnormalities  {\textbar}   {\textbar} 599 {\textbar} . {\textbar} In contrast, the neurological control system  {\textbar}   {\textbar} 999 {\textbar}  taught in the present invention controls fundamental neural states, thereby preventing the development of neural states in which a seizure is even possible. By maintaining neural disentrainment within the normal range, seizures do not occur or are extremely unlikely. Certain pharmacological agents may have this effect as well, by preventing the nervous system from being able to initiate the process that culminates in a seizure. The present invention can continuously monitor and maintain a desired level of therapy, controlling desired neural states to remain within stable regions and out of regions in which neurological signs and symptoms may develop. Through the use of feedback control, the present invention insures that the appropriate neural states, including but not limited to the level of disentrainment of neural chaos, which is inversely related to synchronization of neural chaos and entrainment of neural chaos, remains within the normal range, preventing the nervous system from entering a state, which itself is free of any abnormalities or signs or symptoms, in which it is even possible to develop a seizure or other neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} Not only is a seizure prevented, the potential for a seizure is prevented. Furthermore, the potential for a precursor to a seizure is prevented. The present invention controls the degree of disentrainment of neural chaos as measured in at least one region of the brain. This degree of disentrainment, the quantification of which is embodied in control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , normally varies throughout the day. Certain external inputs, such as perturbations as well as medications, can alter this degree of disentrainment. If control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is maintained in normal range  {\textbar} 587 {\textbar} , the development of a precursors to a seizure, specifically {EEG} abnormalities  {\textbar} 599 {\textbar}  as manifest during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar} , are prevented. Neural state, as quantified in control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , varies overtime. Under certain conditions, i.e. when control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is in critical range  {\textbar} 591 {\textbar} , a seizure may possibly occur, but it is not predetermined to occur under this condition. Maintaining control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  outside of critical range  {\textbar} 591 {\textbar}  and preferably in normal range  {\textbar} 587 {\textbar}  and more preferably in a subset of normal range  {\textbar} 587 {\textbar}  labeled control range  {\textbar} 586 {\textbar}  prevents even the precursor, ie. {EEG} abnormalities  {\textbar} 599 {\textbar} , of a neurological signs or symptoms  {\textbar} 600 {\textbar}  from developing. The present invention prevents the nervous system from entering a state in which it is possible to have a seizure. The present invention monitors the degree of response to therapy and modulates therapy to maintain effect within the desired therapeutic range, i.e. control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  within control range  {\textbar} 586 {\textbar} . Under such conditions, no neurological signs or symptoms  {\textbar} 600 {\textbar}  occur. No precursors, i.e. {EEG} abnormalities  {\textbar} 599 {\textbar} , occur, since the present invention applies a continuous stabilizing influence to modulate the nervous system and thereby maintain it in a stable state. {CROSS} {REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar}   {\textbar} This application is a continuation of pending application Ser. No. 10/889,844, filed Jul. 12, 2004 now U.S. Pat. No. 7,231,254; which application claims benefit of U.S. Provisional Application No. 60/562,487, filed Apr. 14, 2004, and is a continuation-in-part of U.S. application Ser. No. 10/818,333, filed Apr. 5, 2004 now U.S. Pat. No. 7,277,758, which, in turn, claims benefit of U.S. Provisional Application No. 60/460,140, filed Apr. 3, 2003; U.S. application Ser. No. 10/818,333 is also a continuation-in-part of U.S. application Ser. No. 10/753,205, filed Jan. 6, 2004 now U.S. Pat. No. 7,242,984, which claims the benefit of U.S. Provisional Application No. 60/438,286, filed Jan. 6, 2003; U.S. application Ser. No. 10/753,205 is also a continuation-in-part of U.S. application Ser. No. 10/718,248, filed Nov. 20, 2003 now U.S. Pat. No. 7,209,787; which is a continuation-in-part of U.S. application Ser. No. 10/008,576, filed Nov. 11, 2001, now U.S. Pat. No. 6,819,956; which is a continuation-in-part of U.S. application Ser. No. 09/340,326, filed Jun. 25, 1999, now U.S. Pat. No. 6,366,813; which claims the benefit of U.S. Provisional Application No. 60/095,413, filed Aug. 5, 1998; U.S. application Ser. No. 10/718,248 also claims benefit of U.S. Provisional Application Nos. 60/427,699, filed Nov. 20, 2002, and 60/436,792, filed Dec. 27, 2002. {\textbar}   {\textbar} {BACKGROUND} {OF} {THE} {INVENTION} {\textbar}   {\textbar} 1. Field of the Invention {\textbar}   {\textbar} The present invention relates generally to neurological disease and, more particularly, to intracranial stimulation for optimal control of movement disorders and other neurological disease. {\textbar}   {\textbar} 2. Related Art {\textbar}   {\textbar} There are a wide variety of treatment modalities for neurological disease including movement disorders such as Parkinson's disease, Huntington's disease, and Restless Leg Syndrome, as well as psychiatric disease including depression, bipolar disorder and borderline personality disorders. These treatment modalities are moderately efficacious; however, they suffer from several severe drawbacks. Each of these traditional treatment modalities and their associated limitations are described below. {\textbar}   {\textbar} One common conventional technique for controlling neurological disease includes the use of dopaminergic agonists or anticholinergic agents. Medical management using these techniques requires considerable iteration in dosing adjustments before an “optimal” balance between efficacy and side effect minimization is achieved. Variation, including both circadian and postprandial variations, causes wide fluctuation in symptomatology. This commonly results in alternation between “on” and “off” periods during which the patient possesses and loses motor functionality, respectively. {\textbar}   {\textbar} Another traditional approach for controlling movement disorders is tissue ablation. Tissue ablation is most commonly accomplished through stereotactic neurosurgical procedures, including pallidotomy, thalamotomy, subthalamotomy, and other lesioning procedures. These procedures have been found to be moderately efficacious. However, in addition to posing risks that are inherent to neurosurgical operations, these procedures suffer from a number of fundamental limitations. One such limitation is that tissue removal or destruction is irreversible. As a result, excessive or inadvertent removal of tissue cannot be remedied. {\textbar}   {\textbar} Furthermore, undesirable side effects, including compromise of vision and motor or sensory functions, are likely to be permanent conditions. In particular, bilateral interventions place the patient at considerable risk for developing permanent neurologic side effects, including incontinence, aphasia, and grave psychic disorders. An additional drawback to this approach is that the “magnitude” of treatment is constant. That is, it is not possible to vary treatment intensity over time, as may be required to match circadian, postprandial, and other fluctuations in symptomatology and consequent therapeutic needs. Thus, decrease in treatment “magnitude” is not possible while an increase in treatment “magnitude” necessitates reoperation. Some adjustment is possible through augmentation with pharmacologic treatment; however, these additional treatments are subject to the above-noted limitations related to drug therapy. {\textbar}   {\textbar} Another traditional approach for controlling movement disorders and other neurological disease includes tissue transplantation, typically from animal or human mesencephalic cells. Although tissue transplantation in humans has been performed for many years, it remains experimental and is limited by ethical concerns when performed using a human source. Furthermore, graft survival, as well as subsequent functional connection with intracranial nuclei, are problematic. The yield, or percentage of surviving cells, is relatively small and is not always predictable, posing difficulties with respect to the control of treatment “magnitude.” {\textbar}   {\textbar} Another traditional approach for controlling neurological disease is the continuous electrical stimulation of a predetermined neurological region. Chronic high frequency intracranial electrical stimulation is typically used to inhibit cellular activity in an attempt to functionally replicate the effect of tissue ablation, such as pallidotomy and thalamotomy. Acute electrical stimulation and electrical recording and impedance measuring of neural tissue have been used for several decades in the identification of brain structures for both research purposes as well as for target localization during neurosurgical operations for a variety of neurological diseases. During intraoperative electrical stimulation, reduction in tremor has been achieved using frequencies typically on the order of 75 to 330 Hz. Based on these findings, chronically implanted constant-amplitude electrical stimulators have been implanted in such sites as the thalamus, subthalamic nucleus and globus pallidus. {\textbar}   {\textbar} Chronic constant-amplitude stimulation has been shown to be moderately efficacious. However, it has also been found to be limited by the lack of responsiveness to change in patient system symptomatology and neuromotor function. Following implantation, a protracted phase of parameter adjustment, typically lasting several weeks to months, is endured by the patient while stimulation parameters are interactively adjusted during a series of patient appointments. Once determined, an “acceptable” treatment magnitude is maintained as a constant stimulation level. A drawback to this approach is that the system is not responsive to changes in patient need for treatment. Stimulation is typically augmented with pharmacological treatment to accommodate such changes, causing fluctuation of the net magnitude of treatment with the plasma levels of the pharmacologic agent. {\textbar}   {\textbar} As noted, while the above and other convention treatment modalities offer some benefit to patients with movement disorders, their efficacy is limited. For the above-noted reasons, with such treatment modalities it is difficult and often impossible to arrive at an optimal treatment “magnitude,” that is, an optimal dose or intensity of treatment. Furthermore, patients are subjected to periods of overtreatment and undertreatment due to variations in disease state. Such disease state variations include, for example, circadian fluctuations, postprandial (after meal) and nutrition variations, transients accompanying variations in plasma concentrations of pharmacological agents, chronic progression of disease, and others. {\textbar}   {\textbar} Moreover, a particularly significant drawback to the above and other traditional treatment modalities is that they suffer from inconsistencies in treatment magnitude. For example, with respect to drug therapy, a decrease in responsiveness to pharmacologic agents eventually progresses to eventually preclude effective pharmacologic treatment. With respect to tissue ablation, progression of disease often necessitates reoperation to extend pallidotomy and thalamotomy lesion dimensions. Regarding tissue transplantation, imbalances between cell transplant formation rates and cell death rates cause unanticipated fluctuations in treatment magnitude. For continuous electrical stimulation, changes in electrode position, electrode impedance, as well as patient responsiveness to stimulation and augmentative pharmacologic agents, cause a change in response to a constant magnitude of therapy. {\textbar}   {\textbar} Currently, magnets commonly serve as input devices used by patients with implantable stimulators, including deep brain stimulators, pacemakers, and spinal cord stimulators. Current systems require the patient to manually turn the system off at night time to conserve battery power and use such magnets to maintain system power. This presents considerable difficulty to many patients whose tremor significantly impairs arm function, as they are unable to hold a magnet in a stable manner over the implanted electronics module. Consequently, many patients are unable to turn their stimulators on in the morning without assistance. {\textbar}   {\textbar} What is needed, therefore, is an apparatus and method for treatment of patients with neurological disease in general and movement disorders in particular that is capable of determining and providing an optimal dose or intensity of treatment. Furthermore, the apparatus and method should be responsive to unpredictable changes in symptomatology and minimize alternations between states of overtreatment and undertreatment. The system should also be capable of anticipating future changes in symptomatology and neuromotor functionality, and being responsive to such changes when they occur. {\textbar}   {\textbar} {SUMMARY} {OF} {THE} {INVENTION} {\textbar}   {\textbar} One aspect of the invention is a method of monitoring a subject's response to a plurality of neuromodulation therapies. The method comprises delivering a neuromodulation therapy that is adapted to prevent and/or manage a symptom of a subject suffering from a neurological or psychiatric disorder, wherein the neuromodulation therapy is specified by a set of parameters, recording the set of parameters of the neuromodulation therapy and a subject's response to the neuromodulation therapy, delivering a subsequent neuromodulation therapy to the subject, wherein at least one parameter of the set of parameters of the subsequent neuromodulation therapy is automatically changed relative to the set of parameters of the previously delivered neuromodulation therapy, and recording the set of parameters of the subsequent neuromodulation therapy and a subject's response to the subsequent neuromodulation therapy. {\textbar}   {\textbar} In some embodiments the symptom comprises seizure activity and the neurological disorder comprises epilepsy. {\textbar}   {\textbar} In some embodiments recording the set of parameters of the neuromodulation therapy and the subject's response to the neuromodulation therapy and recording the set of parameters of the subsequent neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy are performed in a memory in an implantable neuromodulation system. The method can further include wirelessly transmitting data that is indicative of the recorded parameters of the neuromodulation therapy and the subject's response to the neuromodulation therapy and data that is indicative of the recorded set of parameters of the subsequent neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy from the memory of the implanted neuromodulation system to a memory of an external device that is external to the subject's body. {\textbar}   {\textbar} In some embodiments the method also includes analyzing the data that is indicative of the subject's response to the neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy to determine a substantially optimal set of parameters for a later delivered neuromodulation therapy. The neuromodulation therapy and the subsequent neuromodulation therapy can be delivered to the subject using an implantable neuromodulation system. In some embodiments the method further comprises wirelessly programming the implantable neuromodulation system with the determined optimal parameters, while in some embodiments the implantable neuromodulation system is automatically programmed to use the substantially optimal set of stimulation parameters for a later delivered neuromodulation therapy. {\textbar}   {\textbar} In some embodiments the method also includes analyzing the subject's response to the neuromodulation therapy and subject's response to the subsequent neuromodulation therapy to determine efficacy of the neuromodulation therapy and efficacy of the subsequent neuromodulation therapy. {\textbar}   {\textbar} In some embodiments the method also includes wirelessly transmitting data that is indicative of the set of parameters of the neuromodulation therapy and the subject's response to the neuromodulation therapy and data that is indicative of the set of parameters of the subsequent neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy from an implantable neuromodulation system to a memory of a device external to the subject's body, where recording the parameters of the neuromodulation therapy and the subject's response to the neuromodulation therapy and recording the parameters of the subsequent neuromodulation therapy and the subject's response to the subsequent neuromodulation therapy are performed in the memory of the device external to the subject's body. {\textbar}   {\textbar} In some embodiments the neuromodulation therapy comprises electrical stimulation delivered via electrodes and the set of parameters comprises at least one of electrode configuration, stimulation current, stimulation voltage, stimulation frequency, pulse width, frequency of pulses within a burst, pulses per burst, frequency of bursts, duration of bursts, and pulse train count. {\textbar}   {\textbar} In some embodiments the neuromodulation therapy comprises intracranial electrical stimulation. In some embodiments the neuromodulation therapy comprises peripheral nerve electrical stimulation such as vagus nerve electrical stimulation. {\textbar}   {\textbar} In some embodiments the neuromodulation therapy comprises delivery of medications. Delivery of medications can be performed with an implanted medication dispenser. {\textbar}   {\textbar} In some embodiments the neuromodulation therapy and subsequent neuromodulation therapy(ies) are delivered when the symptom is detected and/or predicted through analysis of an {EEG} signal from the subject. {\textbar}   {\textbar} In some embodiments the subject's response comprises a brain activity response that is monitored with one or more brain electrodes that are in communication with the implantable neuromodulation system. {\textbar}   {\textbar} Another aspect of the invention is a method of determining patient-specific, substantially optimal stimulation parameters of a stimulation signal for managing a patient with epilepsy. The method includes analyzing an {EEG} signal from a patient to detect and/or predict seizure activity, delivering a first stimulation signal to the patient with an implanted stimulation and recording unit when the analysis of the {EEG} signal detects and/or predicts seizure activity, wherein the stimulation signal comprises a set of stimulation parameters, recording the patient's response to the first stimulation signal, automatically determining parameters for a second stimulation signal, wherein the second stimulation signal comprises at least one changed parameter from the set of predetermined stimulation parameters of the first stimulation signal, delivering the second stimulation signal with the implanted stimulation and recording unit when analysis of the {EEG} signal from the patient detects and/or predicts subsequent seizure activity, recording the patient's response to the second stimulation signal, wirelessly transmitting data that is indicative of the patient's response to the first stimulation signal, the set of parameters of the first stimulation signal, response to the second stimulation signal, and set of parameter of the second stimulation signal to a device that is external to the patient's body, analyzing the patient's response to the first stimulation signal and response to the second stimulation signal to determine substantially optimal stimulation parameters, and programming the implanted stimulation and recording unit with the determined substantially optimal stimulation parameters. {\textbar}   {\textbar} Another aspect of the invention is a system for delivering a neural modulation output to a subject suffering from a neurological or psychiatric disorder. The system includes an assembly adapted to acquire a signal from a subject that is indicative or predictive of a symptom of the neurological or psychiatric disorder and to deliver a neural modulation output to the subject to manage and/or prevent the symptom of the neurological or psychiatric disorder, an implantable device coupled to the assembly, the implantable device configured to automatically sweep through a plurality of neural modulation outputs that comprise different sets of neural modulation parameters, and a memory that is adapted to store the different sets of stimulation parameters and the subject's response to the neural modulation outputs that comprise different sets of neural modulation parameters. {\textbar}   {\textbar} In some embodiments the neurological disorder comprises epilepsy and the symptom comprises seizure activity. {\textbar}   {\textbar} In some embodiments the memory is disposed in an external device and the system further comprises the external device that is configured to be external to the subject's body and is in wireless communication with the implantable device, the wireless communication being used to transmit the different sets of neural modulation parameters and the subject's response to the neural modulation outputs that comprise different sets of neural modulation outputs from the implantable device to the memory of the external device. At least one of the external device and implantable device can be configured to analyze the subject's response to the neural modulation outputs that comprise different sets of neural modulation parameters to determine efficacy of the neural modulation outputs. The implantable device can sweep through the different sets of neural modulation parameters to determine substantially optimal neural modulation parameters of the neural modulation output to treat the subject's neurological or psychiatric disorder. {\textbar}   {\textbar} In some embodiments the substantially optimal neural modulation parameters are manually programmed by a user using an external device that is in wireless communication with the implantable device. In other embodiments the implantable device is programmed to automatically use the substantially optimal neural modulation parameters for later delivered neural modulation outputs. {\textbar}   {\textbar} In some embodiments the neural modulation output comprises electrical stimulation and the assembly comprises a plurality of electrodes, wherein the neural modulation parameters comprise at least one of electrode configuration, stimulation current, stimulation voltage, stimulation frequency, pulse width, frequency of pulses within a burst, pulses per burst, frequency of bursts, duration of bursts, and pulse train count. {\textbar}   {\textbar} In some embodiments the assembly comprises a plurality of electrodes, wherein a subset of electrodes are configured to acquire the physiological signals and a subset of electrodes are configured to deliver the neural modulation output. {\textbar}   {\textbar} In some embodiments the neuromodulation output comprises intracranial electrical stimulation. In some embodiments the neuromodulation output comprises peripheral nerve electrical stimulation such as vagus nerve electrical stimulation. {\textbar}   {\textbar} In some embodiments the neuromodulation output comprises delivery of medications. {\textbar}   {\textbar} Further features and advantages of the present invention, as well as the structure and operation of various embodiments of the present invention, are described in detail below with reference to the accompanying drawings. {\textbar}   {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar}   {\textbar} The present invention is described with reference to the accompanying drawings. In the drawings, like reference numerals indicate identical or functionally similar elements. {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention implanted bilaterally in a human patient. {\textbar} {FIG}. 2 {\textbar}   {\textbar}  is an architectural block diagram of one embodiment of the neurological control system of the present invention. {\textbar} {FIG}. 3 {\textbar}   {\textbar}  is a block diagram of one embodiment of an intracranial recording electrode ({ICRE}) signal processor and an intracranial stimulating electrode ({ICSE}) signal processor each of which are included within the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 4 {\textbar}   {\textbar}  is a schematic diagram of a globus pallidus implanted with stimulating and recording electrodes in accordance with one embodiment of the present invention. {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a block diagram of one embodiment of an {EMG} signal processor that is included in one embodiment of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 6 {\textbar}   {\textbar}  is a block diagram of one embodiment of an {EEG} signal processor module that is included in one embodiment of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 7 {\textbar}   {\textbar}  is a block diagram of one embodiment of an accelerometer signal processor that is incorporated into certain embodiments of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 8 {\textbar}   {\textbar}  is a block diagram of one embodiment of an acoustic signal processor that is included in certain embodiments of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 9 {\textbar}   {\textbar}  is block diagram of one embodiment of a peripheral nerve electrode ({PNE}) signal processor  {\textbar} 237 {\textbar}  that is implemented in certain embodiments of signal processor  {\textbar} 71 {\textbar} . {PNE} signal {\textbar} {FIG}. 10 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the signal processor illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 11 {\textbar}   {\textbar}  is a schematic diagram of the patient-neural modulator system illustrated in  {\textbar} {FIG}. 2 {\textbar}  illustrated to show its controller and observer components. {\textbar} {FIG}. 12 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the control circuit illustrated in  {\textbar} {FIG}. 2 {\textbar} . {\textbar} {FIG}. 13 {\textbar}   {\textbar}  is a schematic diagram of electrical stimulation waveforms for neural modulation. {\textbar} {FIG}. 14 {\textbar}   {\textbar}  is a schematic diagram of one example of the recorded waveforms. {\textbar} {FIG}. 15 {\textbar}   {\textbar}  is a schematic block diagram of an analog switch used to connect one or an opposing polarity pair of Zener diodes across the noninverting and inverting inputs of an intracranial recording electrode amplifier. {\textbar} {FIG}. 16 {\textbar}   {\textbar}  is a diagram of a two coil embodiment of the power delivery unit. {\textbar} {FIG}. 17 {\textbar}   {\textbar}  is a magnification of the configurations of  {\textbar} {FIGS}. 16 and 18 {\textbar}  showing the magnetic flux penetrating the skin. {\textbar} {FIG}. 18 {\textbar}   {\textbar}  is a diagram of a three coil embodiment of the power delivery unit. {\textbar} {FIG}. 19 {\textbar}   {\textbar}  is a diagram of the power delivery unit with coil holder. {\textbar} {FIG}. 20 {\textbar}   {\textbar}  is a diagram of the coil holder. {\textbar} {FIG}. 21 {\textbar}   {\textbar}  is a diagram of the electromagnetic copies in proximity to the head of a patient. {\textbar} {FIG}. 22 {\textbar}   {\textbar}  is a diagram of multiple coil embodiments. {\textbar} {FIG}. 23 {\textbar}   {\textbar}  is a diagram of the paracranial design, with implanted components in close proximity to the patient's head. {\textbar} {FIG}. 24 {\textbar}   {\textbar}  is a diagram of the power conversion unit that includes the electromagnetic coupling element. {\textbar} {FIG}. 25 {\textbar}   {\textbar}  is a diagram of the power conversion circuit. {\textbar} {FIG}. 26 {\textbar}   {\textbar}  is a diagram of the overall system. {\textbar} {FIG}. 27 {\textbar}   {\textbar}  is a diagram of the stimulating and recording unit. {\textbar} {FIG}. 28 {\textbar}   {\textbar}  is a diagram of the system enclosure secured to the calvarium. {\textbar} {FIG}. 29 {\textbar}   {\textbar}  is a diagram of a lower profile design. {\textbar} {FIG}. 30 {\textbar}   {\textbar}  is a diagram of a lower profile design with the system enclosure partially recessed into the calvarium. {\textbar} {FIG}. 31 {\textbar}   {\textbar}  is a diagram of a lower profile design with the system enclosure fully recessed into the calvarium. {\textbar} {FIG}. 32 {\textbar}   {\textbar}  is a diagram of a second lower profile design with the system enclosure fully recessed into the calvarium. {\textbar} {FIG}. 33 {\textbar}   {\textbar}  is a diagram of a neurological control system. {\textbar} {FIG}. 34 {\textbar}   {\textbar}  is a diagram of a second neurological control system. {\textbar} {FIG}. 35 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention implanted unilaterally in a human patient, with the system enclosure recessed in the calvarium, shown as a lateral view. {\textbar} {FIG}. 36 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention implanted unilaterally in a human patient, with the system enclosure recessed in the calvarium, shown as a anteroposterior view. {\textbar} {FIG}. 37 {\textbar}   {\textbar}  is a schematic diagram of a cross section of calvarium with system enclosure shown implanted recessed within the calvarium. {\textbar} {FIG}. 38 {\textbar}   {\textbar}  is a schematic diagram of a cross section of calvarium with drill bit shown in place after completion of process of drilling hole in calvarium. {\textbar} {FIG}. 39 {\textbar}   {\textbar}  is a schematic diagram of a cross section of calvarium with drill bit, with a penetration detection release mechanism, shown in place after completion of process of drilling hole in calvarium. {\textbar} {FIG}. 40 {\textbar}   {\textbar}  is a diagram depicting the path of the intracranial catheter and its connection to the electrical elements. {\textbar} {FIG}. 41 {\textbar}   {\textbar}  depicts one design for the system enclosure for implantation in the calvarium. {\textbar} {FIGS}. 42 and 43 {\textbar}   {\textbar}  depict a dual intracranial catheter design. {\textbar} {FIG}. 44 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention implanted bilaterally in a human patient. {\textbar} {FIG}. 45 {\textbar}   {\textbar}  is a schematic diagram, lateral view, of one embodiment of the present invention implanted unilaterally in a human patient. {\textbar} {FIG}. 46 {\textbar}   {\textbar}  is a schematic diagram, anteroposterior view, of one embodiment of the present invention implanted unilaterally in a human patient, with multiple catheters and neuromodulators. {\textbar} {FIG}. 47 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the present invention, depicting a set of noninvasive and implanted sensors and neuromodulators in a human patient. {\textbar} {FIG}. 48 {\textbar}   {\textbar}  is a schematic diagram of the dermatomal distributions recruited by neuromodulators. {\textbar} {FIG}. 49 {\textbar}   {\textbar}  is a schematic diagram of a noninvasive version of neurological control system, with sensors and neuromodulators overlying dermatomal distributions recruited by neuromodulators. {\textbar} {FIG}. 50 {\textbar}   {\textbar}  is a functional block diagram of neurological control system, with sensors and neuromodulators implanted in the temporal lobe. {\textbar} {FIG}. 51 {\textbar}   {\textbar}  is a functional block diagram of neurological control system, with sensors and neuromodulators implanted a multiplicity of locations, including the temporal lobe and deep brain regions. {\textbar} {FIG}. 52 {\textbar}   {\textbar}  is a functional block diagram of neurological control system, with sensors and neuromodulators implanted a multiplicity of locations, including the temporal lobe and deep brain regions, showing control input and control output waveforms versus time. {\textbar} {FIG}. 53 {\textbar}   {\textbar}  is a functional block diagram of neurological control system, with sensors and neuromodulators implanted a multiplicity of locations, including the temporal lobe and deep brain regions, showing control input and control output waveforms versus time. {\textbar} {FIG}. 54 {\textbar}   {\textbar}  is a timing diagram showing control input and control output waveforms versus time along with five representative elements of neural state vector X over time, during which time control input deviates outside target range. {\textbar} {FIG}. 55 {\textbar}   {\textbar}  is a timing diagram showing control input and control output waveforms versus time along with five representative elements of neural state vector X over time, during which time control input remains within target range. {\textbar} {FIG}. 56 {\textbar}   {\textbar}  is a timing diagram showing control input and control output waveforms versus time along with five representative elements of neural state vector X over time, during which time control input remains within target range, under conditions with and without the application of a perturbation. {\textbar} {FIG}. 57 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with five representative elements of neural state vector X over time, during which time control input remains within target range, under conditions with and without the application of a perturbation. {\textbar} {FIG}. 58 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input remains within normal range, under conditions without the application of a perturbation. Closed-loop neuromodulation control is turned on for a duration during which time control input is more tightly maintained in control range, a subset of normal range. {\textbar} {FIG}. 59 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input deviates outside normal range into borderline range and into critical range, under conditions without the application of a perturbation. Closed-loop neuromodulation control remains off, and there are no {EEG} abnormalities nor neurological sings or symptoms. {\textbar} {FIG}. 60 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input deviates outside normal range into borderline range and into critical range, under conditions without the application of a perturbation. Closed-loop neuromodulation control remains off, and {EEG} abnormalities develop and are followed by neurological sings or symptoms. {\textbar} {FIG}. 61 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input remains within normal range, under conditions without the application of a perturbation. Closed-loop neuromodulation control remains on, and there are no {EEG} abnormalities nor neurological sings or symptoms. {\textbar} {FIG}. 62 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input deviates outside normal range and closed-loop neuromodulation control is turned on, bringing control input back into control range, which is a subset of normal range. There are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 63 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time control input deviates outside normal range and closed-loop neuromodulation control is turned on, bringing control input back into control range, which is a subset of normal range, following which time closed-loop neuromodulation control is turned back off. There are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 64 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input decreases but remains inside normal range. Closed-loop neuromodulation control remains off, and there are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 65 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input deviates outside normal range into borderline range and critical range and then returns spontaneously to normal range. Closed-loop neuromodulation control remains off, and there are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 66 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input deviates outside normal range into borderline range and critical range, then back into borderline range and normal range and again into borderline range and critical range, following which {EEG} abnormalities develop and which are followed by neurological sings or symptoms. Closed-loop neuromodulation control remains off during this time. {\textbar} {FIG}. 67 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input decreases but remains inside control range, which is a subset of normal range. Closed-loop neuromodulation control remains on, and there are no {EEG} abnormalities nor neurological sings or symptoms during this time. {\textbar} {FIG}. 68 {\textbar}   {\textbar}  is a timing diagram showing {EEG} waveforms, control input and control output waveforms versus time along with one representative element of neural state vector X over time, during which time a perturbation is applied and control input deviates outside control range yet remains within normal range. Closed-loop neuromodulation control is turned on, and control input is brought back within control range. Control input remains within normal range and there are no {EEG} abnormalities nor neurological signs or symptoms during this time. {\textbar} {DETAILED} {DESCRIPTION} {\textbar}   {\textbar} {FIG}. 1 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the intracranial stimulator of the present invention implanted bilaterally in a human patient. In the embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , two neurological control systems  {\textbar} 999 {\textbar}  are shown implanted bilaterally. Each system  {\textbar} 999 {\textbar}  includes a stimulating and recording unit  {\textbar} 26 {\textbar}  and one or more intracranial components described below. As described in this illustrative embodiment, the intracranial components preferably include a stimulating electrode array  {\textbar} 37 {\textbar} . However, it should become apparent to those of ordinary skill in the relevant art after reading the present disclosure that the stimulating electrodes may also be extracranial; that is, attached to a peripheral nerve in addition to or in place of being located within the cranium. As shown in  {\textbar} {FIG}. 1 {\textbar} , stimulating and recording unit  {\textbar} 26 {\textbar}  of each neurological control system  {\textbar} 999 {\textbar}  is preferably implanted contralateral to the intracranial components of the device. {\textbar} As one skilled in the relevant art would find apparent from the following description, the configuration illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar}  is just one example of the present invention. Many other configurations are contemplated. For example, in alternative embodiments of the present invention, the stimulating and recording unit  {\textbar} 26 {\textbar}  is implanted ipsilateral or bilateral to the intracranial components. It should also be understood that the stimulating and recording unit  {\textbar} 26 {\textbar}  can receive ipsilateral, contralateral or bilateral inputs from sensors and deliver ipsilateral, contralateral, or bilateral outputs to a single or a plurality of intracranial stimulating electrode arrays  {\textbar} 37 {\textbar} . Preferably, these inputs are direct or preamplified signals from at least one of {EMG} electrode array  {\textbar} 50 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , Accelerometer Array  {\textbar} 52 {\textbar} , Acoustic Transducer Array  {\textbar} 53 {\textbar} , Peripheral Nerve Electrode Array  {\textbar} 54 {\textbar} , and Intracranial Recording Electrode Array  {\textbar} 38 {\textbar} . The signals input from these sensors will be referred to herein as “sensory input modalities”  {\textbar} 247 {\textbar} . The outputs include but are not limited to one or more stimulating current signals or stimulating voltage signals to Intracranial Stimulating Electrode Array  {\textbar} 37 {\textbar} . {\textbar} In the embodiment illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , the two unilateral systems  {\textbar} 26 {\textbar}  are shown to receive sensory inputs from the side contralateral as well as the intracranial stimulating electrode arrays  {\textbar} 37 {\textbar} . In the illustrative embodiment, systems  {\textbar} 26 {\textbar}  also receive sensory inputs from intracranial recording electrode arrays  {\textbar} 38 {\textbar} . As will become apparent from the following description, intracranial recording electrode arrays  {\textbar} 38 {\textbar}  may provide valuable feedback information. {\textbar} It should be understood that this depiction is for simplicity only, and that any combination of ipsilateral, contralateral or bilateral combination of each of the multiple sensory input modalities and multiple stimulation output channels may be employed. In addition, stimulating and recording units  {\textbar}   {\textbar} 26 {\textbar}  may be a single device, two communicating devices, or two independent devices. Accordingly, these and other configurations are considered to be within the scope of the present invention. It is anticipated that stimulating and recording units  {\textbar} 26 {\textbar} , if implemented as distinct units, would likely be implanted in separate procedures (soon after clinical introduction) to minimize the likelihood of drastic neurological complications. {\textbar} In the exemplary embodiment illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , the intracranial stimulating electrode array  {\textbar} 37 {\textbar}  includes a plurality of intracranial stimulating electrodes  {\textbar} 1 {\textbar} ,  {\textbar} 2 {\textbar} ,  {\textbar} 3 {\textbar}  and  {\textbar} 4 {\textbar} . Array  {\textbar} 37 {\textbar}  may, of course, have more or fewer electrodes than that depicted in  {\textbar} {FIG}. 1 {\textbar} . These intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar}  may be used to provide stimulation to a predetermined nervous system component. The electrical stimulation provided by the intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar}  may be excitatory or inhibitory, and this may vary in a manner which is preprogrammed, varied in real-time, computed in advance using a predictive algorithm, or determined using another technique now or latter developed. {\textbar} The intracranial recording electrode arrays  {\textbar}   {\textbar} 38 {\textbar}  includes intracranial recording electrodes  {\textbar} 5 {\textbar}  and  {\textbar} 6 {\textbar} . In accordance with one embodiment of the present invention, the intracranial recording electrodes  {\textbar} 5 {\textbar} ,  {\textbar} 6 {\textbar}  are used to record cortical activity as a measure of response to treatment and as a predictor of impeding treatment magnitude requirements. In the illustrative embodiment, intracranial recording electrodes  {\textbar} 5 {\textbar}  and  {\textbar} 6 {\textbar}  are depicted in a location superficial to the intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar} . However, this positioning may be reversed or the intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar}  and intracranial recording electrodes  {\textbar} 5 {\textbar}  and  {\textbar} 6 {\textbar}  may be interspersed in alternative embodiments. For example, these electrodes may be placed in at least one of motor cortex, premotor cortex, supplementary motor cortex, other motor cortical areas, somatosensory cortex, other sensory cortical areas, Wernicke's area, Broca's area, other cortical region, other intracranial region, and other extracranial region. {\textbar} In the illustrative embodiment, an intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  is provided to mechanically support and facilitate electrical connection between intracranial and extracranial structures. In this embodiment, intracranial catheter  {\textbar} 7 {\textbar}  contains one or more wires connecting extracranial stimulating and recording circuit  {\textbar} 26 {\textbar}  to the intracranial electrodes, including but not limited to, intracranial stimulating electrodes  {\textbar} 14 {\textbar}  and intracranial recording electrodes  {\textbar} 5 {\textbar} ,  {\textbar} 6 {\textbar} . The wires contained within intracranial catheter  {\textbar} 7 {\textbar}  transmit stimulating electrode output signal ({SEOS}) to intracranial stimulating electrode array  {\textbar} 37 {\textbar} . Such wires additionally transmit stimulating electrode input signal ({SEIS}) and recording electrode input signal ({REIS}), from intracranial stimulating electrode array  {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar}  respectively, to stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} Stimulating and recording circuit  {\textbar}   {\textbar} 26 {\textbar}  is protected within a circuit enclosure  {\textbar} 44 {\textbar} . Circuit enclosure  {\textbar} 44 {\textbar}  and contained components, including stimulating and recording circuit  {\textbar} 26 {\textbar}  comprise stimulating and recording unit  {\textbar} 43 {\textbar} . It should be understood that more or fewer of either type of electrode as well as additional electrode types and locations may be incorporated or substituted without departing from the spirit of the present invention. Furthermore, stimulating and recording circuit  {\textbar} 26 {\textbar}  can be placed extra cranially in a subclavian pocket as shown in  {\textbar} {FIG}. 1 {\textbar} , or it may be placed in other extracranial or intracranial locations. {\textbar} Connecting cable  {\textbar}   {\textbar} 8 {\textbar}  generally provides electrical connection between intracranial or intracranial locations. A set of electrical wires provides the means for communication between the intracranial and extracranial components; however, it should be understood that alternate systems and techniques such as radiofrequency links, optical (including infrared) links with transcranial optical windows, magnetic links, and electrical links using the body components as conductors, may be used without departing from the present invention. Specifically, in the illustrative embodiment, connecting cable  {\textbar} 8 {\textbar}  provides electrical connection between intracranial components  {\textbar} 246 {\textbar}  and stimulating and recording circuit  {\textbar} 26 {\textbar} . In embodiments wherein stimulating and recording circuit  {\textbar} 26 {\textbar}  has an intracranial location, connecting cable  {\textbar} 8 {\textbar}  would likely be entirely intracranial. Alternatively, connecting in embodiments wherein stimulating and recording circuit  {\textbar} 26 {\textbar}  is implanted under scalp  {\textbar} 10 {\textbar}  or within or attached to calvarium  {\textbar} 9 {\textbar} , connecting cable  {\textbar} 8 {\textbar}  may be confined entirely to subcutaneous region under the scalp  {\textbar} 10 {\textbar} . {\textbar} A catheter anchor  {\textbar}   {\textbar} 29 {\textbar}  provides mechanical connection between intracranial catheter  {\textbar} 7 {\textbar}  and caldarium  {\textbar} 9 {\textbar} . Catheter anchor  {\textbar} 29 {\textbar}  is preferably deep to the overlying scalp  {\textbar} 10 {\textbar} . Such a subcutaneous connecting cable  {\textbar} 8 {\textbar}  provides electrical connection between intracranial electrodes  {\textbar} 246 {\textbar}  and stimulating and recording circuit  {\textbar} 26 {\textbar} . Cable  {\textbar} 8 {\textbar}  may also connect any other sensors, including but not limited to any of sensory input modalities  {\textbar} 247 {\textbar} , or other stimulating electrodes, medication dispensers, or actuators with stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} Sensory feedback is provided to recording and stimulating unit  {\textbar}   {\textbar} 26 {\textbar}  from a multiplicity of sensors, collectively referred to as sensory input modalities  {\textbar} 247 {\textbar} . Intracranial recording electrode array  {\textbar} 38 {\textbar} , previously described, is intracranial in location. Additional sensors, most of which are located extracranially in the preferred embodiment, comprise the remainder of sensory input modalities  {\textbar} 247 {\textbar} . Sensory input modalities  {\textbar} 247 {\textbar}  provide information to stimulating and recording unit  {\textbar} 26 {\textbar} . As will be described in greater detail below, such information is processed by stimulating and recording unit  {\textbar} 26 {\textbar}  to deduce the disease state and progression and its response to therapy. {\textbar} In one embodiment of the invention, a head-mounted acoustic sensor  {\textbar}   {\textbar} 11 {\textbar}  is used to monitor any number of vibratory characteristics such as high frequency head vibration, muscle vibration, and/or speech production. Head-mounted acoustic sensor  {\textbar} 11 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  with an acoustic sensor connecting cable  {\textbar} 30 {\textbar} . {\textbar} A head-mounted accelerometer  {\textbar}   {\textbar} 12 {\textbar}  is implemented in certain embodiments of the present invention to monitor head movement and position with respect to gravity. Head-mounted accelerometer  {\textbar} 12 {\textbar}  may be mounted to any structure or structures that enables it to accurately sense a desired movement. Such structures include, for example, the skull base, caldarium, clavicle, mandible, extraocular structures, soft tissues and vertebrae. Head-mounted accelerometer  {\textbar} 12 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  with an accelerometer connecting cable  {\textbar} 31 {\textbar} . {\textbar} A proximal electromyography ({EMG}) electrode array  {\textbar}   {\textbar} 45 {\textbar}  is also included in certain preferred embodiments of the invention. Proximal {EMG} electrode array  {\textbar} 45 {\textbar}  includes a positive proximal {EMG} electrode  {\textbar} 13 {\textbar} , a reference proximal {EMG} electrode  {\textbar} 14 {\textbar} , and a negative proximal {EMG} electrode  {\textbar} 15 {\textbar} . As one skilled in the relevant art would find apparent, proximal {EMG} electrode array  {\textbar} 45 {\textbar}  may include any number of type of electrodes. Proximal {EMG} electrode array  {\textbar} 45 {\textbar}  is implanted in or adjacent to muscle tissue. In the embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , proximal {EMG} electrode array  {\textbar} 45 {\textbar}  is shown implanted within the neck of the human patient. However, it should be understood that this location is illustrative only and that proximal {EMG} electrode array  {\textbar} 45 {\textbar}  may be implanted in or adjacent to any muscle without departing from the spirit of the present invention. {\textbar} A proximal acoustic sensor  {\textbar}   {\textbar} 27 {\textbar}  may also be implemented in the present invention. Proximal acoustic sensor  {\textbar} 27 {\textbar}  senses muscle vibration and may be used to augment, supplement or replace {EMG} recording. Also, a proximal accelerometer  {\textbar} 28 {\textbar}  may be used to sense movement, including tremor and voluntary activity, and orientation with respect to gravity. Proximal connecting cable  {\textbar} 16 {\textbar}  provides electrical connection from the proximal {EMG} electrodes  {\textbar} 14 {\textbar}  and  {\textbar} 15 {\textbar} , proximal acoustic sensor  {\textbar} 27 {\textbar} , and proximal accelerometer  {\textbar} 28 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} . In the illustrative embodiment, these sensors are shown connected to a common proximal connecting cable  {\textbar} 16 {\textbar} . However, in alternative embodiments, this configuration may include the use of multiple connecting cables or implement other types of communication media without departing from the present invention. It should also be understood from the preceding description that the number of each type of sensor may also be increased or decreased, some sensor types may be eliminated, and other sensor types may be included without departing from the spirit of the present invention. {\textbar} A distal {EMG} electrode array  {\textbar}   {\textbar} 47 {\textbar}  may also be included in certain embodiments of the present invention. In such embodiments, distal {EMG} electrode array  {\textbar} 47 {\textbar}  typically includes a positive distal {EMG} electrode  {\textbar} 17 {\textbar} , a reference distal {EMG} electrode  {\textbar} 42 {\textbar} , and a negative distal {EMG} electrode  {\textbar} 18 {\textbar} . Positive distal {EMG} electrode  {\textbar} 17 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by positive distal {EMG} connecting cable  {\textbar} 20 {\textbar} . Negative distal {EMG} electrode  {\textbar} 18 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by negative distal {EMG} connecting cable  {\textbar} 21 {\textbar} . Reference distal {EMG} electrode  {\textbar} 42 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by reference distal {EMG} connecting cable  {\textbar} 48 {\textbar} . {\textbar} In other embodiments, a distal acoustic sensor  {\textbar}   {\textbar} 19 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by distal acoustic connecting cable  {\textbar} 22 {\textbar} . Distal accelerometer  {\textbar} 33 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by distal accelerometer connecting cable  {\textbar} 34 {\textbar} . Distal accelerometer  {\textbar} 33 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by distal accelerometer connecting cable  {\textbar} 34 {\textbar} . {\textbar} In the embodiment illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , distal {EMG} electrode array  {\textbar} 47 {\textbar} , distal acoustic sensor  {\textbar} 19 {\textbar} , and distal accelerometer  {\textbar} 33 {\textbar}  are shown located in the shoulder region. However, the distal {EMG} electrode array  {\textbar} 47 {\textbar}  may be located in other locations, including, for example, the masseter, temporalis, sternocleidomastoid, other portion of the head and neck, pectoralis, torso, abdomen, upper extremities, lower extremities, and other locations. The number of each type of sensor may be increased or decreased, some sensor types may be eliminated, and other sensor types may be included without departing from the spirit of the present invention. {\textbar} An enclosure-mounted {EMG} electrode array  {\textbar}   {\textbar} 46 {\textbar}  is illustrated in  {\textbar} {FIG}. 1 {\textbar} . Enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar}  includes enclosure-mounted positive {EMG} electrode  {\textbar} 23 {\textbar} , enclosure-mounted negative {EMG} electrode  {\textbar} 24 {\textbar}  and enclosure-mounted reference {EMG} electrode  {\textbar} 25 {\textbar} , all of which are attached to the circuit enclosure  {\textbar} 44 {\textbar}  that encloses stimulating and recording unit  {\textbar} 26 {\textbar} . The circuit enclosure  {\textbar} 44 {\textbar}  is preferably included to provide robustness against potential lead entanglement and fracture. In one particular embodiment, circuit enclosure  {\textbar} 44 {\textbar}  is constructed of titanium and epoxy, or other single or combination of bio-compatible materials. Enclosure-mounted acoustic sensor  {\textbar} 35 {\textbar}  and enclosure-mounted accelerometer  {\textbar} 36 {\textbar}  are mounted to stimulating and recording unit  {\textbar} 43 {\textbar} . The number of each type of sensor may be increased or decreased, their locations changed, some sensor types eliminated, and other sensor types included without departing from the spirit of the present invention. {\textbar} In the embodiment illustrated in  {\textbar}   {\textbar} {FIG}. 1 {\textbar} , {EEG} electrodes  {\textbar} 39 {\textbar} ,  {\textbar} 40 {\textbar} ,  {\textbar} 41 {\textbar}  are provided. The {EEG} electrodes may be mounted directly to connecting cable  {\textbar} 8 {\textbar}  or may be connected via intermediate cables. Any one of the numerous standard and new electrode configurations, or montages, may be employed in {EEG} electrodes  {\textbar} 39 {\textbar} - {\textbar} 41 {\textbar}  without departing from the present invention. {\textbar} In one embodiment, a proximal peripheral nerve electrode array  {\textbar}   {\textbar} 98 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by proximal peripheral nerve electrode array connecting cable  {\textbar} 100 {\textbar} . Proximal peripheral nerve electrode array  {\textbar} 98 {\textbar}  is shown located in the neck region. In this location proximal peripheral nerve electrode array  {\textbar} 98 {\textbar}  can interface with the vagus nerve, spinal accessory nerve, or nerve arising from cervical roots. {\textbar} A distal peripheral nerve electrode array  {\textbar}   {\textbar} 99 {\textbar}  is connected to stimulating and recording circuit  {\textbar} 26 {\textbar}  by distal peripheral nerve electrode array connecting cable  {\textbar} 32 {\textbar} . Distal peripheral nerve electrode array  {\textbar} 99 {\textbar}  is shown located by the proximal arm, in position to interface with the brachial plexus or proximal arm nerve. One or more of these peripheral nerve electrode arrays may be implanted in these or other locations, including but not limited to the head, cranial nerves, neck, torso, abdomen, upper extremities, and lower extremities, without departing from the present invention. {\textbar} In one preferred embodiment, the peripheral nerve electrode arrays are each comprised of three epineural platinum-iridium ring electrodes, each in with an internal diameter approximately 30\% larger than that of the epineurium, longitudinally spaced along the nerve. Electrodes of differing dimensions and geometries and constructed from different materials may alternatively be used without departing from the present invention. Alternative electrode configurations include but are not limited to epineural, intrafascicular, or other intraneural electrodes; and materials include but are not limited to platinum, gold, stainless steel, carbon, and other element or alloy. {\textbar}   {\textbar} {FIG}. 2 {\textbar}   {\textbar}  is an architectural block diagram of one embodiment of the neurological control system  {\textbar} 999 {\textbar}  of the present invention for modulating the activity of at least one nervous system component in a patient. As used herein, a nervous system component includes any component or structure comprising an entirety or portion of the nervous system, or any structure interfaced thereto. In one preferred embodiment, the nervous system component that is controlled by the present invention includes the globus pallidus internus. In another preferred embodiment, the controlled nervous system component is the subthalamic nucleus. {\textbar} The neurological control system  {\textbar}   {\textbar} 999 {\textbar}  includes one or more implantable components  {\textbar} 249 {\textbar}  including a plurality of sensors each configured to sense a particular characteristic indicative of a neurological or psychiatric condition. One or more intracranial ({IC}) stimulating electrodes in an {IC} stimulating electrode array  {\textbar} 37 {\textbar}  delivers a neural modulation signal to the same or other nervous system component as that being monitored by the system  {\textbar} 26 {\textbar} . One or more sensors  {\textbar} 38 {\textbar} ,  {\textbar} 51 {\textbar} ,  {\textbar} 52 {\textbar} ,  {\textbar} 53 {\textbar} , and  {\textbar} 54 {\textbar}  sense the occurrence of neural responses to the neural modulation signals. Stimulating and recording unit  {\textbar} 26 {\textbar}  generates the neural modulation signal based on the neural response sensed by the sensors. {\textbar} The neurological control system  {\textbar}   {\textbar} 999 {\textbar}  preferably also includes a patient interface module  {\textbar} 55 {\textbar}  and a supervisory module  {\textbar} 56 {\textbar} . A control circuit  {\textbar} 72 {\textbar}  (described below) is communicably coupled to the patient interface module  {\textbar} 55 {\textbar}  and receives signal inputs from and provides signal outputs to patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . In one preferred embodiment, patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  remain external to the body of the patient. However either of these devices may be connected via percutaneous leads or be partially or totally implanted without departing from the present invention. {\textbar} Patient interface module  {\textbar}   {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  facilitate adjustment of control parameters, monitoring of disease state, monitoring of response to therapy, monitoring of stimulating and recording circuit  {\textbar} 26 {\textbar} , monitoring of impedance and other characteristics of intracranial stimulating electrode array  {\textbar} 37 {\textbar} , monitoring of physiologic parameters, monitoring of vital signs, monitoring of any other characteristic or function of components of the present invention, including but not limited to the stimulating and recording circuit  {\textbar} 26 {\textbar} , stimulating and recording unit  {\textbar} 43 {\textbar} , circuit enclosure  {\textbar} 44 {\textbar} , {EMG} electrode array  {\textbar} 50 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , accelerometer array  {\textbar} 52 {\textbar} , acoustic transducer array  {\textbar} 53 {\textbar} , peripheral nerve electrode array  {\textbar} 54 {\textbar} , and intracranial recording electrode array  {\textbar} 38 {\textbar} . Such monitoring and adjustment is accomplished through the use of any well known bi-directional communication between control circuit  {\textbar} 72 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . In one preferred embodiment, a radio frequency link is employed. In alternative embodiments, other communication technologies, including but not limited to optical, percutaneous, or electromagnetic, may be used. {\textbar} In one preferred embodiment, patient interface module  {\textbar}   {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  are placed adjacent to the patients garments overlying the implanted stimulating and recording unit  {\textbar} 43 {\textbar} . When neurological control system  {\textbar} 999 {\textbar}  is turned on in this position, a communications handshaking protocol is executed. Communication handshaking routines are known to those or ordinary skill in the art, and they enable establishment of a communication rate and protocol and facilitate mutual identification of devices. Patient interface module  {\textbar} 55 {\textbar}  automatically downloads parameters from stimulating and recording circuit  {\textbar} 26 {\textbar}  and stores values of such parameters in a memory. When the transfer of these parameter values is complete, patient interface module  {\textbar} 55 {\textbar}  emits a audible signal such as a series of beeps, and the patient turns off patient interface module  {\textbar} 55 {\textbar}  and removes it from its position overlying the implanted stimulating and recording unit  {\textbar} 43 {\textbar} . Parameter values may then be retrieved by the patient by a routine including but not limited to a menu driven interface, and the values may be transmitted via telephone conversation or other communication method to a health care professional. Supervisory module  {\textbar} 56 {\textbar}  operates in the same manner with one addition; a step is provided during which the health care professional may upload parameters to stimulating and recording circuit  {\textbar} 26 {\textbar}  to alter its function including by means of changing parameters including but not limited to control laws gains and thresholds, filter parameters, signal processing parameters, stimulation waveform modes (including at least one of current regulated, voltage regulated, frequency regulated, or pulse width regulated), and stimulation waveform parameters. {\textbar} Control laws, well known to those of ordinary skill in the field of control theory, are defined by a set of parameters specific to the particular control law. Common parameters include preset gains, threshold levels, saturation amplitudes, sampling rates, and others. Adaptive controllers change in response to the behavior of the system being controlled; as such, in addition to preset parameters, adaptive controllers possess a set of varying parameters. These varying parameters contain information indicative of the behavior of the system being controlled; downloading of these parameters provides one set of measures of the disease state and its response to therapy. {\textbar}   {\textbar} Such monitoring includes observation of time history of disease state, stimulation parameters, response to therapy, and control law parameters, including time-varying adaptive controller parameters. Such adjustments includes modification of actual stimulation parameters and allowable ranges thereof, including but not limited to pulse width, pulse amplitude, interpulse interval, pulse frequency, number of pulses per burst frequency. Adjustments can further include modification of actual control law parameters and allowable ranges thereof, including but not limited to gains, thresholds and sampling rates of said stimulation waveforms. Signal processor  {\textbar}   {\textbar} 71 {\textbar}  contains signal processor modules for each of the sensory input modalities  {\textbar} 247 {\textbar} . Signal processing algorithms for each of the said sensory input modalities  {\textbar} 247 {\textbar}  may be independent. Additionally, signal processing algorithms the said sensory input modalities  {\textbar} 247 {\textbar}  may be coupled, such that the processing of one of the sensory input modalities  {\textbar} 247 {\textbar}  is dependent on another of the sensory input modalities  {\textbar} 247 {\textbar} . Adjustments may additionally include modification of actual signal processor parameters and allowable ranges thereof, including but not limited to gains, filter cutoff frequencies, filter time constants, thresholds, and sampling rates. In a preferred embodiment, the stimulation and control law parameters are stored in at least one of random access memory and central processing unit registers (not shown). {\textbar} It is anticipated that patient interface module  {\textbar}   {\textbar} 55 {\textbar}  is to be used by the patient, a family member or associate, or home health care personnel to monitor the functions and performance of neurological control system  {\textbar} 999 {\textbar} . In such an embodiment, the use of the patient interface module  {\textbar} 55 {\textbar}  is restricted to monitoring operations; adjustment of stimulation and control parameters is not enabled. However, adjustment of all or a subset of stimulation and control parameters (described below) may be facilitated by patient interface module  {\textbar} 55 {\textbar}  without departing from the present invention. Supervisory module  {\textbar} 56 {\textbar} , on the other hand, is used by a physician or other health care personnel to monitor function and performance of neurological control system  {\textbar} 999 {\textbar}  and to adjust stimulation and control parameters. Control parameters controlled by patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  include allowable stimulation magnitude range, such as maximum combination of stimulation voltage, current, pulse width, pulse frequency, train frequency, pulse train count, pulse train duration. Control parameters may also include variables and constants used to define control laws implemented in control circuit  {\textbar} 72 {\textbar} . Such control parameters include, but are not limited to, control law gains  {\textbar} 197 {\textbar} - {\textbar} 203 {\textbar} , and other parameters for control laws, including but not limited to proportional controller  {\textbar} 230 {\textbar} , differential controller  {\textbar} 204 {\textbar} , integral controller  {\textbar} 205 {\textbar} , nonlinear controller  {\textbar} 206 {\textbar} , adaptive controller  {\textbar} 207 {\textbar} , sliding controller  {\textbar} 208 {\textbar} , model reference controller  {\textbar} 209 {\textbar} , and other controllers. In addition, amplitudes for other controller parameters, including but not limited to amplitudes for controller weights  {\textbar} 210 {\textbar} - {\textbar} 216 {\textbar}  may be set by supervisory module  {\textbar} 56 {\textbar} . Additionally, the parameters specifying the maximum amplitudes, or saturation values, may be set by supervisory module  {\textbar} 56 {\textbar} . Control circuit  {\textbar} 72 {\textbar}  ( {\textbar} {FIG}. 12 {\textbar} ) will be described in detail below. {\textbar} The majority of the computation accomplished by stimulating and recording circuit  {\textbar}   {\textbar} 26 {\textbar}  is performed in signal conditioning circuit  {\textbar} 76 {\textbar} , signal processor  {\textbar} 71 {\textbar} , and control circuit  {\textbar} 72 {\textbar} ; the algorithms and behavior of which are determined by corresponding sets of control parameters, of which some may be set by the supervisory module  {\textbar} 56 {\textbar}  and a typically more restricted set by patient interface module  {\textbar} 55 {\textbar} . In one embodiment, control parameters further includes signal conditioning parameters. Signal conditioning parameters may include, for example, amplifier gains, filter gains and bandwidths, threshold values, and other parameters. In certain embodiments, control parameters additionally include signal processing parameters, including envelope determinator gains and time constants, filter passbands, filter gains, threshold values, integrator gains, analyzer parameters, disease state estimator parameters, artifact rejecter thresholds, envelope determinator time constants, rectifier parameters, spectral analyzer parameters and timer parameters. {\textbar} In the illustrative embodiment described herein, control parameters further include spike detector  {\textbar}   {\textbar} 188 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, spike characterizer  {\textbar} 189 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, spike analyzer  {\textbar} 190 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, spectral energy characterizer  {\textbar} 192 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, spectral energy analyzer  {\textbar} 193 {\textbar}  ( {\textbar} {FIG}. 9 {\textbar} ) parameters, aggregate disease state estimator  {\textbar} 195 {\textbar}  ( {\textbar} {FIG}. 10 {\textbar} ) parameters. {\textbar} In accordance with the present invention, tremor are quantified and monitored by any sensors over time as indicators of disease state. Such sensors include but are not limited to {EMG} electrode array  {\textbar}   {\textbar} 50 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , accelerometer array  {\textbar} 52 {\textbar} , acoustic transducer array  {\textbar} 53 {\textbar} , peripheral nerve electrode array  {\textbar} 54 {\textbar} , intracranial recording electrode array  {\textbar} 38 {\textbar} , and intracranial stimulating electrode array  {\textbar} 37 {\textbar} . In one particular embodiment, the sensed tremor characteristics include, but are not limited to, magnitude, frequency, duration and frequency of occurrence of tremors. Changes in these and other parameters are compared to current levels of, and changes in, treatment parameters. These changes are then used by aggregate disease state estimator  {\textbar} 195 {\textbar}  to estimate the response to therapy as functions of various electrical stimulation treatment parameters. Electrical stimulation treatment parameters are adjusted by control circuit  {\textbar} 72 {\textbar}  in real-time to provide optimal control of disease state. {\textbar} Modulation parameters are optimized to achieve at least one of minimization of disease state, minimization of symptoms of disease, minimization of stimulation magnitude, minimization of side effects, and any constant or time-varying weighted combination of these. Patient interface module  {\textbar}   {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  also preferably monitor the function and operation of other components of neurological control system  {\textbar} 999 {\textbar} , including stimulating and recording unit  {\textbar} 26 {\textbar}  and implanted components  {\textbar} 249 {\textbar} . {\textbar} Stimulating and recording unit  {\textbar}   {\textbar} 26 {\textbar}  receives and processes signals generated by implanted components  {\textbar} 249 {\textbar}  to provide conditioned signals  {\textbar} 78 {\textbar} - {\textbar} 84 {\textbar}  to a signal processor  {\textbar} 71 {\textbar} . For each type of implanted components  {\textbar} 249 {\textbar}  coupled to stimulating and recording unit  {\textbar} 26 {\textbar} , signal conditioning circuit  {\textbar} 76 {\textbar}  preferably includes an associated amplifier and filter. Each amplifier and associated filter is configured to receive and process the signal generated by the associated one of the set of sensors  {\textbar} 38 {\textbar} ,  {\textbar} 51 {\textbar} ,  {\textbar} 52 {\textbar} ,  {\textbar} 53 {\textbar} , and  {\textbar} 54 {\textbar} . {\textbar} In the illustrative embodiment, implanted components  {\textbar}   {\textbar} 249 {\textbar}  include an electromyography ({EMG}) electrode array  {\textbar} 50 {\textbar}  which generate {EMG} signals. Preferably, {EMC} electrode array  {\textbar} 50 {\textbar}  comprises of all {EMG} electrodes implemented in the particular embodiment of the present invention. These include, in the exemplary embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , proximal {EMG} electrode array  {\textbar} 45 {\textbar} , enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar}  and distal {EMG} electrode array  {\textbar} 47 {\textbar} . Array  {\textbar} 50 {\textbar}  may also include, for example, {EMG} electrodes implanted in the head or other location, and surface {EMG} electrodes. {\textbar} Implanted components  {\textbar}   {\textbar} 249 {\textbar}  also include an electroencephalography ({EEG}) electrode array  {\textbar} 51 {\textbar}  which generate {EEG} signals and accelerometer array  {\textbar} 52 {\textbar}  which generates acceleration signals. {EEG} electrodes  {\textbar} 39 {\textbar} ,  {\textbar} 40 {\textbar} ,  {\textbar} 41 {\textbar}  illustrated in  {\textbar} {FIG}. 1 {\textbar}  are representative of {EEG} electrode array  {\textbar} 51 {\textbar} . {EEG} electrodes  {\textbar} 39 {\textbar} - {\textbar} 41 {\textbar}  may be mounted directly to connecting cable  {\textbar} 8 {\textbar}  or connected via intermediate cables. {EEG} electrode array  {\textbar} 51 {\textbar}  may include more or fewer elements than {EEG} electrodes  {\textbar} 39 {\textbar} - {\textbar} 41 {\textbar}  depicted; and any of numerous standard and new electrode configurations, or montages, may be employed without departing from the present invention. {\textbar} Accelerometer array  {\textbar}   {\textbar} 52 {\textbar} , which produces well-known acceleration signals, preferably includes all accelerometers implemented in the patient associated with the present invention. For example, in the embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , accelerometer array  {\textbar} 52 {\textbar}  includes head-mounted accelerometer  {\textbar} 12 {\textbar} , proximal accelerometer  {\textbar} 28 {\textbar} , enclosure-mounted accelerometer  {\textbar} 36 {\textbar}  and distal accelerometer  {\textbar} 33 {\textbar} . Accelerometer array  {\textbar} 52 {\textbar}  may include more or fewer accelerometers than these accelerometers, and accelerometers of any types and locations may be employed without departing from the present invention. {\textbar} Acoustic transducer array  {\textbar}   {\textbar} 53 {\textbar}  includes all acoustic sensors utilized by the present invention. In the exemplary embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , acoustic transducer array  {\textbar} 53 {\textbar} , includes head-mounted acoustic sensor  {\textbar} 11 {\textbar} , proximal acoustic sensor  {\textbar} 27 {\textbar} , enclosure-mounted acoustic sensor  {\textbar} 35 {\textbar}  and distal acoustic sensor  {\textbar} 19 {\textbar} . It should be understood that acoustic transducer array  {\textbar} 53 {\textbar}  may include more or fewer elements than said acoustic sensors listed above; and any of numerous acoustic sensor types and locations may be employed without departing from the present invention. {\textbar} Peripheral nerve electrode array  {\textbar}   {\textbar} 54 {\textbar}  generates peripheral neural signals, including but not limited to efferent and afferent axonal signals. Preferably, peripheral nerve electrode array  {\textbar} 54 {\textbar}  includes all peripheral nerve electrodes implemented in present invention. For example, in the illustrative embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} , peripheral nerve electrode array  {\textbar} 54 {\textbar}  includes proximal peripheral nerve electrode array  {\textbar} 98 {\textbar}  and distal peripheral nerve electrode array  {\textbar} 99 {\textbar} . The single or plurality of individual peripheral nerve electrode arrays which comprise peripheral nerve electrode array  {\textbar} 54 {\textbar}  may be implanted in the illustrated or other locations, as noted above. {\textbar} Intracranial ({IC}) recording electrode array  {\textbar}   {\textbar} 38 {\textbar}  generates central neural signals, including but not limited to cortical, white matter, and deep brain nuclear signals. Neural activity to be sensed includes but is not limited to that found in the primary motor cortex, premotor cortex, supplementary motor cortex, somatosensory cortex, white matter tracts associated with these cortical areas, the globus pallidus internal segment, the globus pallidus external segment, the caudate, the putamen, and other cortical and subcortical areas. As one of ordinary skill in the relevant art will find apparent, the present invention may include additional or different types of sensors that sense neural responses for the type and particular patient. Such sensors generate sensed signals that may be conditioned to generate conditioned signals, as described below. One example of the placement of these electrodes is described above with reference to the embodiment illustrated in  {\textbar} {FIG}. 1 {\textbar} . Many others are contemplated by the present invention. {\textbar} As noted, for each of the different types of sensors included in implanted components  {\textbar}   {\textbar} 249 {\textbar} , signal conditioning circuit  {\textbar} 76 {\textbar}  includes an associated amplifier and filter in the illustrative embodiment. Accordingly, signal conditioning circuit  {\textbar} 76 {\textbar}  includes an {EMG} amplifier  {\textbar} 59 {\textbar}  and filter  {\textbar} 66 {\textbar} , each constructed and arranged to amplify and filter, respectively, the {EMG} signals received from {EMG} electrode array  {\textbar} 50 {\textbar} . Similarly, signal conditioning circuit  {\textbar} 76 {\textbar}  also includes an {EEG} amplifier  {\textbar} 60 {\textbar}  and filter  {\textbar} 67 {\textbar} , accelerometer ({ACC}) amplifier  {\textbar} 61 {\textbar}  and filter  {\textbar} 68 {\textbar} , acoustic ({ACO}) amplifier  {\textbar} 62 {\textbar}  and filter  {\textbar} 69 {\textbar} , peripheral nerve electrode ({PNE}) amplifier  {\textbar} 63 {\textbar}  and filter  {\textbar} 70 {\textbar}  and intracranial ({IC}) recording electrode ({ICRE}) amplifier  {\textbar} 58 {\textbar}  and filter  {\textbar} 65 {\textbar} . {\textbar} Simplifiers  {\textbar}   {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  may be single or multi-channel amplifiers depending upon the number of electrodes with which it interfaces. In one preferred embodiment, amplifiers  {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  are physically located in the same enclosure as filters  {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar} ; that is, in a single signal conditioning circuit  {\textbar} 76 {\textbar} . Preferably, signal conditioning circuit  {\textbar} 76 {\textbar}  is physically contained within stimulating and recording unit  {\textbar} 102 {\textbar} . However, amplifiers  {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  may be located separately from stimulating recording unit  {\textbar} 102 {\textbar} . For example, amplifiers  {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  may be affixed to or situated proximate to their associated electrode arrays  {\textbar} 38 {\textbar} ,  {\textbar} 50 {\textbar} - {\textbar} 54 {\textbar} . This arrangement facilitates the preamplification of the associated signals generated by the associated electrode arrays  {\textbar} 38 {\textbar} ,  {\textbar} 50 {\textbar} - {\textbar} 54 {\textbar} , increasing the signal-to-noise ratio of the signals. Amplifiers  {\textbar} 57 {\textbar} - {\textbar} 63 {\textbar}  may be any known voltage amplifier now or later developed suitable for amplifying the particular signals generated by their associated electrodes. {\textbar} As noted, the amplified signals are passed to their associated filters  {\textbar}   {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar}  as shown in  {\textbar} {FIG}. 2 {\textbar} . As with amplifiers  {\textbar} 57 {\textbar} - {\textbar} 59 {\textbar} , filters  {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar}  may be physically separate from or incorporated into signal conditioning circuit  {\textbar} 76 {\textbar}  and stimulating and recording unit  {\textbar} 26 {\textbar} . In one preferred embodiment, filters  {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar}  are low pass filters having a cut-off frequency of, for example, 3,000 Hz. In alternative embodiments, filters  {\textbar} 64 {\textbar} - {\textbar} 70 {\textbar}  may include a notch filter to remove, for example, 60 Hz noise, or other types of filters appropriate for the type of signals generated by the associated sensors  {\textbar} 38 {\textbar} ,  {\textbar} 51 {\textbar} ,  {\textbar} 52 {\textbar} ,  {\textbar} 53 {\textbar} , and  {\textbar} 54 {\textbar} . Selection of the appropriate frequencies for the cut-off and notch filter frequencies is considered to be well known in the relevant art and within the scope of the present invention. Filters  {\textbar} 66 {\textbar} - {\textbar} 70 {\textbar} ,  {\textbar} 65 {\textbar}  and  {\textbar} 64 {\textbar}  generate conditioned sensed signals  {\textbar} 84 {\textbar} ,  {\textbar} 83 {\textbar}  and  {\textbar} 78 {\textbar} - {\textbar} 82 {\textbar} , respectively. {\textbar} Signal processor  {\textbar}   {\textbar} 71 {\textbar}  processes the conditioned sensed neural response signals  {\textbar} 78 {\textbar} - {\textbar} 84 {\textbar}  generated by signal conditioning circuit  {\textbar} 76 {\textbar}  in accordance with the present invention to determine neural system states. Signal processor  {\textbar} 71 {\textbar}  generally performs well known filtering operations in the time and frequency domains. In one preferred embodiment, the neural system states include one or more physiologic or disease states. Signal processor  {\textbar} 71 {\textbar} , which can be implemented in a fast microprocessor, a {DSP} (digital signal processor) chip, or as analog circuitry, for example, is described in detail below. {\textbar} Control circuit  {\textbar}   {\textbar} 72 {\textbar} , responsive to the signal processor  {\textbar} 71 {\textbar} , patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} , adjusts the magnitude of a neural modulation signal in response to the sensed neural response. Signal processor  {\textbar} 71 {\textbar}  extracts relevant information from the sensed condition signals, and control circuit  {\textbar} 72 {\textbar}  uses this extracted information in the calculation of an output neuromodulation signal ({NMS})  {\textbar} 998 {\textbar} . Neuromodulation signal  {\textbar} 998 {\textbar}  subsequently travels along stimulator output path  {\textbar} 111 {\textbar}  to {IC} stimulating electrode array  {\textbar} 37 {\textbar} . In one embodiment, control circuit  {\textbar} 72 {\textbar}  is a state machine, utilizing current and past system behavior in the calculation of a control signal. In an alternative embodiment, control circuit  {\textbar} 72 {\textbar}  includes an embedded microprocessor to process nonlinear control laws. Alternative embodiments of the control circuit  {\textbar} 72 {\textbar}  appropriate for the particular application may be also be used. {\textbar} Control circuit  {\textbar}   {\textbar} 72 {\textbar}  receives control law selection information, control law parameter information, stimulation waveform parameter range information, stimulation modulation mode, output stage regulation mode, and medication dose and timing information from patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . The waveform parameter or parameters which are modulated by control law output signal U  {\textbar} 997 {\textbar}  are determined by the stimulation modulation mode; these parameters include but are not limited to pulse amplitude, pulse width, pulse frequency, pulses per burst, and burst frequency. Selection between regulation of pulse voltage or pulse current as the regulated pulse amplitude is determined by the output stage regulation mode. {\textbar} Control circuit  {\textbar}   {\textbar} 72 {\textbar}  provides stimulation waveform parameter history information, disease state history information, control law state variable history information, control law error history information, control law input variable history information, control law output variable history information, stimulating electrode impedance history information, sensory input history information, battery voltage history information, and power consumption history information to patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . {\textbar} Provision of stimulating electrode impedance history information allows monitoring of stimulating electrode performance and functionality. If an electrode is determined to be fractured, shorted, or encapsulated by fibrotic tissue, any of various control law parameters, output stage parameters, and waveform range parameters may be adjusted to allow compensation for these changes. Additionally, the Neuromodulation Signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  may be delivered to different sets of electrodes to insure that it reaches neural tissue  {\textbar} 250 {\textbar} . Sensory input history information allows evaluation of validity of any given sensory input. This is useful in determining the functionality of a given sensor and serves as an indicator for sensor replacement or adjustment of the signal processing parameters or algorithm or the control law parameters or algorithm to continue to generate reliable disease state estimate signals X and control law outputs U despite the loss of any particular individual or set of sensory signals. {\textbar} Signal processor  {\textbar}   {\textbar} 71 {\textbar}  receives amplifier gain setting information, filter parameter information, weighting information, and disease state estimator parameter and algorithm information from patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . The function and operation of patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar}  are described above. As noted, patient interface module  {\textbar} 55 {\textbar}  may be used by the patient or home health care personnel to monitor disease state, stimulation parameters, and response to therapy. Limited adjustment of stimulation parameters and ranges is facilitated. Patient interface module  {\textbar} 55 {\textbar}  may be used by the patient or home health care personnel to provide information to the physician, avoiding the need for an office visit for the obtainment of said information. {\textbar} Patient information module  {\textbar}   {\textbar} 55 {\textbar}  queries signal processor  {\textbar} 71 {\textbar}  for present and time histories of monitored values. Time histories of selected variables in signal processor  {\textbar} 71 {\textbar}  and control circuit  {\textbar} 72 {\textbar}  are stored in memory module  {\textbar} 240 {\textbar}  for subsequent retrieval by patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} . Selected variables include but are not limited to disease state, tremor frequency, tremor magnitude, {EMG} magnitude, {EMG} frequency spectra ({EMG} magnitude within frequency ranges), and acceleration of limb, head, mandible, or torso. Selected variables may also include disease state, frequency spectra of limb, torso, and head movements, as determined by {EMG} and accelerometer signals. {\textbar} Stimulating and recording unit  {\textbar}   {\textbar} 26 {\textbar}  also includes an output stage circuit  {\textbar} 77 {\textbar} . Output stage circuit  {\textbar} 77 {\textbar}  takes for an input the control law output signal U, which may be comprised of a single or multiplicity of channels or signals, from control circuit  {\textbar} 72 {\textbar} . This control law output signal U  {\textbar} 997 {\textbar}  modulates the magnitude of the sequence of waveforms comprising the desired output neuromodulation signal ({NMS}.sub.D) which is produced by output stage circuit  {\textbar} 77 {\textbar}  and delivered via intracranial stimulating electrode array  {\textbar} 37 {\textbar}  to neural tissue  {\textbar} 250 {\textbar} . {\textbar} Output stage circuit  {\textbar}   {\textbar} 77 {\textbar}  generates a neuromodulation signal ({NMS}.sub.D)  {\textbar} 998 {\textbar}  with a magnitude specified by control law output signal U  {\textbar} 997 {\textbar}  received from control circuit  {\textbar} 72 {\textbar} . In one preferred embodiment, the waveform parameter of the desired output neuromodulation signal ({NMS}.sub.D) which is modulated by control law output signal U is the stimulation current magnitude. The capability to specifically modulate the stimulation current confers efficacy resistance to perturbations or changes in electrode impedance. Presently implanted systems suffer from a decline in efficacy which results from an increase in electrode impedance which accompanies the normal tissue response to a foreign body, that is fibrotic encapsulation of the electrode. In this design taught in the present invention, a the magnitude of the current delivered to the neural tissue  {\textbar} 250 {\textbar}  will not vary as the electrode becomes encapsulated with fibrotic tissue or its impedance otherwise changes over time. A further advantage conferred by current modulation is the ability to monitor electrode impedance. If a current-modulated waveform, preferably a sinusoid, is delivered to the electrodes, and the resultant voltage potential waveform is concurrently monitored, the relative magnitudes and phase shifts of these waveforms may be computed. From these magnitudes and phases, the complex impedance and hence the resistive and capacitive components of the electrode impedance may be calculated. {\textbar} In an alternative embodiment, the waveform parameter of the desired output neuromodulation signal ({NMS}.sub.D) which is modulated by control law output signal U  {\textbar}   {\textbar} 997 {\textbar}  is the stimulation voltage magnitude. This design would not enjoy the independence of the stimulation current and efficacy from impedance variation enjoyed by the embodiment described above. If fibrosis was uneven around the surface of the electrode, this embodiment would avoid potentially undesirably large current densities along narrow tracts of remaining low resistance unfibrosed regions of neural tissue  {\textbar} 250 {\textbar} . {\textbar} Alternatively, regulation of stimulus pulse width may be desired. In certain circuit implementations, the available resolution or bits for specifying the magnitude of pulse width may be greater than that for specifying the pulse voltage or current. In such a case, if finer control of the magnitude of Neuromodulation signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  is desired than is provided by the control of pulse current or pulse voltage, then it may be desirable to modulate the pulse width. Furthermore, the spatial neuron recruitment characteristics of a pulse width modulated neuromodulation signal ({NMS})  {\textbar} 998 {\textbar}  may provide a more linear, predictable, or controllable response than that obtained with current or voltage modulation. Selection between regulation of pulse voltage, pulse current, or pulse width as the regulated pulse amplitude parameter is determined by the output stage regulation mode, which may be set using supervisory module  {\textbar} 56 {\textbar} . In alternative embodiments, the modulation of pulse frequency and the modulation of the number of pulses per burst are regulated. As one of ordinary skill in the relevant art would find apparent. Other such characteristics may be regulated in addition to or instead of the ones noted above. {\textbar} Output stage circuit  {\textbar}   {\textbar} 77 {\textbar}  includes a pulse generator  {\textbar} 73 {\textbar} , an output amplifier  {\textbar} 74 {\textbar}  and a multiplexor  {\textbar} 75 {\textbar} . Pulse generator  {\textbar} 73 {\textbar}  generates one or more stimulus waveforms, each of which is characterized by several parameters, including but not limited to pulse amplitude, pulse width, pulse frequency, number of pulses per burst, and burst frequency. As noted above, pulse amplitude may comprise pulse voltage or pulse current. Preferably, each of these parameters may be independently varied, as specified by control law output signal U  {\textbar} 997 {\textbar}  generated by control circuit  {\textbar} 72 {\textbar} . As noted, the stimulus waveforms comprising the neuromodulation signal ({NMS}) generated by output stage circuit  {\textbar} 77 {\textbar}  are applied to patient through intracranial ({IC}) stimulating electrode array  {\textbar} 37 {\textbar} . Pulse generator  {\textbar} 73 {\textbar}  generates a single waveform when single channel stimulation is to be used, and a plurality of waveforms when multiple channel stimulation is to be used. It may generate monophasic or biphasic waveforms. {\textbar} In one preferred embodiment, charge balanced biphasic waveforms are produced. Those skilled in the art are aware that the net charge contained in a given pulse is given by the time integral of the stimulus current over the duration of the pulse. In a biphasic configuration, a pair of pulses of opposite polarity is generated, and the pulse current amplitude and pulse width are chosen such that the charge amplitude is equal in magnitude and opposite in polarity. In some cases, it is desirable for the pulses comprising the biphasic pulse pair to have different amplitudes; in this case, the pulse widths are chosen to insure equal and opposite charges so the pulse par introduces zero net charge to the neural tissue  {\textbar}   {\textbar} 250 {\textbar} . The capability to deliver pulse pairs with balanced charges is yet a further advantage conferred by the current regulation mode described above. {\textbar} Even though the waveform parameters of the pulse pairs are calculated to deliver a zero net charge, in practice, noise and precision limitations in computation and resolution limitations and nonlinearities in the digital to analog conversion and amplification stages may result in slight imbalances in the pulse pair charges. Over time, this can result in the delivery of a substantial accumulated net charge to the neural tissue. To eliminate this potential for net charge delivery to neural tissue, a direct current ({DC}) blocking capacitor is employed. This is a technique that is well known to those or ordinary skill in the art. In one preferred embodiment, a {DC} blocking capacitor is included within multiplexor  {\textbar}   {\textbar} 75 {\textbar}  in series with stimulator output path  {\textbar} 111 {\textbar} . {\textbar} Typically, multi-channel stimulation is used in the case of bilateral stimulation. Since the disease progression is typically asymmetrical, and the normal motor control systems governing movement on the left and right side of the body are also highly independent of each other, the delivery of treatment to the left and right sides of the body should be controlled separately. This represents one need for a multiple channel neuromodulation signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar} . Multichannel stimulation is also expected to be beneficial in treating patients with variable involvement of different limbs. For example, the magnitude neuromodulation of a portion of the globus pallidus required to achieve optimal controls of arm tremor may be different from the optimal level of neuromodulation of separate portion of the globus pallidus to achieve optimal control of leg tremor. In this case, separate electrodes or electrode pairs are required to deliver optimal levels of neuromodulation to control tremor in these two regions of the body. Correspondingly, these separate electrodes or electrode pairs will be driven by separate neuromodulation signal ({NMS}) channels, necessitating a multichannel system. {\textbar} A further need for multichannel neuromodulation signal ({NMS}) is the control of multiple symptoms of the movement disorder and the side effects arising from pharmacologic treatment. Optimal control of tremor, dyskinesias, and rigidity are not achieved by modulation of the same site at the same intensity. For this reason, multiple and separately controlled channels of neuromodulation are required to simultaneously achieve optimal control of these multiple symptoms and side effects. Each of these symptoms and side effects may be considered to comprise one or more element in a multivariable disease state. A multivariable control system will be required to optimally drive each of these disease state elements to its desired value, ideally toward a target minimum level and thus achieve optimal control of this multiplicity of disease states. This multivariable control system may be implemented as multiple independent control laws each with separate though potentially overlapping sensory inputs or as a multivariable control law matrix. {\textbar}   {\textbar} Stimulation via each of the multiple channels comprising the neuromodulation signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  is characterized by separate though possibly overlapping sets of one or more of the following parameters: stimulation voltage, stimulation current stimulation frequency of pulses within the same burst, frequency of bursts, pulse width, pulses per burst, duration of burst, and interpulse interval. The stimulus waveforms are amplified by output amplifier  {\textbar} 74 {\textbar}  to generate an amplified stimulus waveform. Specifically, pulse generator  {\textbar} 73 {\textbar}  transfers information to output amplifier  {\textbar} 74 {\textbar}  which includes information that uniquely specifies the desired stimulation waveform. In a preferred embodiment, the information is in the form of an analog signal which represents a scaled version of the voltage or current waveform to be delivered to the tissue. It should be understood that other forms of the signal generated by pulse generator  {\textbar} 73 {\textbar}  may be used, including combinations of at least one of analog and digital representations. Output amplifier  {\textbar} 74 {\textbar}  performs amplification and regulation of the received stimulus waveform generated by the pulse generator  {\textbar} 73 {\textbar} . This may be regulation of electrical current to achieve desired voltage or regulation of electrical voltage to achieve desired current, depending on whether a voltage or current waveform is to be delivered to the nervous system component. {\textbar} As one skilled in the relevant art would find apparent, voltage regulation is simpler to implement, and is a technique which is commonly used by many conventional stimulators. Current regulation, on the other hand, is more complex but allows for more precise control of the applied stimulation. Current regulation insures that a specified amount of current is delivered, regardless of the impedance of the electrode. Current regulation is advantageous in that it allows for precise control of stimulation level despite changes in electrode impedance which invariably occur over time. Since electrode impedances often change, typically increasing as they become encapsulated by fibrosis, current regulation is preferred to avoid the decrease in current which would occur if voltage regulation were to be used in such circumstances. {\textbar}   {\textbar} The amplified stimulus waveform generated by output amplifier  {\textbar}   {\textbar} 74 {\textbar}  is conducted along stimulator amplifier output path  {\textbar} 112 {\textbar}  to multiplexor  {\textbar} 75 {\textbar} . Multiplexor  {\textbar} 75 {\textbar}  allows for delivery of a stimulating electrode output signal ({SEOS}) to the intracranial stimulating electrode array  {\textbar} 37 {\textbar} , multiplexed with sensing of a stimulating electrode input signal ({SEIS}). Specifically, multiplexor  {\textbar} 75 {\textbar}  serves to alternately connect intracranial stimulating electrode ({ICSE}) array  {\textbar} 37 {\textbar}  to output amplifier  {\textbar} 74 {\textbar}  and intracranial stimulating electrode amplifier  {\textbar} 57 {\textbar} . Connection of intracranial stimulating electrode ({ICSE}) array  {\textbar} 37 {\textbar}  to output amplifier  {\textbar} 74 {\textbar}  facilitates delivery of neural modulation signal to neural tissue, while connection of intracranial stimulating electrode ({ICSE}) array  {\textbar} 37 {\textbar}  to intracranial stimulating electrode amplifier  {\textbar} 57 {\textbar}  facilitates monitoring of neural activity in the region being stimulated. {\textbar} Multiplexor  {\textbar}   {\textbar} 75 {\textbar}  allows delivery of neural modulation signals to neural tissue concurrent with monitoring of activity of same neural tissue; this facilitates real-time monitoring of disease state and response to treatment. Stimulating electrode output signal ({SEOS}) from output amplifier  {\textbar} 74 {\textbar}  is conducted along stimulator amplifier output path  {\textbar} 112 {\textbar}  to multiplexor  {\textbar} 75 {\textbar} . Multiplexor  {\textbar} 75 {\textbar}  conducts output from output amplifier  {\textbar} 74 {\textbar}  to stimulator output path  {\textbar} 111 {\textbar}  which conducts the stimulating electrode output signal to intracranial stimulating electrode array  {\textbar} 37 {\textbar} . To facilitate periodic sampling of neural activity in tissue being stimulated, multiplexor  {\textbar} 75 {\textbar}  alternatively conducts signal arising from stimulated tissue via intracranial stimulating electrode array ({ICSE})  {\textbar} 37 {\textbar}  and stimulator output path  {\textbar} 111 {\textbar}  to multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  and intracranial stimulating electrode amplifier  {\textbar} 57 {\textbar} . {\textbar} Multiplexor  {\textbar}   {\textbar} 75 {\textbar}  selectively conducts the signal on multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  to amplifier  {\textbar} 57 {\textbar} . Multiplexor  {\textbar} 75 {\textbar}  may alternate conduction between path  {\textbar} 111 {\textbar}  and path  {\textbar} 112 {\textbar}  or path  {\textbar} 113 {\textbar}  using temporal multiplexing, frequency multiplexing or other techniques to allow concurrent access to the intracranial stimulating electrode ({ICSE}) array  {\textbar} 37 {\textbar}  for modulation of tissue activity and monitoring of tissue activity. Temporal multiplexing is a well known technique and frequency multiplexing of stimulation and recording signals in known to those skilled in the art. In this embodiment, temporal multiplexing is accomplished by alternately connecting stimulator output path  {\textbar} 111 {\textbar}  to stimulator amplifier output path  {\textbar} 112 {\textbar}  and multiplexed stimulator recording input path  {\textbar} 113 {\textbar} . In one embodiment, frequency multiplexing is accomplished by passing a band-limited portion of stimulating electrode output signal {SEOS} via the stimulator output path  {\textbar} 111 {\textbar}  to intracranial stimulating electrode array  {\textbar} 37 {\textbar}  while simultaneously monitoring activity on intracranial stimulating electrode array  {\textbar} 37 {\textbar}  within a separate frequency band, thereby generating a stimulating electrode input signal {SEIS}. Thus, stimulating electrode input signal {SEIS} is conducted from the intracranial stimulating electrode array  {\textbar} 37 {\textbar}  to stimulator output path  {\textbar} 111 {\textbar}  to multiplexor  {\textbar} 75 {\textbar}  and via multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  to intracranial stimulating electrode array amplifier  {\textbar} 57 {\textbar} . {\textbar} Multiplexor  {\textbar}   {\textbar} 75 {\textbar}  facilitates conduction between stimulator amplifier output path  {\textbar} 112 {\textbar}  and multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  to allow automated calibration. In this mode, a calibration signal of known amplitude is generated by pulse generator  {\textbar} 73 {\textbar}  and amplified by output amplifier  {\textbar} 74 {\textbar}  which, for calibration purposes, delivers a voltage regulated signal via stimulator amplifier output path  {\textbar} 112 {\textbar}  to multiplexor  {\textbar} 75 {\textbar} . Multiplexor  {\textbar} 75 {\textbar}  conducts amplified calibration signal to multiplexed stimulator recording input path  {\textbar} 113 {\textbar}  which conducts signal to intracranial stimulating electrode amplifier  {\textbar} 57 {\textbar} . {\textbar} Although not included in the illustrative embodiment, multiplexed or intermittent connection of stimulator amplifier output path  {\textbar}   {\textbar} 112 {\textbar}  to the inputs of at least on of the other amplifiers, including {EMG} amplifier  {\textbar} 59 {\textbar} , {EEG} amplifier  {\textbar} 60 {\textbar} , accelerometer amplifier  {\textbar} 61 {\textbar} , acoustic amplifier  {\textbar} 62 {\textbar} , peripheral nerve electrode amplifier  {\textbar} 63 {\textbar} , and intracranial recording electrode amplifier  {\textbar} 58 {\textbar} , may be implemented without departing from the present invention. The same multiplexed connections may be used to calibrate the pulse generator  {\textbar} 73 {\textbar}  and output amplifier  {\textbar} 74 {\textbar} . {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 15 {\textbar} , an analog switch may be used to connect one or an opposing polarity pair of Zener diodes across the noninverting and inverting inputs of intracranial recording electrode amplifier  {\textbar} 58 {\textbar} . In this configuration, the Zener diodes would limit the maximal amplitude of the calibration signal in one or both polarities to known values, allowing for accurate calibration of intracranial recording electrode amplifier  {\textbar} 58 {\textbar} . The analog switch may then be deactivated, removing the cathode of the single or pair of Zener diodes from the input of intracranial recording electrode amplifier  {\textbar} 58 {\textbar}  to allow measurement of stimulating electrode output signal ({SEOS}) for calibration of pulse generator  {\textbar} 73 {\textbar}  and output amplifier  {\textbar} 74 {\textbar} . This is described in greater detail below. {\textbar} Multiplexor  {\textbar}   {\textbar} 75 {\textbar}  also facilitates conduction between stimulator amplifier output path  {\textbar} 112 {\textbar} , multiplexed stimulator recording input path  {\textbar} 113 {\textbar} , and stimulator output path  {\textbar} 111 {\textbar}  to allow measurement of impedances of components of intracranial stimulating electrode array  {\textbar} 37 {\textbar} . In this electrode impedance measurement mode, a three way connection between stimulator amplifier output path  {\textbar} 112 {\textbar} , multiplexed stimulator recording input path  {\textbar} 113 {\textbar} , and stimulator output path  {\textbar} 111 {\textbar}  is created. When output amplifier  {\textbar} 74 {\textbar}  is operated in current regulated mode, it delivers an {SEOS} of known current via stimulator output path  {\textbar} 111 {\textbar}  to intracranial stimulating electrode array  {\textbar} 37 {\textbar} . The voltages generated across the elements of intracranial stimulating electrode array  {\textbar} 37 {\textbar}  generally are the products of the electrode impedances and the known stimulating currents. These voltages are sensed as the stimulating electrode input signal {SEIS} by the intracranial stimulating electrical amplifier  {\textbar} 57 {\textbar} . {\textbar} Reference module  {\textbar}   {\textbar} 1116 {\textbar}  contains memory registers in which control law reference values are stored. Such reference values include but are not limited to target disease state levels, target symptom levels, including target tremor level, and threshold levels. Threshold levels include but are not limited to disease and symptom levels, including tremor threshold levels. Neural modulation amplitude may be increased when at least one of disease state and symptom level exceed the corresponding threshold. Similarly neural modulation amplitude may be decreased or reduced to zero when either the disease state or symptom level falls below the corresponding threshold. {\textbar} Reference module  {\textbar}   {\textbar} 116 {\textbar}  is connected to patient interface module  {\textbar} 55 {\textbar} , facilitating both monitoring and adjustment of reference values by patient. Reference module  {\textbar} 116 {\textbar}  is also connected to supervisory module  {\textbar} 56 {\textbar} , facilitating both monitoring and adjustment of reference values by physician or other health care provider. Supervisory module  {\textbar} 56 {\textbar}  may be used by the neurologist, neurosurgeon, or other health care professional, to adjust disease state reference R values for the one or more control laws implemented in control circuit  {\textbar} 72 {\textbar} . The disease state reference R values specify the target level at which the corresponding disease states are to be maintained, as quantified by the disease state estimate X values, providing reference values for control laws implemented in control law circuit block  {\textbar} 231 {\textbar}  ( {\textbar} {FIG}. 11 {\textbar} ; discussed below) and contained within control circuit  {\textbar} 72 {\textbar} . Reference module  {\textbar} 116 {\textbar}  may also receive input from control circuit  {\textbar} 72 {\textbar} , facilitating the dynamic adjustment of reference disease state “r” (discussed below). Reference module  {\textbar} 116 {\textbar}  may additionally receive input from disease state estimator module array ({DSEMA})  {\textbar} 229 {\textbar}  ( {\textbar} {FIG}. 11 {\textbar} ; discussed below) and aggregate disease state estimator  {\textbar} 195 {\textbar}  ( {\textbar} {FIG}. 11 {\textbar}  discussed below) and components of signal processor  {\textbar} 71 {\textbar} , for use in dynamically determining reference disease state “r”. {\textbar} {FIG}. 10 {\textbar}   {\textbar}  is a schematic diagram of signal processor  {\textbar} 71 {\textbar} . In this illustrative embodiment, signal processor  {\textbar} 71 {\textbar}  includes a disease state estimator module array  {\textbar} 229 {\textbar}  that includes one or more signal processor modules that generate a quantitative estimate of at least one disease state or parameter thereof based upon its respective input. For example, magnitude of tremor in the 3 to 5 Hz range represents one possible representation of a disease state. This could be an absolute or normalized quantification of limb acceleration in meters per second squared. This component of the disease state would be calculated almost exclusively from sensory feedback from accelerometer array  {\textbar} 52 {\textbar} . Another possible disease state is the frequency of occurrence of episodes of tremor activity per hour. This element of the disease state may be estimated from any of several of the sensory feedback signals. In this case, the most accurate representation of this disease state element is obtained by applying a filter such as a Kalman filter to calculate this parameter based upon a weighted combination of the sensory feedback signals. Such weighting coefficients are calculated from quantified measures of the accuracy of and noise present upon each sensory feedback channel. {\textbar} In the illustrative embodiment, disease state estimator module array  {\textbar}   {\textbar} 229 {\textbar}  includes an {EMG} signal processor  {\textbar} 233 {\textbar} , {EEG} signal processor  {\textbar} 234 {\textbar} , accelerometer signal processor  {\textbar} 235 {\textbar} , acoustic signal processor  {\textbar} 236 {\textbar} , peripheral nerve electrode ({PNE}) signal processor  {\textbar} 237 {\textbar} , intracranial recording electrode ({ICRE}) signal processor  {\textbar} 238 {\textbar} , and intracranial stimulating electrode ({ICSE}) signal processor  {\textbar} 239 {\textbar} . It should be understood that other signal processors may also be included in the array  {\textbar} 229 {\textbar} . Inputs to these modules include conditioned {EMG} signal path  {\textbar} 78 {\textbar} , conditioned {EEG} signal path  {\textbar} 79 {\textbar} , conditioned accelerometer signal path  {\textbar} 80 {\textbar} , conditioned acoustic signal path  {\textbar} 81 {\textbar} , conditioned peripheral nerve electrode ({PNE}) signal path  {\textbar} 82 {\textbar} , conditioned intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar} , and conditioned intracranial stimulating electrode ({ICSE}) signal path  {\textbar} 84 {\textbar} , respectively. Communication between these modules is facilitated. The output(s) of each of the modules is connected to an aggregate disease state estimator  {\textbar} 195 {\textbar} . Aggregate disease state estimator  {\textbar} 195 {\textbar}  generates a single or plurality of disease state estimates “X” indicative of state of disease and response to treatment. {\textbar} In the preferred embodiment, the acceleration of at least one of the affected limb and the head, each of which is sensed as a sensory feedback channel by an element of the accelerometer array  {\textbar}   {\textbar} 52 {\textbar} , serves as respective elements in the disease state estimate X. These elements of disease state estimate X are inputs to respective control laws implemented in control circuit  {\textbar} 72 {\textbar} . of input to the control law. A control law governing the function of a proportional controller using acceleration as its single sensory feedback channel is given by equation (1):  {\textbar} u {\textbar}   {\textbar} 1 {\textbar} =0.3166( {\textbar} V*S {\textbar} 2 {\textbar} /m {\textbar} )* {\textbar} {ACC} {\textbar}   (1) {\textbar} and if {\textbar}   {\textbar} u {\textbar}   {\textbar} 2 {\textbar} =0.6333( {\textbar} V*S {\textbar} 2 {\textbar} /m {\textbar} )* {\textbar} {ACC} {\textbar}   (2) {\textbar}  where u {\textbar}   {\textbar} 1  {\textbar} and u {\textbar} 1  {\textbar} are the stimulation voltage given in volts; and {ACC} is the limb, mandible, or head acceleration given in meters per second squared (m/s {\textbar} 2 {\textbar} ). {\textbar} In equation (1), the stimulation site is the ventroposterolateral pallidum, the output stage mode is voltage regulated, the waveform is a continuous train of square waves, the amplitude u {\textbar}   {\textbar} 1  {\textbar} is given in volts (typically approximately 1 volt), and the remaining stimulation parameters include a pulse width of 210 microseconds, and a stimulation frequency of 130 Hz. In equation (2), the stimulation site is the ventral intermediate thalamic nucleus (Vim), the output stage mode is voltage regulated, the waveform is an intermittent train of square waves with an on time of 5 minutes and an off time of 45 seconds, the amplitude u {\textbar} 2  {\textbar} is given in volts (typically approximately 3 volts), and the remaining stimulation parameters include a pulse width of 60 microseconds, and a stimulation frequency of 130 Hz. {\textbar} In one preferred embodiment, the {ACC} signal represents the average acceleration over a finite time window, typically 15 to 60 seconds. This effective lowpass filtering provides a stable sensory feedback signal for which a proportional control law is appropriate. If stability and performance requirements dictate, as is familiar to those practiced in the art of feedback control, other components, including an integrator and a differentiator may be added to the control law to produce a proportional-integral-differential ({PID}) controller, as needed. {\textbar}   {\textbar} One preferred embodiment also includes electromyographic ({EMG}) signals as sensory feedback in the calculation of at least one element of the disease state estimate X which is an input to the control law. As discussed in the section describing {EMG} signal processor  {\textbar}   {\textbar} 233 {\textbar} , the {EMG} signals are rectified by full wave rectifier  {\textbar} 123 {\textbar} , passed through envelope determiner  {\textbar} 124 {\textbar} , passed through several bandpass filters  {\textbar} 125 {\textbar} ,  {\textbar} 127 {\textbar} ,  {\textbar} 129 {\textbar} ,  {\textbar} 131 {\textbar} ,  {\textbar} 133 {\textbar}  and associated threshold discriminators  {\textbar} 126 {\textbar} ,  {\textbar} 128 {\textbar} ,  {\textbar} 130 {\textbar} ,  {\textbar} 132 {\textbar} ,  {\textbar} 134 {\textbar}  and then passed in parallel to each of integrator  {\textbar} 135 {\textbar}  and counter  {\textbar} 136 {\textbar} . Integrator  {\textbar} 135 {\textbar}  generates an output which is a weighted function of it inputs and represents the average magnitude of tremor activity over a given time window −w/2 to +w/2. A simplified representation of this is given by equation (3): {\textbar} u {\textbar}   {\textbar} 3 {\textbar} = {\textbar} ∫ {\textbar} - {\textbar} w {\textbar} / {\textbar} 2 {\textbar} w {\textbar} / {\textbar} 2 {\textbar} ⁢ {\textbar} X {\textbar} {EMG} {\textbar} - {\textbar} ⁢ {\textbar} ⅆ {\textbar} t {\textbar} ( {\textbar} 3 {\textbar} ) {\textbar}  over a given time window −w/2 to +w/2. A simplified representation of this is given by the equation: {\textbar}   {\textbar} As is familiar to those skilled in the art of control theory, an integral controller is marginally stable. To confer stability to this control law, the equivalent of a finite leak of the output magnitude u.sub.4 to zero is added to maintain stability. A more general form of this equation is given by equation (4):  {\textbar}   {\textbar} − {\textbar}   {\textbar} C {\textbar} 1 {\textbar} ∂C {\textbar} 4 {\textbar} /dt+C {\textbar} 2 {\textbar} ·u {\textbar} 4 {\textbar} =B {\textbar} 1 {\textbar} ·∂X {\textbar} {EMG} {\textbar} /dt+B {\textbar} 2 {\textbar} ·X {\textbar} {EMG} {\textbar}   (4) {\textbar} Shown as a system function, the control law output U is given as the product of a transfer function H(s) and the disease estimate X, the input to the control law:  {\textbar}   {\textbar} u {\textbar}   {\textbar} ( {\textbar} s {\textbar} )( {\textbar} C {\textbar} 1 {\textbar} ∘s+C {\textbar} 2 {\textbar} )= {\textbar} X {\textbar} {EMG} {\textbar} ( {\textbar} s {\textbar} )( {\textbar} B {\textbar} 1 {\textbar} ∘s+B {\textbar} 2 {\textbar} )  (5) {\textbar} u {\textbar}   {\textbar} ( {\textbar} s {\textbar} )/ {\textbar} X {\textbar} {EMG} {\textbar} ( {\textbar} s {\textbar} )=( {\textbar} B {\textbar} 1 {\textbar} ∘s+B {\textbar} 2 {\textbar} )/( {\textbar} C {\textbar} 1 {\textbar} ∘s+C {\textbar} 2 {\textbar} )  (6) {\textbar} H {\textbar}   {\textbar} ( {\textbar} s {\textbar} )= {\textbar} U {\textbar} ( {\textbar} s {\textbar} )/ {\textbar} X {\textbar} {EMG} {\textbar} ( {\textbar} s {\textbar} )=( {\textbar} B {\textbar} 1 {\textbar} ∘s+B {\textbar} 2 {\textbar} )/( {\textbar} C {\textbar} 1 {\textbar} ∘s+C {\textbar} 2 {\textbar} )  (7) {\textbar}  One such control law with an appropriate time response is given by:  {\textbar}   {\textbar} H {\textbar}   {\textbar} ( {\textbar} s {\textbar} )= {\textbar} u {\textbar} ( {\textbar} s {\textbar} )/ {\textbar} X {\textbar} {EMG} {\textbar} ( {\textbar} s {\textbar} )= {\textbar} G {\textbar} {VIEMG} {\textbar} (0.1 {\textbar} ∘s+ {\textbar} 1)/(2 {\textbar} ∘s+ {\textbar} 1)  (8) {\textbar}  where G {\textbar}   {\textbar} V/{EMG}  {\textbar} is the gain in neuromodulation signal ({NMS}) (volts per volt of {EMG} signal). {\textbar} For intramuscular {EMG} electrodes, signal amplitudes are on the order of 100 microvolts. For neuromodulation signal ({NMS}) parameters of 2 volts amplitude, 60 microseconds pulse width, 130 Hz stimulation frequency, the appropriate overall gain G′ {\textbar}   {\textbar} v/{EMG}  {\textbar} is 20,000 volts {\textbar} {NMS} {\textbar} /volts {\textbar} {EMG} {\textbar} . Since the preamplifier stage performs amplification,  {\textbar} 1000 {\textbar} , in the preferred embodiment, the actual value for G {\textbar} v {\textbar} /{EMG} as implemented in the control law is 20 volts {\textbar} {NMS} {\textbar} /volts {\textbar} {PREAMPL} {EMG} {\textbar} . {\textbar} Disease state estimator  {\textbar}   {\textbar} 195 {\textbar}  determines estimates of disease state including but not limited to long-term, or baseline, components, circadian components, postprandial components, medication induced alleviation of components, medication induced components, and future predicted behavior of said components. Output of disease state estimator  {\textbar} 195 {\textbar}  includes output of observer  {\textbar} 228 {\textbar} , depicted in  {\textbar} {FIG}. 11 {\textbar} , which makes use of an adaptive model of disease behavior to estimate disease states which are not directly detectable from sensors. Such sensors provide input to the adaptive model to correct state estimates and model parameters. Each of the signal processor modules in disease state estimator module array  {\textbar} 229 {\textbar}  are described below. {\textbar} {FIG}. 3 {\textbar}   {\textbar}  is a block diagram of intracranial recording electrode ({ICRE}) signal processor  {\textbar} 238 {\textbar}  and intracranial stimulating electrode ({ICSE}) signal processor  {\textbar} 239 {\textbar} , each of which are included within signal processor  {\textbar} 71 {\textbar}  in the illustrative embodiment illustrated in  {\textbar} {FIGS}. 2 and 10 {\textbar} . {ICRE} signal processor module  {\textbar} 238 {\textbar}  and {ICSE} signal processor module  {\textbar} 239 {\textbar}  process signals from one or more intracranial electrodes, including but not limited to those comprising intracranial recording electrode array  {\textbar} 38 {\textbar}  and intracranial stimulating electrode array  {\textbar} 37 {\textbar} . As noted, intracranial stimulating electrode array  {\textbar} 37 {\textbar}  is comprised of one or more intracranial stimulating electrodes while intracranial recording electrode array  {\textbar} 38 {\textbar}  is comprised of one or more intracranial recording electrodes. {\textbar} Input to {ICRE} signal processor  {\textbar}   {\textbar} 238 {\textbar}  is conditioned intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar}  noted above. This input is connected to a spike detector  {\textbar} 85 {\textbar}  which identifies action potentials. Spike detection techniques are well known to those skilled in the art and generally employ low and high amplitude thresholds. Waveforms having amplitudes greater than the low threshold and lower than the high threshold are determined to be action potentials. These thresholds may be predetermined or adjusted manually using supervisory module  {\textbar} 56 {\textbar}  or may be adapted in real-time by an algorithm which sweeps the threshold through a range of values to search for values at which action potential spikes are consistently recorded. The low amplitude threshold is set above the amplitude of background noise and that of nearby cells not of interest, and the high amplitude threshold is set above the amplitude of the desired action potentials to allow their passage while eliminating higher amplitude noise spikes, such as artifacts arising from electrical stimulation currents. Bandpass, notch, and other filtering techniques may also be used to improve signal to noise ratio and the sensitivity and specificity of spike detectors. Individual neuron action potentials are usually recorded using fine point high-impedance electrodes, with impedances typically ranging from 1 to 5 megohms. Alternatively, larger lower-impedance electrodes may be used for recording, in which case the signals obtained typically represent aggregate activity of populations of neurons rather than action potentials from individual neurons. Spike detector  {\textbar} 85 {\textbar}  passes the waveform(s) to a spike characterizer  {\textbar} 86 {\textbar} . Spike characterizer  {\textbar} 86 {\textbar}  determines firing patterns of individual neurons. The patterns include, for example, tonic activity, episodic activity, and burst firing. Spike characterizer  {\textbar} 86 {\textbar}  calculates parameters that characterize the behavior of the individual and groups of neurons, the activity of which is sensed by intracranial recording electrode array  {\textbar} 38 {\textbar} . In one embodiment, the characterization includes parameterization of recorded action potentials, also referred to as spikes, bursts of spikes, and overall neural activity patterns. This parameterization includes, but is not limited to, calculation of frequencies of spikes, frequencies of bursts of spikes, inter-spike intervals, spike amplitudes, peak-to-valley times, valley-to-peak times, spectral composition, positive phase amplitudes, negative phase amplitudes, and positive-negative phase differential amplitudes. These parameters are depicted in  {\textbar} {FIG}. 14 {\textbar}  and are discussed below. Based on these parameterization, spike characterizer  {\textbar} 86 {\textbar}  discriminates individual spikes and bursts originating from different neurons. This discrimination facilitates serial monitoring of activity of individual and groups of neurons and the assessment and quantification of activity change, reflective of change in disease state and of response to therapy. {\textbar} A spike analyzer  {\textbar}   {\textbar} 87 {\textbar}  receives as input the parameters from spike characterizer  {\textbar} 86 {\textbar} . Spike analyzer  {\textbar} 87 {\textbar}  extracts higher level information, including but not limited to average spike frequencies, average interspike intervals, average amplitudes, standard deviations thereof, trends, and temporal patterning. By comparing current spike frequency rates to historical spike frequency data, spike analyzer  {\textbar} 87 {\textbar}  additionally calculates the rates of change of spike parameters. Prior trends and current rates of change may then be used to predict future behaviors. Rates of change of the parameters include but are not limited to autocorrelation and digital filtering. {\textbar} Spike analyzer  {\textbar}   {\textbar} 87 {\textbar}  may receive additional input from accelerometers, including but not limited to at least one of head mounted accelerometer  {\textbar} 12 {\textbar} , proximal accelerometer  {\textbar} 28 {\textbar} , enclosure mounted accelerometer- {\textbar} 36 {\textbar} , and distal accelerometer  {\textbar} 33 {\textbar} . Spike analyzer  {\textbar} 87 {\textbar}  may receive indirect input from accelerometers, such as from conditioned or processed signals arising therefrom. This may include, for example, the signal transmitted by conditioned accelerometer signal path  {\textbar} 80 {\textbar} . {\textbar} Spike analyzer  {\textbar}   {\textbar} 87 {\textbar}  may also receive additional input from {EMG} arrays  {\textbar} 50 {\textbar} , such as a proximal {EMG} electrode array  {\textbar} 45 {\textbar} , enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar} , or distal {EMG} electrode array  {\textbar} 47 {\textbar} . Spike analyzer  {\textbar} 87 {\textbar}  may receive indirect input from such {EMG} electrode arrays  {\textbar} 50 {\textbar} , such as from conditioned or processed signals arising therefrom, including but not limited to the signal transmitted by conditioned {EMG} signal path  {\textbar} 78 {\textbar} . {\textbar} These additional inputs from accelerometers and {EMG} arrays facilitates the characterization of neuronal firing patterns relative to activity of muscle groups and movement of joints, including but not limited to characterization of neuronal spike amplitudes and tuning of firing to movement, including but not limited to movement velocity and direction. The characterization may be used to assess functioning of the sensorimotor system, including but not limited to motor response time, and to measure the disease state and response to therapy. {\textbar}   {\textbar} Intracranial recording electrode ({ICRE}) single unit-based ({SU}) disease state estimator  {\textbar}   {\textbar} 88 {\textbar}  receives input from spike characterizer  {\textbar} 86 {\textbar}  and/or spike analyzer  {\textbar} 87 {\textbar} . Spike analyzer  {\textbar} 87 {\textbar}  provides higher level information, including but not limited to average spike frequencies, average interspike intervals, average amplitudes, standard deviations thereof, trends, and temporal patterning to disease state estimator  {\textbar} 88 {\textbar} . These inputs are representative of the current neuronal activity in the tissue from which the intracranial recording electrodes ({ICRE}) are recording. {ICRE} {SU} disease state estimator  {\textbar} 88 {\textbar}  may also receive input representative of one or more signals, including desired neuronal activity, from control circuit  {\textbar} 72 {\textbar} . The {ICRE} {SU} disease state estimate X {\textbar} {ICRE} {\textbar} \_ {\textbar} su  {\textbar} calculated by {ICRE} {SU} disease state estimator  {\textbar} 88 {\textbar} , may be comprised of a single or a plurality of signals, consistent with a representation of the disease state by a single or a multitude of state variables, respectively. The {ICRE} {MU} disease state estimate X {\textbar} {ICRE} {\textbar} \_ {\textbar} {MU}  {\textbar} calculated by {ICRE} {MU} disease state estimator  {\textbar} 88 {\textbar} , may be comprised of a single or a plurality of signals, each representative of multiunit neurophysiological signals, i.e. reflective of concurrent activity of numerous neurons. Both {ICRE} {SU} disease state estimate X {\textbar} {ICRE} {\textbar} \_ {\textbar} {SU}  {\textbar} and {ICRE} {MU} disease state estimate X {\textbar} {ICRE} {\textbar} \_ {\textbar} {MU}  {\textbar} are output to aggregate disease state estimator  {\textbar} 195 {\textbar} . {\textbar} Referring to  {\textbar}   {\textbar} {FIG}. 3 {\textbar} , conditioned intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar}  additionally connects to filter  {\textbar} 101 {\textbar} . Filter  {\textbar} 101 {\textbar}  is preferably of the bandpass type filter. In one embodiment, the bandpass filter  {\textbar} 101 {\textbar}  has a passband of 0.1 to 100 Hz, although other ranges may be used. Output of filter  {\textbar} 101 {\textbar}  connects to spectral energy characterizer  {\textbar} 102 {\textbar} , which may be implemented in any of several hardware or software forms. For example, in one embodiment, the spectral energy characterizer  {\textbar} 102 {\textbar}  is implemented using real-time fast Fourier transform ({FFT}) techniques. Alternatively, other digital or analog techniques may also be used. {\textbar} It should be understood that inputs and outputs from spike detector  {\textbar}   {\textbar} 85 {\textbar} , spike characterizer  {\textbar} 86 {\textbar} , spike analyzer  {\textbar} 87 {\textbar} , disease state estimator  {\textbar} 88 {\textbar} , filter  {\textbar} 101 {\textbar} , spectral energy characterizer  {\textbar} 102 {\textbar} , spectral energy analyzer  {\textbar} 103 {\textbar} , and disease state estimator  {\textbar} 104 {\textbar}  may be comprised of individual signals or a plurality of signals. Further, spike detector  {\textbar} 85 {\textbar} , spike characterizer  {\textbar} 86 {\textbar} , spike analyzer  {\textbar} 87 {\textbar} , disease state estimator  {\textbar} 88 {\textbar} , filter  {\textbar} 101 {\textbar} , spectral energy characterizer  {\textbar} 102 {\textbar} , spectral energy analyzer  {\textbar} 103 {\textbar} , and disease state estimator  {\textbar} 104 {\textbar}  may each have different parameters and signal processing characteristics for each of the multiple signals processed. Because baseline neuronal firing rates differ among various anatomical and functional regions of the brain, and their involvement in disease states and susceptibility to change in firing patterns varies, the respective signal processing circuitry and logic will vary correspondingly. For example, baseline firing rates among neurons in the globus pallidus externus are approximately 43 Hz and those in the globus pallidus internus are 59 Hz. {\textbar} The input to intracranial stimulating electrode {ICSE} signal processor  {\textbar}   {\textbar} 239 {\textbar} , referred to above as conditioned intracranial stimulating electrode ({ICSE}) signal path  {\textbar} 84 {\textbar} , connects to spike detector  {\textbar} 89 {\textbar} . Spike detector  {\textbar} 89 {\textbar}  identifies action potentials in a manner similar to that described above with reference to spike detector  {\textbar} 85 {\textbar} . Intracranial stimulating electrode {ICSE} signal processor  {\textbar} 239 {\textbar}  performs a similar set of functions as intracranial recording electrode {ICRE} signal processor  {\textbar} 238 {\textbar}  on a different set of sensory feedback signals. As noted above, spike detection techniques are well known to those skilled in the art. {\textbar} Spike detector  {\textbar}   {\textbar} 89 {\textbar}  passes waveforms to spike characterizer  {\textbar} 90 {\textbar} , which uses well known techniques to calculate parameters than characterize the behavior of the individual and groups of neurons, the activity of which is sensed by intracranial stimulating electrode array  {\textbar} 37 {\textbar} . As noted above with respect to spike characterizer  {\textbar} 86 {\textbar} , this characterization may include parameterization of spikes, bursts of spikes, and overall neural activity patterns. Similarly, the parameterization may include calculation of spike frequencies, burst frequencies, inter-spike intervals, amplitudes, peak-to-valley times, valley-to-peak times, spectral composition, positive phase amplitudes, negative phase amplitudes, and positive-negative phase differential amplitudes. Such characterization of neural spikes is known to those skilled in the art of neurophysiology. Based on this parameterization, spike characterizer  {\textbar} 90 {\textbar}  discriminates individual spikes and bursts originating from different neurons. As noted, such discrimination facilitates serial monitoring of activity of individual and groups of neurons and the assessment and quantification of activity change, reflective of change in disease state and of response to therapy. {\textbar} Spike analyzer  {\textbar}   {\textbar} 91 {\textbar}  receives the parameters from spike characterizer  {\textbar} 90 {\textbar} , and extracts higher level information, including average spike frequencies, average interspike intervals, average amplitudes, standard deviations thereof, trends, and temporal patterning. The function and operation of spike analyzer  {\textbar} 91 {\textbar}  is similar to that described herein with reference to spike analyzer  {\textbar} 87 {\textbar} . Similarly, spike analyzer  {\textbar} 91 {\textbar}  may receive additional input directly or indirectly from accelerometers and/or {EMG} arrays to facilitate the characterization of neuronal firing patterns relative to activity of muscle groups and movement of joints. This may include, for example, characterization of neuronal spike amplitudes and tuning of firing to movement, including but not limited to movement velocity and direction. Such characterization may be used to asses functioning of the sensorimotor system, including but not limited to motor response time, and to measure the disease state and response to therapy. {\textbar} Intracranial stimulating electrode ({ICSE}) single unit-based ({SU}) disease state estimator  {\textbar}   {\textbar} 92 {\textbar}  receives input from either or both spike characterizer  {\textbar} 90 {\textbar}  and spike analyzer  {\textbar} 91 {\textbar} . {ICSE} {SU} disease state estimator  {\textbar} 92 {\textbar}  receives input representative of the current neuronal activity from spike characterizer  {\textbar} 90 {\textbar} . {ICSE} {SU} disease state estimator  {\textbar} 92 {\textbar}  may receive input representative of at least one of several signals, including desired neuronal activity, actual neuronal activity, and the difference between these quantities. The {ICSE} {SU} disease state estimate, calculated by {ICSE} {SU} disease state estimator  {\textbar} 92 {\textbar} , may be comprised of a single or a plurality of signals, consistent with a representation of the disease state by a single or a multitude of state variables, respectively. {\textbar} As with intracranial recording electrode signal processor  {\textbar}   {\textbar} 238 {\textbar} , inputs and outputs from spike detector  {\textbar} 89 {\textbar} , spike characterizer  {\textbar} 90 {\textbar} , spike analyzer  {\textbar} 91 {\textbar} , disease state estimator  {\textbar} 92 {\textbar} , filter  {\textbar} 106 {\textbar} , spectral energy characterizer  {\textbar} 107 {\textbar} , spectral energy analyzer  {\textbar} 108 {\textbar} , and disease state estimator  {\textbar} 109 {\textbar}  may include individual or a plurality of signals, and each may have different parameters and signal processing characteristics for each of the multiple signals processed. Because baseline neuronal firing rates differ among various anatomical and functional regions of the brain, and their involvement in disease states and susceptibility to change in firing patters varies, the respective signal processing circuitry and logic varies correspondingly. {\textbar} {FIG}. 4 {\textbar}   {\textbar}  is a schematic diagram of a globus pallidus  {\textbar} 119 {\textbar}  implanted with stimulating and recording electrodes. Intracranial catheter  {\textbar} 7 {\textbar}  is shown in place with electrode of the intracranial stimulating electrode array  {\textbar} 37 {\textbar}  located within the globus pallidus internus (Gpi)  {\textbar} 120 {\textbar} , including globus pallidus internus internal segment ({GPi},i)  {\textbar} 94 {\textbar}  and globus pallidus internus external segment ({GPi},e)  {\textbar} 95 {\textbar} , and globus pallidus externus ({GPe})  {\textbar} 96 {\textbar} . {\textbar} Intracranial stimulating electrodes  {\textbar}   {\textbar} 1 {\textbar}  and  {\textbar} 2 {\textbar}  are shown implanted in the globus pallidus internus internal segment ({GPi},i)  {\textbar} 94 {\textbar} ; and intracranial stimulating electrodes  {\textbar} 3 {\textbar}  and  {\textbar} 4 {\textbar}  are shown implanted in the globus pallidus internus external segment ({GPi},e)  {\textbar} 95 {\textbar}  and globus pallidus externus ({GPe})  {\textbar} 96 {\textbar} , respectively. It should be understood that this arrangement is illustrative of one preferred embodiment, and other stimulating and recording electrode configurations may be employed without departing from the present invention. {\textbar} The optic tract  {\textbar}   {\textbar} 97 {\textbar}  is shown in its close anatomical relationship to the globus pallidus internus (Gpi)  {\textbar} 120 {\textbar} . The risk inherent in treatment modalities involving irreversible tissue ablation should be apparent; stereotactic errors of only one to several millimeters during lesioning of the globus pallidus internus (Gpi)  {\textbar} 120 {\textbar}  may result in irreversible damage or complete destruction of the optic tract  {\textbar} 97 {\textbar} . Furthermore, the advantage of a system which dynamically adjusts the amplitude of inhibitory electrical stimulus to the globus pallidus  {\textbar} 119 {\textbar}  to minimize said amplitude offers the potential advantage of minimization of side effects including interference with visual signals of the optic tract  {\textbar} 97 {\textbar}  and prevention of overtreatment. {\textbar} Intracranial stimulating electrodes  {\textbar}   {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} , {\textbar} 4 {\textbar}  are shown implanted in the {GPi},i  {\textbar} 94 {\textbar} , {GPi},e  {\textbar} 95 {\textbar} , {GPe}  {\textbar} 96 {\textbar} , respectively. This is one preferred embodiment. Numerous permutations of electrode stimulation site configuration may be employed, including more or fewer electrodes in each of these said regions, without departing from the present invention. Electrodes may be implanted within or adjacent to other regions in addition to or instead of those listed above without departing from the present invention, said other reasons including but not limited to the ventral medial Vim thalamic nucleus, other portion of the thalamus, subthalamic nucleus ({STN}), caudate, putamen, other basal ganglia components, cingulate gyrus, other subcortical nuclei, nucleus locus ceruleus, pedunculopontine nuclei of the reticular formation, red nucleus, substantia nigra, other brainstem structure, cerebellum, internal capsule, external capsule, corticospinal tract, pyramidal tract, ansa lenticularis, white matter tracts, motor cortex, premotor cortex, supplementary motor cortex, other motor cortical regions, somatosensory cortex, other sensory cortical regions, Broca's area, Wernickie's area, other cortical regions, other central nervous system structure, other peripheral nervous system structure, other neural structure, sensory organs, muscle tissue, or other non-neural structure. {\textbar} Referring to  {\textbar}   {\textbar} {FIGS}. 3 and 4 {\textbar} , a small percentage of cells in the globus pallidus internus internal segment  {\textbar} 94 {\textbar}  and globus pallidus internus external segment  {\textbar} 95 {\textbar}  exhibit tremor-synchronous discharges. As noted, at least one of single unit recordings from individual cells and multiple unit recordings from a plurality of cells are processed by signal processor  {\textbar} 71 {\textbar} . The single and multiple unit recordings may be derived from signals arising from intracranial stimulating electrode array  {\textbar} 37 {\textbar} , intracranial recording electrode array  {\textbar} 38 {\textbar} , or other sources. The output from signal processor  {\textbar} 71 {\textbar}  is connected to control circuit  {\textbar} 72 {\textbar}  and the output may represent at least one of disease state, magnitude of symptomatology, response to therapy, other parameter, and combination thereof. {\textbar} Individual electrodes comprising intracranial stimulating electrode array  {\textbar}   {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar}  may each be of the microelectrode type for single unit recordings, macroelectrode type for multiple unit recordings, other electrode type, or a combination thereof, without departing from the spirit of the present invention. In one preferred embodiment, intracranial stimulating electrode array  {\textbar} 37 {\textbar}  consists of macroelectrodes. The macroelectrodes facilitate delivery of stimulation current at a lower charge density (coulombs per unit of electrode surface area) than microelectrodes of the same chemistry and surface treatment. The dimensions of intracranial stimulating electrodes  {\textbar} 1 {\textbar} - {\textbar} 4 {\textbar}  are selected such that the current density, or electrical current divided by electrode surface area, is below the threshold of reversible charge injection for the given electrode material. {\textbar} Standard single cell recording technique, using an electrode with an impedance of typically 1-2 Megohms, involves bandpass filtering with −6 decibel ({dB}) points at 300 and 10,000 Hertz. This filtering, or a modification thereof, may be accomplished by {ICRE} filter  {\textbar}   {\textbar} 65 {\textbar}  and {ICSE} filter  {\textbar} 64 {\textbar} ; alternatively, it may be performed in spike detector  {\textbar} 85 {\textbar}  and spike detector  {\textbar} 89 {\textbar} , respectively, or other portion of stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} {FIG}. 5 {\textbar}   {\textbar}  is a block diagram of one embodiment of an {EMG} signal processor  {\textbar} 233 {\textbar}  which is included in a preferred embodiment of signal processor  {\textbar} 71 {\textbar} . {EMG} signal processor  {\textbar} 233 {\textbar}  processes signals from {EMG} electrode array  {\textbar} 50 {\textbar} , performing functions including but not limited to full wave rectification, envelope determination, bandpass filtering, threshold discrimination, and others described in more detail below, to produce signals indicative of the overall magnitude of tremor as well as the frequency at which tremor episodes occur. As noted, {EMG} electrode array  {\textbar} 50 {\textbar}  includes, but is not limited to, proximal {EMG} electrode array  {\textbar} 45 {\textbar} , enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar} , and distal {EMG} electrode array  {\textbar} 47 {\textbar} . {EMG} electrodes may be located in any implanted or external location without departing from the present invention. For example, electrodes may be located within or in proximity to the hand, forearm, arm foot, calf, leg, abdomen, torso, neck, head, haw, lip, eyelid, larynx, vocal cords, and tongue. {\textbar} Conditioned {EMG} signal path  {\textbar}   {\textbar} 78 {\textbar}  is also connected to a well-known full wave rectifier  {\textbar} 123 {\textbar}  now or later developed. Output from the full wave rectifier  {\textbar} 123 {\textbar}  is coupled to an input of an envelope determiner  {\textbar} 124 {\textbar} . Determination of the envelope of a modulated signal is well known to those skilled in the art of electronics; this may be readily implemented in analog or digital hardware or in software. Output of envelope determiner  {\textbar} 124 {\textbar}  is connected to inputs of filters  {\textbar} 125 {\textbar} ,  {\textbar} 127 {\textbar} ,  {\textbar} 129 {\textbar} ,  {\textbar} 131 {\textbar}  and  {\textbar} 133 {\textbar} . In one embodiment, filters  {\textbar} 125 {\textbar} ,  {\textbar} 127 {\textbar} ,  {\textbar} 129 {\textbar} ,  {\textbar} 131 {\textbar} ,  {\textbar} 133 {\textbar}  implement passbands of approximately 0.1-2 Hz, 2-3 Hz, 3-5 Hz, 7-8 Hz, and 8-13 Hz, respectively. Outputs of filters  {\textbar} 125 {\textbar} ,  {\textbar} 127 {\textbar} ,  {\textbar} 129 {\textbar} ,  {\textbar} 131 {\textbar}  and  {\textbar} 133 {\textbar}  are connected to threshold discriminators  {\textbar} 126 {\textbar} ,  {\textbar} 128 {\textbar} ,  {\textbar} 130 {\textbar} ,  {\textbar} 132 {\textbar} ,  {\textbar} 134 {\textbar} , respectively. {\textbar} Threshold discriminators  {\textbar}   {\textbar} 126 {\textbar} ,  {\textbar} 128 {\textbar} ,  {\textbar} 130 {\textbar} ,  {\textbar} 132 {\textbar} , and  {\textbar} 134 {\textbar}  generate outputs representing episodes of normal voluntary movement (Mv), low frequency intention tremor (Til) resting tremor (Tr), high frequency intention tremor (Tih), and physiologic tremor (Tp), respectively. These outputs are each connected to both of integrator  {\textbar} 135 {\textbar}  and counter  {\textbar} 136 {\textbar} . Integrator  {\textbar} 135 {\textbar}  generates outputs representative of the total activity of each of the above types of movement over at least one period of time. One such time period may be, for example, time since implantation, time since last visit to physician or health care provider, month internal, week interval, day interval, interval since last medication dose, interval since last change in stimulation parameters, weighted average of multiple time windows, and convolution of said activity with arbitrary time window function. {\textbar} Counter  {\textbar}   {\textbar} 136 {\textbar}  generates outputs representative of the number of episodes of each of the above types of movement over at least one period of time. Such period of time may be, for example, time since implantation, time since last visit to physician or health care provider, month interval, week internal, day interval, interval since last medication dose, interval since last change in stimulation parameters, and weighted average of said number of episodes over multiple time windows. Outputs from integrator  {\textbar} 135 {\textbar}  and counter  {\textbar} 136 {\textbar}  are connect to {EMG} analyzer  {\textbar} 137 {\textbar} . {EMG} analyzer  {\textbar} 137 {\textbar}  performs a number of functions including, for example, calculation of proportions of tremor activity which are of the rest and the intention type, ratios of different types of tremor activity, the level of suppression of resting tremor activity with voluntary movement, assessment of temporal patterns of {EMG} activity. {EMG} disease state estimator  {\textbar} 138 {\textbar}  receives inputs from {EMG} analyzer  {\textbar} 137 {\textbar}  and generates output representative of disease state based upon said input. In one preferred embodiment, two disease states are calculated, including a signal representative of the overall magnitude of tremor activity and a signal representative of the frequency of occurrence of tremor events. It should be understood that all signals paths may transmit one or more signals without departing from the present invention. {\textbar} {EMG} signals may be sensed from any individual or group of muscles and processed in a manner including but not limited to the determination of severity and frequency of occurrence of various tremor types. Normal or physiologic tremor includes movement in the 8-13 Hz range and may be used as a normalization for the other types of sensed tremor. The predominant pathological form of tremor exhibited in Parkinson's disease patients is the classical “resting” tremor which includes movements in the 3-5 Hz range which are present at rest and suppressed in the presence of voluntary movement. In the present invention, quantification of this tremor type serves as a heavily weighted sensory input in the assessment of disease state and response to therapy. Parkinson's disease patients may also exhibit intention tremor, of which there are two types. The first type of intention tremor is referred to as “low frequency intention tremor” (Til in the present invention) and consists of movements in the 2-3 Hz range. A second type of intention tremor is referred to as “high frequency intention tremor” Tih in the present invention and consists of irregular movements in the 7-8 Hz range which persist throughout voluntary movement. Other types of tremor having associated movement in other ranges may be sensed and represented by the {EMG} signals. {\textbar}   {\textbar} {EMG} signals from at least one of orbicularis oculi (effecting eye closure), levator palpebrae (effecting eye opening), and other muscles contributing to eyelid movement, may be sensed and processed to determine frequency of eye blinking. Patients with Parkinson's disease exhibit a reduction in eyeblinking frequency from the normal of 20 per minute to 5 to 10 per minute, and this parameter is sensed as a measure of disease severity and response to treatment. Additionally, said {EMG} signals may be sensed and processed for detection and quantification of blepharoclonus, or rhythmic fluttering of the eyelids, and used as a measure of disease state and response to therapy. {EMG} signals, including baseline levels thereof, may be used to quantify rigidity and hypertonus as measures of disease state and response to therapy. Discharge patterns of individual motor units, including but not limited to synchronization of multiple units and distribution of intervals preceding and following discharge, may be used as measures of disease state and response to therapy. {\textbar}   {\textbar} {FIG}. 6 {\textbar}   {\textbar}  is a block diagram of one embodiment of an {EEG} signal processor module  {\textbar} 234 {\textbar}  which is included in embodiments of signal processor  {\textbar} 71 {\textbar} . The {EEG} signal processor module  {\textbar} 234 {\textbar}  processes signals from {EEG} electrode array  {\textbar} 51 {\textbar} . Conditioned {EEG} signal path  {\textbar} 79 {\textbar}  connects to an input of artifact rejecter  {\textbar} 139 {\textbar}  which rejects signals with amplitudes above a threshold. In one embodiment, this threshold is 0.1 {mV}. An output from artifact rejecter  {\textbar} 139 {\textbar}  connects to an input of each of supplementary motor area signal extractor  {\textbar} 140 {\textbar}  and filters  {\textbar} 143 {\textbar} ,  {\textbar} 146 {\textbar} ,  {\textbar} 149 {\textbar} ,  {\textbar} 152 {\textbar} ,  {\textbar} 219 {\textbar} . Filters  {\textbar} 143 {\textbar} ,  {\textbar} 146 {\textbar} ,  {\textbar} 149 {\textbar} ,  {\textbar} 152 {\textbar} , and  {\textbar} 219 {\textbar}  are preferably of the bandpass type with passbands of 13-30 Hz, 8-13′ Hz, 4-7 Hz, 0.1-4 Hz, and 0.1-0.3 Hz, respectively. Each filter output is connected to an input of an associated full wave rectifier  {\textbar} 141 {\textbar} ,  {\textbar} 144 {\textbar} ,  {\textbar} 147 {\textbar} ,  {\textbar} 150 {\textbar} ,  {\textbar} 153 {\textbar} ,  {\textbar} 220 {\textbar} . Each full wave rectifier  {\textbar} 141 {\textbar} ,  {\textbar} 144 {\textbar} ,  {\textbar} 147 {\textbar} ,  {\textbar} 150 {\textbar} ,  {\textbar} 153 {\textbar} ,  {\textbar} 220 {\textbar}  is connected to an input of an associated envelope determiner  {\textbar} 142 {\textbar} ,  {\textbar} 145 {\textbar} ,  {\textbar} 148 {\textbar} ,  {\textbar} 151 {\textbar} ,  {\textbar} 154 {\textbar} , and  {\textbar} 221 {\textbar} , respectively. The envelope determiners generate a signal representative of the envelope of the input signal, typically performed by lowpass filtering with a time constant of 5 seconds. Finally, outputs of envelope determiners  {\textbar} 142 {\textbar} ,  {\textbar} 145 {\textbar} ,  {\textbar} 148 {\textbar} ,  {\textbar} 151 {\textbar} ,  {\textbar} 154 {\textbar} , and  {\textbar} 221 {\textbar}  are connected to {EEG} disease state estimator  {\textbar} 155 {\textbar} . {\textbar} Signal {SMA} generated by supplementary motor area signal extractor  {\textbar}   {\textbar} 140 {\textbar}  represents activity in the supplementary motor area ipsilateral to the intracranial stimulating electrode array ({ISEA})  {\textbar} 37 {\textbar} . Supplementary motor area signal extractor  {\textbar} 140 {\textbar}  amplifies signals which are unique to elements of the {EEG} electrode array  {\textbar} 51 {\textbar}  which overlie the supplementary motor area. The supplementary motor area receives neural signals via neural projections from the basal ganglia and exhibits decreased activity in patients with Parkinson disease. The {SMA} is essential for sequential movements, which are often impaired in Parkinson's disease patients. The {SMA} signal provides a quantitative measure of disease state and response to therapy. The {SMA} signal is extracted from the anterior {EEC} leads, predominantly from those in the vicinity of the frontal cortex, and provides a quantitative measure of disease state and response to therapy. Signals beta, alpha, theta, and delta consist of 13-30 Hz, 8-13 Hz, 4-7 Hz, and 0.14 Hz activity, respectively. {\textbar} Signal “resp” consists of 0.1-0.3 Hz activity and reflects respiration. Parkinson's disease patients exhibit irregular respiratory patterns characterized by pauses and by abnormally deep breathing while at rest and preceding speech. Assessment of respiratory irregularity as well as other parameters derived from such resp signal serve as quantitative measures of disease state and response to therapy. {\textbar}   {\textbar} Anterior {EEG} electrodes are also used to sense {EMG} signals, and the {EMG} signals are processed to determine activity of muscles including but not limited to those related to eye blinking activity. Processing of the {EMG} signals is included in the  {\textbar}   {\textbar} {FIG}. 6 {\textbar}  circuit block diagram which contains the {EEC} signal processing component of signal processor  {\textbar} 71 {\textbar} . However, the processing could be incorporated into {EMG} signal processing component of signal processor  {\textbar} 71 {\textbar}  without departing from scope of the present invention. Conditioned {EEG} signal path  {\textbar} 79 {\textbar}  is additionally connected to input of full wave rectifier  {\textbar} 222 {\textbar} , the output of which is connected to the input of an envelope determiner  {\textbar} 223 {\textbar} . Envelope determiner  {\textbar} 223 {\textbar}  includes an output connected to input of filter  {\textbar} 224 {\textbar} . Filter  {\textbar} 224 {\textbar}  is preferably of the bandpass type with a passband range of 0.1 to 20 Hz. Filter  {\textbar} 224 {\textbar}  has an output connected to input of threshold discriminator  {\textbar} 225 {\textbar} , the output of which is connected to {EEG} disease state estimator  {\textbar} 155 {\textbar} . {\textbar} Preferably, {EMG} signals arising from activity of at least one of orbicularis oculi (effecting eye closure), levator palpebrae (effecting eye opening), and other muscles the activity of which is associated with eyelid movement are sensed by anterior {EEG} electrodes. These {EMG} signals are processed to determine eye blink events, and the rates and regularity of eye blinking activity are calculated. Frequency and irregularity of eyeblinking as well as blepharoclonus, or rhythmic fluttering of the eyelids, are quantified as measures of disease state and response to therapy. {\textbar}   {\textbar} {FIG}. 7 {\textbar}   {\textbar}  is a block diagram of one embodiment of an accelerometer signal processor  {\textbar} 235 {\textbar}  which is incorporated into certain embodiments of signal processor  {\textbar} 71 {\textbar} . The accelerometer signal processor  {\textbar} 235 {\textbar}  processes signals from accelerometer array  {\textbar} 52 {\textbar} . Conditioned accelerometer signal path  {\textbar} 80 {\textbar}  is connected to an input of each of a plurality of filters  {\textbar} 156 {\textbar} ,  {\textbar} 160 {\textbar} ,  {\textbar} 164 {\textbar} ,  {\textbar} 168 {\textbar} ,  {\textbar} 172 {\textbar} . The filters are preferably of the bandpass type with passbands of 0.1-2 Hz, 2-3 Hz, 3-5 Hz, 7-8 Hz, and 8-13 Hz, respectively. Other passband frequency ranges may also be used. The output of each filter  {\textbar} 156 {\textbar} ,  {\textbar} 160 {\textbar} ,  {\textbar} 164 {\textbar} ,  {\textbar} 168 {\textbar} ,  {\textbar} 172 {\textbar}  is connected to an associated full wave rectifiers  {\textbar} 157 {\textbar} ,  {\textbar} 161 {\textbar} ,  {\textbar} 165 {\textbar} ,  {\textbar} 169 {\textbar} , and  {\textbar} 173 {\textbar} , respectively. The output of each rectifier  {\textbar} 157 {\textbar} ,  {\textbar} 161 {\textbar} ,  {\textbar} 165 {\textbar} ,  {\textbar} 169 {\textbar} , and  {\textbar} 173 {\textbar}  is connected to an associated envelope determiners  {\textbar} 158 {\textbar} ,  {\textbar} 162 {\textbar} ,  {\textbar} 166 {\textbar} ,  {\textbar} 170 {\textbar} , and  {\textbar} 174 {\textbar} , respectively. Outputs of envelope determiners  {\textbar} 158 {\textbar} ,  {\textbar} 162 {\textbar} ,  {\textbar} 166 {\textbar} ,  {\textbar} 170 {\textbar} , and  {\textbar} 174 {\textbar}  are connected to inputs of an associated threshold discriminators  {\textbar} 159 {\textbar} ,  {\textbar} 163 {\textbar} ,  {\textbar} 167 {\textbar} ,  {\textbar} 171 {\textbar} , and  {\textbar} 175 {\textbar} , respectively. {\textbar} Outputs of threshold discriminators  {\textbar}   {\textbar} 159 {\textbar} ,  {\textbar} 163 {\textbar} ,  {\textbar} 167 {\textbar} ,  {\textbar} 171 {\textbar} ,  {\textbar} 175 {\textbar}  represent episodes of normal voluntary movement (Mv), low frequency intention tremor (Til), resting tremor (Tr), high frequency intention tremor (Tih), and physiologic tremor (Tp), respectively. These outputs are each connected to an integrator  {\textbar} 176 {\textbar}  and a counter  {\textbar} 177 {\textbar} . Integrator  {\textbar} 176 {\textbar}  generates outputs representative of the total activity of each of the above types of movement over at least one period of time. As noted, such a time period may be, for example, time since implementation, time since last visit to physician or health care provider, or some other time interval, weighted average of multiple time windows, or convolution of selected activities with an arbitrary time window function. {\textbar} Counter  {\textbar}   {\textbar} 177 {\textbar}  generates outputs representative of the number of episodes of each of the above types of movements over at least one such period of time. Outputs from integrator  {\textbar} 176 {\textbar}  and counter  {\textbar} 177 {\textbar}  are connect to an acceleration analyzer  {\textbar} 178 {\textbar} . Acceleration analyzer  {\textbar} 178 {\textbar}  calculates proportions of tremor types, such as the rest and intention types, ratios of different types of tremor activity, the level of suppression of resting tremor activity with voluntary movement, and assessment of temporal patterns of movement and acceleration. Acceleration analyzer  {\textbar} 178 {\textbar}  may perform some or all of these calculations, as well as other calculations, on alternative embodiments of the present invention. Acceleration-based disease state estimator  {\textbar} 179 {\textbar}  receives input from acceleration analyzer  {\textbar} 178 {\textbar}  and generates output representative of disease state based upon such input. {\textbar} It should be understood that accelerometer signals may be sensed from any individual or group of body components. For example, such signals may be sensed from joints, bones, and muscles. Furthermore, such signals may be processed in any well known manner, including the determination of severity and frequency of occurrence of various tremor types. The types of tremor have been described above with respect to  {\textbar}   {\textbar} {FIG}. 5 {\textbar} . {\textbar} {FIG}. 8 {\textbar}   {\textbar}  is a block diagram of one embodiment of an acoustic signal processor  {\textbar} 236 {\textbar}  which is included in certain embodiments of signal processor  {\textbar} 71 {\textbar} . Acoustic signal processor  {\textbar} 236 {\textbar}  processes signals from acoustic transducer array  {\textbar} 53 {\textbar} . Conditioned acoustic signal path  {\textbar} 81 {\textbar}  is connected to a full wave rectifier  {\textbar} 180 {\textbar}  and a spectral analyzer  {\textbar} 185 {\textbar} . The output of full wave rectifier  {\textbar} 180 {\textbar}  is connected to an input of an envelope determiner  {\textbar} 181 {\textbar} , an output of which is connected to an input of a low threshold discriminator  {\textbar} 182 {\textbar}  and a high threshold discriminator  {\textbar} 183 {\textbar} . Low threshold discriminator  {\textbar} 182 {\textbar}  and high threshold discriminator  {\textbar} 183 {\textbar}  each have an output connected to an input of timer  {\textbar} 184 {\textbar} . Timer  {\textbar} 184 {\textbar}  generates an output signal representing latency (Lat) and is connected to acoustic analyzer  {\textbar} 186 {\textbar} . An output of acoustic analyzer  {\textbar} 186 {\textbar}  is connected to an input of acoustic-based disease state estimator  {\textbar} 187 {\textbar} . Latency (Lat) represents the latency between initiation of vocal utterance and the subsequent achievement of a threshold level of vocal amplitude. Such a vocal amplitude level is set by high threshold discriminator  {\textbar} 183 {\textbar}  and may represent steady state vocal amplitude or a preset or dynamically varying threshold. Latency from voice onset to achievement of steady state volume may be delayed in patients with Parkinson's disease and is calculated as a measure of disease state and response to therapy. {\textbar} Acoustic analyzer  {\textbar}   {\textbar} 186 {\textbar}  receives input from spectral analyzer  {\textbar} 185 {\textbar} . The respiratory pattern is determined from rhythmic modulation of voice and breathing sounds, sensed by elements of the acoustic transducer array  {\textbar} 53 {\textbar} . Irregularity and pauses in respiration as well as abnormally deep breathing patterns at rest and preceding speech are exhibited in Parkinson's disease patients. Such parameters are quantified and used as estimates of disease state and response to therapy. Respiration durations are quantified; abnormally deep respiration both during rest and preceding speech are identified and used as indicators of disease state and response to therapy. Pauses in speech and decline in speech amplitude, or fading, are additionally monitored as indicators of disease state and response to therapy. Spectral composition of speech is monitored and the change in spectral composition, reflective of changes of pharyngeal and laryngeal geometry, are quantified. Additionally, the fundamental vocal frequency; that is, the frequency at which the epiglottis vibrates, is extracted an that standard deviation of the fundamental vocal frequency is calculated over various time intervals as a quantified measure of the monotonic quality of speech characteristic of Parkinson's disease. This serves as yet another indicator of disease state and response to therapy. {\textbar} {FIG}. 9 {\textbar}   {\textbar}  is block diagram of one embodiment of a peripheral nerve electrode ({PNE}) signal processor  {\textbar} 237 {\textbar}  which is implemented in certain embodiments of signal processor  {\textbar} 71 {\textbar} . {PNE} signal processor  {\textbar} 237 {\textbar}  processes signals from peripheral nerve electrode array  {\textbar} 54 {\textbar} . These signals provided by peripheral nerve electrode array  {\textbar} 54 {\textbar}  are provided to {PNE} signal processor  {\textbar} 237 {\textbar}  via conditioned {PNE} signal path  {\textbar} 82 {\textbar} . Conditioned {PNE} signal path  {\textbar} 82 {\textbar}  is connected to an input of a spike detector  {\textbar} 188 {\textbar}  and a filter  {\textbar} 191 {\textbar} . {\textbar} Spike detector  {\textbar}   {\textbar} 188 {\textbar}  identifies action potentials. As noted, spike detection techniques are well known to those skilled in the art, and generally employ low and high amplitude thresholds. Waveforms with amplitudes greater than the low threshold and lower than the high threshold are determined to be action potentials. These thresholds may be adjusted in real-time, and the low amplitude threshold is set above the amplitude of background noise and that of nearby cells not of interest, and the high amplitude threshold is set above the amplitude of the desired action potentials to allow their passage while eliminating higher amplitude noise spikes, such as artifacts arising from electrical stimulation currents. It should be understood that bandpass, notch, and other filtering techniques may also used to improve signal to noise ratio and the sensitivity and specific of spike detectors. Individual neuron action potentials are usually recorded using fine point high-impedance electrodes, with impedances typically ranging from 1 to 5 megohms. Alternatively, larger lower-impedance electrodes may be used for recording, in which case the signals obtained typically represent aggregate activity of populations of neurons rather than action potentials from individual neurons. As noted above, peripheral nerve electrode array  {\textbar} 54 {\textbar}  may include such electrodes as single unit recording microelectrodes, multiple unit recording microelectrodes, intrafascicular electrodes, other intraneural electrodes, epineural electrodes, and any combination thereof. {\textbar} A spike characterizer  {\textbar}   {\textbar} 189 {\textbar}  determines firing patterns of individual neurons, including, for example, tonic activity, episodic activity and burst firing. Spike characterizer  {\textbar} 189 {\textbar}  receives the signals passed by spike detector  {\textbar} 188 {\textbar}  and calculates parameters that characterize the behavior of the individual and groups of neurons, the activity of which is sensed by peripheral nerve electrode array  {\textbar} 54 {\textbar} . Such characterization includes but is not limited to parameterization of spikes, bursts of spikes, and overall neural activity patterns. Parameterization includes but is not limited to calculation of frequencies of spikes, frequencies of bursts of spikes, inter-spike intervals, spike amplitudes, peak-to-valley times, valley-to-peak times, spectral composition, positive phase amplitudes, negative phase amplitudes, and positive-negative phase differential amplitudes. These parameters are described in further detail below with reference to  {\textbar} {FIG}. 14 {\textbar} . Based on this parameterization, spike characterizer  {\textbar} 189 {\textbar}  discriminates individual spikes and bursts originating from different neurons. The discrimination facilitates aerial monitoring of activity of individual and groups of neurons and the assessment and quantification of activity change, reflective of change in disease state and of response to therapy. {\textbar} A spike analyzer  {\textbar}   {\textbar} 190 {\textbar}  receives as input the parameters from spike characterizer  {\textbar} 189 {\textbar} , and extracts higher level information, including but not limited to average spike frequencies, average frequencies o bursts of spikes, average interspike intervals, average spike amplitudes, standard deviations thereof, trends, and temporal patterning. {\textbar} Preferably, spike analyzer  {\textbar}   {\textbar} 190 {\textbar}  additionally calculates the rates of change of spike parameters. From prior and current rates of change, future behaviors may be predicted. Rates of change of the parameters include but are not limited to first, second, and third time derivatives. In alternative embodiments, spike analyzer  {\textbar} 190 {\textbar}  additionally calculates weighted combinations of spike characteristics and performs convolutions of spike waveforms with other spike waveforms, and other preset and varying waveforms. Such operations may be performed, for example, for purposes including but not limited to autocorrelation and digital filtering. {\textbar} Spike analyzer  {\textbar}   {\textbar} 190 {\textbar}  may receive additional input from accelerometers, such as those described above, including head mounted accelerometer  {\textbar} 12 {\textbar} , proximal accelerometer  {\textbar} 28 {\textbar} , enclosure mounted accelerometer  {\textbar} 36 {\textbar} , and distal accelerometer  {\textbar} 33 {\textbar} . Spike analyzer  {\textbar} 190 {\textbar}  may receive indirect input from these or other accelerometers, as well as from conditioned or processed signals arising therefrom. Such conditioned or processed signals include, for example, the signal transmitted by conditioned accelerometer signal path  {\textbar} 80 {\textbar}  ( {\textbar} {FIG}. 7 {\textbar} ). {\textbar} Spike analyzer  {\textbar}   {\textbar} 190 {\textbar}  may receive additional input from {EMG} arrays. As noted, such {EMG} arrays may include, for example, proximal {EMG} electrode array  {\textbar} 4 {\textbar} S, enclosure-mounted {EMG} electrode array  {\textbar} 46 {\textbar} , and distal {EMG} electrode array  {\textbar} 47 {\textbar} . Spike analyzer  {\textbar} 190 {\textbar}  may also receive indirect input from these or other {EMG} electrode arrays, as well as from conditioned or processed signals arising therefrom. Such conditioned or processed signals include but are not limited to the signal transmitted by conditioned {EMG} signal path  {\textbar} 78 {\textbar}  ( {\textbar} {FIG}. 5 {\textbar} ). These additional inputs from accelerometers and {EMG} arrays facilitates the characterization of neuronal firing patterns relative to activity of muscle groups and movement of joints. Such characterization may include, for example, characterization of neuronal spike amplitudes and tuning of neuronal spike frequencies to movement, including but not limited to the signal transmitted by conditioned {EMG} signal path  {\textbar} 78 {\textbar} . {\textbar} The additional input from accelerometers and {EMG} arrays also facilitates the characterization of neuronal firing patterns relative to activity of muscle groups and movement of joints, including but not limited to characterization of neuronal spike amplitudes and tuning of neuronal spike frequencies to movement, including but not limited to movement velocity and direction. These characterizations may be used to assess functioning of the sensorimotor system, including but not limited to motor response time, and to measure the disease state and response to therapy. {\textbar}   {\textbar} Peripheral nerve electrode ({PNE})-based single unit ({SU}) disease state estimator  {\textbar}   {\textbar} 194 {\textbar}  receives an input representative of the current neuronal activity from spike characterizer  {\textbar} 189 {\textbar} . {PNE}-based single unit disease state estimator  {\textbar} 194 {\textbar}  may receive input representative of at least one of several signals, including desired neuronal activity, actual neuronal activity, and the difference between these quantities. The output from estimator  {\textbar} 194 {\textbar}  may carry a single or a plurality of signals, consistent with a representation of the disease state by a single or a multitude of state variables, respectively. {\textbar} Filter  {\textbar}   {\textbar} 191 {\textbar}  has an output connected to an input of spectral energy characterizer  {\textbar} 192 {\textbar} . Spectral energy characterizer  {\textbar} 192 {\textbar}  calculates the spectral composition of the signals sensed by the peripheral nerve electrode array  {\textbar} 54 {\textbar} . Spectral energy characterizer  {\textbar} 192 {\textbar}  provides outputs to each of spectral energy analyzer  {\textbar} 193 {\textbar}  and peripheral nerve electrode ({PNE})-based multiple unit disease state estimator  {\textbar} 232 {\textbar} . Output of spectral energy analyzer  {\textbar} 193 {\textbar}  is connected to an input of {PNE}-based multiple unit ({MU}) disease state estimator  {\textbar} 232 {\textbar} . {PNE} {SU} disease state estimator  {\textbar} 194 {\textbar}  both receives input from and provides output to {PNE} {MU} disease state estimator  {\textbar} 232 {\textbar} . {\textbar} {PNE} {MU} disease state estimator  {\textbar}   {\textbar} 232 {\textbar}  receives as an input signals representative of the current neuronal activity from spectral energy characterizer  {\textbar} 192 {\textbar} . {PNE} {MU} disease state estimator  {\textbar} 232 {\textbar}  may receive input representative of at least one of several signals, including desired neuronal activity, actual neuronal activity, and the difference between these quantities. The output from {PNE} {MU} disease state estimator  {\textbar} 232 {\textbar}  may carry a single or a plurality of signals, consistent with a representation of the disease state by a single or a multitude of state variables, respectively. {\textbar} It should be understood that inputs and outputs from each spike detector  {\textbar}   {\textbar} 188 {\textbar} , spike characterizer  {\textbar} 189 {\textbar} , spike analyzer  {\textbar} 190 {\textbar} , filter  {\textbar} 191 {\textbar} , spectral energy characterizer  {\textbar} 192 {\textbar} , spectral energy analyzer  {\textbar} 193 {\textbar} , and {PNE}-based single unit disease state estimator  {\textbar} 194 {\textbar} , and {PNE}-based multiple unit disease state estimator  {\textbar} 232 {\textbar}  may each be comprised of individual signals or a plurality of signals. It should also be understood that each of these the units, spike detector  {\textbar} 188 {\textbar} , spike characterizer  {\textbar} 189 {\textbar} , spike analyzer  {\textbar} 190 {\textbar} , filter  {\textbar} 191 {\textbar} , spectral energy characterizer  {\textbar} 192 {\textbar} , spectral energy analyzer  {\textbar} 193 {\textbar} , and {PNE}-based single unit disease state estimator  {\textbar} 194 {\textbar} , and {PNE} {MU} disease state estimator  {\textbar} 232 {\textbar}  may each have different parameters and signal processing characteristics for each of the multiple signals processed. Modifications of this processing circuitry may be made to accommodate various combinations of intraneural electrodes, used for single and multiple unit recordings, and epineural electrodes, used for compound action potential recordings, without departing from the present invention. {\textbar} {FIG}. 11 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of a patient-neural modulator system  {\textbar} 999 {\textbar}  illustrated in  {\textbar} {FIG}. 2 {\textbar}  with feedback control. Patient-neural modulator system  {\textbar} 999 {\textbar}  primarily includes an observer  {\textbar} 228 {\textbar}  and a controller  {\textbar} 229 {\textbar} . An observer is a component of a control system that is known to those or ordinary skill in the art of control systems. An observer is a functional block in which variables, typically represented in software as parameter values or in hardware as electrical signal amplitudes, represent states of the controlled system. Such a component is used in controlling systems in which one or more of the state variables are not directly observable from the sensed signals. An observer essentially includes a simulated version of the controlled system. Its input are the same control law output signals delivered to the controlled system, and its outputs are desired to match those sensed outputs of the controlled system. The difference between the outputs of the observer and the measured outputs of the controlled system, that is, the outputs of a motor control portion of the patient's nervous system in this case, are used to calculate an observer error signal which may then be used to correct the observer error. Since the observer is implemented in software or hardware, all of its signals, including all state variables, are accessible. In a system such as the complex neural circuitry of the patient, one or more of the state variables may not be “observable”, that is directly measurable or calculatable based on measured values. In such a case, the state variables present in the observer may be used as “estimates” of the actual state variables and included in the control law. The general use of “observers” for estimation of “unobservable” state variables is known to those skilled in the art of control theory. The use of observers for the estimation of neural state variables, disease states, and responses to therapy is one of the teachings of the present invention. {\textbar} Observer  {\textbar}   {\textbar} 228 {\textbar}  includes signal conditioning circuit  {\textbar} 76 {\textbar}  ( {\textbar} {FIG}. 2 {\textbar} ) and signal processor  {\textbar} 71 {\textbar}  ( {\textbar} {FIGS}. 2, 10 {\textbar} ). Signal processor  {\textbar} 71 {\textbar} , as noted, includes disease state estimator module array ({DSEMA})  {\textbar} 229 {\textbar}  and aggregate disease state estimator  {\textbar} 195 {\textbar} . Observer  {\textbar} 228 {\textbar}  receives patient output “y” from patient  {\textbar} 227 {\textbar} . Patient output “y” is comprised of one or more signals arising from patient  {\textbar} 227 {\textbar} . In one preferred embodiment patient output “y” includes one or more signals from {EMG} electrode array  {\textbar} 50 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , accelerometer array  {\textbar} 52 {\textbar} , acoustic transducer array  {\textbar} 53 {\textbar} , peripheral nerve electrode array  {\textbar} 54 {\textbar} , intracranial recording electrode array  {\textbar} 38 {\textbar} , and intracranial stimulating electrode array  {\textbar} 37 {\textbar} . It should be understood that additional signals f the same or different type may also be included. {\textbar} Control circuit  {\textbar}   {\textbar} 72 {\textbar}  ( {\textbar} {FIG}. 2 {\textbar} ) includes summator  {\textbar} 226 {\textbar}  which receives an input from reference module  {\textbar} 116 {\textbar} , and a control law circuit block  {\textbar} 231 {\textbar} . Controller  {\textbar} 229 {\textbar}  includes the control law circuit lock  {\textbar} 231 {\textbar}  and output stage circuit  {\textbar} 77 {\textbar} . Controller  {\textbar} 229 {\textbar}  generates a neural modulation waveforms “u”, described in detail below with reference to  {\textbar} {FIG}. 13 {\textbar} . The function and operation of each of these modules is described in detail below. {\textbar} Reference disease state “r”, generated by reference module  {\textbar}   {\textbar} 116 {\textbar} , is a non-inverting input to summator  {\textbar} 226 {\textbar} , providing disease state and target reference values for the single or plurality of control laws implemented in control law circuit block  {\textbar} 231 {\textbar}  introduced above with reference to  {\textbar} {FIG}. 2 {\textbar} . Reference module  {\textbar} 116 {\textbar}  may also receive input from control circuit  {\textbar} 72 {\textbar} , facilitating the dynamic adjustment of reference values. Reference disease state “r” may comprise a single or plurality of signals, each of which may be zero, constant, or time-varying independent of the other. Disease state error “e” is output from summator  {\textbar} 226 {\textbar}  and input to controller  {\textbar} 229 {\textbar} . Disease state error “e”, which may comprise a single or plurality of signals, represents a difference between a desired disease state (represented by reference disease state “r”) and an actual disease state (represented by disease state estimate “x”). Other methods of calculating disease state estimate “x”, including but not limited to linear or nonlinear combinations of reference disease state “r” and disease state estimate “x”, may be employed without departing from the present invention. Controller  {\textbar} 229 {\textbar}  is comprised of control law circuit block  {\textbar} 231 {\textbar}  and output stage circuit  {\textbar} 77 {\textbar} . {\textbar} Disease state error “e” is input to control law circuit block  {\textbar}   {\textbar} 231 {\textbar}  which generates a control circuit output “uc.” Control law circuit block  {\textbar} 231 {\textbar}  is connected to an input of output stage circuit  {\textbar} 77 {\textbar} . The output of the controller  {\textbar} 229 {\textbar} , which is generated by the output stage circuit  {\textbar} 77 {\textbar} , “u”, is delivered to patient  {\textbar} 227 {\textbar}  in the form of neural modulation waveforms, described in detail below with reference to  {\textbar} {FIG}. 13 {\textbar} . {\textbar} Patient output “y” is input to signal conditioning circuit  {\textbar}   {\textbar} 76 {\textbar} , the output of which is connected to the input of {DSEMA}  {\textbar} 229 {\textbar} . The output of {DSEMA}  {\textbar} 229 {\textbar}  is provided to an aggregate disease state estimator  {\textbar} 195 {\textbar} , the output of which is the disease state estimate x. Disease state estimate x, which may be comprised of a single or plurality of signals, is an inverting input to summator  {\textbar} 226 {\textbar} . {\textbar} Control law circuit block  {\textbar}   {\textbar} 231 {\textbar}  receives disease state estimate x as an additional input, for use in nonlinear, adaptive and other control laws. Reference module  {\textbar} 116 {\textbar}  receives input from {DSEMA}  {\textbar} 229 {\textbar}  and aggregate disease state estimator  {\textbar} 195 {\textbar}  for use in dynamically determining reference disease state r. Other modifications, including substitutions, additions, and deletions, may be made to the control loop without departing from the present invention. {\textbar} Control law circuit block  {\textbar}   {\textbar} 231 {\textbar}  has an autocalibration mode in which multivariable sweeps through stimulation parameters and stimulating electrode configurations are performed to automate and expedite parameter and configuration optimization. This autocalibration feature enables rapid optimization of treatment, eliminating months of iterations of trial and error in optimizing stimulation parameters and electrode configuration necessitated by the prior technique of constant parameter stimulation. Additionally, this autocalibration feature permits real-time adjustment and optimization of stimulation parameters and electrode configuration. This is particularly useful to overcome increases in electrode impedance which result from the body's normal response to implanted foreign bodies in which a fibrotic capsule is commonly formed around the electrodes. Effects of shifts in electrode position relative to a target structures may be minimized by said autocalibration feature. Detection of changes in electrode impedance and position are facilitated by autocalibration feature. The autocalibration feature facilitates detection of changes in electrode impedance and position. Notification of patient and health care provider allows proactive action, including automated or manual adjustment of treatment parameters and advance knowledge of impending electrode replacement needs. {\textbar} {FIG}. 12 {\textbar}   {\textbar}  is a schematic diagram of control circuit  {\textbar} 72 {\textbar} . As noted, control circuit  {\textbar} 72 {\textbar}  comprises control laws circuit block  {\textbar} 231 {\textbar}  and summator  {\textbar} 226 {\textbar} . Disease state error “e” is input to gain stages of control laws, including but not limited to at least one of proportional gain  {\textbar} 197 {\textbar} , differential gain  {\textbar} 198 {\textbar} , integral gain  {\textbar} 199 {\textbar} , nonlinear gain  {\textbar} 200 {\textbar} , adaptive gain  {\textbar} 201 {\textbar} , sliding gain  {\textbar} 202 {\textbar} , and model reference gain  {\textbar} 203 {\textbar} . {\textbar} An output of each of these gain stages is connected to what is referred to herein as control law stages. In the illustrative embodiment, control law stages includes proportional controller  {\textbar}   {\textbar} 230 {\textbar} , differential controller  {\textbar} 204 {\textbar} , integral controller  {\textbar} 205 {\textbar} , nonlinear controller  {\textbar} 206 {\textbar} , adaptive controller  {\textbar} 207 {\textbar} , sliding controller  {\textbar} 208 {\textbar} , and model reference controller  {\textbar} 209 {\textbar} , respectively. {\textbar} Outputs of these control law stages are connected to weight stages, including proportional controller weight  {\textbar}   {\textbar} 210 {\textbar} , differential controller weight  {\textbar} 211 {\textbar} , integral controller weight  {\textbar} 212 {\textbar} , nonlinear controller weight  {\textbar} 213 {\textbar} , adaptive controller weight  {\textbar} 214 {\textbar} , sliding controller weight  {\textbar} 215 {\textbar} , and model reference controller weight  {\textbar} 216 {\textbar} . Outputs of the weight stages are noninverting inputs to summator  {\textbar} 217 {\textbar} , the output of which is control circuit output “uc”. The weight stages may be any combination of at least one of constant, time varying, and nonlinear without departing from the present invention. {\textbar} Disease state estimate x is input to nonlinear controller  {\textbar}   {\textbar} 206 {\textbar} , adaptive controller  {\textbar} 207 {\textbar} , sliding controller  {\textbar} 208 {\textbar} , and model reference controller  {\textbar} 209 {\textbar} . The control laws depicted are representative of one possible implementation; numerous variations, including substitutions, additions, and deletions, may be made without departing from the present invention. {\textbar} The present invention optimizes the efficiency of energy used in the treatment given to the patient by minimizing to a satisfactory level the stimulation intensity to provide the level of treatment magnitude necessary to control disease symptoms without extending additional energy delivering unnecessary overtreatment. In the definition of the control law, a command input or reference input (denoted as r in  {\textbar}   {\textbar} {FIGS}. 11 and 12 {\textbar} ) specifies the target disease state. In the preferred embodiment, r specifies the target amplitude of tremor. The control law generates an electrical stimulation magnitude just sufficient to reduce the patient's tremor to the target value. With this apparatus and method, the precise amount of electrical energy required is delivered, and overstimulation is avoided. In present stimulation systems, a constant level of stimulation is delivered, resulting in either of two undesirable scenarios when disease state and symptoms fluctuate: (1) undertreatment, i.e. tremor amplitude exceeds desirable level or (2) overtreatment or excess stimulation, in which more electrical energy is delivered than is actually needed. In the overtreatment case, battery life is unnecessarily reduced. The energy delivered to the tissue in the form of a stimulation signal represents a substantial portion of the energy consumed by the implanted device; minimization of this energy substantially extends battery life, with a consequent extension of time in between reoperations to replace expended batteries. {\textbar} {FIG}. 13 {\textbar}   {\textbar}  is a schematic diagram of electrical stimulation waveforms for neural modulation. The illustrated ideal stimulus waveform is a charge balanced biphasic current controlled electrical pulse train. Two cycles of this waveform are depicted, each of which is made of a smaller cathodic phase followed, after a short delay, by a larger anodic phase. In one preferred embodiment, a current controlled stimulus is delivered; and the “Stimulus Amplitude” represents stimulation current. A voltage controlled or other stimulus may be used without departing from the present invention. Similarly, other waveforms, including an anodic phase preceding a cathodic phase, a monophasic pulse, a triphasic pulse, or the waveform may be used without departing from the present invention. {\textbar} The amplitude of the first phase, depicted here as cathodic, is given by pulse amplitude  {\textbar}   {\textbar} 1 {\textbar}  {PA} {\textbar} 1 {\textbar} ; the amplitude of the second phase, depicted here as anodic, is given by pulse amplitude  {\textbar} 2 {\textbar}  {PA} {\textbar} 2 {\textbar} . The durations of the first and second phases are pulse width  {\textbar} 1 {\textbar}  {PW} {\textbar} 1 {\textbar}  and pulse width  {\textbar} 1 {\textbar}  {PW} {\textbar} 2 {\textbar} , respectively. Phase I and phase  {\textbar} 2 {\textbar}  are separated by a brief delay d. Waveforms repeat with a stimulation period T, defining the stimulation frequency as f=1/T. {\textbar} The area under the curve for each phase represents the charge Q transferred, and in the preferred embodiment, these quantities are equal and opposite for the cathodic (Q1) and anodic (Q2) pulses, i.e. Q=Q1=Q2. For rectangular pulses, the charge transferred per pulse is given by Q1={PA} {\textbar}   {\textbar} 1 {\textbar} *{PW} {\textbar} 1 {\textbar}  and Q2={PA} {\textbar} 2 {\textbar} *{PW} {\textbar} 2 {\textbar} . The charge balancing constraint given by −Q1=Q2 imposes the relation {PA} {\textbar} 1 {\textbar} *{PW} {\textbar} 1 {\textbar} =−{PA} {\textbar} 2 {\textbar} *{PW} {\textbar} 2 {\textbar} . Departure from the charge balancing constraint, as is desired for optimal function of certain electrode materials, in included in the present invention. {\textbar} The stimulus amplitudes {PA} {\textbar}   {\textbar} 1 {\textbar}  and {PA} {\textbar} 2 {\textbar} , durations {PW} {\textbar} 1 {\textbar}  and {PW} {\textbar} 2 {\textbar} , frequency f, or a combination thereof may be varied to modulate the intensity of the said stimulus. A series of stimulus waveforms may be delivered as a burst, in which case the number of stimuli per burst, the frequency of waveforms within the said burst, the frequency at which the bursts are repeated, or a combination thereof may additionally be varied to modulate the stimulus intensity. {\textbar} Typical values for stimulation parameters include f=100-300 Hz, {PA} {\textbar}   {\textbar} 1 {\textbar}  and {PA} {\textbar} 2 {\textbar}  range from 10 microamps to 10 milliamps, {PW} {\textbar} 1 {\textbar}  and {PW} {\textbar} 2 {\textbar}  range from 50 microseconds to 100 milliseconds. These values are representative, and departure from these ranges is included in the apparatus and method of the present invention. {\textbar} {FIG}. 14 {\textbar}   {\textbar}  is a schematic diagram of one example of the recorded waveforms. This represents an individual action potential from a single cell recording, typically recorded from intracranial microelectrodes. Aggregates of multiple such waveforms are recorded from larger intracranial electrodes. The action potentials may be characterized according t a set of parameters including but not limited to time to valley  {\textbar} 1 {\textbar}  {TV} {\textbar} 1 {\textbar} , time to peak  {\textbar} 1 {\textbar}  {TP} {\textbar} 1 {\textbar} , time to valley  {\textbar} 2 {\textbar}  {TV} {\textbar} 2 {\textbar} , amplitude of valley  {\textbar} 1 {\textbar}  {AV} {\textbar} 1 {\textbar} , amplitude of peak  {\textbar} 1 {\textbar}  {AP} {\textbar} 1 {\textbar} , amplitude of valley  {\textbar} 2 {\textbar}  {AV} {\textbar} 2 {\textbar} , and algebraic combinations and polarity reversals thereof. {\textbar} When recording activity from more than one cell, said characterization facilitates discrimination of waveforms by individual recorded cell. The discrimination allows activity of a plurality of cells to be individually followed over time. The parameterization may be performed separately on signals recorded from different electrodes. Alternatively, said parameterization may be performed on signals pooled from multiple electrodes. {\textbar}   {\textbar} Following is a description of a general form for representing disease state. {\textbar}   {\textbar} Disease State {DS} is a vector of individual disease states, including intrinsic disease states {DSI} and extrinsic disease states {DSE}:  {\textbar}   {\textbar} {DS}=[{DS} {\textbar}   {\textbar} I {\textbar} {DS} {\textbar} E {\textbar} ] {\textbar} Intrinsic disease states and extrinsic disease states are, themselves vectors of individual disease states:  {\textbar}   {\textbar} {DS} {\textbar}   {\textbar} I {\textbar} =[{DS} {\textbar} I1 {\textbar} {DS} {\textbar} I2 {\textbar} {DS} {\textbar} I3  {\textbar} . . . {DS} {\textbar} {IN} {\textbar} ] {\textbar} {DS} {\textbar}   {\textbar} E {\textbar} =[{DS} {\textbar} E1 {\textbar} {DS} {\textbar} E2 {\textbar} {DS} {\textbar} E3  {\textbar} . . . {DS} {\textbar} {EM} {\textbar} ] {\textbar} Intrinsic Disease States include those disease states which characterize the state of disease at a given point in time. Extrinsic Disease States include variations of intrinsic disease states, including but not limited to cyclical variations in Intrinsic Disease States, variations in Intrinsic Disease States which occur in response to external events, and variations in Intrinsic Disease States which occur in response to levels of and changes in levels of electrical stimulation. Said external events include but are not limited to pharmacologic dosing, consumption of meals, awakening, falling asleep, transitioning from Parkinsonian “on” state to Parkinsonian “off” state, transitioning from Parkinsonian “off” state to Parkinsonian “on” state. {\textbar}   {\textbar} Each of Intrinsic Disease States and Extrinsic Disease States include but are not limited to those defined herein; additional disease states and definitions thereof may be added without departing from the present invention. {\textbar}   {\textbar} The first intrinsic disease state {DS} {\textbar}   {\textbar} I1  {\textbar} represents the level of resting tremor  {\textbar} {DS} {\textbar}   {\textbar} I1 {\textbar} ={RT} {\textbar} N  {\textbar} Where Normalized Resting Tremor Magnitude {RT}.sub.N is given by:  {\textbar}   {\textbar} {RT} {\textbar}   {\textbar} N {\textbar} =T {\textbar} A,3-5 {\textbar} *W {\textbar} {TA},3-5 {\textbar} +T {\textbar} E,3-5 {\textbar} *W {\textbar} {TE},3-5 {\textbar} +T {\textbar} P,3-5 {\textbar} *W {\textbar} {PE},3-5 {\textbar} +T {\textbar} C,3-5 {\textbar} +W {\textbar} {TC},3-5 {\textbar} +T {\textbar} N,3-5 {\textbar} *W {\textbar} {TN},3-5 {\textbar} +T {\textbar} S,3-5 {\textbar} *W {\textbar} {TS},3-5 {\textbar} +T {\textbar} E,3-5 {\textbar} *W {\textbar} {TE},3-5  {\textbar} Where the factors from which the Resting Tremor Magnitude {RT}.sub.N is determined, representing estimates of the magnitude of 3-5 Hertz movement of selected body segments, including but not limited to limbs, torso, and head are: {\textbar}   {\textbar} T {\textbar}   {\textbar} A,3-5 {\textbar} =Tremor level determined by acceleration monitoring {\textbar} W {\textbar}   {\textbar} {TA},3-5 {\textbar} =Weighting factor for tremor T {\textbar} A,3-5  {\textbar} T {\textbar}   {\textbar} E,3-5 {\textbar} =Tremor level determined by electromyographic ({EMG}) monitoring {\textbar} W {\textbar}   {\textbar} {TE},3-5 {\textbar} =Weighting factor for tremor T {\textbar} E,3-5  {\textbar} T {\textbar}   {\textbar} P,3-5 {\textbar} =Tremor level determined by peripheral nerve electrode monitoring {\textbar} W {\textbar}   {\textbar} {TP},3-5 {\textbar} =Weighting factor for tremor T {\textbar} P,3-5  {\textbar} T {\textbar}   {\textbar} C,3-5 {\textbar} =Tremor level determined by cortical electrode monitoring {\textbar} W {\textbar}   {\textbar} {TC},3-5 {\textbar} =Weighting factor for tremor T {\textbar} C,3-5  {\textbar} T {\textbar}   {\textbar} N,3-5 {\textbar} =Tremor level determined by neural monitoring, including subcortical nuclei, white matter tracts, and spinal cord neurons {\textbar} W {\textbar}   {\textbar} {TN},3-5 {\textbar} =Weighting factor for tremor T {\textbar} N,3-5  {\textbar} T {\textbar}   {\textbar} S,3-5 {\textbar} =Tremor level determined by acoustic sensor monitoring {\textbar} W {\textbar}   {\textbar} {TS},3-5 {\textbar} =Weighting factor for tremor T {\textbar} S,3-5  {\textbar} Weighting factors are adjusted after implantation to achieve normalization of {RT} {\textbar}   {\textbar} N  {\textbar} and to allow for selective weighting of tremor levels as determined from signals arising from various sensors, including but not limited to those listed. {\textbar} These calculations may be implemented in analog hardware, digital hardware, software, or other form. In the preferred embodiment, values are implemented as 16-bit variables; ranges for said weighting factors and tremor levels are 0 to 65535. These ranges may be changed or implemented in analog form without departing from the present invention. {\textbar}   {\textbar} The second intrinsic disease state {DS} {\textbar}   {\textbar} I2  {\textbar} represents the level of dyskinesia:  {\textbar} {DS} {\textbar}   {\textbar} I2 {\textbar} =D {\textbar} N  {\textbar} Where Normalized Dyskinesia Magnitude D {\textbar}   {\textbar} N  {\textbar} is given by:  {\textbar} D {\textbar}   {\textbar} N {\textbar} =D {\textbar} A {\textbar} *W {\textbar} {DA} {\textbar} +T {\textbar} E {\textbar} *W {\textbar} {TE} {\textbar} +T {\textbar} P {\textbar} *W {\textbar} {PE} {\textbar} +T {\textbar} C {\textbar} +W {\textbar} {TC} {\textbar} +T {\textbar} N {\textbar} *W {\textbar} {TN} {\textbar} +T {\textbar} S {\textbar} *W {\textbar} {TS} {\textbar} +T {\textbar} E {\textbar} *W {\textbar} {TE}  {\textbar} Where {\textbar}   {\textbar} D {\textbar}   {\textbar} A,3-5 {\textbar} =Dyskinesia level determined by acceleration monitoring {\textbar} W {\textbar}   {\textbar} {DA},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} A,3-5  {\textbar} D {\textbar}   {\textbar} E,3-5 {\textbar} =Dyskinesia level determined by electromyographic ({EMG}) monitoring {\textbar} W {\textbar}   {\textbar} {DE},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} E,3-5  {\textbar} D {\textbar}   {\textbar} P,3-5 {\textbar} =Dyskinesia level determined by peripheral nerve electrode monitoring {\textbar} W {\textbar}   {\textbar} {DP},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} P,3-5  {\textbar} D {\textbar}   {\textbar} C,3-5 {\textbar} =Dyskinesia level determined by cortical electrode monitoring {\textbar} W {\textbar}   {\textbar} {DC},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} C,3-5  {\textbar} D {\textbar}   {\textbar} N,3-5 {\textbar} =Dyskinesia level determined by neural monitoring, including subcortical nuclei, white matter tracts, and spinal cord neurons {\textbar} W {\textbar}   {\textbar} {DN},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} N,3,5  {\textbar} D {\textbar}   {\textbar} S,3-5 {\textbar} =Dyskinesia level determined by acoustic sensor monitoring {\textbar} W {\textbar}   {\textbar} {DS},3-5 {\textbar} =Weighting factor for Dyskinesia D {\textbar} S,3,5  {\textbar} The third intrinsic disease state {DS} {\textbar}   {\textbar} I3  {\textbar} represents the level of rigidity.  {\textbar} {DS} {\textbar}   {\textbar} I3 {\textbar} =R {\textbar} N  {\textbar} Where Normalized Rigidity Magnitude R {\textbar}   {\textbar} N  {\textbar} is given by:  {\textbar} R {\textbar}   {\textbar} N {\textbar} =R {\textbar} A {\textbar} *W {\textbar} {RA} {\textbar} +R {\textbar} E {\textbar} *W {\textbar} {RE} {\textbar} +R {\textbar} P {\textbar} *W {\textbar} {RE} {\textbar} +R {\textbar} C {\textbar} +W {\textbar} {RC} {\textbar} +R {\textbar} N {\textbar} *W {\textbar} {RN} {\textbar} +R {\textbar} S {\textbar} *W {\textbar} {RS} {\textbar} +R {\textbar} E {\textbar} *W {\textbar} {RE}  {\textbar} Where {\textbar}   {\textbar} R {\textbar}   {\textbar} A,3-5 {\textbar} =Rigidity level determined by acceleration monitoring {\textbar} W {\textbar}   {\textbar} {RA},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} A,3-5  {\textbar} R {\textbar}   {\textbar} E,3-5 {\textbar} =Rigidity level determined by electromyographic ({EMG}) monitoring {\textbar} W {\textbar}   {\textbar} {RE},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} F,3-5  {\textbar} R {\textbar}   {\textbar} P,3-5 {\textbar} =Rigidity level determined by peripheral nerve electrode monitoring {\textbar} W {\textbar}   {\textbar} {RP},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} P,3-5  {\textbar} R {\textbar}   {\textbar} C,3-5 {\textbar} =Rigidity level determined by cortical electrode monitoring {\textbar} W {\textbar}   {\textbar} {RC},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} C,3-5  {\textbar} R {\textbar}   {\textbar} N,3-5 {\textbar} =Rigidity level determined by neural monitoring, including subcortical nuclei, white matter tracts, and spinal cord neurons {\textbar} W {\textbar}   {\textbar} {RN},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} N,3-5  {\textbar} R {\textbar}   {\textbar} S,3-5 {\textbar} =Rigidity level determined by acoustic sensor monitoring {\textbar} W {\textbar}   {\textbar} {RS},3-5 {\textbar} =Weighting factor for Rigidity R {\textbar} S,3-5  {\textbar} The fourth intrinsic disease state {DS} {\textbar}   {\textbar} I4  {\textbar} represents the level of bradykinesia.  {\textbar} {DS} {\textbar}   {\textbar} I4 {\textbar} =B {\textbar} N  {\textbar} Where Normalized Bradykinesia Magnitude {BN} is given by:  {\textbar}   {\textbar} B {\textbar}   {\textbar} N {\textbar} =B {\textbar} A {\textbar} *W {\textbar} {BA} {\textbar} +B {\textbar} E {\textbar} *W {\textbar} {BE} {\textbar} +B {\textbar} P {\textbar} *W {\textbar} {PE} {\textbar} +B {\textbar} C {\textbar} +W {\textbar} {BC} {\textbar} +B {\textbar} N {\textbar} *W {\textbar} {BN} {\textbar} +B {\textbar} S {\textbar} *W {\textbar} {BS} {\textbar} +B {\textbar} E {\textbar} *W {\textbar} {BE}  {\textbar} Where {\textbar}   {\textbar} R {\textbar}   {\textbar} A {\textbar} =Bradykinesia level determined by acceleration monitoring {\textbar} W {\textbar}   {\textbar} {RA} {\textbar} =Weighting factor for Bradykinesia R {\textbar} A  {\textbar} R {\textbar}   {\textbar} E {\textbar} =Bradykinesia level determined by electromyographic ({EMG}) monitoring {\textbar} W {\textbar}   {\textbar} {RE} {\textbar} =Weighting factor for Bradykinesia R {\textbar} E  {\textbar} R {\textbar}   {\textbar} P {\textbar} =Bradykinesia level determined by peripheral nerve electrode monitoring {\textbar} W {\textbar}   {\textbar} {RP} {\textbar} =Weighting factor for Bradykinesia R {\textbar} P  {\textbar} R {\textbar}   {\textbar} C {\textbar} =Bradykinesia level determined by cortical electrode monitoring {\textbar} W {\textbar}   {\textbar} {RC} {\textbar} =Weighting factor for Bradykinesia R {\textbar} C  {\textbar} R {\textbar}   {\textbar} N {\textbar} =Bradykinesia level determined by neural monitoring, including subcortical nuclei, white matter tracts, and spinal cord neurons {\textbar} W {\textbar}   {\textbar} {RN} {\textbar} =Weighting factor for Bradykinesia R {\textbar} N  {\textbar} R {\textbar}   {\textbar} S {\textbar} =Bradykinesia level determined by acoustic sensor monitoring {\textbar} W {\textbar}   {\textbar} {RS} {\textbar} =Weighting factor for Bradykinesia R {\textbar} S  {\textbar} The control law drives these disease states toward their reference values, nominally 0, according to a vector of weights, establishing a prioritization. {\textbar}   {\textbar} Side effects and other parameters, such as power consumption and current magnitude, are also quantified and minimized according to a cost function. {\textbar}   {\textbar} One advantage of the present invention is that it provides prediction of future symptomatology, cognitive and neuromotor functionality, and treatment magnitude requirements. Such predictions may be based on preset, learned and real-time sensed parameters as well as input from the patient, physician or other person or system. The prediction of future symptomatology is based upon any of several weighted combination of parameters. Based upon prior characterization of the circadian fluctuation in symptomatology (that is, tremor magnitude for deep brain stimulation or level of depression for stimulation of other sites including locus ceruleus), future fluctuations may be predicted. An estimate, or model, of fluctuation may be based upon a combination of preset, learned, and real-time sensed parameters. Preset parameters are derived from clinical studies designed specifically for the purpose of gathering such data, or from estimates extracted from data gleaned from published literature. Real-time sensed parameters are derived from the current states (and changes, i.e. derivatives and other processed signals, thereof) of sensed and processed signals. Learned parameters are based upon the time histories of previously sensed signals. For example, the circadian fluctuation in tremor amplitude may be sensed; a weighted average of this data collected over numerous prior days provides as estimate of the expected tremor amplitude as well as a standard deviation and other statistical parameters to characterize the anticipated tremor amplitude. Similarly, in the presence of closed-loop feedback, the level of stimulation required to reduce or eliminate tremor may be used as an estimate of the “amplitude” or state of the underlying disease. {\textbar}   {\textbar} Another advantage of the present invention is that it performs automated determination of the optimum magnitude of treatment—by sensing and quantifying the magnitude and frequency of tremor activity in the patient, a quantitative representation of the level or “state” of the disease is determined. The disease state is monitored as treatment parameters are automatically varied, and the local or absolute minimum in disease state is achieved as the optimal set of stimulation parameters is converged upon. The disease state may be represented as a single value or a vector or matrix of values; in the latter two cases, a multivariable optimization algorithm is employed with appropriate weighting factors. {\textbar}   {\textbar} Having now described several embodiments of the invention, it should be apparent to those skilled in the art that the foregoing is merely illustrative and not limiting, having been presented by way of example only. For example, all signal paths may transmit a single or plurality of signals without departing from the present invention. Numerous modifications and other embodiments are within the scope of one of ordinary skill in the art and are contemplated as falling within the scope of the invention as defined by the appended claims. {\textbar}   {\textbar} Current implanted neurostimulators suffer from limited battery life necessitating replacement. The original filing of this invention teaches a closed-loop technique which allows lower average power delivery, providing extended batter life. A further improvement is taught in the present invention. The present invention teaches a novel form of power delivery, in which electromagnetic power is provided externally and radiated transcutaneously through the skin  {\textbar}   {\textbar} 382 {\textbar}  to the implanted circuit. {\textbar} A multiplicity of electromagnetic coils is used, to provide electromagnetic fields of multiple non-collinear orientations. The purpose of this design is to overcome fluctuations and interruptions in power that otherwise occur when the implanted circuit moves along with the body parts relative to electromagnetic coils. {\textbar}   {\textbar} An additional improvement is taught in the application of time multiplexing of signals delivered by said multiplicity of electromagnetic coils. Multiplexing signals in time from a multiplicity of coils allows electromagnetic energy to be delivered at a multiplicity of spatial orientations without mutual interference between fields. In one embodiment, three coils are positioned such that they are mutually orthogonal. Regardless of the orientation of the implanted circuit, mutual coupling between the implanted circuit and at least one element of the coil array will facilitate power transmission. {\textbar}   {\textbar} The present invention further includes an embodiment in which the coils are embedded in a flexible cloth assembly, including but not limited to a pillow, bandana, hat, or other accessory or piece of apparel. {\textbar}   {\textbar} Additionally, low profile mounting of the neurological control system  {\textbar}   {\textbar} 999 {\textbar}  is taught, including a design in which the device is implanted entirely adjacent to the head, avoiding the subcutaneous cables plaguing current designs with high failure and fracture rates. Additionally, a low-profile design is taught in which the neurological control system is implanted beneath the skin and recessed in the caldarium. {\textbar} {FIG}. 16 {\textbar}   {\textbar}  and  {\textbar} {FIG}. 18 {\textbar}  show two coil and three coil embodiments, respectively, of power delivery unit  {\textbar} 413 {\textbar} . Different numbers of coils may be used without departing from the present invention. Each of electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  radiates electromagnetic power, represented by magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar} , which radiates through the skin  {\textbar} 382 {\textbar}  and is then converted to electrical energy by power conversion unit  {\textbar} 378 {\textbar} . Power is then transmitted from power conversion unit  {\textbar} 378 {\textbar}  via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of the neurological control system  {\textbar} 999 {\textbar} . {\textbar} A single or multiplicity of coil holder  {\textbar}   {\textbar} 380 {\textbar}  holds electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  in place. Coil holder  {\textbar} 380 {\textbar}  may be placed atop bedding  {\textbar} 381 {\textbar} , which may include a pillow, blanket, or mattress. Alternatively, coil holder  {\textbar} 380 {\textbar}  may be placed below bedding  {\textbar} 381 {\textbar} , which may include a pillow, blanket, mattress, or other element. {\textbar} {FIG}. 17 {\textbar}   {\textbar}  shows this configuration at greater magnification, in which magnetic flux  {\textbar} 375 {\textbar}  is seen to penetrate skin  {\textbar} 382 {\textbar} . {\textbar} {FIG}. 19 {\textbar}   {\textbar}  depicts power delivery unit  {\textbar} 413 {\textbar}  with coil holder  {\textbar} 380 {\textbar}  shown holding electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  in place, as seen from above. In this design, all electromagnetic coils  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  are contained within coil holder  {\textbar} 380 {\textbar} . For illustrative purposes, coil holder  {\textbar} 380 {\textbar}  is shown in this embodiment as a convex shape. Other shapes may be used without departing from the present invention. {\textbar} {FIG}. 20 {\textbar}   {\textbar}  shows coil holder  {\textbar} 380 {\textbar}  with electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  in place, as seen from above. In this design, all electromagnetic coils  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  are contained within coil holder  {\textbar} 380 {\textbar} . For illustrative purposes, coil holder  {\textbar} 380 {\textbar}  is shown in this embodiment as a multi-lobed shape, with electromagnetic coil  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  contained within coil pockets  {\textbar} 383 {\textbar} ,  {\textbar} 384 {\textbar} ,  {\textbar} 385 {\textbar} , respectively. Other shapes may be used without departing from the present invention. {\textbar} Electromagnetic coils  {\textbar}   {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  may be permanently affixed within coil holder  {\textbar} 380 {\textbar} . Alternatively, electromagnetic coils  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  may be removable form coil holder  {\textbar} 380 {\textbar}  to facilitate cleaning or laundering of coil holder  {\textbar} 380 {\textbar} . {\textbar} Further, use of electromagnetic fields, as direct modulators of neural activity is taught in the present invention. [This also references provisional application filed Jul. 29, 2002.] {\textbar}   {\textbar} As shown in  {\textbar}   {\textbar} {FIG}. 21 {\textbar} , electromagnetic coils  {\textbar} 372 {\textbar} ,  {\textbar} 373 {\textbar} ,  {\textbar} 374 {\textbar}  may be positioned by coil holder  {\textbar} 380 {\textbar}  to lie in close proximity to the head  {\textbar} 398 {\textbar}  of a patient. Magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar} , which radiate through the skin  {\textbar} 382 {\textbar}  penetrate into underlying brain  {\textbar} 251 {\textbar} , or other neural tissue  {\textbar} 354 {\textbar} , and generate electrical currents. Said electrical currents serve to stimulate or inhibit neural activity. Other neural tissue includes but is not limited to brain  {\textbar} 251 {\textbar} , brainstem, spinal cord, peripheral nerves, cranial nerves, neurosensory organs, and other structures. {\textbar} {FIG}. 22 {\textbar}   {\textbar}  shows multiple coil embodiments. Different numbers of coils may be used without departing from the present invention.  {\textbar} {FIG}. 22 {\textbar}  shows a distributed arrangement of coils, to facilitate strong signal coupling with a minimum of tissue heating or sensory stimulation. Brain  {\textbar} 251 {\textbar}  is shown underlying skin  {\textbar} 382 {\textbar}  in head  {\textbar} 398 {\textbar} . Temporal cortex  {\textbar} 255 {\textbar}  and thalamus  {\textbar} 270 {\textbar}  are shown. {\textbar} Headband coil holder  {\textbar}   {\textbar} 386 {\textbar}  is in mechanical connection with each of electromagnetic coils  {\textbar} 387 {\textbar} ,  {\textbar} 388 {\textbar} ,  {\textbar} 389 {\textbar} ,  {\textbar} 390 {\textbar} ,  {\textbar} 391 {\textbar} ,  {\textbar} 392 {\textbar} ,  {\textbar} 393 {\textbar} , which radiate electromagnetic power through the skin  {\textbar} 382 {\textbar} . This is then converted to electrical energy by power conversion unit  {\textbar} 378 {\textbar} , which is implanted in any of several locations, shown in  {\textbar} {FIG}. 17 {\textbar}  and  {\textbar} {FIG}. 18 {\textbar} , omitted here for diagram clarity. As shown in  {\textbar} {FIG}. 17 {\textbar} , power is then transmitted from power conversion unit  {\textbar} 378 {\textbar}  via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of the neurological control system  {\textbar} 999 {\textbar} . {\textbar} Power source  {\textbar}   {\textbar} 397 {\textbar}  provides power to power modulator  {\textbar} 396 {\textbar} , which modulates power on a carrier frequency and is electrically connected via electromagnetic coil cable  {\textbar} 394 {\textbar}  to electromagnetic coils  {\textbar} 387 {\textbar} ,  {\textbar} 388 {\textbar} ,  {\textbar} 389 {\textbar} ,  {\textbar} 390 {\textbar}  which radiate power through skin  {\textbar} 382 {\textbar} . Power modulator  {\textbar} 396 {\textbar}  is also electrically connected via electromagnetic coil cable  {\textbar} 395 {\textbar}  to electromagnetic coils  {\textbar} 391 {\textbar} ,  {\textbar} 392 {\textbar} ,  {\textbar} 393 {\textbar}  which radiate power through skin  {\textbar} 382 {\textbar} . Electromagnetic coils  {\textbar} 387 {\textbar} ,  {\textbar} 388 {\textbar} ,  {\textbar} 389 {\textbar} ,  {\textbar} 390 {\textbar} ,  {\textbar} 391 {\textbar} ,  {\textbar} 392 {\textbar} ,  {\textbar} 393 {\textbar}  can be arranged in a different geometrical or anatomical configuration, with the same, a higher or a lower number of electromagnetic coils, without departing from the present invention. Electromagnetic coils  {\textbar} 387 {\textbar} ,  {\textbar} 388 {\textbar} ,  {\textbar} 389 {\textbar} ,  {\textbar} 390 {\textbar} ,  {\textbar} 391 {\textbar} ,  {\textbar} 392 {\textbar} ,  {\textbar} 393 {\textbar}  may alternatively be affixed to a different form of apparel, clothing, or fixture without departing from the present invention. Such embodiments include a hat, cap, bandana, or other device. {\textbar} {FIG}. 23 {\textbar}   {\textbar}  shows the paracranial design, with implanted components in close proximity to the head  {\textbar} 398 {\textbar} . This design eliminates the pervasive problem of moving parts, inherent in all current technology devices. All cabling is in close approximation to the caldarium, a rigid structure; therefore all implanted parts remain stationary. Since no implanted parts are subjected to movement, they are at greatly reduced risk for mechanical fatigue, the single highest failure mode for current implanted neuromodulators. This innovation dramatically reduces the frequency and likelihood for re-operation to repair broken implanted components, a major concern in all patients and particularly the elderly, who are often poor operative candidates, and who are at highest risk for many of the neurological and neurodegenerative diseases amenable to treatment by neuromodulation. {\textbar} {FIG}. 23 {\textbar}   {\textbar}  depicts an embodiment in which the head  {\textbar} 398 {\textbar}  of the patient lies atop coil holder  {\textbar} 380 {\textbar} , placing the power conversion unit  {\textbar} 378 {\textbar}  within at least one of magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar} . Power conversion unit  {\textbar} 378 {\textbar}  converts power transmitted as magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar}  into electrical energy, which is transmitted by power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of the neurological control system  {\textbar} 999 {\textbar} . Stimulating and recording circuit  {\textbar} 26 {\textbar}  generates neuromodulation signal that is transmitted via connecting cable  {\textbar} 8 {\textbar}  to intracranial stimulating electrode array  {\textbar} 37 {\textbar} , depicted in more detail in  {\textbar} {FIG}. 1 {\textbar} , which deliver neuromodulation signal to brain  {\textbar} 251 {\textbar} . or other neural tissue  {\textbar} 354 {\textbar} . Connecting cable  {\textbar} 8 {\textbar}  furthermore provides bi-directional electrical connection between intracranial electrodes  {\textbar} 246 {\textbar}  and stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of neurological control system  {\textbar} 999 {\textbar} . {\textbar} Catheter anchor  {\textbar}   {\textbar} 29 {\textbar}  is in mechanical communication with intracranial catheter  {\textbar} 7 {\textbar} . and secures it to caldarium  {\textbar} 9 {\textbar} . Intracranial electrodes  {\textbar} 246 {\textbar}  are mounted on or incorporated into intracranial catheter  {\textbar} 7 {\textbar} . {\textbar} {FIG}. 24 {\textbar}   {\textbar}  shows power conversion unit  {\textbar} 378 {\textbar}  includes electromagnetic coupling element  {\textbar} 399 {\textbar} , such as a wire coil, circuit board tracing coil, or equivalent implementation. In one embodiment, power conversion unit  {\textbar} 378 {\textbar}  also includes power conversion circuit  {\textbar} 400 {\textbar} , which converts electrical signal induced by any of magnetic flux  {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar} , on electromagnetic coupling element  {\textbar} 399 {\textbar} , into at least one of electrical power and electrical signal, which are transmitted via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , which generates neuromodulation signal  {\textbar} 412 {\textbar} , which is transmitted on connecting cable  {\textbar} 8 {\textbar}  to intracranial catheter  {\textbar} 7 {\textbar} . {\textbar} Power conversion circuit  {\textbar}   {\textbar} 400 {\textbar}  includes rectifier  {\textbar} 401 {\textbar} , energy storage element  {\textbar} 402 {\textbar} , regulator  {\textbar} 403 {\textbar} , filter  {\textbar} 404 {\textbar} , demodulator  {\textbar} 405 {\textbar} , and amplifier  {\textbar} 406 {\textbar} . Electromagnetic coupling element  {\textbar} 399 {\textbar}  is electrically connected via electromagnetic coupling element cable  {\textbar} 407 {\textbar}  to power conversion circuit  {\textbar} 400 {\textbar} . {\textbar} Either of magnetic flux  {\textbar}   {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar}  passing through electromagnetic coupling element  {\textbar} 399 {\textbar}  induces induced current  {\textbar} 408 {\textbar} , which is transmitted via electromagnetic coupling element cable  {\textbar} 407 {\textbar}  to power conversion circuit  {\textbar} 400 {\textbar} . Induced current  {\textbar} 408 {\textbar}  is rectified by rectifier  {\textbar} 401 {\textbar}  to a direct current form and is stored or lowpass filtered by energy storage element  {\textbar} 402 {\textbar}  and regulated by regulator  {\textbar} 403 {\textbar}  and then transmitted as regulated power  {\textbar} 409 {\textbar}  by power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , a component of neurological control system  {\textbar} 999 {\textbar} . {\textbar} {FIG}. 25 {\textbar}   {\textbar}  shows the communication circuit. This circuit also provides bi-directional communication with external devices, including power delivery unit  {\textbar} 413 {\textbar}  as well as with patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} , shown in  {\textbar} {FIG}. 1 {\textbar} . {\textbar} Either of magnetic flux  {\textbar}   {\textbar} 375 {\textbar} ,  {\textbar} 376 {\textbar} ,  {\textbar} 377 {\textbar}  passing through electromagnetic coupling element  {\textbar} 399 {\textbar}  induces induced current  {\textbar} 408 {\textbar} , which is transmitted via electromagnetic coupling element cable  {\textbar} 407 {\textbar}  to power conversion circuit  {\textbar} 400 {\textbar} . Induced current  {\textbar} 408 {\textbar}  is filtered by filter  {\textbar} 404 {\textbar} , then demodulated by  {\textbar} 405 {\textbar} , then amplified by amplifier  {\textbar} 406 {\textbar} , then transmitted as incoming data stream  {\textbar} 410 {\textbar}  via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} . At least one of digital to analog or analog to digital conversion may also be performed without departing from the present invention. {\textbar} Outgoing data stream  {\textbar}   {\textbar} 411 {\textbar}  is transmitted from stimulating and recording circuit  {\textbar} 26 {\textbar}  via power cable  {\textbar} 379 {\textbar}  to power conversion circuit  {\textbar} 400 {\textbar}  where it is modulated by modulator  {\textbar} 414 {\textbar}  and then amplified by amplifier  {\textbar} 415 {\textbar}  and transmitted as inducing current  {\textbar} 416 {\textbar}  along electromagnetic coupling element cable  {\textbar} 407 {\textbar}  to electromagnetic coupling element  {\textbar} 399 {\textbar}  where it generated magnetic flux that is detected and decoded by external devices, including power delivery unit  {\textbar} 413 {\textbar}  as well as with patient interface module  {\textbar} 55 {\textbar}  and supervisory module  {\textbar} 56 {\textbar} , shown in  {\textbar} {FIG}. 1 {\textbar} . At least one of digital to analog or analog to digital conversion may also be performed without departing from the present invention. {\textbar} {FIG}. 26 {\textbar}   {\textbar}  depicts the overall system, with power conversion unit  {\textbar} 378 {\textbar}  connected via power cable  {\textbar} 379 {\textbar}  to power management unit  {\textbar} 417 {\textbar} , a component of stimulating recording and power circuit  {\textbar} 419 {\textbar} . Power management unit  {\textbar} 417 {\textbar}  is in electrical connection with energy storage unit  {\textbar} 418 {\textbar}  and in electrical connection with stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} In one preferred embodiment, energy storage unit  {\textbar}   {\textbar} 418 {\textbar}  is implemented as a capacitor. Power management unit  {\textbar} 417 {\textbar}  converts regulated power  {\textbar} 409 {\textbar}  into charge, which is stored in energy storage unit  {\textbar} 418 {\textbar} . {\textbar} In another preferred embodiment, energy storage unit  {\textbar}   {\textbar} 418 {\textbar}  is implemented as a rechargeable battery. Power management unit  {\textbar} 417 {\textbar}  converts regulated power  {\textbar} 409 {\textbar}  into current, which recharges energy storage unit  {\textbar} 418 {\textbar} . {\textbar} When regulated power  {\textbar}   {\textbar} 409 {\textbar}  is insufficient to power stimulating and recording circuit  {\textbar} 26 {\textbar} , power management unit  {\textbar} 417 {\textbar}  withdrawals energy from energy storage unit  {\textbar} 418 {\textbar}  and delivers energy to stimulating and recording circuit  {\textbar} 26 {\textbar} . {\textbar} An embodiment of this invention further includes novel geometrical features to enhance form and function of this neuromodulation system as well as any neural stimulation system. One invention taught is the refinement of the implanted case such that one side is concave. An additional invention taught is the refinement of the implanted case such that one side is convex. A further extension of this invention includes the use of at least one concave side and at least one convex side. Advantages of this design include the close positioning of the casing against the intact outer table of the skull of the patient. {\textbar}   {\textbar} {FIG}. 27 {\textbar}   {\textbar}  shows stimulating and recording unit  {\textbar} 43 {\textbar}  enclosed within system enclosure  {\textbar} 434 {\textbar} , implanted beneath the scalp  {\textbar} 10 {\textbar} , overlying the caldarium  {\textbar} 9 {\textbar} . System enclosure  {\textbar} 434 {\textbar}  is designed with an enclosure inner surface  {\textbar} 427 {\textbar}  and enclosure outer surface  {\textbar} 426 {\textbar} . In one preferred embodiment, enclosure inner surface  {\textbar} 427 {\textbar}  and enclosure outer surface  {\textbar} 426 {\textbar}  are concave and convex, respectively. {\textbar} By designing enclosure inner surface  {\textbar}   {\textbar} 427 {\textbar}  to be concave, system enclosure  {\textbar} 434 {\textbar}  may be placed tightly and securely against caldarium  {\textbar} 9 {\textbar} . This represents a substantial innovation over flat machined enclosures, the designs currently implanted elsewhere and that are based upon established pacemaker technology. This innovation reduces of eliminates movement of the implant that would otherwise occur with existing devices. {\textbar} By designing enclosure outer surface  {\textbar}   {\textbar} 426 {\textbar}  to be convex, system enclosure  {\textbar} 434 {\textbar}  may be placed against calvarium  {\textbar} 9 {\textbar}  with a substantially improved cosmetic result and less displacement of scalp  {\textbar} 10 {\textbar}  or other skin  {\textbar} 382 {\textbar} . This represents a substantial innovation over flat machined enclosures, the designs currently implanted elsewhere and that are based upon established pacemaker technology. This innovation reduces or eliminates movement of the implant that would otherwise occur with existing devices. {\textbar} Furthermore, each of enclosure inner surface  {\textbar}   {\textbar} 427 {\textbar}  and enclosure outer surface  {\textbar} 426 {\textbar}  serve to reduce the profile of system enclosure  {\textbar} 434 {\textbar}  and to improve the cosmetic appearance of the overlying skin  {\textbar} 382 {\textbar}  or scalp  {\textbar} 10 {\textbar} . {\textbar} In this embodiment, system enclosure  {\textbar}   {\textbar} 434 {\textbar}  overlies the intact pericranium  {\textbar} 420 {\textbar} . This facilitates attachment of System enclosure  {\textbar} 434 {\textbar}  to the pericranium  {\textbar} 420 {\textbar}  by means of mechanical attachment  {\textbar} 424 {\textbar} , providing mechanical attachment between mechanical attachment mount  {\textbar} 425 {\textbar}  and at least one of pericranium  {\textbar} 420 {\textbar} , skin  {\textbar} 382 {\textbar} , scalp  {\textbar} 10 {\textbar} , or other tissue of the patient. Mechanical attachment  {\textbar} 424 {\textbar} , may be implemented as sutures, wires, clips, or other attachment means. In this embodiment, the caldarium outer table  {\textbar} 421 {\textbar} , caldarium marrow layer  {\textbar} 422 {\textbar} , and caldarium inner table  {\textbar} 423 {\textbar}  remain intact. {\textbar} Alternatively, System enclosure  {\textbar}   {\textbar} 434 {\textbar}  is implanted beneath the scalp  {\textbar} 10 {\textbar}  and beneath the pericranium  {\textbar} 420 {\textbar} , directly overlying the caldarium  {\textbar} 9 {\textbar} . In this embodiment, the pericranium  {\textbar} 420 {\textbar}  serves to secure System enclosure  {\textbar} 434 {\textbar}  in place against the caldarium  {\textbar} 9 {\textbar} . {\textbar} {FIG}. 28 {\textbar}   {\textbar}  depicts system enclosure  {\textbar} 434 {\textbar}  secured to the calvarium  {\textbar} 9 {\textbar}  using screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  which are shown inserted through screw mounts  {\textbar} 428 {\textbar} ,  {\textbar} 430 {\textbar} , respectively, into calvarium  {\textbar} 9 {\textbar} . Additional or fewer screws and screw mounts may be used without departing form the present invention. Screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  may penetrate in depth to the level of the calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow layer  {\textbar} 422 {\textbar} , or calvarium inner table  {\textbar} 423 {\textbar} . {\textbar} {FIG}. 29 {\textbar}   {\textbar}  depicts a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is partially recessed into the calvarium  {\textbar} 9 {\textbar} . Protruding component  {\textbar} 432 {\textbar}  lies above the outer surface of calvarium  {\textbar} 9 {\textbar} , and recessed component  {\textbar} 433 {\textbar}  lies below the outer surface of calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  is shown occupying volume previously occupied by calvarium outer table  {\textbar} 421 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  may also occupying volume previously occupied by calvarium marrow layer without departing from the present invention. {\textbar} {FIG}. 30 {\textbar}   {\textbar}  depicts a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is partially recessed into the calvarium  {\textbar} 9 {\textbar} . Protruding component  {\textbar} 432 {\textbar}  lies above the outer surface of calvarium  {\textbar} 9 {\textbar} , and recessed component  {\textbar} 433 {\textbar}  lies below the outer surface of calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  is shown occupying volume previously occupied by calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow  {\textbar} 422 {\textbar} , and calvarium inner table  {\textbar} 423 {\textbar} . System enclosure  {\textbar} 434 {\textbar}  is shown secured to the calvarium outer table  {\textbar} 421 {\textbar}  portion of calvarium  {\textbar} 9 {\textbar}  using screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  which are shown inserted through screw mounts  {\textbar} 428 {\textbar} ,  {\textbar} 430 {\textbar} , respectively. Additional or fewer screws and screw mounts may be used without departing form the present invention. Screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  may penetrate in depth to the level of the calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow layer  {\textbar} 422 {\textbar} , or calvarium inner table  {\textbar} 423 {\textbar} . {\textbar} {FIG}. 31 {\textbar}   {\textbar}  depicts a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is fully recessed into the calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  lies below the outer surface of calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  is shown occupying volume previously occupied by calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow  {\textbar} 422 {\textbar} , and calvarium inner table  {\textbar} 423 {\textbar} . System enclosure  {\textbar} 434 {\textbar}  is shown secured to the calvarium outer table  {\textbar} 421 {\textbar}  portion of calvarium  {\textbar} 9 {\textbar}  using screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  which are shown inserted through screw mounts  {\textbar} 428 {\textbar} ,  {\textbar} 430 {\textbar} , respectively. Additional or fewer screws and screw mounts may be used without departing form the present invention. Screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  may penetrate in depth to the level of the calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow layer  {\textbar} 422 {\textbar} , or calvarium inner table  {\textbar} 423 {\textbar} . {\textbar} {FIG}. 32 {\textbar}   {\textbar}  depicts a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is fully recessed into the calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  lies below the outer surface of calvarium  {\textbar} 9 {\textbar} . Recessed component  {\textbar} 433 {\textbar}  is shown occupying volume previously occupied by calvarium outer table  {\textbar} 421 {\textbar} , calvarium marrow  {\textbar} 422 {\textbar} , and calvarium inner table  {\textbar} 423 {\textbar} . In one embodiment shown, enclosure inner surface  {\textbar} 427 {\textbar}  is shown extending below the level of calvarium inner table  {\textbar} 423 {\textbar} . This design facilitates close proximity of stimulating and recording unit  {\textbar} 43 {\textbar}  to underlying neural tissue  {\textbar} 354 {\textbar}  and brain  {\textbar} 251 {\textbar} , valuable in sensing neural activity and in delivering an output neuromodulation signal ({NMS})  {\textbar} 998 {\textbar}  via intracranial stimulating electrode array  {\textbar} 37 {\textbar} , shown in  {\textbar} {FIG}. 1 {\textbar}  and  {\textbar} {FIG}. 2 {\textbar} . {\textbar} System enclosure  {\textbar}   {\textbar} 434 {\textbar}  is shown secured to the calvarium inner table  {\textbar} 423 {\textbar}  portion of calvarium  {\textbar} 9 {\textbar}  using screws  {\textbar} 429 {\textbar} ,  {\textbar} 431 {\textbar}  which are shown inserted through screw mounts  {\textbar} 428 {\textbar} ,  {\textbar} 430 {\textbar} , respectively. Additional or fewer screws and screw mounts may be used without departing form the present invention. Alternate means of mechanically attaching system enclosure  {\textbar} 434 {\textbar}  to calvarium  {\textbar} 9 {\textbar}  may be employed without departing from the present invention. {\textbar} {FIG}. 33 {\textbar}   {\textbar}  depicts the neurological control system  {\textbar} 999 {\textbar}  employing a lower profile design in which the system enclosure  {\textbar} 434 {\textbar}  is recessed into the calvarium  {\textbar} 9 {\textbar} . Power delivery unit  {\textbar} 413 {\textbar} , via generated magnetic flux, transmits power to power conversion unit  {\textbar} 378 {\textbar} , which transmits power via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , part of stimulating and recording unit  {\textbar} 43 {\textbar} , contained within system enclosure  {\textbar} 434 {\textbar} . Stimulating and recording circuit  {\textbar} 26 {\textbar}  is electrically connected via connecting cable  {\textbar} 8 {\textbar}  to intracranial catheter  {\textbar} 7 {\textbar}  which provides electrical connection to intracranial stimulating electrode array  {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar} . Intracranial catheter is mechanically secured via catheter anchor  {\textbar} 29 {\textbar}  to calvarium  {\textbar} 9 {\textbar} . {\textbar} {FIG}. 34 {\textbar}   {\textbar}  depicts the neurological control system  {\textbar} 999 {\textbar}  employing a lower profile and more compact design in which the system enclosure  {\textbar} 434 {\textbar}  is recessed into the calvarium  {\textbar} 9 {\textbar} . Power delivery unit  {\textbar} 413 {\textbar} , via generated magnetic flux, transmits power to power conversion unit  {\textbar} 378 {\textbar} , which transmits power via power cable  {\textbar} 379 {\textbar}  to stimulating and recording circuit  {\textbar} 26 {\textbar} , part of stimulating and recording unit  {\textbar} 43 {\textbar} , contained within system enclosure  {\textbar} 434 {\textbar} . {\textbar} Stimulating and recording circuit  {\textbar}   {\textbar} 26 {\textbar}  is in close proximity to intracranial catheter  {\textbar} 7 {\textbar} , this includes but is not limited to a preferred embodiment in which stimulating and recording circuit  {\textbar} 26 {\textbar}  is recessed into calvarium at the site surrounding the entry point at which intracranial catheter  {\textbar} 7 {\textbar}  passes from outside the calvarium to inside the calvarium. Stimulating and recording circuit  {\textbar} 26 {\textbar}  is electrically connected directly or via connecting cable  {\textbar} 8 {\textbar}  to intracranial catheter  {\textbar} 7 {\textbar}  which provides electrical connection to intracranial stimulating electrode array  {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar} . Intracranial catheter is mechanically secured via catheter anchor  {\textbar} 29 {\textbar}  to calvarium  {\textbar} 9 {\textbar} . {\textbar} An advantage of the closed-loop system includes the natural variability of the output signal. The nervous system exhibits a natural tendency to attenuate responses to continuous stimuli, such as continuous background noises. A natural example includes imperceptibility of stationary visual images on frog retina. A related example is electrical stimulation of peripheral nerves, such as stimulation of the tibial or peroneal nerves for use in eliciting the flexion withdrawal reflex to facilitate gait restoration in paraplegics. With time, these reflexes attenuate or habituate, reducing their effectiveness. {\textbar}   {\textbar} The time-varying nature of a closed-loop signal, responding to environmental and system fluctuations and noise, the natural neural process of habituation to constant signals will be reduced. {\textbar}   {\textbar} Furthermore, by specifically and intentionally altering the output signal, such as intermittently reducing the amplitude of the stimulus, and allowing the closed-loop system to compensate in between these intentional amplitude restrictions, further reduction and prevention of habituation is achieved. {\textbar}   {\textbar} As shown previously, ventricular electrode catheter  {\textbar}   {\textbar} 1 {\textbar}  is shown positioned within the lateral ventricle  {\textbar} 2 {\textbar} , with ventricular electrode  {\textbar} 17 {\textbar}  in contact with the {CSF} fluid  {\textbar} 18 {\textbar}  in lateral ventricle  {\textbar} 2 {\textbar} . Cortical electrode  {\textbar} 3 {\textbar}  is in contact with the {CSF} fluid overlying the cerebral cortex  {\textbar} 19 {\textbar} . Cortical electrode  {\textbar} 3 {\textbar}  may be placed over any portion of the cerebral or cerebellar cortex without departing from the present invention. Hippocampal electrode  {\textbar} 4 {\textbar}  is shown underlying the hippocampal regions of the cerebrum. {\textbar} The parenchyma of the nervous system is used as a dielectric to establish a voltage potential gradient between any of the {CSF} reservoirs, including the lateral ventricles, third ventricle, cerebral aqueduct, fourth ventricle, foramen of lushke, foramen of magende, basal cisterns, {CSF} overlying the cerebellar hemispheres, {CSF} overlying the cerebral hemispheres, central spinal canal, {CSF} overlying the spinal cord, and {CSF} overlying the spinal nerves and roots. {\textbar}   {\textbar} Patients currently implanted with neuromodulation devices must undergo repeat surgery to replace implanted pulse generators every 3-5 years to replace units when batteries fail. Tradeoffs between acceptable implanted device size and limited energy density with current battery technology are responsible for this pervasive problem. Many of these patients are older, and the risks of general anesthesia and surgery are not insignificant. Subjecting these patents to these large risks is a pervasive problem in the field of neuromodulation. The present invention overcomes these limitations with a clever design employing a novel external radiofrequency power delivery system. {\textbar}   {\textbar} The present embodiment of the invention includes an external coil use of Limited energy density because technology is limited. {\textbar}   {\textbar} The present embodiment of this invention teaches a device, method of implantation, and surgical tools for the rapid implantation of a neuromodulation system. Current devices suffer form the need to implant a pulse generator in the subclavicular pocket or other site remote form the site of electrode implantation. Because of this, subcutaneous cables must be implanted to connect the implanted circuit to the implanted stimulating electrode. The present invention teaches a device and method for implanting the circuit in close proximity to the site of stimulation. The design taught herein obviates the need for any subcutaneous cables. Additionally, it teaches a compact design that allows placement of the implanted circuit and the implantation of the intracranial electrode catheter through a single hole. This is a substantial improvement, facilitating much more rapid implantation and eliminating the need for subcutaneous cable implantation. As a result, surgical procedures are much faster and may be performed under local anesthesia, no longer requiring general anesthesia. This substantially increases the market size, allowing implantation in older and frail patients who might otherwise not benefit from neuromodulation technology because of their being poor surgical candidates, due to their inability to safely tolerate general anesthesia and long surgical procedures. {\textbar}   {\textbar} {FIGS}. 35 and 36 {\textbar}   {\textbar}  depict the neurological control system  {\textbar} 999 {\textbar}  employing a lower profile and more compact design in which the system enclosure  {\textbar} 434 {\textbar}  is recessed into the calvarium  {\textbar} 9 {\textbar} , shown in the anteroposterior and lateral projections, respectively. Power delivery unit  {\textbar} 413 {\textbar} , is included within system enclosure  {\textbar} 434 {\textbar} ; however, power delivery unit  {\textbar} 413 {\textbar}  may also be external to system enclosure  {\textbar} 434 {\textbar}  without departing from the present invention. {\textbar} Stimulating and recording circuit  {\textbar}   {\textbar} 26 {\textbar}  is in close proximity to intracranial catheter  {\textbar} 7 {\textbar} , this includes but is not limited to a preferred embodiment in which stimulating and recording circuit  {\textbar} 26 {\textbar}  is recessed into calvarium at the site surrounding the entry point at which intracranial catheter  {\textbar} 7 {\textbar}  passes from outside the calvarium to inside the calvarium. Stimulating and recording circuit  {\textbar} 26 {\textbar}  is electrically connected to intracranial catheter  {\textbar} 7 {\textbar}  which provides electrical connection to intracranial stimulating electrode array  {\textbar} 37 {\textbar}  and intracranial recording electrode array  {\textbar} 38 {\textbar} . Intracranial catheter is mechanically secured to system enclosure  {\textbar} 434 {\textbar} . System enclosure  {\textbar} 434 {\textbar}  is secured to calvarium  {\textbar} 9 {\textbar}  via mechanical attachment  {\textbar} 424 {\textbar} , which is attached to system enclosure  {\textbar} 434 {\textbar}  via machine screw  {\textbar} 439 {\textbar}  or equivalent means and to calvarium  {\textbar} 9 {\textbar}  via bone screw  {\textbar} 438 {\textbar}  or equivalent means. Catheter recess  {\textbar} 441 {\textbar}  provides space for establishment of electrical and mechanical connection of stimulating and recording circuit  {\textbar} 26 {\textbar}  to intracranial catheter  {\textbar} 7 {\textbar} . Catheter mount socket  {\textbar} 437 {\textbar}  and catheter mount ball  {\textbar} 436 {\textbar} . {\textbar} {FIG}. 37 {\textbar}   {\textbar}  shows an expanded view of the neurological control system  {\textbar} 999 {\textbar}  also shown in  {\textbar} {FIGS}. 35 and 36 {\textbar} . {\textbar} {FIGS}. 38 and 39 {\textbar}   {\textbar}  depict a Caldarium drill bit is used to create a circular hole in the calvarium. The present invention teaches a major advance in the expeditiousness of the implantation procedure for creating a craniotomy, with particular relevance to the implantation of a neuromodulation device recessed in the calvarium. In a single pass, a drill bit creates a hole of a diameter similar to that of the implanted device. The outer diameter portion is created by calvarium bit outer diameter segment  {\textbar} 443 {\textbar} . Attached to and deep to calvarium bit outer diameter segment  {\textbar} 443 {\textbar}  is the calvarium bit inner diameter segment  {\textbar} 442 {\textbar} , which creates a hole in the calvarium of a smaller diameter. The resulting geometry, as seen in  {\textbar} {FIG}. 38 {\textbar}  and  {\textbar} {FIG}. 39 {\textbar} , produces bone ledge  {\textbar} 447 {\textbar} . Bone ledge  {\textbar} 447 {\textbar}  serves to provide mechanical support to system enclosure  {\textbar} 434 {\textbar} , preventing system enclosure  {\textbar} 434 {\textbar}  from becoming displaced and impinging upon brain  {\textbar} 251 {\textbar} . {\textbar} Intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  is secured to system enclosure  {\textbar} 434 {\textbar}  by means of catheter mount ball  {\textbar} 436 {\textbar} . A compressible material is either adjacent to or comprises catheter mount ball  {\textbar} 436 {\textbar} . {\textbar} {FIG}. 40 {\textbar}   {\textbar}  depicts the path of the intracranial catheter  {\textbar} 7 {\textbar}  and its connection to the electrical elements of stimulating and recording circuit  {\textbar} 26 {\textbar} , which is contained within system enclosure  {\textbar} 434 {\textbar}  and in close proximity to intracranial catheter  {\textbar} 7 {\textbar} . Intracranial Catheter Proximal End  {\textbar} 451 {\textbar}  is largely contained within or at least has a component that occupies a portion of the catheter recess  {\textbar} 441 {\textbar} . Intracranial Catheter Proximal Electrode  {\textbar} 452 {\textbar}  and Intracranial Catheter Proximal Electrode  {\textbar} 453 {\textbar}  are shown. Additional electrodes or alternate connection means may be employed without departing from the present invention. {\textbar} In one embodiment, set screws are used to electrically connect electrodes on intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  to contacts mounted on system enclosure  {\textbar} 434 {\textbar} . Electrode contacts and set screw are recessed in catheter recess  {\textbar} 441 {\textbar}  in system enclosure  {\textbar} 434 {\textbar} . {\textbar} System enclosure is constructed from a castable material, such as potted epoxy, methylmethacrylate, or other plastic, silicone, or polymer. {RF} electrodes are included within the system enclosure. A titanium or stainless steel shield may be included into eh center of the system enclosure  {\textbar}   {\textbar} 434 {\textbar} . The outer surface of system enclosure  {\textbar} 434 {\textbar}  may have a convex shape, to better approximate the shape of the calvarium removed and replaced by system enclosure  {\textbar} 434 {\textbar} , and the convex shape of outer surface of system enclosure  {\textbar} 434 {\textbar}  minimized stress concentrations on the overlying scalp  {\textbar} 10 {\textbar} . {\textbar} Disease state is estimated using a measure or estimate of chaos of neural activity. Such measures include Lyupanov functions and other measures of chaos or system synchronicity or correlation. {\textbar}   {\textbar} Bottom surface of system enclosure  {\textbar}   {\textbar} 434 {\textbar}  may include electrodes used for at least one of recording, stimulation, ground, or reference electrode functions. {\textbar} An array of at least one {EEG} electrode is used for recording electroencephalographic signals. Said {EEG} electrode may be placed in at least one of a subgaleal location, subcutaneous location, epidural location, subdural location, intracerebral location, or other location enabling {EEG} electrode to sense neural activity. {\textbar}   {\textbar} An advancement in intracranial catheter design is taught in the present invention. Intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  includes a microelectrode channel  {\textbar} 448 {\textbar} . Microelectrode  {\textbar} 449 {\textbar}  is inserted through microelectrode channel  {\textbar} 448 {\textbar} , with microelectrode tip  {\textbar} 450 {\textbar}  protruding beyond tip of intracranial catheter  {\textbar} 7 {\textbar} . Microelectrode tip  {\textbar} 450 {\textbar}  is used to record single cell activity to identify neural structures during advancement of intracranial catheter  {\textbar} 7 {\textbar}  through brain  {\textbar} 251 {\textbar} . At the completion of the insertion of intracranial catheter  {\textbar} 7 {\textbar}  through brain  {\textbar} 251 {\textbar} , microelectrode  {\textbar} 449 {\textbar}  may be removed from intracranial catheter  {\textbar} 7 {\textbar} . {\textbar} This allows microelectrode recording and implantation of intracranial catheter  {\textbar}   {\textbar} 7 {\textbar}  during a single pass, saving substantial time during the implantation procedure. {\textbar} During and Following implantation, closed-loop optimization of electrical field shaping is performed by control circuit  {\textbar}   {\textbar} 72 {\textbar} . {\textbar} Disease state is characterized by a measure of correlation between neural signals measured from neural tissue. Disease State {DS} is a vector of individual disease states, including intrinsic disease states {DSI} and extrinsic disease states {DSE}:  {\textbar}   {\textbar} {DS}=[{DS} {\textbar}   {\textbar} I {\textbar} {DS} {\textbar} E {\textbar} ] {\textbar} Intrinsic disease states and extrinsic disease states are, themselves vectors of individual disease states:  {\textbar}   {\textbar} {DS} {\textbar}   {\textbar} I {\textbar} =[{DS} {\textbar} I1 {\textbar} {DS} {\textbar} I2 {\textbar} {DS} {\textbar} I3  {\textbar} . . . {DS} {\textbar} {IN} {\textbar} ] {\textbar} {DS} {\textbar}   {\textbar} E {\textbar} =[{DS} {\textbar} E1 {\textbar} {DS} {\textbar} E2 {\textbar} {DS} {\textbar} E3  {\textbar} . . . {DS} {\textbar} {EM} {\textbar} ] {\textbar} Intrinsic Disease States include those disease states which characterize the state of disease at a given point in time. Extrinsic Disease States include variations of intrinsic disease states, including but not limited to cyclical variations in Intrinsic Disease States, variations in Intrinsic The fifth intrinsic disease state {DS} {\textbar}   {\textbar} I5  {\textbar} represents the level of correlation between neural activity in multiple areas of the nervous system.  {\textbar} {DS} {\textbar}   {\textbar} I5 {\textbar} =C {\textbar} N  {\textbar} Where Normalized Correlation Magnitude matrix C {\textbar}   {\textbar} N  {\textbar} is given by: {\textbar} C {\textbar}   {\textbar} N {\textbar} = {\textbar} [ {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 1 {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 1 {\textbar} , {\textbar} M {\textbar} : {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 1 {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 2 {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 2 {\textbar} , {\textbar} M {\textbar} : {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 1 {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 2 {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 3 {\textbar} , {\textbar} M {\textbar} : {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⁢ {\textbar} : {\textbar} C {\textbar} M {\textbar} , {\textbar} 1 {\textbar} C {\textbar} M {\textbar} , {\textbar} 2 {\textbar} C {\textbar} M {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} M {\textbar} , {\textbar} M {\textbar} ] {\textbar}  Which becomes: {\textbar}   {\textbar} C {\textbar}   {\textbar} N {\textbar} = {\textbar} [ {\textbar} 1 {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 1 {\textbar} , {\textbar} M {\textbar} : {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 1 {\textbar} 1 {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} C {\textbar} 2 {\textbar} , {\textbar} M {\textbar} : {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 1 {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 2 {\textbar} 1 {\textbar} ⋯ {\textbar} C {\textbar} 3 {\textbar} , {\textbar} M {\textbar} : {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⋯ {\textbar} ⁢ {\textbar} : {\textbar} C {\textbar} M {\textbar} , {\textbar} 1 {\textbar} C {\textbar} M {\textbar} , {\textbar} 2 {\textbar} C {\textbar} M {\textbar} , {\textbar} 3 {\textbar} ⋯ {\textbar} 1 {\textbar} ] {\textbar} This matrix or a weighted sum of its components represents an additional measure of disease state. This has broad applications in neurological disease quantification and also has particular relevance to measurement of tremor and assessment of seizure activity as well as prediction of likelihood and onset of seizure activity. {\textbar}   {\textbar} C {\textbar}   {\textbar} N {\textbar} = {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} * {\textbar} W {\textbar} 1 {\textbar} , {\textbar} 2 {\textbar} + {\textbar} C {\textbar} 1 {\textbar} , {\textbar} 3 {\textbar} * {\textbar} W {\textbar} 1 {\textbar} , {\textbar} 3 {\textbar} + {\textbar} … {\textbar} + {\textbar} C {\textbar} 1 {\textbar} , {\textbar} M {\textbar} * {\textbar} W {\textbar} 1 {\textbar} , {\textbar} M {\textbar} + {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 1 {\textbar} * {\textbar} W {\textbar} 2 {\textbar} , {\textbar} 1 {\textbar} + {\textbar} C {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} * {\textbar} W {\textbar} 2 {\textbar} , {\textbar} 3 {\textbar} + {\textbar} … {\textbar} + {\textbar} C {\textbar} 2 {\textbar} , {\textbar} M {\textbar} * {\textbar} W {\textbar} 2 {\textbar} , {\textbar} M {\textbar} + {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 1 {\textbar} * {\textbar} W {\textbar} 3 {\textbar} , {\textbar} 1 {\textbar} + {\textbar} C {\textbar} 3 {\textbar} , {\textbar} 2 {\textbar} * {\textbar} W {\textbar} 3 {\textbar} , {\textbar} 2 {\textbar} + {\textbar} … {\textbar} + {\textbar} C {\textbar} 3 {\textbar} , {\textbar} M {\textbar} * {\textbar} W {\textbar} 3 {\textbar} , {\textbar} M {\textbar} + {\textbar} ⋯ {\textbar} C {\textbar} M {\textbar} , {\textbar} 1 {\textbar} * {\textbar} W {\textbar} M {\textbar} , {\textbar} 1 {\textbar} + {\textbar} C {\textbar} M {\textbar} , {\textbar} 2 {\textbar} * {\textbar} W {\textbar} M {\textbar} , {\textbar} 2 {\textbar} + {\textbar} C {\textbar} M {\textbar} , {\textbar} 3 {\textbar} * {\textbar} W {\textbar} M {\textbar} , {\textbar} 3 {\textbar} + {\textbar} … {\textbar}  Where {\textbar}   {\textbar} C {\textbar}   {\textbar} I,J {\textbar} =Correlation between signal I and signal J {\textbar} W {\textbar}   {\textbar} I,J {\textbar} =Weighting factor for Correlation between signal I and signal J {\textbar} The sixth intrinsic disease state {DS} {\textbar}   {\textbar} I6  {\textbar} represents the level of chaos in neural activity in a single or multiplicity of areas of the nervous system. This may be implemented as any measure of entropy or chaos, including variance, standard deviation, Lyupanov exponent values, maximum Lyupanov exponent value, or other measure of entropy or chaos without departing from the present invention.  {\textbar} {DS} {\textbar}   {\textbar} I6 {\textbar} =S {\textbar} N  {\textbar} {DS} {\textbar}   {\textbar} I6 {\textbar} =S {\textbar} 1 {\textbar} *W {\textbar} S1 {\textbar} +S {\textbar} 2 {\textbar} *W {\textbar} S2 {\textbar} +S {\textbar} 3 {\textbar} *W {\textbar} S3 {\textbar} + . . . +S {\textbar} N {\textbar} *W {\textbar} {SN}  {\textbar}  Where {\textbar}   {\textbar} S {\textbar}   {\textbar} 1 {\textbar} =Entropy measure for signal I, which may be implemented in any of several ways outlined above, some of which are detailed below. {\textbar} W {\textbar}   {\textbar} {SI} {\textbar} =Weighting factor for Entropy measure for signal {\textbar} Chaos measurement implemented and quantified as Entropy:  {\textbar}   {\textbar} S {\textbar}   {\textbar} I {\textbar} =Entropy measure for signal  {\textbar} I {\textbar} =− {\textbar}   {\textbar} k∫J[{dX}]P[X {\textbar} I {\textbar} ] log  {\textbar} P[X {\textbar} I {\textbar} ] {\textbar} Where {\textbar}   {\textbar} k=a constant, i.e. Boltzmann's constant as in thermodynamics, or by convention a dimensionless constant in information theory; {\textbar}   {\textbar} X {\textbar}   {\textbar} I {\textbar} =Signal I, such as {EEG} voltage signal I or implanted electrode signal I or microelectrode voltage signal {\textbar} P[X {\textbar}   {\textbar} I {\textbar} ]=Probability distribution of Signal I {\textbar} {dX}=integration variable {\textbar}   {\textbar} In a typical implementation in digital hardware, based upon a base 2 digitization scheme, chaos measurement implemented and quantified as Entropy becomes:  {\textbar}   {\textbar} S {\textbar}   {\textbar} I {\textbar} =−Σp {\textbar} i  {\textbar} log {\textbar} 2  {\textbar} p {\textbar} i  {\textbar} bits {\textbar}  Where {\textbar}   {\textbar} S {\textbar}   {\textbar} I {\textbar} =Entropy measure for signal I {\textbar} p {\textbar}   {\textbar} i {\textbar} =probability of outcome i, for example of sensed voltage being within a particular discretization bin window or value range. {\textbar} log {\textbar}   {\textbar} 2  {\textbar} p {\textbar} i {\textbar} =Log base 2 of p {\textbar} i {\textbar} , alternative bases could be used, but 2 is typically chosen to be consistent with digital hardware, which is implemented using the binary (base 2) system. {\textbar} Chaos measurement implemented and quantified as Lyupanov exponent, which is defined as: {\textbar}   {\textbar} S {\textbar}   {\textbar} l {\textbar} = {\textbar} L {\textbar} = {\textbar} ( {\textbar} 1 {\textbar} / {\textbar} ∑ {\textbar} k {\textbar} = {\textbar} 1 {\textbar} M {\textbar} ⁢ {\textbar} Dt {\textbar} k {\textbar} ) {\textbar} * {\textbar} ∑ {\textbar} k {\textbar} = {\textbar} 1 {\textbar} M {\textbar} ⁢ {\textbar} L {\textbar} k {\textbar} ⁢ {\textbar} ⁢ {\textbar} bits {\textbar} ⁢ {\textbar} ⁢ {\textbar} per {\textbar} ⁢ {\textbar} ⁢ {\textbar} second {\textbar}  Where {\textbar}   {\textbar} L=Lyupanov Exponent {\textbar}   {\textbar} L {\textbar}   {\textbar} k  {\textbar} Satisfies the condition: L(t {\textbar} k {\textbar} )=L(t {\textbar} k-1 {\textbar} )*2 {\textbar} Lk*Dtk  {\textbar} Dt {\textbar}   {\textbar} k {\textbar} =t {\textbar} k {\textbar} −t {\textbar} k-1  {\textbar} is the evolution time of L(t {\textbar} k {\textbar} ) {\textbar} L(t {\textbar}   {\textbar} k {\textbar} ) is the distance between two close points in phase space at time t {\textbar} k  {\textbar} S {\textbar}   {\textbar} I {\textbar} =Entropy measure for signal I, calculated with Lypoanov Exponent {\textbar} Other measures of chaos, including variations of these and other measures or estimates for chaos, may be used without departing from the present invention. {\textbar}   {\textbar} {FIGS}. 37 and 40 {\textbar}   {\textbar}  show system enclosure in cross section, in which intracranial catheter  {\textbar} 7 {\textbar}  traverses catheter mount ball  {\textbar} 436 {\textbar} , which rotates within catheter mount socket  {\textbar} 437 {\textbar} , providing a swivel mechanism to facilitate the selection of a continuum of potential intracranial target sites for intracranial electrode array and intracranial catheter using a single mounted position for system enclosure  {\textbar} 434 {\textbar}  on caldarium  {\textbar} 9 {\textbar} . {\textbar} The reader is requested to note the following labels on  {\textbar}   {\textbar} {FIG}. 37 {\textbar} : {\textbar} Catheter mount ball  {\textbar}   {\textbar} 436 {\textbar} Catheter mount socket  {\textbar}   {\textbar} 437 {\textbar} stimulating and recording unit  {\textbar}   {\textbar} 43 {\textbar} {FIG}. 41 {\textbar}   {\textbar}  depicts one design for the system enclosure for implantation in the calvarium. Mechanical attachment  {\textbar} 424 {\textbar}  is shown in plurality, facilitating mechanical attachment of system enclosure  {\textbar} 434 {\textbar}  to calvarium  {\textbar} 9 {\textbar} , including calvarium outer table  {\textbar} 421 {\textbar}  or calvarium inner table  {\textbar} 423 {\textbar} , calvarium stabilization lip  {\textbar} 501 {\textbar} , or other portion of calvarium without departing from the present invention. Alternatively, other attachment means may be fashioned to perform the equivalent function of attaching system enclosure  {\textbar} 434 {\textbar}  to calvarium  {\textbar} 9 {\textbar}  without departing from the present invention. A single or plurality of screw  {\textbar} 429 {\textbar}  is used to perform the attachment of mechanical attachment  {\textbar} 424 {\textbar}  to calvarium  {\textbar} 9 {\textbar}  and to system enclosure  {\textbar} 434 {\textbar} . Mechanical attachment may be implemented as a cranial plate, craniofacial plate, or other form well known to neurosurgeons, or it may be implemented in another equivalent fashion without departing form the present invention. {\textbar} Electrode  {\textbar}   {\textbar} 452 {\textbar} ,  {\textbar} 453 {\textbar} ,  {\textbar} 454 {\textbar} ,  {\textbar} 455 {\textbar} ,  {\textbar} 456 {\textbar} ,  {\textbar} 457 {\textbar} ,  {\textbar} 458 {\textbar} ,  {\textbar} 459 {\textbar} , are shown on the end of intracranial catheter  {\textbar} 7 {\textbar} , said electrode facilitate contact between intracranial electrodes  {\textbar} 246 {\textbar} , and circuitry enclosed within system enclosure  {\textbar} 434 {\textbar} , including but not limited to output stage, signal conditioning circuit, signal processing circuit, control circuit, and other circuit components. {\textbar} {FIGS}. 42 and 43 {\textbar}   {\textbar}  depict a dual intracranial catheter design, shown from above and shown in cross section profile implanted in a patient, respectively. Mechanical attachment  {\textbar} 424 {\textbar}  are as described in  {\textbar} {FIG}. 41 {\textbar} . Intracranial catheter  {\textbar} 7 {\textbar}  and Electrode  {\textbar} 452 {\textbar} ,  {\textbar} 453 {\textbar} ,  {\textbar} 454 {\textbar} ,  {\textbar} 455 {\textbar} ,  {\textbar} 456 {\textbar} ,  {\textbar} 457 {\textbar} ,  {\textbar} 458 {\textbar} ,  {\textbar} 459 {\textbar}  are as described in  {\textbar} {FIG}. 41 {\textbar} . Electrode  {\textbar} 476 {\textbar} ,  {\textbar} 477 {\textbar} ,  {\textbar} 478 {\textbar} ,  {\textbar} 479 {\textbar} ,  {\textbar} 480 {\textbar} ,  {\textbar} 481 {\textbar} ,  {\textbar} 482 {\textbar} ,  {\textbar} 483 {\textbar}  are shown on the end of intracranial catheter  {\textbar} 500 {\textbar} . A multiplicity of intracranial catheter y or intracranial catheter  {\textbar} 500 {\textbar}  may be employed without departing from the spirit of the present invention. In  {\textbar} {FIG}. 43 {\textbar} , a plurality of bone screw  {\textbar} 438 {\textbar}  is shown facilitating mechanical attachment of mechanical attachment  {\textbar} 424 {\textbar}  to caldarium  {\textbar} 9 {\textbar} . In  {\textbar} {FIG}. 43 {\textbar} , a plurality of machine screw  {\textbar} 439 {\textbar}  is shown facilitating mechanical attachment of mechanical attachment  {\textbar} 424 {\textbar}  to system enclosure  {\textbar} 434 {\textbar} . In  {\textbar} {FIG}. 43 {\textbar} , catheter recess  {\textbar} 441 {\textbar}  is seen in cross section, providing space for intracranial catheter  {\textbar} 7 {\textbar}  and intracranial catheter  {\textbar} 500 {\textbar}  to minimize the profile or height of system enclosure and avoid surface protuberances that could cause ulceration of overlying portions of scalp  {\textbar} 10 {\textbar} . {\textbar} {FIG}. 44 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the intracranial stimulator of the present invention implanted bilaterally in a human patient. In the embodiment illustrated in  {\textbar} {FIG}. 44 {\textbar} , two neurological control systems  {\textbar} 999 {\textbar}  are shown implanted bilaterally. Each system  {\textbar} 999 {\textbar}  includes a stimulating and recording unit  {\textbar} 26 {\textbar}  and one or more intracranial components described below. As described in this illustrative embodiment, the intracranial components preferably include a stimulating electrode array  {\textbar} 37 {\textbar} . However, it should become apparent to those of ordinary skill in the relevant art after reading the present disclosure that the stimulating electrodes may also be extracranial; that is, attached to a peripheral nerve in addition to or in place of being located within the cranium. {\textbar} {FIG}. 45 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the neurological control system  {\textbar} 999 {\textbar}  implanted unilaterally in a human patient. A multiplicity of components or multiplicity of entire systems may be implanted unilaterally or bilaterally without departing from the present invention. In the embodiment illustrated in  {\textbar} {FIG}. 45 {\textbar} , one neurological control systems  {\textbar} 999 {\textbar}  is shown implanted unilaterally in the temporal lobe, shown in an orientation intersecting the hippocampus  {\textbar} 277 {\textbar} . Each system  {\textbar} 999 {\textbar}  includes a stimulating and recording unit  {\textbar} 26 {\textbar}  and one or more intracranial components described in detail above in parent cases. As described in this illustrative embodiment, the intracranial components preferably include an intracranial catheter  {\textbar} 7 {\textbar}  with at least one of a sensor array  {\textbar} 560 {\textbar}  or neuromodulator array  {\textbar} 561 {\textbar} . Sensor array  {\textbar} 560 {\textbar}  may be implemented as a intracranial recording electrode array  {\textbar} 38 {\textbar} , {EEG} electrode array  {\textbar} 51 {\textbar} , or other form of sensory input including sensory input modalities  {\textbar} 247 {\textbar}  shown in  {\textbar} {FIG}. 1 {\textbar}  or other form, including optical, metabolic, chemical, or other sensor, without departing form the present invention. Neuromodulator array  {\textbar} 561 {\textbar} , shown on intracranial catheter  {\textbar} 7 {\textbar} , serve to stimulate, inhibit, or both, neural activity. Neuromodulator array  {\textbar} 561 {\textbar}  may be on the same intracranial catheter  {\textbar} 7 {\textbar}  as sensor array  {\textbar} 560 {\textbar}  or on a second intracranial catheter  {\textbar} 500 {\textbar} , as shown in  {\textbar} {FIG}. 46 {\textbar} , on a multiplicity of intracranial catheter  {\textbar} 7 {\textbar} , or on other structure, without departing from the present invention. There may be partial or complete overlap in elements that comprise neuromodulator array  {\textbar} 561 {\textbar}  and sensor array  {\textbar} 560 {\textbar} . For example, neural interface array  {\textbar} 562 {\textbar}  may be implemented as electrode array  {\textbar} 563 {\textbar} , some or all of elements of intracranial recording electrode array  {\textbar} 38 {\textbar}  and elements of intracranial stimulating electrode array  {\textbar} 37 {\textbar}  may be shared. Various forms of multiplexing, in various dimensions, including time, space, frequency, phase, or other dimension, may be employed to facilitate dual or multiple function of elements of sensor array  {\textbar} 560 {\textbar}  and neuromodulator array  {\textbar} 561 {\textbar} , to one skilled in the art, without departing form the present invention. It should become apparent to those of ordinary skill in the relevant art after reading the present disclosure that the stimulating electrodes may also be extracranial; that is, attached to a peripheral nerve or other location such as on the surface of the skin in addition to or in place of being located within the cranium. {\textbar} {FIG}. 46 {\textbar}   {\textbar}  is a schematic diagram of one embodiment of the neurological control system  {\textbar} 999 {\textbar}  implanted unilaterally in a human patient. A multiplicity of components or multiplicity of entire systems may be implanted unilaterally or bilaterally without departing from the present invention. In the embodiment illustrated in the sagittal view diagram in  {\textbar} {FIG}. 46 {\textbar} , one neurological control systems  {\textbar} 999 {\textbar}  is shown implanted unilaterally, with two intracranial catheters, intracranial catheter  {\textbar} 7 {\textbar}  and intracranial catheter  {\textbar} 500 {\textbar} , in the right thalamus  {\textbar} 335 {\textbar}  and the right hippocampus  {\textbar} 564 {\textbar} , respectively. The same or a multiplicity of neurological control systems  {\textbar} 999 {\textbar}  may be placed in contralateral structures, including left thalamus  {\textbar} 336 {\textbar}  and left hippocampus  {\textbar} 565 {\textbar} , and other structures including the right anterior nucleus of the thalamus, left anterior nucleus of the thalamus, right subthalamic nucleus, left subthalamic nucleus, right substantia nigra, left substantia nigra, other single structures, or other multiplicity of structures. {\textbar} Modulation of right hippocampus  {\textbar}   {\textbar} 564 {\textbar}  is also accomplished via hippocampal modulator  {\textbar} 534 {\textbar}  and hippocampal modulator  {\textbar} 535 {\textbar} . Modulation of left hippocampus  {\textbar} 565 {\textbar}  is also accomplished via hippocampal modulator  {\textbar} 536 {\textbar}  and hippocampal modulator  {\textbar} 357 {\textbar} . Cortex  {\textbar} 252 {\textbar}  is modulated via cortical modulator  {\textbar} 530 {\textbar} , cortical modulator  {\textbar} 531 {\textbar} , cortical modulator  {\textbar} 532 {\textbar} , and cortical modulator  {\textbar} 533 {\textbar} . {\textbar} {FIG}. 46 {\textbar}   {\textbar}  also shows cortical modulator  {\textbar} 530 {\textbar} , cortical modulator  {\textbar} 531 {\textbar} , cortical modulator  {\textbar} 532 {\textbar} , cortical modulator  {\textbar} 533 {\textbar} , hippocampal modulator  {\textbar} 534 {\textbar} , hippocampal modulator  {\textbar} 535 {\textbar} , hippocampal modulator  {\textbar} 536 {\textbar} , and hippocampal modulator  {\textbar} 537 {\textbar} , which facilitate modulation of multiple regions of cortex  {\textbar} 252 {\textbar} , right hippocampus  {\textbar} 564 {\textbar} , and left hippocampus  {\textbar} 565 {\textbar} . {\textbar} {FIG}. 46 {\textbar}   {\textbar}  and  {\textbar} {FIG}. 47 {\textbar}  are sagittal and lateral view diagrams, respectively, depicting a multiplicity of neural interfacing nodes. Neural interfacing is accomplished with olfactory nerve  {\textbar} 525 {\textbar}  via at least one of olfactory nerve modulator  {\textbar} 527 {\textbar}  and with trigeminal nerve  {\textbar} 368 {\textbar}  via at least one of trigeminal nerve modulator  {\textbar} 528 {\textbar} . {\textbar} {FIG}. 47 {\textbar}   {\textbar}  depicts neural interfacing with vagus nerve  {\textbar} 369 {\textbar}  via at least one of vagus nerve modulator  {\textbar} 529 {\textbar} , with baroreceptor  {\textbar} 370 {\textbar}  via baroreceptor modulator  {\textbar} 566 {\textbar} , with sympathetic ganglion  {\textbar} 371 {\textbar}  via sympathetic modulator  {\textbar} 567 {\textbar} . Modulation of these structures is used for control of neurological state in the treatment of neurological disease as well as hypertension and hypotension. {\textbar} {FIG}. 47 {\textbar}   {\textbar}  also depicts several noninvasive techniques for the treatment of neurological disease. Orbitofrontal modulator  {\textbar} 279 {\textbar} , prefrontal modulator  {\textbar} 280 {\textbar} , precentral modulator  {\textbar} 281 {\textbar} , postcentral modulator  {\textbar} 282 {\textbar} , parietal modulator  {\textbar} 283 {\textbar} , parietooccipital modulator  {\textbar} 284 {\textbar} , occipital modulator  {\textbar} 285 {\textbar} , cerebellar modulator  {\textbar} 286 {\textbar}  are shown overlying the scalp  {\textbar} 10 {\textbar} . These may be implemented as electromagnetic coils or as electrodes, to produce electromagnetic waves for the induction of current or to directly produce currents, respectively. There may also be implemented optically or using other modality for the modulation of neurological activity. These neuromodulators may be located at any anatomical depth, including superficial to the scalp, implanted at any level including but not limited to within the scalp, under the scalp, recessed in the caldarium, deep to the caldarium, in the epidural space, in the subdural space, overlying the cortex, within the cortex, or deep to the cortex, without departing from the present invention. Neuromodulators may take the form of macroelectrodes, macroelectrode arrays, microelectrodes, microelectrode arrays, nerve cuffs, other designs described in the present invention, other electrode designs known in the art, and other neural interfaces to be developed, without departing form the present invention. {\textbar} Neural chaos is modulated by the controlled introduction of energy into a single or multiplicity of neural structures including but not limited to olfactory nerve  {\textbar}   {\textbar} 525 {\textbar} , trigeminal nerve  {\textbar} 368 {\textbar} , vagus nerve  {\textbar} 369 {\textbar} , cutaneous nerves, other cranial nerves, subcutaneous nerve endings, cortex  {\textbar} 252 {\textbar} , cerebral cortex, cerebellar cortex  {\textbar} 257 {\textbar} , deep brain structures  {\textbar} 349 {\textbar} , thalamus  {\textbar} 121 {\textbar} , subthalamic nucleus  {\textbar} 122 {\textbar} , basal ganglia, locus ceruleus, any portion or portions of Papez' circuit, hippocampus, amygdala, fornix, subthalamic nucleus, anterior nucleus of the thalamus, prepyriform cortex, solitary nucleus, dorsal column nucleus, cerebellar nuclei, caudate, putamen, corpus callosum, other nuclei, other tracts, other nerves, other nuclei, other neural structures, and other non-neural structures. {\textbar} {FIG}. 48 {\textbar}   {\textbar}  shows dermatomal zones, revealing specific areas of innervation of skin  {\textbar} 382 {\textbar}  by underlying nerves. Dermatomal zone  {\textbar} 538 {\textbar} , dermatomal zone  {\textbar} 539 {\textbar} , and dermatomal zone  {\textbar} 540 {\textbar}  are innervated by trigeminal nerve branches  {\textbar} 1 {\textbar} ,  {\textbar} 2 {\textbar} , and  {\textbar} 3 {\textbar} , respectively. Dermatomal zone  {\textbar} 541 {\textbar} , dermatomal zone  {\textbar} 542 {\textbar} , and dermatomal zone  {\textbar} 543 {\textbar}  are innervated by cervical nerve roots C {\textbar} 2 {\textbar} , C {\textbar} 2 {\textbar} , and C {\textbar} 3 {\textbar} , respectively. {\textbar} {FIG}. 49 {\textbar}   {\textbar}  depicts two implementations of noninvasive versions of neurological control system  {\textbar} 999 {\textbar} ; these are shown as neurological control system  {\textbar} 994 {\textbar}  which is preferably mounted on the had and neurological control system  {\textbar} 995 {\textbar}  which is preferably mounted on the neck. {\textbar} Neurological control system  {\textbar}   {\textbar} 994 {\textbar}  comprises head band  {\textbar} 568 {\textbar} , recording and stimulating unit  {\textbar} 555 {\textbar} , connecting cable  {\textbar} 556 {\textbar} , connecting cable  {\textbar} 557 {\textbar} , and neuromodulator  {\textbar} 545 {\textbar} , neuromodulator  {\textbar} 546 {\textbar} , neuromodulator  {\textbar} 547 {\textbar} , neuromodulator  {\textbar} 548 {\textbar} , neuromodulator  {\textbar} 549 {\textbar} , neuromodulator  {\textbar} 550 {\textbar} , neuromodulator  {\textbar} 551 {\textbar} , neuromodulator  {\textbar} 552 {\textbar} , and an additional set, which may be symmetrical or asymmetrical, on the contralateral side. {\textbar} Neurological control system  {\textbar}   {\textbar} 995 {\textbar}  comprises head band  {\textbar} 569 {\textbar} , recording and stimulating unit  {\textbar} 570 {\textbar} , connecting cable  {\textbar} 558 {\textbar} , connecting cable  {\textbar} 559 {\textbar} , and neuromodulator  {\textbar} 553 {\textbar} , neuromodulator  {\textbar} 554 {\textbar} , and an additional set, which may be symmetrical or asymmetrical, on the contralateral side. {\textbar} Any single or plurality of said dermatomal zone  {\textbar}   {\textbar} 538 {\textbar} ,  {\textbar} 539 {\textbar} ,  {\textbar} 540 {\textbar} ,  {\textbar} 541 {\textbar} ,  {\textbar} 542 {\textbar} ,  {\textbar} 543 {\textbar}  may be modulated using implanted nerve cuff electrode disclosed in pending patent application Ser. No. 10/198,871 ({GISTIM}) and the cited provisional Appln. No. 60/307,124. Other techniques for modulating innervation to these regions may be employed without departing from the present invention. These include surface electrical stimulation, magnetic stimulation, transcranial magnetic stimulation, vibrotactile stimulation, thermal stimulation, pressure stimulation, optical stimulation, or other stimulation modality. {\textbar} {FIG}. 50 {\textbar}   {\textbar}  depicts a functional block diagram of the neurological control system  {\textbar} 999 {\textbar} , connected to intracranial catheter  {\textbar} 7 {\textbar} , shown implanted in the temporal lobe  {\textbar} 571 {\textbar} , intersecting the hippocampus  {\textbar} 277 {\textbar} . In this diagram, signal from sensor array  {\textbar} 560 {\textbar}  is conditioned, conducted along intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar}  to signal processor  {\textbar} 71 {\textbar} , which generates control input (Y)  {\textbar} 996 {\textbar} , which is conducted to control circuit  {\textbar} 72 {\textbar} , which generates control output (U)  {\textbar} 997 {\textbar} , which is conducted to Output stage circuit  {\textbar} 77 {\textbar} , which generates neuromodulating signal ({NMS})  {\textbar} 998 {\textbar} , which is conducted along stimulator output path  {\textbar} 111 {\textbar}  to neuromodulator array  {\textbar} 561 {\textbar} . Neuromodulator array  {\textbar} 561 {\textbar}  and sensor array  {\textbar} 560 {\textbar}  are implemented as intracranial recording electrode array ({ICREA})  {\textbar} 38 {\textbar}  and intracranial stimulating electrode array ({ICSEA})  {\textbar} 37 {\textbar} , in one preferred embodiment. In the present invention, control input (Y)  {\textbar} 996 {\textbar}  is a function of at least one of neural chaos, T-index, neural signal correlation, neural signal cross-correlation, and neural synchronization. Control output (U)  {\textbar} 997 {\textbar}  and neuromodulatory signal ({NMS})  {\textbar} 998 {\textbar}  are selected to modulate at least one of neural chaos, neural signal correlation, neural signal cross-correlation, and neural synchronization. {\textbar} {FIG}. 51 {\textbar}   {\textbar}  depicts the same functional block diagram as in  {\textbar} {FIG}. 50 {\textbar}  with the addition of a second intracranial catheter  {\textbar} 500 {\textbar}  positioned to intersect at least one of the thalamus  {\textbar} 121 {\textbar} , subthalamic nucleus  {\textbar} 122 {\textbar} , or other anatomical target, including at least one of the centromedian nucleus, substantia nigra, locus ceruleus, reticular activating center, nucleus solitarus, or other neural structure or non-neural structure. {\textbar} {FIG}. 52 {\textbar}   {\textbar}  depicts the same functional block diagram as in  {\textbar} {FIG}. 51 {\textbar}  with the addition of a time diagram of the control input (Y)  {\textbar} 996 {\textbar}  and control output (U)  {\textbar} 997 {\textbar}  shown versus time. The control input (Y)  {\textbar} 996 {\textbar}  is shown to vary with time and to remain within the bounds delimited by threshold  {\textbar} 572 {\textbar}  and threshold  {\textbar} 575 {\textbar} . Control output (U)  {\textbar} 997 {\textbar}  is shown to vary with time in a manner designed to maintain control input (Y)  {\textbar} 996 {\textbar}  within the range specified, below threshold  {\textbar} 572 {\textbar}  and above threshold  {\textbar} 575 {\textbar} . Any of the control laws specified in this patent as well as any others may be used without departing form the present invention. In  {\textbar} {FIG}. 52 {\textbar} , signals form a nonlinear control law is shown; as the disease state varies and approaches threshold  {\textbar} 575 {\textbar}  toward the center of the diagram, control output (U)  {\textbar} 997 {\textbar}  is seen to increase and drive control input (Y)  {\textbar} 996 {\textbar}  back toward the center of the range delimited by threshold  {\textbar} 572 {\textbar}  and threshold  {\textbar} 575 {\textbar} . {\textbar} {FIG}. 53 {\textbar}   {\textbar}  depicts the same functional block diagram and time diagram as in  {\textbar} {FIG}. 52 {\textbar}  with the addition of a threshold  {\textbar} 573 {\textbar} , threshold  {\textbar} 574 {\textbar} , and target value  {\textbar} 576 {\textbar} . In this time diagram, control output (U)  {\textbar} 997 {\textbar}  is shown to vary in accordance with a more complex nonlinear control law. The variation is representative of a piecewise linear control law, which response differently when the control input (Y) is in different regions as defined by threshold  {\textbar} 572 {\textbar} , threshold  {\textbar} 573 {\textbar} , threshold  {\textbar} 574 {\textbar} , threshold  {\textbar} 575 {\textbar} , and target value  {\textbar} 576 {\textbar} . In this embodiment, as control input (Y)  {\textbar} 996 {\textbar}  diverges farther from target value  {\textbar} 576 {\textbar} , the absolute value of the magnitude of control output (U)  {\textbar} 997 {\textbar}  becomes larger. The vertical center of the time diagram for control output (U) may be interpreted as being zero, though other offsets and baseline values may be used without departing form the present invention. As disease state enters the range delimited by threshold  {\textbar} 572 {\textbar}  and threshold  {\textbar} 573 {\textbar} , the gain of control law is seen to increase, as reflected by the incremental increase in magnitude of control output (U)  {\textbar} 997 {\textbar} . As disease state enters the range delimited by threshold  {\textbar} 574 {\textbar}  and threshold  {\textbar} 575 {\textbar} , the gain of control law is seen to increase, as reflected by the incremental increase, in the opposite polarity, in magnitude of control output (U)  {\textbar} 997 {\textbar} . This behavior demonstrates a control law designed to maintain control input (Y)  {\textbar} 996 {\textbar}  within the operating range defined by threshold  {\textbar} 573 {\textbar}  and threshold  {\textbar} 574 {\textbar} , shown as target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} , which are above and below target value  {\textbar} 576 {\textbar} , respectively. As is shown subsequently, state (X)  {\textbar} 991 {\textbar}  is a scalar or vector of value representative of neurological state and disease state. Components of state (X)  {\textbar} 991 {\textbar}  may be identical to or functions of control input (Y). Furthermore, the same, similar, or different control laws and systems may be employed to control the behavior of state (X)  {\textbar} 991 {\textbar} . f control input (Y)  {\textbar} 996 {\textbar}  diverges outside this range and into critical range  {\textbar} 579 {\textbar}  or critical range  {\textbar} 580 {\textbar} , a different control scheme is used. This may be implemented as the same control law with different gains or as a different control law. {\textbar} In  {\textbar}   {\textbar} {FIG}. 53 {\textbar} , the signal path is shown along with the system block diagram, detailed in  {\textbar} {FIG}. 2 {\textbar} , which is from the original filing of the parent case of this patent. Neural recording signal ({NRS})  {\textbar} 993 {\textbar}  is sensed by sensor array  {\textbar} 560 {\textbar} , and is transmitted to signal conditioning circuit  {\textbar} 76 {\textbar} . Feedback signal (F)  {\textbar} 992 {\textbar}  is generated by signal conditioning circuit  {\textbar} 76 {\textbar}  from neural recording signal ({NRS})  {\textbar} 993 {\textbar}  and transmitted to signal processor  {\textbar} 71 {\textbar} . Feedback signal (F) is shown transmitted on Conditioned Intracranial recording electrode ({ICRE}) signal path  {\textbar} 83 {\textbar} , though for a non-implanted neurological control system  {\textbar} 999 {\textbar} , a different transmission means would be used, without departing form the present invention. Signal conditioning circuit  {\textbar} 76 {\textbar} , may have a unity gain, and equivalently be omitted from neurological control system  {\textbar} 999 {\textbar} , without departing from the present or parent case invention. {\textbar} In  {\textbar}   {\textbar} {FIG}. 54 {\textbar} , a time diagram of the control input (Y)  {\textbar} 996 {\textbar}  and control output (U)  {\textbar} 997 {\textbar}  shown versus time. In addition, a time diagram of state vector (X)  {\textbar} 991 {\textbar} , with components state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar} , state  {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar} , state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar} , and state  {\textbar} 5 {\textbar}  (X {\textbar} 5 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 5 {\textbar} , are shown. More or fewer states, comprising the range of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  to state N ({XN})  {\textbar} 991 {\textbar} -N, as shown in  {\textbar} {FIG}. 56 {\textbar} , may be defined without departing from the present invention. {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  is identical to control input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  is a function of neural chaos. This may be used to facilitate a proportional control law component in the control of neural chaos. In one preferred embodiment the function of neural chaos includes the disentrainment of neural chaos, inversely related to the synchronization of neural chaos among at least 1 recording electrode or other neural signal transducer. {\textbar} There are a multiplicity of methods and designs in which this can be implemented in the present invention. In one such preferred embodiment, one state may be allocated to represent the measure of neural chaos for each element of neural recording signal ({NRS})  {\textbar}   {\textbar} 993 {\textbar} , as recorded from each recording electrode or signal transducer, including at least one of intracranial recording electrode  {\textbar} 5 {\textbar} , intracranial recording electrode  {\textbar} 6 {\textbar} , elements of intracranial recording electrode array  {\textbar} 38 {\textbar} , elements of neural interface array  {\textbar} 562 {\textbar}  (shown in  {\textbar} {FIG}. 45 {\textbar} ), or other neural signal transducer. At least one additional state is defined as a function of these states, specifically the disentrainment of neural chaos, inversely related to the correlation or synchronization of neural chaos, which is a measure of the correlation between these measures of neural chaos derived from elements of neural recording signal ({NRS})  {\textbar} 993 {\textbar} . These measures of neural chaos and the correlation between neural chaos measurements may be alternatively calculated within signal processor  {\textbar} 71 {\textbar}  as a neural state or disease state estimate, without departing from the present invention. {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar}  is a time derivative of control input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar}  is a measure of the first derivative with respect to time of neural chaos or function thereof, which is used to facilitate a differential control law component in the control of said function of neural chaos. {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is a time integral of control Input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is a measure of the first integral with respect to time of neural chaos or function thereof, which is used to facilitate an integral control law component in the control of said function of neural chaos. {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar}  is a nonlinear function of control input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is a measure of a nonlinear function of neural chaos, which is used to facilitate a nonlinear control law component in the control of neural chaos or function thereof, including disentrainment of neural chaos or of synchronization of neural chaos. As shown, state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar}  depicts a nonlinear function which is approximately zero during the condition in which control input (Y)  {\textbar} 996 {\textbar}  is within target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar}  and increases in magnitude as control input (Y) deviates from the region defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar}  and migrates into at least one of critical range  {\textbar} 579 {\textbar}  and critical range  {\textbar} 580 {\textbar} . State  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar}  is shown to represent “target range deviation”, a continuous function which is shown as the amount by which state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ) deviates outside the limits defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . {\textbar} In state time diagram shown, state  {\textbar}   {\textbar} 5 {\textbar}  (X {\textbar} 5 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 5 {\textbar}  is an error signal representing the difference between a constant or time varying reference value and control input (Y)  {\textbar} 996 {\textbar} . As such it represents an error signal. It may also be processed to generate additional states, such as a combination of first, second, and higher order derivatives and integrals with respect to time, to produce control laws of arbitrary complexity to facilitate tracking of any or all components of state (X)  {\textbar} 991 {\textbar}  to a desired reference signal. In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 5 {\textbar}  (X {\textbar} 5 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 5 {\textbar}  is a measure of the difference between the actual level of neural chaos and the desired level of neural chaos, such as target value  {\textbar} 576 {\textbar}  or other signal. {\textbar} These components of state (X)  {\textbar}   {\textbar} 991 {\textbar} , and other signals and functions thereof, are used to drive the neural chaos to a desired level, such as within the normal level seen during inter-ictal periods, and to prevent the neural chaos form entering critical range  {\textbar} 579 {\textbar}  or critical range  {\textbar} 580 {\textbar} . When neural chaos decreases to a value within critical range  {\textbar} 580 {\textbar} , the probability of a seizure is increased. Generation of neuromodulatory signal ({NMS})  {\textbar} 998 {\textbar}  is performed to drive neural chaos out of this region into either of target range  {\textbar} 577 {\textbar}  or target range  {\textbar} 578 {\textbar} , to reduce the probability of a seizure and thereby prevent the occurrence of a seizure. {\textbar} This control system is also used to prevent occurrence of other neurological events, including mania, depression, psychosis, rage, narcolepsy, desire for addicting agents (i.e. opiates, cocaine, nicotine, alcohol, or other drug), or other undesirable neurological state, condition, perception, or symptom. {\textbar}   {\textbar} Neuromodulatory signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  is transmitted to neuromodulator array  {\textbar} 561 {\textbar} . Neuromodulator array  {\textbar} 561 {\textbar} , encompasses any single or plurality of neuromodulator elements, including neuromodulator  {\textbar} 545 {\textbar} , neuromodulator  {\textbar} 546 {\textbar} , neuromodulator  {\textbar} 547 {\textbar} , neuromodulator  {\textbar} 548 {\textbar} , neuromodulator  {\textbar} 549 {\textbar} , neuromodulator  {\textbar} 550 {\textbar} , neuromodulator  {\textbar} 551 {\textbar} , neuromodulator  {\textbar} 552 {\textbar} , neuromodulator  {\textbar} 553 {\textbar} , neuromodulator  {\textbar} 554 {\textbar} , intracranial stimulating electrode  {\textbar} 1 {\textbar} , intracranial stimulating electrode  {\textbar} 2 {\textbar} , intracranial stimulating electrode  {\textbar} 3 {\textbar} , and intracranial stimulating electrode  {\textbar} 4 {\textbar} . Any of said neuromodulator elements may be implemented as a singularity or combination of an electrode for the delivery of electrical energy, a drug delivery catheter for the delivery of drug or chemical agent, a microcatheter for the intraparenchymal delivery of drug or agent, an optical element for the delivery of optical energy, a coil or other transceiver for the delivery of electromagnetic energy, ultrasonic transducer for the delivery of ultrasound energy, thermal source for the introduction of thermal energy, thermal sink for the removal of thermal energy, microdialysis device for the introduction or control of chemical concentrations, or other device for the modulation of neural activity. {\textbar} Neuromodulatory signal ({NMS})  {\textbar}   {\textbar} 998 {\textbar}  is transmitted to neuromodulator array  {\textbar} 561 {\textbar} , according to closed-loop control laws described above, to control state (X)  {\textbar} 991 {\textbar}  in any of several manners or combinations thereof, including control laws to: (1) maintain state (X)  {\textbar} 991 {\textbar}  at or near a target value (scalar or vector), (2) maintain state (X)  {\textbar} 991 {\textbar}  within a single or plurality of target ranges, including but not limited to target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} , (3) prevent state (X)  {\textbar} 991 {\textbar}  from entering any critical range, including but not limited to critical range  {\textbar} 579 {\textbar}  and critical range  {\textbar} 580 {\textbar} , (4) to maintain state (X)  {\textbar} 991 {\textbar}  at or near any constant or time-varying reference value, (scalar or vector), (5) maintain state (X)  {\textbar} 991 {\textbar}  within a single or plurality of constant or time-varying target ranges, (6) prevent state (X)  {\textbar} 991 {\textbar}  from entering any constant or time-varying critical range, and (7) other form of closed-loop control. {\textbar} As is typical of control systems, the farther any single or plurality of component of state (X)  {\textbar}   {\textbar} 991 {\textbar}  is from a critical range, such as critical range  {\textbar} 579 {\textbar}  and critical range  {\textbar} 580 {\textbar} , the lower the probability of entering said critical range by said single or plurality of component of state (X)  {\textbar} 991 {\textbar} . The larger the difference between a single or plurality of component of state (X)  {\textbar} 991 {\textbar}  from said critical range, the larger the system dynamic effect, external perturbation, or noise magnitude would be required to drive said single or plurality of component of state (X)  {\textbar} 991 {\textbar}  into said critical range. For a neurological condition that has an elevated probability of occurring when said single or plurality of component of state (X)  {\textbar} 991 {\textbar}  are in critical range, the probability of said neurological condition occurring can be minimized if said single or plurality of component of state (X)  {\textbar} 991 {\textbar}  is kept outside or as far in value as possible from of said critical range. {\textbar} When the present invention is applied to the treatment of epilepsy, at least one component, i.e. state  {\textbar}   {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , of state (X)  {\textbar} 991 {\textbar} , is decreases as the probability of a seizure occurring increases. Through the introduction of chaos into the nervous system, the neural chaos is increased, thereby reducing the probability of a seizure occurring. With sufficient control gain, the probability of a seizure occurring can be driven to small values approaching zero; resulting in the prevention of a seizure. {\textbar} State (X)  {\textbar}   {\textbar} 991 {\textbar}  comprises disease state estimate as shown in  {\textbar} {FIG}. 12 {\textbar} . As taught in the parent case, and is shown in  {\textbar} {FIG}. 12 {\textbar} , a control error (e) is calculated as the difference between the disease reference state (r) and the disease state estimate (X). Control circuit  {\textbar} 72 {\textbar}  operates to drive this control error (e) toward zero, such that the disease state estimate (X) follows the disease state reference (r). This same invention, taught in the parent case, is used to control state (X) as also shown in  {\textbar} {FIG}. 52 {\textbar} , to follow a desired disease reference state. This same invention, taught in the parent case, is also used to control state (X) as also shown in  {\textbar} {FIG}. 52 {\textbar} , to remain within a desired target range. This same invention, taught in the parent case, is also used to control state (X) as also shown in  {\textbar} {FIG}. 52 {\textbar} , to remain outside of a critical range. Control law circuit block  {\textbar} 231 {\textbar}  teaches a configuration for accomplishing each of these control schemes. {\textbar} In the control of neurological state to prevent seizures, the control circuit  {\textbar}   {\textbar} 72 {\textbar}  shown in the parent invention may be employed to perform at least one of (1) maintenance of neurological chaos or function thereof at a reference value, typically defined within the normal inter-ictal range; (2) maintenance of neurological chaos or function thereof within a target range, typically representative of normal inter-ictal chaos range; (3) maintenance of neurological chaos or function thereof outside of a critical range, typically outside of the normal inter-ictal chaos range, (4) maintenance of neurological chaos or function thereof as far as possible from a critical range which is associated with an increased probability of seizure; (5) maintenance of neurological chaos or function thereof at a constant value, (6), maintenance of neurological chaos at a time varying value. Functions of neurological chaos included in the present invention comprise disentrainment of neural chaos, entrainment of neural chaos, synchronization of neural chaos, correlation of neural chaos, differences between actual and reference values of neural chaos, and functions thereof. {\textbar} In  {\textbar}   {\textbar} {FIG}. 55 {\textbar} , a time diagram of the control input (Y)  {\textbar} 996 {\textbar}  and control output (U)  {\textbar} 997 {\textbar}  shown versus time. In addition, a time diagram of state vector (X)  {\textbar} 991 {\textbar} , with components state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar} , state  {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar} , state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar} , and state N ({XN})  {\textbar} 991 {\textbar} -N, are shown. More or fewer states may be defined without departing from the present invention. {\textbar} In this figure, state  {\textbar}   {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  is shown to be the same as control input  {\textbar} 1 {\textbar}  (Y- {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , which represents disentrainment of neural chaos among elements of neural recording signal ({NRS})  {\textbar} 993 {\textbar} , calculated in this preferred embodiment as a disease state estimate by signal processor  {\textbar} 71 {\textbar}  and transmitted to control circuit  {\textbar} 72 {\textbar} . The calculations may be allocated differently among signal processor  {\textbar} 71 {\textbar}  and control circuit  {\textbar} 72 {\textbar}  without departing form the present invention. State  {\textbar} 2 {\textbar}  (X {\textbar} 2 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 2 {\textbar}  is shown as the first derivative with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} . State  {\textbar} 3 {\textbar}  (X {\textbar} 3 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is shown as the first integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} As seen in  {\textbar}   {\textbar} {FIG}. 55 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  remains within target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . State  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 9914 {\textbar}  represents a function of the amount by which state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ) deviates outside the limits defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . In state time diagram shown, state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 4 {\textbar}  is a nonlinear function of control input (Y)  {\textbar} 996 {\textbar} . In the application of seizure control, one embodiment for such a state as represented by state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  is a measure of a nonlinear function of the disentrainment of neural chaos. As seen in related  {\textbar} {FIG}. 54 {\textbar} , state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 3 {\textbar}  depicts a nonlinear function which is approximately zero during the condition in which control input (Y)  {\textbar} 996 {\textbar}  is within target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar}  and increases in magnitude as control input (Y) deviates from the region defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar}  and migrates into at least one of critical range  {\textbar} 579 {\textbar}  and critical range  {\textbar} 580 {\textbar} . State  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 9914 {\textbar}  is shown to represent “target range deviation”, a continuous function which is shown as the amount by which state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ) deviates outside the limits defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . In  {\textbar} {FIG}. 55 {\textbar} , state  {\textbar} 4 {\textbar}  (X {\textbar} 4 {\textbar} )  {\textbar} 9914 {\textbar}  remains approximately zero during the time span shown, since control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  remains within the union of union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} , suggesting satisfactory closed-loop control performance, specifically in the regulation of the disentrainment of neural chaos. {\textbar} In  {\textbar}   {\textbar} {FIG}. 56 {\textbar} , a time diagram of the unperturbed control input (Y′)  {\textbar} 988 {\textbar}  and perturbed control input (Y″)  {\textbar} 989 {\textbar} , unperturbed control output (U′)  {\textbar} 983 {\textbar}  and perturbed control output (U″)  {\textbar} 984 {\textbar} , unperturbed state (X′)  {\textbar} 986 {\textbar} , and perturbed state (X″)  {\textbar} 987 {\textbar}  in response to perturbation (P)  {\textbar} 990 {\textbar} . This figure shows the effect of perturbation (P)  {\textbar} 990 {\textbar}  on the neurophysiology of patient  {\textbar} 227 {\textbar}  and signals processed by neurological control system  {\textbar} 999 {\textbar} . {\textbar} Unperturbed control input  {\textbar}   {\textbar} 1 {\textbar}  (Y- {\textbar} 1 {\textbar} ′)  {\textbar} 988 {\textbar} , unperturbed control output  {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ′)  {\textbar} 983 {\textbar} , and unperturbed state  {\textbar} 1 {\textbar}  (X- {\textbar} 1 {\textbar} ′)  {\textbar} 986 {\textbar}  represent the neurophysiology of patient  {\textbar} 227 {\textbar}  and signals processed by neurological control system  {\textbar} 999 {\textbar}  in the absence of perturbation (P)  {\textbar} 990 {\textbar} . Additional elements of any values, including but not limited to unperturbed control input (Y′)  {\textbar} 988 {\textbar} , unperturbed control output (U′)  {\textbar} 983 {\textbar} , and unperturbed state (X′)  {\textbar} 986 {\textbar}  are included in the present invention, in a multivariable implementation of a preferred embodiment of the present invention. {\textbar} Perturbed control input  {\textbar}   {\textbar} 1 {\textbar}  (Y- {\textbar} 1 {\textbar} ″)  {\textbar} 989 {\textbar} - {\textbar} 1 {\textbar} , perturbed control output  {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ″)  {\textbar} 984 {\textbar} - {\textbar} 1 {\textbar} , and perturbed state  {\textbar} 1 {\textbar}  (X- {\textbar} 1 {\textbar} ″)  {\textbar} 987 {\textbar} - {\textbar} 1 {\textbar}  represent the neurophysiology of patient  {\textbar} 227 {\textbar}  and signals processed by neurological control system  {\textbar} 999 {\textbar}  in the presence of perturbation (P)  {\textbar} 990 {\textbar} , such as the application of flashing lights. Additional elements of any values, including but not limited to perturbed control input (Y″)  {\textbar} 989 {\textbar} , perturbed control output (U″)  {\textbar} 984 {\textbar} , and perturbed state (X″)  {\textbar} 987 {\textbar}  are included in the present invention, in a multivariable implementation of a preferred embodiment of the present invention. {\textbar} Independence of neural chaos and disentrainment of neural chaos are seen to decrease, reflective of an increase in synchronization of neural chaos, in response to perturbation (P)  {\textbar}   {\textbar} 990 {\textbar} ; and other state variables, including perturbed state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ″)  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , through perturbed state N ({XN}″)  {\textbar} 991 {\textbar} -N, as described in detail in  {\textbar} {FIG}. 54 {\textbar}  and  {\textbar} {FIG}. 55 {\textbar} , are shown to respond accordingly. {\textbar} Perturbed control output  {\textbar}   {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ″)  {\textbar} 984 {\textbar} - {\textbar} 1 {\textbar}  is seen to increase relative to unperturbed control output  {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ′)  {\textbar} 983 {\textbar} - {\textbar} 1 {\textbar} , as determined by control law implemented in control circuit  {\textbar} 72 {\textbar} , in response to the increase in perturbed state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} ″)  {\textbar} 987 {\textbar} - {\textbar} 1 {\textbar} . This incremental increase in perturbed control output  {\textbar} 1 {\textbar}  (U- {\textbar} 1 {\textbar} ″)  {\textbar} 984 {\textbar} - {\textbar} 1 {\textbar}  causes a corresponding incremental increase in neuromodulating signal ({NMS})  {\textbar} 998 {\textbar} , which causes an incremental increase in the level of neural disentrainment to compensate for the effects of perturbation (P)  {\textbar} 990 {\textbar} , driving the level of disentrainment of neural chaos back into the desired range, comprising the region defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} . {\textbar} In  {\textbar}   {\textbar} {FIG}. 57 {\textbar} , a time diagram of the {EEG} signal (E)  {\textbar} 985 {\textbar} , unperturbed control input (Y′)  {\textbar} 988 {\textbar}  and perturbed control input (Y″)  {\textbar} 989 {\textbar} , unperturbed control output (U′)  {\textbar} 983 {\textbar}  and perturbed control output (U″)  {\textbar} 984 {\textbar} , unperturbed state (X′)  {\textbar} 986 {\textbar}  and perturbed state (X″)  {\textbar} 987 {\textbar}  in response to perturbation (P)  {\textbar} 990 {\textbar} . This figure shows the effect of perturbation (P)  {\textbar} 990 {\textbar}  on the neurophysiology of patient  {\textbar} 227 {\textbar}  and signals processed by neurological control system  {\textbar} 999 {\textbar} . {\textbar} In addition to the values shown in  {\textbar}   {\textbar} {FIG}. 56 {\textbar} ,  {\textbar} {FIG}. 57 {\textbar}  further shows {EEG} signal  {\textbar} 985 {\textbar} , including {EEG} signal  {\textbar} 1 {\textbar}  (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and {EEG} signal  {\textbar} 2 {\textbar}  (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during which time span there are no {EEG} abnormalities  {\textbar} 599 {\textbar} . Neurological control system  {\textbar} 999 {\textbar}  maintains perturbed control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 989 {\textbar} - {\textbar} 1 {\textbar}  within the desired range, comprising the region defined by the union of target range  {\textbar} 577 {\textbar}  and target range  {\textbar} 578 {\textbar} , preventing any neurological signs or symptoms and preventing any {EEG} abnormalities which may precede or be concurrent with such neurological signs or symptoms. {\textbar} In  {\textbar}   {\textbar} {FIG}. 58 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y)  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the normal unperturbed state. This diagram shows normal {EEG} signals, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , with no {EEG} abnormalities  {\textbar} 599 {\textbar}  nor neurological signs or symptoms  {\textbar} 600 {\textbar}  during this time span {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . Additional states (X)  {\textbar} 991 {\textbar}  may be defined or used without departing from the present invention. In one embodiment, for the treatment of seizures, state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  represent the level of correlation of neural chaos between {EEG} signals (E {\textbar} 1 {\textbar}  to E-N)  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  to  {\textbar} 985 {\textbar} -N. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  may occupy a range of values that are subdivided into specific ranges shown in  {\textbar} {FIG}. 58 {\textbar} . {\textbar} Under normal baseline conditions, as shown for baseline nonperturbed nontreated period  {\textbar}   {\textbar} 592 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary within normal range  {\textbar} 587 {\textbar} . This demonstrated variation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  occurs throughout the day under normal conditions and in the absence of any signs or symptoms of disease. This represents a normal range of disease state. In one preferred embodiment for the treatment of epilepsy, this represents the normal range of a metric of disentrainment of neural chaos and during which there are no signs and no symptoms of seizure. {\textbar} Under normal conditions and during which time the present invention is in operation (“Closed-Loop Neuromodulator Control {ON}”), shown as nonperturbed treated period  {\textbar}   {\textbar} 593 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary within control range  {\textbar} 586 {\textbar} . Control range  {\textbar} 586 {\textbar}  is a subset of normal range  {\textbar} 587 {\textbar} . This demonstrates variation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  that occurs throughout the day under conditions in which the present invention is active (“Closed-Loop Neuromodulator Control {ON}”) and in the absence of any signs or symptoms of disease. This represents a normal range of disease state. In one preferred embodiment for the treatment of epilepsy, this represents the normal range of a metric of neural chaos during which there are no signs and no symptoms of seizure. During nonperturbed treated period  {\textbar} 593 {\textbar} , the Closed-Loop Neuromodulator Control is {ON} and control output (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is active. Due to the action of control output (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar} , implemented as electrical current or voltage pulses, flow of pharmacological or chemical agent, emission of light, delivery of vibratory or ultrasound energy, production of electromagnetic energy, application of pressure or other neuromodulating energy form, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is maintained within control range  {\textbar} 586 {\textbar} . {\textbar} Under normal conditions and during which time the present invention is inactive (“Closed-Loop Neuromodulator Control {OFF}”), shown as nonperturbed nontreated period  {\textbar}   {\textbar} 594 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary within normal range  {\textbar} 587 {\textbar} . This demonstrated variation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  occurs throughout the day under normal conditions and in the absence of any signs or symptoms of disease. This represents a normal range of disease state. In one preferred embodiment for the treatment of epilepsy, this represents the normal range of a metric of neural chaos during which there are no signs and no symptoms of seizure. There may be some aftereffects that persist following the deactivation of the present invention (Closed-Loop Neuromodulator Control {OFF}); these are anticipated in the present invention. The persistence of beneficial effects for some period following the use of the present invention allows the duty cycle of operation to be reduced, thereby minimizing tissue stimulation, drug or other agent delivery. {\textbar} There are no {EEG} abnormalities  {\textbar}   {\textbar} 599 {\textbar}  and no neurological signs or symptoms  {\textbar} 600 {\textbar} , including seizures, during the time periods depicted in  {\textbar} {FIG}. 58 {\textbar} . As shown during nonperturbed nontreated period  {\textbar} 594 {\textbar} , the action of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  provides a continuous stabilizing influence on control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , preventing it from deviating outside of control range  {\textbar} 586 {\textbar} . At no point in time in  {\textbar} {FIG}. 58 {\textbar}  does control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  indicate any adverse neurological conditions that would be reflective of a seizure, and aura, or associated event. Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  does not enter borderline range  {\textbar} 588 {\textbar} , borderline range  {\textbar} 589 {\textbar} , critical range  {\textbar} 590 {\textbar} , or critical range  {\textbar} 591 {\textbar} . {\textbar} In  {\textbar}   {\textbar} {FIG}. 59 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the normal unperturbed state. This diagram shows normal {EEG} signals, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying interictal period  {\textbar} 603 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of normal range  {\textbar} 587 {\textbar}  and into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar}  without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or signs or symptoms of neurological disease  {\textbar} 600 {\textbar} . {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . Additional states (X)  {\textbar} 991 {\textbar} , including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other elements of state (X)  {\textbar} 991 {\textbar}  and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary first within the normal range  {\textbar} 587 {\textbar}  and to have multiple excursions into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} . During this time, there are no episodes of abnormal {EEG} nor episodes of neurological signs or symptoms. Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , as well as corresponding elements of state (X)  {\textbar} 991 {\textbar} , exhibit excursions outside of normal range  {\textbar} 587 {\textbar} , and corresponding ranges likewise for elements of state (X)  {\textbar} 991 {\textbar} , and return to normal range  {\textbar} 587 {\textbar}  without event. {\textbar} In  {\textbar}   {\textbar} {FIG}. 60 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the unperturbed state in which the present invention is not activated and a seizure spontaneously develops. This diagram shows the development of {EEG} abnormalities  {\textbar} 599 {\textbar} , shown in (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, followed by the progression of the seizure to be manifest by neurological signs or symptoms  {\textbar} 600 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of normal range  {\textbar} 587 {\textbar}  and into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} , during which time {EEG} abnormalities  {\textbar} 599 {\textbar}  subsequently develop, followed by neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . Additional states (X)  {\textbar} 991 {\textbar} , including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other elements of state (X)  {\textbar} 991 {\textbar}  and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary first within the normal range  {\textbar} 587 {\textbar}  and to have multiple excursions into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} . During the first such excursion, which occurs in interictal period  {\textbar} 595 {\textbar} , there are no episodes of {EEG} abnormalities  {\textbar} 599 {\textbar}  nor episodes of neurological signs or symptoms  {\textbar} 600 {\textbar} . Sometime during the second such excursion into critical range  {\textbar} 591 {\textbar} , {EEG} abnormalities  {\textbar} 599 {\textbar}  develop, as seen during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar} . The {EEG} abnormalities  {\textbar} 599 {\textbar}  that appears during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar}  then progresses to involve a larger portion of the brain and is manifest as neurological signs or symptoms  {\textbar} 600 {\textbar}  which define the clinical seizure  {\textbar} 597 {\textbar} . Following clinical seizure  {\textbar} 597 {\textbar} , neurological signs or symptoms  {\textbar} 600 {\textbar}  cease and {EEG} abnormalities  {\textbar} 599 {\textbar}  cease. During and Following clinical seizure  {\textbar} 597 {\textbar} , Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  progressively moves back to normal range  {\textbar} 587 {\textbar} . {\textbar} In  {\textbar}   {\textbar} {FIG}. 61 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the unperturbed state in which the present invention is activated and providing a continuous stabilizing influence on the nervous system, during controlled interictal period  {\textbar} 604 {\textbar} . This diagram shows the persistence of normal {EEG} signals, shown in (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying controlled interictal period  {\textbar} 604 {\textbar} , accompanied by no neurological signs or symptoms  {\textbar} 600 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , within the control range  {\textbar} 586 {\textbar} . A single or multiplicity of additional states may be used without departing from the present invention. {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . Additional states (X)  {\textbar} 991 {\textbar} , including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other elements of state (X)  {\textbar} 991 {\textbar}  and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} In one preferred embodiment for the treatment of epilepsy, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is calculated as a measure of the disentrainment of neural chaos. Other measures of neural chaos, functions of neural chaos, or other function of at least one of neural chaos or neural entropy may be used without departing from the present invention. Neural chaos may be measured using a Lyapunov exponent, Kolmogorov entropy, or other measure of chaos. These measures of neural chaos, disentrainment of neural chaos, entrainment of neural chaos, synchronization of neural chaos, and other functions of neural chaos may be calculated using any of the methods taught in the present invention or using other measures, including those in which information rate, neural signal correlations or cross-correlations, or other measure of entropy, chaos, or equivalent measure, or other function of neural or physiological signals are employed. Other functions include metrics of neural signal overall energy levels, energy levels within a single or multiplicity frequency bands or ratios thereof, changes in spike and wave frequencies, or other parameters. {\textbar} Control output  {\textbar}   {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is used to generate Neuromodulatory signal ({NMS})  {\textbar} 998 {\textbar} , which is transmitted to at least one of the implementations neural modulator described herein or to other neuromodulator; these include but are not limited to neuromodulator array  {\textbar} 561 {\textbar} , hippocampal modulator  {\textbar} 534 {\textbar}  and hippocampal modulator  {\textbar} 535 {\textbar} , hippocampal modulator  {\textbar} 536 {\textbar}  and hippocampal modulator  {\textbar} 357 {\textbar} , cortical modulator  {\textbar} 530 {\textbar} , cortical modulator  {\textbar} 531 {\textbar} , cortical modulator  {\textbar} 532 {\textbar} , and cortical modulator  {\textbar} 533 {\textbar} , olfactory nerve modulator  {\textbar} 527 {\textbar} , trigeminal nerve modulator  {\textbar} 528 {\textbar} , vagus nerve modulator  {\textbar} 529 {\textbar} , sympathetic modulator  {\textbar} 567 {\textbar} , crbitofrontal modulator  {\textbar} 279 {\textbar} , prefrontal modulator  {\textbar} 280 {\textbar} , precentral modulator  {\textbar} 281 {\textbar} , postcentral modulator  {\textbar} 282 {\textbar} , parietal modulator  {\textbar} 283 {\textbar} , parietooccipital modulator  {\textbar} 284 {\textbar} , occipital modulator  {\textbar} 285 {\textbar} , cerebellar modulator  {\textbar} 286 {\textbar} , neuromodulator  {\textbar} 545 {\textbar} , neuromodulator  {\textbar} 546 {\textbar} , neuromodulator  {\textbar} 547 {\textbar} , neuromodulator  {\textbar} 548 {\textbar} , neuromodulator  {\textbar} 549 {\textbar} , neuromodulator  {\textbar} 550 {\textbar} , neuromodulator  {\textbar} 551 {\textbar} , neuromodulator  {\textbar} 552 {\textbar} , neuromodulator  {\textbar} 553 {\textbar} , neuromodulator  {\textbar} 554 {\textbar} , neuromodulator array  {\textbar} 561 {\textbar} , contralateral implementations of any of these, and other neuromodulators. Other variations of these neuromodulator designs or locations may be envisioned by one skilled in the art, and these are included in the present invention. Other anatomical locsaiotns or electrode designs or configurations may be used without departing form the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to remain within control range  {\textbar} 586 {\textbar} , while responding to the continuous stabilizing influence provided by control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar} . There are no {EEG} abnormalities  {\textbar} 599 {\textbar}  and no neurological signs or symptoms  {\textbar} 600 {\textbar}  during the action provided by the feedback driven controller embodied in the present invention. The present invention encompasses the use of any single or multiplicity of elements of control input Y  {\textbar} 996 {\textbar} , representing any single or multiplicity of disease state. One preferred state used in the treatment of epilepsy is the use of at least one measure of disentrainment of neural chaos. These and other measures of neural activity, chaos, disentrainment of neural chaos, entrainment of neural chaos, synchronization of chaos are also used in the treatment of psychosis, depression, schizophrenia, mania, bipolar disorder, rage, anxiety, and other neurological and psychiatric conditions. {\textbar} In  {\textbar}   {\textbar} {FIG}. 62 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the unperturbed state in which the control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) is initially {OFF} during uncontrolled interictal period  {\textbar} 605 {\textbar}  and is subsequently activated and begins providing a continuous stabilizing influence on the nervous system, during controlled interictal period  {\textbar} 606 {\textbar} . {\textbar} The transition from control output  {\textbar}   {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) in the {OFF} state during uncontrolled interictal period  {\textbar} 605 {\textbar}  to the {ON} state during controlled interictal period  {\textbar} 606 {\textbar}  occurs at an arbitrary time and under normal conditions. In the diagram shown, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has deviated from arbitrarily defined control range  {\textbar} 586 {\textbar}  and is still within normal range  {\textbar} 587 {\textbar} . As has been shown in  {\textbar} {FIG}. 59 {\textbar} , this does not represent a precursor to a seizure, and even if control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  were to enter orderline range  {\textbar} 588 {\textbar} , borderline range  {\textbar} 589 {\textbar} , critical range  {\textbar} 590 {\textbar} , or critical range  {\textbar} 591 {\textbar} , this condition would not represent a precursor to a seizure. At the point shown, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has deviated by an arbitrary amount from target value  {\textbar} 576 {\textbar} , at which point control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is activated to apply closed-loop feedback control to stabilize control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  and bring control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  into control range  {\textbar} 586 {\textbar} . {\textbar} This diagram shows the persistence of normal {EEG} signals, shown in (E {\textbar}   {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying controlled interictal period  {\textbar} 604 {\textbar} , accompanied by no neurological signs or symptoms  {\textbar} 600 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , within the control range  {\textbar} 586 {\textbar} . A single or multiplicity of additional states may be used without departing from the present invention. {\textbar} In  {\textbar}   {\textbar} {FIG}. 63 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time in the unperturbed state in which the control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) is initially {OFF} during uncontrolled interictal period  {\textbar} 607 {\textbar} , is subsequently activated and begins providing a continuous stabilizing influence on the nervous system during controlled interictal period  {\textbar} 608 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) is subsequently {OFF} in uncontrolled interictal period  {\textbar} 609 {\textbar} . {\textbar} The transition from control output  {\textbar}   {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) in the {OFF} state during uncontrolled interictal period  {\textbar} 605 {\textbar}  to the {ON} state during controlled interictal period  {\textbar} 606 {\textbar}  occurs at an arbitrary time and under normal conditions. In the diagram shown, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has deviated from arbitrarily defined control range  {\textbar} 586 {\textbar}  and is still within normal range  {\textbar} 587 {\textbar} . As has been shown in  {\textbar} {FIG}. 59 {\textbar} , this does not represent a precursor to a seizure, and even if control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  were to enter borderline range  {\textbar} 588 {\textbar} , borderline range  {\textbar} 589 {\textbar} , critical range  {\textbar} 590 {\textbar} , or critical range  {\textbar} 591 {\textbar} , this condition would not represent a precursor to a seizure. At the point shown, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has deviated by an arbitrary amount from target value  {\textbar} 576 {\textbar} , at which point control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is activated to apply closed-loop feedback control to stabilize control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  and bring control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  into control range  {\textbar} 586 {\textbar} . Once control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  has been stabilized into an arbitrary range, such as control range  {\textbar} 586 {\textbar}  or other range, control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) is turned {OFF}, as shown in uncontrolled interictal period  {\textbar} 609 {\textbar} . The turning of control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} ) {OFF} is performed to conserve battery power, minimize electrical current induced tissue damage, minimize {pH} changes at the tissue-electrode interface, to further minimize neural habituation, which is itself a benefit of closed-loop feedback driven neuromodulation, and other benefits. {\textbar} This diagram shows the persistence of normal {EEG} signals, shown in (E {\textbar}   {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying controlled interictal period  {\textbar} 604 {\textbar} , accompanied by no neurological signs or symptoms  {\textbar} 600 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , within the control range  {\textbar} 586 {\textbar} . A single or multiplicity of additional states may be used without departing from the present invention. {\textbar} In  {\textbar}   {\textbar} {FIG}. 64 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights. This diagram shows normal {EEG} signals, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying uncontrolled baseline period  {\textbar} 610 {\textbar}  preceding the application of perturbation (P)  {\textbar} 990 {\textbar} , uncontrolled perturbation period  {\textbar} 611 {\textbar}  during the application of perturbation (P)  {\textbar} 990 {\textbar} , and uncontrolled post-perturbation period  {\textbar} 612 {\textbar}  following the application of perturbation (P)  {\textbar} 990 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , within normal range  {\textbar} 587 {\textbar} , and without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar} . Despite the application of perturbation (P)  {\textbar} 990 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , a measure of disease state, remains in normal range  {\textbar} 587 {\textbar} ; and corresponding elements of state (X)  {\textbar} 991 {\textbar}  remain in their corresponding normal ranges. {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . In a preferred embodiment for the treatment of seizures, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is a function of disentrainment of neural chaos, for which neural chaos is calculated using Lyapunov exponents, Kolmogorov entropy or other measure of chaos. Additional elements of state (X)  {\textbar} 991 {\textbar} , including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other elements of state (X)  {\textbar} 991 {\textbar}  and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} In  {\textbar}   {\textbar} {FIG}. 65 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights. This diagram shows normal {EEG} signals, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , during this time span, occupying uncontrolled baseline period  {\textbar} 610 {\textbar}  preceding the application of perturbation (P)  {\textbar} 990 {\textbar} , uncontrolled perturbation period  {\textbar} 611 {\textbar}  during the application of perturbation (P)  {\textbar} 990 {\textbar} , and uncontrolled post-perturbation period  {\textbar} 612 {\textbar}  following the application of perturbation (P)  {\textbar} 990 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of normal range  {\textbar} 587 {\textbar}  and into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar}  without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . In a preferred embodiment for the treatment of seizures, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is a function of disentrainment of neural chaos, for which neural chaos is calculated using Lyapunov exponents, Kolmogorov entropy or other measure of chaos. Additional elements of state (X)  {\textbar} 991 {\textbar}  may be used, including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other variables or constants and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary first within the normal range  {\textbar} 587 {\textbar}  and to have multiple excursions into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} . During this time, there are no episodes of {EEG} abnormalities  {\textbar} 599 {\textbar}  nor episodes of neurological signs or symptoms  {\textbar} 600 {\textbar} . Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , as well as corresponding elements of state (X)  {\textbar} 991 {\textbar} , exhibit excursions outside of normal range  {\textbar} 587 {\textbar} , and corresponding ranges likewise for elements of state (X)  {\textbar} 991 {\textbar} , and return to normal range  {\textbar} 587 {\textbar}  without event. {\textbar} In  {\textbar}   {\textbar} {FIG}. 66 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y)  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights, during which time the present invention is not activated and a seizure subsequently develops. {\textbar} This diagram shows {EEG} signals, (E {\textbar}   {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , which are initially normal during uncontrolled baseline period  {\textbar} 613 {\textbar} , preceding the application of perturbation (P)  {\textbar} 990 {\textbar} , and which remain normal during uncontrolled perturbation period  {\textbar} 614 {\textbar}  during the application of perturbation (P)  {\textbar} 990 {\textbar} , and remain normal for some time thereafter during uncontrolled post-perturbation period  {\textbar} 615 {\textbar}  following the application of perturbation (P)  {\textbar} 990 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of normal range  {\textbar} 587 {\textbar}  and into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar}  without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar}  during uncontrolled baseline period  {\textbar} 613 {\textbar} , uncontrolled perturbation period  {\textbar} 614 {\textbar} , and uncontrolled post-perturbation period  {\textbar} 615 {\textbar} . {\textbar} During the second excursion of control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  into critical range  {\textbar} 591 {\textbar} , {EEG} abnormalities  {\textbar} 599 {\textbar}  develop, shown in (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , defining the beginning of sustained organized paroxysmal discharge period  {\textbar} 616 {\textbar} , which is followed by the progression of {EEG} abnormalities  {\textbar} 599 {\textbar}  into clinical seizure  {\textbar} 617 {\textbar} , which is manifest by neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} In one preferred embodiment, control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  calculated by signal processor  {\textbar} 71 {\textbar}  is representative of disease state, which is implemented as state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar}  in control circuit  {\textbar} 72 {\textbar} . In a preferred embodiment for the treatment of seizures, control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is a function of disentrainment of neural chaos, for which neural chaos is calculated using Lyapunov exponents, Kolmogorov entropy or other measure of chaos. Additional elements of state (X)  {\textbar} 991 {\textbar}  may be used, including but not limited to the time derivative of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , the integral with respect to time of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and other functions of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , other variables or constants and functions thereof, other elements of control input (Y)  {\textbar} 996 {\textbar}  and functions thereof, and other values without departing from the present invention. {\textbar} Control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is shown to vary first within the normal range  {\textbar} 587 {\textbar}  and to have multiple excursions into borderline range  {\textbar} 589 {\textbar}  and critical range  {\textbar} 591 {\textbar} . During the first such excursion, which occurs in uncontrolled post-perturbation period  {\textbar} 615 {\textbar} , there are no episodes of {EEG} abnormalities  {\textbar} 599 {\textbar}  nor episodes of neurological signs or symptoms  {\textbar} 600 {\textbar} . Sometime during the second such excursion into critical range  {\textbar} 591 {\textbar} , {EEG} abnormalities  {\textbar} 599 {\textbar}  develop, as seen during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar} . The {EEG} abnormalities  {\textbar} 599 {\textbar}  that appears during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar}  then progresses to involve a larger portion of the brain and is manifest as neurological signs or symptoms  {\textbar} 600 {\textbar}  which define the clinical seizure  {\textbar} 597 {\textbar} . Following clinical seizure  {\textbar} 597 {\textbar} , neurological signs or symptoms  {\textbar} 600 {\textbar}  cease and {EEG} abnormalities  {\textbar} 599 {\textbar}  cease; and this remains the case during uncontrolled interictal period  {\textbar} 618 {\textbar} . During and Following clinical seizure  {\textbar} 597 {\textbar} , Control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , reflective of disease state, progressively moves back to normal range  {\textbar} 587 {\textbar} . {\textbar} In  {\textbar}   {\textbar} {FIG}. 67 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights. The present invention is shown continuously activated, producing control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  to provide a continuous stabilizing influence, and the potential for a neurological signs or symptoms  {\textbar} 600 {\textbar}  is prevented. Furthermore, the very potential for even a precursor, i.e. {EEG} abnormalities  {\textbar} 599 {\textbar} , is prevented, because the nervous system is prevented from entering a state in which such neurological signs or symptoms  {\textbar} 600 {\textbar}  or their precursors may develop and progress. Said neurological signs or symptoms  {\textbar} 600 {\textbar}  include but are not limited to a seizure, status epilepticus, headache, manic episode, depressive episode, anxiety episode, panic attack, rage episode, psychotic episode. {\textbar} In  {\textbar}   {\textbar} {FIG}. 68 {\textbar} , a time diagram of the {EEG} tracings, (E {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , and control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  are shown versus time before, during, and after the application of a perturbation (P)  {\textbar} 990 {\textbar} , such as flashing lights. The present invention is shown conditionally activated, when control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  moves outside of control range, to resume the production of control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  to provide a continuous stabilizing influence and prevent the potential for a neurological signs or symptoms  {\textbar} 600 {\textbar}  or their precursors. There are no {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar}  present and no potential for them to occur at any point in this figure. {\textbar} This diagram shows {EEG} signals, (E {\textbar}   {\textbar} 1 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 1 {\textbar}  and (E {\textbar} 2 {\textbar} )  {\textbar} 985 {\textbar} - {\textbar} 2 {\textbar} , which remain normal during uncontrolled baseline period  {\textbar} 622 {\textbar} , preceding the application of perturbation (P)  {\textbar} 990 {\textbar} , and which remain normal during uncontrolled perturbation period  {\textbar} 623 {\textbar}  during which time perturbation (P)  {\textbar} 990 {\textbar}  is applied, and remain normal thereafter during uncontrolled post-perturbation period  {\textbar} 624 {\textbar}  and controlled post-perturbation period  {\textbar} 625 {\textbar} . This figure demonstrates fluctuation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , outside of control range  {\textbar} 586 {\textbar}  without the occurrence of any {EEG} abnormalities  {\textbar} 599 {\textbar}  or neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} When control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  moves outside of control range  {\textbar} 586 {\textbar}  but remains within normal range  {\textbar} 587 {\textbar} , then control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is delivered to maintain the nervous system in a stable state and thereby prevent even the possibility of undesirable neurological signs or symptoms  {\textbar} 600 {\textbar}  or their precursors, i.e. {EEG} abnormalities  {\textbar} 599 {\textbar} , from developing. The precise time of initiation of delivery of control output  {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar}  is somewhat arbitrary, as the action is taken no t in response to any event but as a measure to prevent a neural state, as quantified by control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  and correspondingly of state  {\textbar} 1 {\textbar}  (X {\textbar} 1 {\textbar} )  {\textbar} 991 {\textbar} - {\textbar} 1 {\textbar} , from exiting normal range  {\textbar} 587 {\textbar}  and progressing into a critical range  {\textbar} 591 {\textbar}  in which neurological signs or symptoms  {\textbar} 600 {\textbar}  may subsequently develop. {\textbar} By this action of control output  {\textbar}   {\textbar} 1 {\textbar}  (U {\textbar} 1 {\textbar} )  {\textbar} 997 {\textbar} - {\textbar} 1 {\textbar} , the very potential for even a precursor, i.e. {EEG} abnormalities  {\textbar} 599 {\textbar} , is prevented, because the nervous system is prevented from entering a state in which such neurological signs or symptoms  {\textbar} 600 {\textbar}  or their precursors may develop and progress. Said neurological signs or symptoms  {\textbar} 600 {\textbar}  include but are not limited to a seizure, status epilepticus, headache, manic episode, depressive episode, anxiety episode, panic attack, rage episode, psychotic episode. {\textbar} {SUMMARY} {\textbar}   {\textbar} In one preferred embodiment, the control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is calculated as a measure of disentrainment of neural chaos among regions of the nervous system. This representation of control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  then reflects degree of neural entrainment, which is inversely related to entrainment of neural chaos and synchronization of neural chaos. During normal interictal states, when no seizure or other neurological signs or symptoms  {\textbar} 600 {\textbar}  are present, the nervous system possesses a normal degree of neural entrainment, that is, the various neural regions exhibit some correlation in their level of chaos. A seizure occurs as a significant portion of neural tissue exhibits synchronization of activity. By minimizing neural entrainment and maximizing disentrainment, seizures and their precursors may be prevented. {\textbar} This is fundamentally different from and a dramatic improvement over the system described by but not enabled by Fischell U.S. Pat. No. 6,016,449. Fischell describes a system that detects and terminates a seizure. The patent then claims but does not enable a system to detect and terminate a precursor to a seizure, by detecting {EEG} thresholds. Precursors are not defined and their detection no described nor enabled. In either of these two cases of terminating seizures or precursors to seizures, the aberrant neural condition has already occurred and its progression t seizure is imminent and inevitable without intervention. At this point, terminating the process, which has already begun, is difficult and may not be possible. In the Fischell designs, an event detection signal is generated upon detection of a seizure or its precuror, in either case of which, progression to clinical seizure has begun or is imminent, as manifest by {EEG} abnormalities  {\textbar}   {\textbar} 599 {\textbar} . {\textbar} In contrast, the neurological control system  {\textbar}   {\textbar} 999 {\textbar}  taught in the present invention controls fundamental neural states, thereby preventing the development of neural states in which a seizure is even possible. By maintaining neural disentrainment within the normal range, seizures do not occur or are extremely unlikely. Certain pharmacological agents may have this effect as well, by preventing the nervous system from being able to initiate the process that culminates in a seizure. The present invention can continuously monitor and maintain a desired level of therapy, controlling desired neural states to remain within stable regions and out of regions in which neurological signs and symptoms may develop. Through the use of feedback control, the present invention insures that the appropriate neural states, including but not limited to the level of disentrainment of neural chaos, which is inversely related to synchronization of neural chaos and entrainment of neural chaos, remains within the normal range, preventing the nervous system from entering a state, which itself is free of any abnormalities or signs or symptoms, in which it is even possible to develop a seizure or other neurological signs or symptoms  {\textbar} 600 {\textbar} . {\textbar} Not only is a seizure prevented, the potential for a seizure is prevented. Furthermore, the potential for a precursor to a seizure is prevented. The present invention controls the degree of disentrainment of neural chaos as measured in at least one region of the brain. This degree of disentrainment, the quantification of which is embodied in control input  {\textbar}   {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , normally varies throughout the day. Certain external inputs, such as perturbations as well as medications, can alter this degree of disentrainment. If control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is maintained in normal range  {\textbar} 587 {\textbar} , the development of a precursors to a seizure, specifically {EEG} abnormalities  {\textbar} 599 {\textbar}  as manifest during sustained organized paroxysmal discharge period  {\textbar} 596 {\textbar} , are prevented. Neural state, as quantified in control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar} , varies overtime. Under certain conditions, i.e. when control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  is in critical range  {\textbar} 591 {\textbar} , a seizure may possibly occur, but it is not predetermined to occur under this condition. Maintaining control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  outside of critical range  {\textbar} 591 {\textbar}  and preferably in normal range  {\textbar} 587 {\textbar}  and more preferably in a subset of normal range  {\textbar} 587 {\textbar}  labeled control range  {\textbar} 586 {\textbar}  prevents even the precursor, ie. {EEG} abnormalities  {\textbar} 599 {\textbar} , of a neurological signs or symptoms  {\textbar} 600 {\textbar}  from developing. The present invention prevents the nervous system from entering a state in which it is possible to have a seizure. The present invention monitors the degree of response to therapy and modulates therapy to maintain effect within the desired therapeutic range, i.e. control input  {\textbar} 1 {\textbar}  (Y {\textbar} 1 {\textbar} )  {\textbar} 996 {\textbar} - {\textbar} 1 {\textbar}  within control range  {\textbar} 586 {\textbar} . Under such conditions, no neurological signs or symptoms  {\textbar} 600 {\textbar}  occur. No precursors, i.e. {EEG} abnormalities  {\textbar} 599 {\textbar} , occur, since the present invention applies a continuous stabilizing influence to modulate the nervous system and thereby maintain it in a stable state.},
}

@patent{park_javed21,
	location = {{US}},
	title = {Robot-aided system and method for diagnosis of autism spectrum disorder},
	url = {https://www.derwentinnovation.com/tip-innovation/recordView.do?hideHighlightPanel=true&idType=uid/recordid&datasource=T3&databaseIds=PATENT&category=PAT&recordKeys=US20210236032A120210805&TYPE=RECORDVIEW&fromExternalLink=true&fromLocation=external&isDAJImageAllowed=false},
	abstract = {The disclosed system uses facial expressions and upper body movement patterns to detect autism spectrum disorder. Emotionally expressive robots participate in sensory experiences by reacting to stimuli designed to resemble typical everyday experiences, such as uncontrolled sounds and light or tactile contact with different textures. The robot-child interactions elicit social engagement from the children, which is captured by a camera. A convolutional neural network, which has been trained to evaluate multimodal behavioral data collected during those robot-child interactions, identifies children that are at risk for autism spectrum disorder. Because the robot-assisted framework effectively engages the participants and models behaviors in ways that are easily interpreted by the participants, the disclosed system may also be used to teach children with autism spectrum disorder to communicate their feelings about discomforting sensory stimulation (as modeled by the robots) instead of allowing uncomfortable experiences to escalate into extreme negative reactions (e.g., tantrums or meltdowns).
The disclosed system uses facial expressions and upper body movement patterns to detect autism spectrum disorder. Emotionally expressive robots participate in sensory experiences by reacting to stimuli designed to resemble typical everyday experiences, such as uncontrolled sounds and light or tactile contact with different textures. The robot-child interactions elicit social engagement from the children, which is captured by a camera. A convolutional neural network, which has been trained to evaluate multimodal behavioral data collected during those robot-child interactions, identifies children that are at risk for autism spectrum disorder. Because the robot-assisted framework effectively engages the participants and models behaviors in ways that are easily interpreted by the participants, the disclosed system may also be used to teach children with autism spectrum disorder to communicate their feelings about discomforting sensory stimulation (as modeled by the robots) instead of allowing uncomfortable experiences to escalate into extreme negative reactions (e.g., tantrums or meltdowns).
The disclosed system uses facial expressions and upper body movement patterns to detect autism spectrum disorder. Emotionally expressive robots participate in sensory experiences by reacting to stimuli designed to resemble typical everyday experiences, such as uncontrolled sounds and light or tactile contact with different textures. The robot-child interactions elicit social engagement from the children, which is captured by a camera. A convolutional neural network, which has been trained to evaluate multimodal behavioral data collected during those robot-child interactions, identifies children that are at risk for autism spectrum disorder. Because the robot-assisted framework effectively engages the participants and models behaviors in ways that are easily interpreted by the participants, the disclosed system may also be used to teach children with autism spectrum disorder to communicate their feelings about discomforting sensory stimulation (as modeled by the robots) instead of allowing uncomfortable experiences to escalate into extreme negative reactions (e.g., tantrums or meltdowns).},
	type = {patentus},
	number = {20210236032A1},
	author = {Park, Chung Hyuk and Javed, Hifza},
	urldate = {2021-01-27},
	date = {2021-08-05},
	note = {Edition: A61B000516 {\textbar} A61B000500 {\textbar} A61B000511 {\textbar} G16H002070 {\textbar} G16H005020 {CPC} - A61B000516 {\textbar} A61B00050077 {\textbar} A61B00051128 {\textbar} A61B0005168 {\textbar} A61B00057267 {\textbar} A61B00057275 {\textbar} B25J0011001 {\textbar} B25J00110015 {\textbar} G06K0009627 {\textbar} G06V0010764 {\textbar} G06V001082 {\textbar} G06V002046 {\textbar} G06V004010 {\textbar} G06V0040165 {\textbar} G06V0040176 {\textbar} G16H002070 {\textbar} G16H004063 {\textbar} G16H004067 {\textbar} G16H005020 {\textbar} G16H005070 {\textbar} A61M002100 {\textbar} A61M20210016 {\textbar} A61M20210022 {\textbar} A61M20210027 {\textbar} A61M20210044 {\textbar} A61M2021005 {\textbar} A61M22053306 {\textbar} A61M22053317 {\textbar} A61M22053375 {\textbar} A61M22053553 {\textbar} A61M22053592 {\textbar} A61M2205505 {\textbar} A61M220552 {\textbar} A61M2205587 {\textbar} A61M220559 {\textbar} A61M223063 {\textbar} G06N0003008 {\textbar} G06N00030454 {\textbar} G06N000308 {EP}; {US} {US} A61M 2230/005, A61M 2230/63 What is claimed is: {\textbar} {\textbar} 1 {\textbar} . A system for determining whether a child is at risk for autism spectrum disorder based on movement and facial expression, the system comprising: {\textbar} a video camera that captures video images of the child; {\textbar} {\textbar} a computer that: {\textbar} {\textbar} extracts body tracking keypoints and facial keypoints from the video images; and {\textbar} {\textbar} derives movement features from the body tracking keypoints; and {\textbar} {\textbar} a convolutional neural network, trained on a dataset that includes movement features and facial keypoints of children diagnosed with autism spectrum disorder, that: {\textbar} {\textbar} receives the movement features derived from the video images and the facial keypoints extracted from the video images; and {\textbar} {\textbar} generates a diagnosis indicative of the risk for autism spectrum disorder based on the facial keypoints extracted from the video images of the child and the movement features derived from the video images of the child. {\textbar} {\textbar} 2 {\textbar} . The system of {\textbar} claim 1 {\textbar} , wherein the movement features include a weight feature indicative of intensity of perceived force in the movement, a space feature indicative of distance of the arms of the child relative to the body of the child, and a time feature indicative of a change in tempo in the movement. {\textbar} 3 {\textbar} . The system of {\textbar} claim 1 {\textbar} , wherein the convolutional neural network includes two one-dimensional convolution layers to identify temporal data patterns, three dense layers for classification, and a plurality of dropout layers to avoid overfitting. {\textbar} 4 {\textbar} . The system of {\textbar} claim 1 {\textbar} , further comprising an emotionally expressive robot programmed to mimic the expression of human emotion. {\textbar} 5 {\textbar} . The system of {\textbar} claim 4 {\textbar} , wherein the emotionally expressive robot comprises a humanoid robot programmed to mimic the expression of human emotion through gestures or speech. {\textbar} 6 {\textbar} . The system of {\textbar} claim 4 {\textbar} , wherein the emotionally expressive robot comprises a facially expressive robot programmed to mimic the expression of human emotion through facial expression. {\textbar} 7 {\textbar} . The system of {\textbar} claim 4 {\textbar} , wherein the video camera captures video images of the child interacting with the emotionally expressive robot. {\textbar} 8 {\textbar} . The system of {\textbar} claim 4 {\textbar} , further comprising a plurality of sensory stations that each provide sensory stimulation. {\textbar} 9 {\textbar} . The system of {\textbar} claim 8 {\textbar} , wherein the plurality of sensory stations include a seeing station that provides visual stimulus, a hearing station that provides auditory stimulus, a smelling station provide olfactory stimulus, a tasting station that provides gustatory stimulus, or a touching station that provides tactile stimulus. {\textbar} 10 {\textbar} . The system of {\textbar} claim 8 {\textbar} , wherein the video camera captures video images of the child observing the emotionally expressive robot interacting with each of the sensory stations. {\textbar} 11 {\textbar} . A method for determining whether a child may be at risk for autism spectrum disorder based on movement and facial expression, the method comprising: {\textbar} receiving video images of the child by a computer; {\textbar} {\textbar} extracting body tracking keypoints and facial keypoints from the video images by the computer; {\textbar} {\textbar} deriving movement features from the body tracking keypoints by the computer; {\textbar} {\textbar} providing the movement features derived from the video images and the facial keypoints extracted from the video images, by the computer, to a convolutional neural network trained on a dataset that includes movement features and facial keypoints of children diagnosed with autism spectrum disorder; and {\textbar} {\textbar} generating a diagnosis indicative of the risk of the child for autism spectrum disorder, by the convolutional neural network, based on the facial keypoints extracted from the video images of the child and the movement features derived from the video images of the child. {\textbar} {\textbar} 12 {\textbar} . The method of {\textbar} claim 11 {\textbar} , wherein the movement features include a weight feature indicative of intensity of perceived force in the movement, a space feature indicative of distance of the arms of the child relative to the body of the child, and a time feature indicative of a change in tempo in the movement. {\textbar} 13 {\textbar} . The method of {\textbar} claim 11 {\textbar} , wherein the convolutional neural network includes two one-dimensional convolution layers to identify temporal data patterns, three dense layers for classification, and a plurality of dropout layers to avoid overfitting. {\textbar} 14 {\textbar} . The method of {\textbar} claim 11 {\textbar} , further comprising: {\textbar} mimicking the expression of human emotion by an emotionally expressive robot. {\textbar} {\textbar} 15 {\textbar} . The method of {\textbar} claim 14 {\textbar} , wherein the emotionally expressive robot comprises a humanoid robot programmed to mimic the expression of human emotion through gestures or speech or a facially expressive robot programmed to mimic the expression of human emotion through facial expression. {\textbar} 16 {\textbar} . The method of {\textbar} claim 14 {\textbar} , wherein the video images are captured while the child interacts with the emotionally expressive robot. {\textbar} 17 {\textbar} . The method of {\textbar} claim 14 {\textbar} , further comprising: {\textbar} providing sensory stimulation by each of a plurality of sensory stations. {\textbar} {\textbar} 18 {\textbar} . The method of {\textbar} claim 17 {\textbar} , wherein the plurality of sensory stations include a seeing station that provides visual stimulus, a hearing station that provides auditory stimulus, a smelling station provide olfactory stimulus, a tasting station that provides gustatory stimulus, or a touching station that provides tactile stimulus. {\textbar} 19 {\textbar} . The method of {\textbar} claim 17 {\textbar} , wherein the video images are captured while the child observes the emotionally expressive robot interacting with each of the sensory stations. {\textbar} 20 {\textbar} . Non-transitory computer readable storage media storing instructions that, when executed by a hardware computer processor, cause a computer to determine whether a child may be at risk for autism spectrum disorder based on movement and facial expression by: {\textbar} receiving video images of the child; {\textbar} {\textbar} extracting body tracking keypoints and facial keypoints from the video images; {\textbar} {\textbar} deriving movement features from the body tracking keypoints; {\textbar} {\textbar} providing the movement features and body tracking keypoints extracted from the video images to a convolutional neural network trained on a dataset that includes movement features and body tracking keypoints of children diagnosed with autism spectrum disorder; and {\textbar} {\textbar} generating a diagnosis indicative of the risk for autism spectrum disorder by the convolutional neural network. What is claimed is: {\textbar} {\textbar} 1 {\textbar} . A system for determining whether a child is at risk for autism spectrum disorder based on movement and facial expression, the system comprising: {\textbar} a video camera that captures video images of the child; {\textbar} {\textbar} a computer that: {\textbar} {\textbar} extracts body tracking keypoints and facial keypoints from the video images; and {\textbar} {\textbar} derives movement features from the body tracking keypoints; and {\textbar} {\textbar} a convolutional neural network, trained on a dataset that includes movement features and facial keypoints of children diagnosed with autism spectrum disorder, that: {\textbar} {\textbar} receives the movement features derived from the video images and the facial keypoints extracted from the video images; and {\textbar} {\textbar} generates a diagnosis indicative of the risk for autism spectrum disorder based on the facial keypoints extracted from the video images of the child and the movement features derived from the video images of the child. {\textbar} {\textbar} 2 {\textbar} . The system of {\textbar} claim 1 {\textbar} , wherein the movement features include a weight feature indicative of intensity of perceived force in the movement, a space feature indicative of distance of the arms of the child relative to the body of the child, and a time feature indicative of a change in tempo in the movement. {\textbar} 3 {\textbar} . The system of {\textbar} claim 1 {\textbar} , wherein the convolutional neural network includes two one-dimensional convolution layers to identify temporal data patterns, three dense layers for classification, and a plurality of dropout layers to avoid overfitting. {\textbar} 4 {\textbar} . The system of {\textbar} claim 1 {\textbar} , further comprising an emotionally expressive robot programmed to mimic the expression of human emotion. {\textbar} 5 {\textbar} . The system of {\textbar} claim 4 {\textbar} , wherein the emotionally expressive robot comprises a humanoid robot programmed to mimic the expression of human emotion through gestures or speech. {\textbar} 6 {\textbar} . The system of {\textbar} claim 4 {\textbar} , wherein the emotionally expressive robot comprises a facially expressive robot programmed to mimic the expression of human emotion through facial expression. {\textbar} 7 {\textbar} . The system of {\textbar} claim 4 {\textbar} , wherein the video camera captures video images of the child interacting with the emotionally expressive robot. {\textbar} 8 {\textbar} . The system of {\textbar} claim 4 {\textbar} , further comprising a plurality of sensory stations that each provide sensory stimulation. {\textbar} 9 {\textbar} . The system of {\textbar} claim 8 {\textbar} , wherein the plurality of sensory stations include a seeing station that provides visual stimulus, a hearing station that provides auditory stimulus, a smelling station provide olfactory stimulus, a tasting station that provides gustatory stimulus, or a touching station that provides tactile stimulus. {\textbar} 10 {\textbar} . The system of {\textbar} claim 8 {\textbar} , wherein the video camera captures video images of the child observing the emotionally expressive robot interacting with each of the sensory stations. {\textbar} 11 {\textbar} . A method for determining whether a child may be at risk for autism spectrum disorder based on movement and facial expression, the method comprising: {\textbar} receiving video images of the child by a computer; {\textbar} {\textbar} extracting body tracking keypoints and facial keypoints from the video images by the computer; {\textbar} {\textbar} deriving movement features from the body tracking keypoints by the computer; {\textbar} {\textbar} providing the movement features derived from the video images and the facial keypoints extracted from the video images, by the computer, to a convolutional neural network trained on a dataset that includes movement features and facial keypoints of children diagnosed with autism spectrum disorder; and {\textbar} {\textbar} generating a diagnosis indicative of the risk of the child for autism spectrum disorder, by the convolutional neural network, based on the facial keypoints extracted from the video images of the child and the movement features derived from the video images of the child. {\textbar} {\textbar} 12 {\textbar} . The method of {\textbar} claim 11 {\textbar} , wherein the movement features include a weight feature indicative of intensity of perceived force in the movement, a space feature indicative of distance of the arms of the child relative to the body of the child, and a time feature indicative of a change in tempo in the movement. {\textbar} 13 {\textbar} . The method of {\textbar} claim 11 {\textbar} , wherein the convolutional neural network includes two one-dimensional convolution layers to identify temporal data patterns, three dense layers for classification, and a plurality of dropout layers to avoid overfitting. {\textbar} 14 {\textbar} . The method of {\textbar} claim 11 {\textbar} , further comprising: {\textbar} mimicking the expression of human emotion by an emotionally expressive robot. {\textbar} {\textbar} 15 {\textbar} . The method of {\textbar} claim 14 {\textbar} , wherein the emotionally expressive robot comprises a humanoid robot programmed to mimic the expression of human emotion through gestures or speech or a facially expressive robot programmed to mimic the expression of human emotion through facial expression. {\textbar} 16 {\textbar} . The method of {\textbar} claim 14 {\textbar} , wherein the video images are captured while the child interacts with the emotionally expressive robot. {\textbar} 17 {\textbar} . The method of {\textbar} claim 14 {\textbar} , further comprising: {\textbar} providing sensory stimulation by each of a plurality of sensory stations. {\textbar} {\textbar} 18 {\textbar} . The method of {\textbar} claim 17 {\textbar} , wherein the plurality of sensory stations include a seeing station that provides visual stimulus, a hearing station that provides auditory stimulus, a smelling station provide olfactory stimulus, a tasting station that provides gustatory stimulus, or a touching station that provides tactile stimulus. {\textbar} 19 {\textbar} . The method of {\textbar} claim 17 {\textbar} , wherein the video images are captured while the child observes the emotionally expressive robot interacting with each of the sensory stations. {\textbar} 20 {\textbar} . Non-transitory computer readable storage media storing instructions that, when executed by a hardware computer processor, cause a computer to determine whether a child may be at risk for autism spectrum disorder based on movement and facial expression by: {\textbar} receiving video images of the child; {\textbar} {\textbar} extracting body tracking keypoints and facial keypoints from the video images; {\textbar} {\textbar} deriving movement features from the body tracking keypoints; {\textbar} {\textbar} providing the movement features and body tracking keypoints extracted from the video images to a convolutional neural network trained on a dataset that includes movement features and body tracking keypoints of children diagnosed with autism spectrum disorder; and {\textbar} {\textbar} generating a diagnosis indicative of the risk for autism spectrum disorder by the convolutional neural network. 1 {\textbar} . A system for determining whether a child is at risk for autism spectrum disorder based on movement and facial expression, the system comprising: {\textbar} a video camera that captures video images of the child; {\textbar} {\textbar} a computer that: {\textbar} {\textbar} extracts body tracking keypoints and facial keypoints from the video images; and {\textbar} {\textbar} derives movement features from the body tracking keypoints; and {\textbar} {\textbar} a convolutional neural network, trained on a dataset that includes movement features and facial keypoints of children diagnosed with autism spectrum disorder, that: {\textbar} {\textbar} receives the movement features derived from the video images and the facial keypoints extracted from the video images; and {\textbar} {\textbar} generates a diagnosis indicative of the risk for autism spectrum disorder based on the facial keypoints extracted from the video images of the child and the movement features derived from the video images of the child. 1 {\textbar} . A system for determining whether a child is at risk for autism spectrum disorder based on movement and facial expression, the system comprising: {\textbar} a video camera that captures video images of the child; {\textbar} {\textbar} a computer that: {\textbar} {\textbar} extracts body tracking keypoints and facial keypoints from the video images; and {\textbar} {\textbar} derives movement features from the body tracking keypoints; and {\textbar} {\textbar} a convolutional neural network, trained on a dataset that includes movement features and facial keypoints of children diagnosed with autism spectrum disorder, that: {\textbar} {\textbar} receives the movement features derived from the video images and the facial keypoints extracted from the video images; and {\textbar} {\textbar} generates a diagnosis indicative of the risk for autism spectrum disorder based on the facial keypoints extracted from the video images of the child and the movement features derived from the video images of the child. {CROSS}-{REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar} {\textbar} This application claims priority to U.S. Prov. Pat. Appl. No. 62/967,873, filed Jan. 30, 2020, which is hereby incorporated by reference. {\textbar} {\textbar} {FEDERAL} {FUNDING} {\textbar} {\textbar} This system was made with government support from the National Institutes of Health (under Grant Number R01-{HD}082914, University Account No. 37987-1-{CCLS}29193F) and the National Science Foundation (under Grant No. 1846658, University Account No. 42008-1-{CCLS}29502F). The government has certain rights in the invention. {\textbar} {\textbar} {BACKGROUND} {\textbar} {\textbar} Children with autism spectrum disorder typically experience difficulties in social communication and interaction. As a result, they display a number of distinctive behaviors including atypical facial expressions and repetitive behaviors such as hand flapping and rocking. {\textbar} {\textbar} Sensory abnormalities are reported to be central to the autistic experience. Anecdotal accounts and clinical research both provide sufficient evidence to support this notion. One study found that, in a sample size of 200, over 90 percent of children with autism spectrum disorder had sensory abnormalities and showed symptoms in multiple sensory processing domains. The symptoms include hyposensitivity, hypersensitivity, multichannel receptivity, processing difficulties and sensory overload. A higher prevalence of unusual responses (particularly to tactile, auditory and visual stimuli) is seen in children with autism spectrum disorder when compared to their typically developing and developmentally delayed counterparts. The distress caused by some sensory stimuli can cause self-injurious and aggressive behaviors in children who may be unable to communicate their anguish. Families also report that difficulties with sensory processing and integration can restrict participation in everyday activities, resulting in social isolation for them and their child and impact social engagement. {\textbar} {\textbar} Given the subjective, cumbersome and time intensive nature of the current methods of diagnosis, there is a need for a behavior-based approach to identify children at risk for autism spectrum disorder in order to streamline the standard diagnostic procedures and facilitate rapid detection and clinical prioritization of at-risk children. Children with autism spectrum disorder have been found to show a strong interest in technology in general and robots in particular. Therefore, robot-based tools may be particularly adept at stimulating socio-emotional engagement from children with autism spectrum disorder. {\textbar} {\textbar} {SUMMARY} {\textbar} {\textbar} The disclosed system uses facial expressions and upper body movement patterns to detect autism spectrum disorder. For example, emotionally expressive robots may participate in sensory experiences by reacting to stimuli designed to resemble typical everyday experiences, such as uncontrolled sounds and light or tactile contact with different textures. The robot-child interactions elicit social engagement from the children, which is captured by a camera. A convolutional neural network, which has been trained to evaluate multimodal behavioral data collected during those robot-child interactions, identifies children that are at risk for autism spectrum disorder. {\textbar} {\textbar} The disclosed system has been shown to accurately identify children at risk for autism spectrum disorder. Meanwhile, the robot-assisted framework effectively engages the participants and models behaviors in ways that are easily interpreted by the participants. Therefore, with long-term exposure to the robots in this setting, the disclosed system may also be used to teach children with autism spectrum disorder to communicate their feelings about discomforting sensory stimulation (as modeled by the robots) instead of allowing uncomfortable experiences to escalate into extreme negative reactions (e.g., tantrums or meltdowns). {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} The accompanying drawings are incorporated in and constitute a part of this specification. It is to be understood that the drawings illustrate only some examples of the disclosure and other examples or combinations of various examples that are not specifically illustrated in the figures may still fall within the scope of this disclosure. Examples will now be described with additional detail through the use of the drawings. {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a diagram of a robot-aided platform according to an exemplary embodiment. {\textbar} {FIG}. 2 {\textbar} {\textbar} illustrates example emotions expressed by the humanoid robot according to an exemplary embodiment. {\textbar} {FIG}. 3 {\textbar} {\textbar} illustrates example emotions expressed by the facially expressive robot according to an exemplary embodiment. {\textbar} {FIG}. 4 {\textbar} {\textbar} illustrates sensory stations according to an exemplary embodiment. {\textbar} {FIG}. 5 {\textbar} {\textbar} illustrates the facial keypoints and body tracking keypoints extracted according to an exemplary embodiment. {\textbar} {FIG}. 6 {\textbar} {\textbar} is a diagram illustrating the convolutional neural network according to an exemplary embodiment. {\textbar} {FIG}. 7 {\textbar} {\textbar} illustrates a graph {\textbar} 700 {\textbar} depicting the engagement of one participant using the disclosed system according to an exemplary embodiment. {\textbar} {FIG}. 8 {\textbar} {\textbar} illustrates graphs of each target behavior during an interaction with each emotionally expressive robot. {\textbar} {DETAILED} {DESCRIPTION} {\textbar} {\textbar} In describing the illustrative, non-limiting embodiments illustrated in the drawings, specific terminology will be resorted to for the sake of clarity. However, the disclosure is not intended to be limited to the specific terms so selected, and it is to be understood that each specific term includes all technical equivalents that operate in similar manner to accomplish a similar purpose. Several embodiments are described for illustrative purposes, it being understood that the description and claims are not limited to the illustrated embodiments and other embodiments not specifically shown in the drawings may also be within the scope of this disclosure. {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a diagram of a robot-aided platform {\textbar} 100 {\textbar} according to an exemplary embodiment. {\textbar} As shown in {\textbar} {\textbar} {FIG}. 1 {\textbar} , the platform {\textbar} 100 {\textbar} may include a computer {\textbar} 120 {\textbar} , a database {\textbar} 130 {\textbar} , one or more networks {\textbar} 150 {\textbar} , one or more emotionally expressive robots {\textbar} 160 {\textbar} , a video camera {\textbar} 170 {\textbar} , and a number of sensory stations {\textbar} 400 {\textbar} . The one or more emotionally expressive robots {\textbar} 160 {\textbar} may include, for example, a humanoid robot {\textbar} 200 {\textbar} and a facially expressive robot {\textbar} 300 {\textbar} . {\textbar} The computer {\textbar} {\textbar} 120 {\textbar} may be any suitable computing device programmed to perform the functions described herein. The computer {\textbar} 120 {\textbar} includes at least one hardware processor and memory (i.e., non-transitory computer readable storage media). For example, the computer {\textbar} 120 {\textbar} may be a server, a personal computer, etc. {\textbar} The network(s) {\textbar} {\textbar} 150 {\textbar} may include a local area network, the Internet, etc. The computer {\textbar} 120 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} and the video camera {\textbar} 170 {\textbar} may communicate via the network(s) {\textbar} 150 {\textbar} using wired or wireless connections (e.g., ethernet, {WiFi}, etc.). {\textbar} The emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} , which are described in detail below, may be controllable via the computer {\textbar} 120 {\textbar} . Alternatively, an emotionally expressive robot {\textbar} 160 {\textbar} may be controllable via a computing device {\textbar} 124 {\textbar} (e.g., a smartphone, a tablet computer, etc.), for example via wireless communications (e.g., Bluetooth). {\textbar} The video camera {\textbar} {\textbar} 170 {\textbar} may be any suitable device configured to capture and record video images. For example, the video camera {\textbar} 170 {\textbar} may be a digital camcorder, a smartphone, etc. The video camera {\textbar} 170 {\textbar} may be configured to transfer those video images to the computer {\textbar} 120 {\textbar} via the network(s) {\textbar} 150 {\textbar} . However, as one of ordinary skill in the art would recognize, those video images may be stored by the video camera {\textbar} 170 {\textbar} and transferred to the computer {\textbar} 120 {\textbar} , for example via a wired connection or physical storage medium. {\textbar} The humanoid robot {\textbar} {\textbar} 200 {\textbar} may include a torso, arms, legs, and a face. The humanoid robot {\textbar} 200 {\textbar} may be programmable such that it mimics the expression of human emotion through gestures, speech, and/or facial expressions. The humanoid robot {\textbar} 200 {\textbar} may be a Robotis Mini available from Robotis, Inc. {\textbar} {FIG}. 2 {\textbar} {\textbar} illustrates example emotions expressed by the humanoid robot {\textbar} 200 {\textbar} according to an exemplary embodiment. {\textbar} The humanoid robot {\textbar} {\textbar} 200 {\textbar} may be programmed to portray the emotions that are commonly held to be the six basic human emotions (happiness, sadness, fear, anger, surprise and disgust) as well as additional emotional states relevant to interactions involving sensory stimulation. As shown in {\textbar} {FIG}. 2 {\textbar} , the humanoid robot {\textbar} 200 {\textbar} may be programmed to portray emotions such as dizzy {\textbar} 320 {\textbar} , happy {\textbar} 340 {\textbar} , scared {\textbar} 360 {\textbar} , and frustrated {\textbar} 380 {\textbar} . Additionally, the humanoid robot {\textbar} 200 {\textbar} may be programmed to portray additional emotions and physical states (not pictured), including unhappy, sniff, sneeze, excited, curious, wanting, celebrating, bored, sleepy, sad, nervous, tired, disgust, crying, and/or angry. {\textbar} The facially expressive robot {\textbar} {\textbar} 300 {\textbar} may include a wheeled platform and a display (e.g., a smartphone display). The facially expressive robot {\textbar} 300 {\textbar} may be programmable such that it mimics the expression of human emotion through motion, sound effects, and/or facial expressions. The facially expressive robot {\textbar} 300 {\textbar} may be a Romo, a controllable, wheeled platform for an {iPhone} that was previously available from Romotive Inc. {\textbar} {FIG}. 3 {\textbar} {\textbar} illustrates example emotions expressed by the facially expressive robot {\textbar} 300 {\textbar} according to an exemplary embodiment. In the example shown in {\textbar} {FIG}. 3 {\textbar} , the facially expressive robot {\textbar} 300 {\textbar} is programmed to display an animation that includes a custom-designed penguin avatar. {\textbar} Similar to the humanoid robot {\textbar} {\textbar} 200 {\textbar} , the facially expressive robot {\textbar} 300 {\textbar} may be programmed to portray the emotions that are commonly held to be the six basic human emotions (happiness, sadness, fear, anger, surprise and disgust) as well as additional emotional states relevant to interactions involving sensory stimulation. As shown in {\textbar} {FIG}. 3 {\textbar} , the facially expressive robot {\textbar} 300 {\textbar} may be programmed to display animations that portray emotions (and physical states) that include neutral, unhappy, sniff, sneeze, happy, excited, curious, wanting, celebrating, bored, sleepy, scared, sad, nervous, frustrated, tired, dizzy, disgust, crying, and/or angry. Each animation for each emotion or physical state may be accompanied by a dedicated background color, complementary changes in the tilt angle of the display, and/or movement of the facially expressive robot {\textbar} 300 {\textbar} (e.g., circular or back-and-forth movement of the treads). {\textbar} In either or both instances, the emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} may be programmed to depict simple but meaningful behaviors, combining all available modalities of emotional expression (e.g., movement, speech and facial expressions). The emotionally expressive robot(s) {\textbar} 160 {\textbar} may be designed to be expressive, clear and straightforward so as to facilitate interpretation in the context of the scenario being presented at the given sensory station {\textbar} 400 {\textbar} (discussed below). A humanoid robot {\textbar} 200 {\textbar} that communicates through gestures and speech is capable of responding to the sensory stimulation in a manner that resembles natural human-human communication. According, the humanoid robot {\textbar} 200 {\textbar} is capable of meaningfully responding to sensory stimulation without acting out explicit emotions. By contrast, a facially expressive robot {\textbar} 300 {\textbar} may use relatively primitive means of communication, like facial expressions, sound effects and movements. Therefore, the facially expressive robot {\textbar} 300 {\textbar} may be programmed to react to sensory stimulation through explicit emotional expressions joined one after another to form meaningful responses. {\textbar} {FIG}. 4 {\textbar} {\textbar} illustrates the sensory stations {\textbar} 400 {\textbar} according to an exemplary embodiment. {\textbar} As shown in {\textbar} {\textbar} {FIG}. 4 {\textbar} , the sensory stations {\textbar} 400 {\textbar} may include a seeing station {\textbar} 420 {\textbar} , a hearing station {\textbar} 430 {\textbar} , a smelling station {\textbar} 440 {\textbar} , a tasting station {\textbar} 450 {\textbar} , a touching station {\textbar} 460 {\textbar} , and a celebration station {\textbar} 480 {\textbar} . The sensory stations {\textbar} 400 {\textbar} are designed to resemble real world scenarios that form a typical part of one's everyday experiences, such as uncontrolled sounds and light in a public space (e.g., a mall or a park) or tactile contact with clothing made of fabrics with different textures. The emotionally expressive robot(s) {\textbar} 160 {\textbar} are programmed to interact with each sensory station {\textbar} 400 {\textbar} and react in a manner that demonstrates socially acceptable responses to each stimulation. The emotionally expressive robot(s) {\textbar} 160 {\textbar} interact with each sensory station {\textbar} 400 {\textbar} in a manner that is interactive and inclusive of the child, such that the emotionally expressive robot {\textbar} 160 {\textbar} and the child engage in a shared sensory experience. {\textbar} The seeing station {\textbar} {\textbar} 420 {\textbar} may designed to provide visual stimulus. For example, the seeing station {\textbar} 420 {\textbar} may include a flashlight inside a lidded box (e.g., constructed from a {LEGO} Mindstorm {EV}3 kit) with an infrared sensor that opens the lid of the box when movement is detected in proximity. The emotionally expressive robot {\textbar} 160 {\textbar} may be programmed to move toward the seeing station {\textbar} 420 {\textbar} at which point the lid of the box is opened and the flashlight directs a bright beam of light in the direction of the approaching emotionally expressive robot {\textbar} 160 {\textbar} . {\textbar} The hearing station {\textbar} {\textbar} 430 {\textbar} may be designed to provide an auditory stimulus. For example, the hearing station {\textbar} 430 {\textbar} may include a Bluetooth speaker play plays music. The smelling station {\textbar} 440 {\textbar} may be designed to provide olfactory stimulus. For example, the smelling station {\textbar} 440 {\textbar} may include scented artificial flowers inside a flowerpot. The tasting station {\textbar} 450 {\textbar} may be designed to provide gustatory stimulus. For example, the tasting station {\textbar} 450 {\textbar} may include two small plastic plates with two different food items. (Those food items may be modified according to likes and dislikes of each every subject child.) The touching station {\textbar} 460 {\textbar} may be designed to provide tactile stimulus. For example, the touching station may include a soft blanket {\textbar} 462 {\textbar} and a bowl of sand {\textbar} 464 {\textbar} (e.g., with golden stars hidden inside it). {\textbar} Each of the emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} may be programmed to travel (e.g., walk and/or drive) to each sensory station {\textbar} 400 {\textbar} and interact with the sensory stimuli presented at each sensory station {\textbar} 400 {\textbar} . While interacting with each sensory stimuli, the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to initiate a conversation with the child and facilitate a joint sensory experience. {\textbar} Diagnosis {\textbar} {\textbar} The video camera {\textbar} {\textbar} 170 {\textbar} records each interaction between each child and the emotionally expressive robot(s) {\textbar} 160 {\textbar} . Images of each child are then analyzed by the computer {\textbar} 120 {\textbar} . {\textbar} {FIG}. 5 {\textbar} {\textbar} illustrates facial keypoints {\textbar} 520 {\textbar} and body tracking keypoints {\textbar} 560 {\textbar} according to an exemplary embodiment. In image analysis, “keypoints” are distinctive points in an input image that are invariant to rotation, scale and distortion. Facial keypoints {\textbar} 520 {\textbar} , sometimes referred to as “facial landmarks,” are specific areas of the face (e.g., nose, eyes, mouth, etc.) identified in images of faces. Similarly, body tracking keypoints {\textbar} 560 {\textbar} are specific points of the bodies identified in images of people. Facial keypoints {\textbar} 520 {\textbar} and body tracking keypoints {\textbar} 560 {\textbar} are identified in images in order to identify the coordinates of the specified body part. Image recognition systems generally use the facial keypoints {\textbar} 520 {\textbar} to perform facial recognition, emotion recognition, etc. Similarly, body tracking keypoints {\textbar} 560 {\textbar} may be used to identify body poses and movements. {\textbar} Body tracking keypoints {\textbar} {\textbar} 560 {\textbar} and facial keypoints {\textbar} 520 {\textbar} are extracted from the video images by the computer {\textbar} 120 {\textbar} , for example using {OpenPose}. As shown in {\textbar} {FIG}. 5 {\textbar} , for example, the computer {\textbar} 120 {\textbar} may analyze a subset {\textbar} 540 {\textbar} of the facial keypoints {\textbar} 520 {\textbar} originating from the nose and eyes. Additionally, because the children may interact with the sensory stations {\textbar} 400 {\textbar} from behind a table, the computer {\textbar} 120 {\textbar} may extract only upper body keypoints {\textbar} 580 {\textbar} originating from the arms, torso, and head of the child. {\textbar} The computer {\textbar} {\textbar} 120 {\textbar} may derive movement features from the body upper body keypoints {\textbar} 580 {\textbar} , for example using Laban movement analysis, to determine the intent behind human movement. In machine learning, pattern recognition, and image processing, “feature extraction” starts from an initial set of measured data and builds derived values (“features”) intended to be informative and non-redundant, facilitating the subsequent learning and generalization steps. As described below, those movement features derived by the computer {\textbar} 120 {\textbar} may include weight, space, and time. Those movement features may be derived using a moving time window (e.g., a 1 second window) to capture the temporal nature of the data. The three derived movement features may be combined with facial keypoints (e.g., 68 facial keypoints originating from the nose and eyes) to form a dataset. Accordingly, the dataset may include a total of 71 features. {\textbar} As mentioned above, the computer may derive movement features from the upper body keypoints {\textbar} {\textbar} 580 {\textbar} . Those movement features may include weight, space, and time. {\textbar} Weight can be described as the intensity of perceived force in movement. High and constant intensity is considered high weight (strong) and the opposite is considered low weight (light). Strong weight characterizes bold, forceful, powerful, and/or determined intention. Light weight characterizes delicate, sensitive buoyant, and easy intention. Weight may be derived by the computer {\textbar} {\textbar} 120 {\textbar} as follows: {\textbar} Weight {\textbar} {\textbar} = {\textbar} ∑ {\textbar} i {\textbar} ⁢ {\textbar} τ {\textbar} i {\textbar} ⁢ {\textbar} ω {\textbar} i {\textbar} ⁡ {\textbar} ( {\textbar} t {\textbar} ) {\textbar} where: {\textbar} {\textbar} τ {\textbar} {\textbar} i {\textbar} = {\textbar} F {\textbar} * {\textbar} L {\textbar} = {\textbar} L {\textbar} 2 {\textbar} ⁢ {\textbar} ω {\textbar} i {\textbar} 2 {\textbar} ⁢ {\textbar} sin {\textbar} ⁡ {\textbar} ( {\textbar} θ {\textbar} ) {\textbar} * {\textbar} mas {\textbar} ⁢ {\textbar} s {\textbar} ω {\textbar} i {\textbar} = {\textbar} d {\textbar} ⁢ {\textbar} θ {\textbar} d {\textbar} ⁢ {\textbar} t {\textbar} i {\textbar} = {\textbar} Joint {\textbar} ⁢ {\textbar} ⁢ {\textbar} Number {\textbar} Space is a measure of the distance of the legs and arms to the body. Space is considered low (direct) when legs and arms are constantly close to the body center and is considered high (indirect) if a person is constantly using outstretched movements. Direct space is characterized by linear actions, focused and specific actions, and/or attention to a singular spatial possibility. Indirect space characterizes flexibility of the joints, three-dimensionality of space, and/or all-around awareness. Because the disclosed system may be limited to analyzing upper body keypoints {\textbar} {\textbar} 580 {\textbar} , space may be indicative of the distance of the arms of the child relative to the body of the child. Space may be derived by the computer {\textbar} 120 {\textbar} as follows: {\textbar} Space=(0.5{\textbar} {\textbar} {\textbar} {\textbar}{\textbar} {\textbar} {\textbar}sin(θ {\textbar} 1 {\textbar} ))+(0.5{\textbar} {\textbar} {\textbar}{\textbar} {\textbar} {\textbar}sin(θ {\textbar} 2 {\textbar} )) {\textbar} where {\textbar} {\textbar} =Left Shoulder to Left Hand {\textbar} =Right Shoulder to Left Shoulder {\textbar} =Right Hand to Right Shoulder {\textbar} =Left Hand to Right Hand {\textbar} θ {\textbar} 1 {\textbar} =Angle between \{right arrow over (a)\} \& \{right arrow over (d)\} {\textbar} θ {\textbar} 2 {\textbar} =Angle between \{right arrow over (c)\} \& \{right arrow over (b)\} {\textbar} Time is a measure of the distinct change from one prevailing tempo to some other tempo. Space is considered high when movements are sudden and low when movements are sustained. Sudden movements are characterized as unexpected, isolated, surprising, and/or urgent. Sustained movements are characterized as continuous, lingering, indulging in time, and/or leisurely. Time may be calculated by the computer {\textbar} {\textbar} 120 {\textbar} as follows: {\textbar} T {\textbar} {\textbar} ⁢ {\textbar} i {\textbar} ⁢ {\textbar} m {\textbar} ⁢ {\textbar} e {\textbar} i {\textbar} = {\textbar} ∑ {\textbar} i {\textbar} ⁢ {\textbar} ω {\textbar} . {\textbar} i {\textbar} ⁡ {\textbar} ( {\textbar} t {\textbar} ) {\textbar} where: {\textbar} {\textbar} \{dot over (ω)\} {\textbar} {\textbar} i {\textbar} =Angular Velocity for Joint {\textbar} i {\textbar} As described above, preferred embodiments utilize a video camera {\textbar} {\textbar} 170 {\textbar} to capture video images of children and a computer {\textbar} 120 {\textbar} to extract facial keypoints {\textbar} 520 {\textbar} and body tracking keypoints {\textbar} 560 {\textbar} and derive movement features of those children. However, the disclosed system is not limited to a video camera {\textbar} 170 {\textbar} and may instead utilize any sensor (e.g., {RADAR}, {SONAR}, {LIDAR}, etc.) suitably configured to capture data indicative of the facial keypoints {\textbar} 520 {\textbar} and body tracking keypoints {\textbar} 560 {\textbar} of the child over time. {\textbar} Referring back to {\textbar} {\textbar} {FIG}. 1 {\textbar} , the subset {\textbar} 540 {\textbar} of the facial keypoints {\textbar} 520 {\textbar} and the movement features (e.g., weight, space, and time) are stored in the database {\textbar} 130 {\textbar} . Meanwhile, the computer {\textbar} 120 {\textbar} includes a convolutional neural network {\textbar} 600 {\textbar} designed to process that data and identify children at risk for autism spectrum disorder. {\textbar} {FIG}. 6 {\textbar} {\textbar} is a diagram illustrating the convolutional neural network {\textbar} 600 {\textbar} according to an exemplary embodiment. {\textbar} As shown in {\textbar} {\textbar} {FIG}. 6 {\textbar} , convolutional neural network {\textbar} 600 {\textbar} may include two Conv1D layers (1-dimensional convolution layers) {\textbar} 620 {\textbar} to identify temporal data patterns, three dense layers {\textbar} 660 {\textbar} for classification, and multiple dropout layers {\textbar} 650 {\textbar} to avoid overfitting. {\textbar} The Conv1D layers {\textbar} {\textbar} 620 {\textbar} may include a first Conv1D layer {\textbar} 622 {\textbar} and a second Conv1D layer {\textbar} 624 {\textbar} . The first Conv1D layer {\textbar} 622 {\textbar} may include five channels with 64 filters and the second Conv1D layer {\textbar} 624 {\textbar} may include 128 filters. Each of the Conv1D layers {\textbar} 620 {\textbar} may have a kernel size of 3. The convolutional neural network {\textbar} 600 {\textbar} may include two Conv1D layers {\textbar} 620 {\textbar} to extract high-level features from the temporal data because the dataset being used has a high input dimension and a relatively small number of datapoints. {\textbar} Each dropout layer {\textbar} {\textbar} 650 {\textbar} may have a dropout rate of 20 percent. {\textbar} The dense layers {\textbar} {\textbar} 660 {\textbar} may include a first dense layer {\textbar} 662 {\textbar} , a second dense layer {\textbar} 664 {\textbar} , and a third dense layer {\textbar} 668 {\textbar} . Since the data have a non-linear structure, the first dense layer {\textbar} 662 {\textbar} and the second dense layer {\textbar} 664 {\textbar} may be used to spread the feature dimension while the third dense layer {\textbar} 668 {\textbar} generates an output dimension {\textbar} 690 {\textbar} . {\textbar} The convolutional neural network {\textbar} {\textbar} 600 {\textbar} models the risk of autism spectrum disorder as a binary classification problem. The convolutional neural network {\textbar} 600 {\textbar} is trained using a corpus of data captured by the disclosed system analyzing children that have been diagnosed with autism spectrum disorder and children having been diagnosed as not at risk for autism spectrum disorder (e.g., typically developing). The convolutional neural network {\textbar} 600 {\textbar} can then be supplied with input data {\textbar} 610 {\textbar} , for example the facial keypoints {\textbar} 520 {\textbar} and the movement features (e.g., weight, space, and time) described above. Having been trained on a dataset characterizing children of known risk, the convolutional neural network {\textbar} 600 {\textbar} is then configured to generate an output dimension {\textbar} 690 {\textbar} indicative of the subject's risk for autism spectrum disorder. {\textbar} The disclosed system has been shown to accurately identify children at risk for autism spectrum disorder. In an initial study, the convolutional neural network {\textbar} {\textbar} 600 {\textbar} was trained on 80 percent of the interaction data and the remaining 20 percent were used to validate its performance. The convolutional neural network {\textbar} 600 {\textbar} achieved high accuracy (0.8846), precision (0.8912), and recall (0.8853). {\textbar} Unlike previous methods, the disclosed system identifies children at risk for autism spectrum disorder based only on behavioral data captured through video recordings of a naturalistic interaction with social robots. The movement of the child was not restricted and no obtrusive sensors were used. Accordingly, the disclosed system and method can easily be generalized to other interactions (e.g., play time at home) increasing the utility of the disclosed method. The possibility of using the disclosed system in additional settings also raises the possibility that larger datasets may be obtained, thereby increasing the accuracy of the disclosed method. {\textbar} {\textbar} Treatment {\textbar} {\textbar} As described above, the sensory stations {\textbar} {\textbar} 400 {\textbar} closely resemble situations that children would encounter frequently in their everyday lives. Therefore, they are relatable and easy to interpret. Given the strong interest in technology from children with autism spectrum disorder, the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be used to elicit a higher level of socio-emotional engagement from these children. For example, the emotionally expressive robot(s) {\textbar} 160 {\textbar} navigating the sensory stations {\textbar} 400 {\textbar} may be used to demonstrate socially acceptable responses to stimulation and encourage children to become more receptive to a variety of sensory experiences and to effectively communicate their feelings if the experiences cause them discomfort. {\textbar} The emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} may be programmed to show both positive and negative responses at some of the sensory stations {\textbar} 400 {\textbar} with the aim of demonstrating to the children how to communicate their feelings even when experiencing discomforting or unfavorable sensory stimulation (instead of allowing the negative experience to escalate into a tantrum or meltdown). The negative reactions may be designed not to be too extreme so as to focus on the communication of one's feelings rather than encouraging intolerance of the stimulation. {\textbar} At the seeing station {\textbar} {\textbar} 420 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to demonstrate effectively handle uncomfortable visual stimuli and to communicate discomfort instead of allowing it to manifest as extreme negative reactions (tantrums/meltdowns). This can be especially useful in controlled environments like movie theaters and malls where light intensity cannot be fully regulated. {\textbar} The hearing station {\textbar} {\textbar} 430 {\textbar} may improve tolerance for sounds louder than those to which one is accustomed, to learn to not be overwhelmed by music, and to promote gross motor movements by encouraging dancing along to it. This can be especially useful in uncontrolled environments like movie theaters and malls where sounds cannot be fully regulated. {\textbar} At the smelling station {\textbar} {\textbar} 440 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to not react with extreme aversion to odors that may be disliked and to communicate the dislike instead. This can be useful for parents of children with autism spectrum disorder who are very particular about the smell of their food, clothes, and/or environments etc. {\textbar} At the tasting station {\textbar} {\textbar} 450 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to demonstrate diversifying one's food preferences instead of adhering strictly to the same ones. {\textbar} At the touching station {\textbar} {\textbar} 460 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to demonstrate acclimating oneself to different textures by engaging in tactile interactions with different materials. This is especially useful for those children with autism spectrum disorder who may be sensitive to the texture of their clothing fabrics and/or those who experience significant discomfort with wearables (e.g., hats, wrist watches, etc.). {\textbar} At the celebration station {\textbar} {\textbar} 480 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to convey a sense of shared achievement while also encouraging the children to practice their motor and vestibular skills by imitating the celebration routines of the robots. {\textbar} The emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} may be particularly effective after the children have already interacted with the emotionally expressive robot(s) {\textbar} 160 {\textbar} over several sessions. Once an emotionally expressive robot {\textbar} 160 {\textbar} has formed a rapport with the child by liking and disliking the same foods as the child, for example, it could start to deviate from those responses and encourage the child to be more receptive to the foods their robot “friends” prefer. To achieve this goal, for example, different food items may be introduced in the tasting station {\textbar} 450 {\textbar} in the future sessions. {\textbar} While the disclosed system may include any emotionally expressive robot {\textbar} {\textbar} 160 {\textbar} , the humanoid robot {\textbar} 200 {\textbar} and the facially expressive robot {\textbar} 300 {\textbar} are examples of preferred emotionally expressive robots {\textbar} 160 {\textbar} for a number of reasons. The emotionally expressive robot(s) {\textbar} 160 {\textbar} are preferably not be too large in size in order to prevent children from being intimidated by them. The emotionally expressive robot(s) {\textbar} 160 {\textbar} are preferably capable of expressing emotions through different modalities such as facial expressions, gestures and speech. The emotionally expressive robot(s) {\textbar} 160 {\textbar} are preferably friendly in order to form a rapport with the children. {\textbar} The sensory stations {\textbar} {\textbar} 400 {\textbar} are preferably designed to be relatable to the children such that they are able to draw the connection between the stimulation presented to the emotionally expressive robot(s) {\textbar} 160 {\textbar} and that experienced by them in their everyday lives. The activity being conducted is preferably able to maintain a child's interest through the entire length of the interaction. Accordingly, the content (and duration) of the activity is preferably appealing to the children. {\textbar} The actions performed by the emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} is preferably simple and easy to understand for children in the target age range. The gestures, speech, facial expressions and/or body language emotionally expressive robot(s) {\textbar} 160 {\textbar} is preferably combined to form meaningful and easily interpretable behaviors. The emotion library of the emotionally expressive robot(s) {\textbar} 160 {\textbar} is preferably large enough to effectively convey different reactions to the stimulation but also simple enough to be easily understood by the children. {\textbar} In order to derive a meaningful quantitative measure of engagement, we utilized several key behavioral traits of social interactions, including gaze focus, vocalizations and verbalizations, smile, triadic interactions, self-initiated interactions and imitation: {\textbar} {\textbar} Behavior {\textbar} {\textbar} Description {\textbar} Eye gaze focus {\textbar} {\textbar} Deficits in social attention and establishing eye {\textbar} contact are two of the most commonly reported {\textbar} {\textbar} deficits in children with autism spectrum disorder. {\textbar} {\textbar} We therefore used the children's gaze focus on the {\textbar} {\textbar} robots and/or the setup to mark the presence of this {\textbar} {\textbar} behavior. {\textbar} {\textbar} Vocalizations/ {\textbar} {\textbar} The volubility of utterances produced by children {\textbar} verbalizations {\textbar} {\textbar} with autism spectrum disorder is low compared to {\textbar} their typically developing counterparts. Since {\textbar} {\textbar} communication is a core aspect of social {\textbar} {\textbar} responsiveness, the frequency and duration of the {\textbar} {\textbar} vocalizations and verbalizations produced by the {\textbar} {\textbar} children during the interaction is also important in {\textbar} {\textbar} computing the engagement index. {\textbar} {\textbar} Smile {\textbar} {\textbar} Smiling has also been established as an aspect of {\textbar} social responsiveness. We recorded the frequency {\textbar} {\textbar} and duration of smiles displayed by the children {\textbar} {\textbar} while interacting with the robots, as a contributing {\textbar} {\textbar} factor to the engagement index. {\textbar} {\textbar} Triadic {\textbar} {\textbar} A triadic relationship involves three agents, including {\textbar} interactions {\textbar} {\textbar} the child, the robot and a third person that may be the {\textbar} parent or the instructor. In this study, the robot acts as {\textbar} {\textbar} tool to elicit interactions between the child and other {\textbar} {\textbar} humans. An example of such interactions is the {\textbar} {\textbar} child sharing her excitement about the dancing robot {\textbar} {\textbar} by directing the parent's attention to it. {\textbar} {\textbar} Self-initiated {\textbar} {\textbar} Children with autism spectrum disorder prefer to {\textbar} interactions {\textbar} {\textbar} play alone and make fewer social initiations compared {\textbar} to their peers. Therefore, we recorded the frequency {\textbar} {\textbar} and duration of the interactions with the robot initiated {\textbar} {\textbar} by the children as factors contributing to the {\textbar} {\textbar} engagement index. Examples of self-initiated {\textbar} {\textbar} interactions can include talking to the robots, {\textbar} {\textbar} attempting to feed the robots, guiding the robots to {\textbar} {\textbar} the next station etc. without any prompts from the {\textbar} {\textbar} instructors. {\textbar} {\textbar} Imitation {\textbar} {\textbar} Infants have been found to produce and recognize {\textbar} imitation from the early stages of development, and {\textbar} {\textbar} both these skills have been linked to the development {\textbar} {\textbar} of socio-communicative abilities. In this study, we {\textbar} {\textbar} monitored a child's unprompted imitation of the {\textbar} {\textbar} robot behaviors as a measure of their engagement {\textbar} {\textbar} in the interaction. {\textbar} {\textbar} The aforementioned behaviors were selected because they have proven to be useful measures of social attention and social responsiveness from previous studies. {\textbar} {\textbar} {FIG}. 7 {\textbar} {\textbar} illustrates a graph {\textbar} 700 {\textbar} depicting the engagement of one participant using the disclosed system according to an exemplary embodiment. {\textbar} As shown in {\textbar} {\textbar} {FIG}. 7 {\textbar} , the graph includes an engagement index {\textbar} 740 {\textbar} and a general engagement trend {\textbar} 760 {\textbar} . Video data was coded for the target behaviors above (smile, eye gaze focus, vocalizations/verbalizations, triadic interaction, self-initiated interaction, and imitation) and the engagement index {\textbar} 740 {\textbar} was derived as the indicator of every child's varying social engagement throughout the interaction with the emotionally expressive robots {\textbar} 160 {\textbar} . The engagement index {\textbar} 740 {\textbar} was computed as a sum of these factors, each with the same weight, such that the maximum value of the engagement index {\textbar} 740 {\textbar} was 1. {\textbar} Each behavior contributed a factor of ⅙ to the engagement index {\textbar} {\textbar} 740 {\textbar} . For example, for a participant observed to have a smile and gaze focus while interacting with the humanoid robot {\textbar} 200 {\textbar} during the tasting station {\textbar} 450 {\textbar} but only gaze focus following the end of the station, the engagement index {\textbar} 740 {\textbar} was assigned a constant value of ⅙+⅙=⅓ for the entire duration of the station, and reduced to ⅙ immediately after its end. Any changes in engagement within an interval of 1 second were detected and reflected in the engagement index {\textbar} 740 {\textbar} . {\textbar} Time periods when each emotionally expressive robot {\textbar} {\textbar} 160 {\textbar} interacts with each sensory station {\textbar} 400 {\textbar} , including time period {\textbar} 732 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the seeing station {\textbar} 420 {\textbar} ; time period {\textbar} 733 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the hearing station {\textbar} 430 {\textbar} ; including time period {\textbar} 734 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the smelling station {\textbar} 440 {\textbar} ; including time period {\textbar} 735 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the tasting station {\textbar} 450 {\textbar} ; including time period {\textbar} 736 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the touching station {\textbar} 460 {\textbar} ; including time period {\textbar} 738 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the celebration station {\textbar} 480 {\textbar} ; time period {\textbar} 722 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the seeing station {\textbar} 420 {\textbar} ; time period {\textbar} 723 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the hearing station {\textbar} 430 {\textbar} ; including time period {\textbar} 724 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the smelling station {\textbar} 440 {\textbar} ; including time period {\textbar} 725 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the tasting station {\textbar} 450 {\textbar} ; including time period {\textbar} 726 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the touching station {\textbar} 460 {\textbar} ; and including time period {\textbar} 728 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the celebration station {\textbar} 480 {\textbar} . {\textbar} Analyzing the engagement index {\textbar} {\textbar} 740 {\textbar} when each emotionally expressive robot {\textbar} 160 {\textbar} interacts with each sensory station {\textbar} 400 {\textbar} allows for a comparison of the effectiveness of each sensory station {\textbar} 400 {\textbar} in eliciting social engagement from the participants. {\textbar} {FIG}. 8 {\textbar} {\textbar} illustrates graphs {\textbar} 800 {\textbar} of each target behavior (smile, eye gaze focus, vocalizations/verbalizations, triadic interaction, self-initiated interaction, and imitation) during an interaction with each emotionally expressive robot {\textbar} 160 {\textbar} according to an exemplary embodiment. Labels for each time period {\textbar} 732 {\textbar} , {\textbar} 733 {\textbar} , etc. are omitted for clarity, but they are legibility but are the same as shown in {\textbar} {FIG}. 7 {\textbar} . By identifying the target behaviors elicited by each emotionally expressive robot {\textbar} 160 {\textbar} at each sensory station {\textbar} 400 {\textbar} , the frequency each target behavior and the sensory stations {\textbar} 400 {\textbar} emotionally expressive robot {\textbar} 160 {\textbar} responsible for eliciting them can be compared. {\textbar} Finally, the engagement generated by each emotionally expressive robot {\textbar} {\textbar} 160 {\textbar} may also be assessed individually and compared to study the social engagement potential of each emotionally expressive robots {\textbar} 160 {\textbar} in this sensory setting. {\textbar} Using the method to derive the engagement index {\textbar} {\textbar} 740 {\textbar} described above, several other metrics were also generated to evaluate various aspects of the disclosed system. First, the session comprising interactions with both emotionally expressive robots {\textbar} 160 {\textbar} was analyzed as a whole, resulting in consolidated engagement metrics. In addition, engagement resulting from each target behavior was also computed to study the contribution of each target behavior toward the engagement index. As an example, an engagement metric resulting from the vocalizations of participant X was computed as: {\textbar} eng {\textbar} {\textbar} voc {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} vocalization {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} throughout {\textbar} ⁢ {\textbar} ⁢ {\textbar} the {\textbar} ⁢ {\textbar} ⁢ {\textbar} session {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} from {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} target {\textbar} ⁢ {\textbar} ⁢ {\textbar} behaviors {\textbar} ⁢ {\textbar} ⁢ {\textbar} throughout {\textbar} ⁢ {\textbar} ⁢ {\textbar} the {\textbar} ⁢ {\textbar} ⁢ {\textbar} session {\textbar} By isolating the engagement resulting from each emotionally expressive robot {\textbar} {\textbar} 160 {\textbar} , the metrics generated by the humanoid robot {\textbar} 200 {\textbar} and the facially expressive robot {\textbar} 300 {\textbar} may be compared to evaluate the impact of each emotionally expressive robot {\textbar} 160 {\textbar} . Once again, an overall engagement index was obtained for each emotionally expressive robot {\textbar} 160 {\textbar} as an indicator of its performance throughout its interaction in addition to a breakdown in terms of the target behaviors that comprise the engagement. The engagement metric for the interaction of participant X with the facially expressive robot {\textbar} 300 {\textbar} (“Romo”) was calculated as: {\textbar} eng {\textbar} {\textbar} Romo {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} throughout {\textbar} ⁢ {\textbar} ⁢ {\textbar} interaction {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Romo {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} throughout {\textbar} session {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} both {\textbar} ⁢ {\textbar} ⁢ {\textbar} robots {\textbar} Similarly, the engagement metric resulting from the vocalizations of participant X while interacting with the facially expressive robot {\textbar} {\textbar} 300 {\textbar} (“Romo”) was calculated as: {\textbar} eng {\textbar} {\textbar} Romo {\textbar} , {\textbar} voc {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} vocalization {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} throughout {\textbar} ⁢ {\textbar} ⁢ {\textbar} interaction {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Romo {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} throughout {\textbar} session {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} both {\textbar} ⁢ {\textbar} ⁢ {\textbar} robots {\textbar} An analysis was then performed to study the differences in engagement at each sensory station {\textbar} {\textbar} 400 {\textbar} . This was analyzed separately for each emotionally expressive robot {\textbar} 160 {\textbar} so as to derive an understanding of the engagement potential of each station per robot. The engagement metric resulting from the hearing station {\textbar} 430 {\textbar} while participant X interacted with the humanoid robot {\textbar} 200 {\textbar} (“Mini”) was calculated as: {\textbar} eng {\textbar} {\textbar} Mini {\textbar} , {\textbar} hear {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} at {\textbar} ⁢ {\textbar} ⁢ {\textbar} hearing {\textbar} station {\textbar} ⁢ {\textbar} ⁢ {\textbar} during {\textbar} ⁢ {\textbar} ⁢ {\textbar} interaction {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Mini {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} throughout {\textbar} session {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Mini {\textbar} In addition, a breakdown of engagement at each sensory station {\textbar} {\textbar} 400 {\textbar} was obtained in terms of the elicited target behaviors and analyzed separately for each emotionally expressive robot {\textbar} 160 {\textbar} . This allowed for a finer-grain assessment of the capability of each sensory station {\textbar} 400 {\textbar} for eliciting the individual target behaviors. For example, the engagement metric resulting from the gaze of participant X at the smelling station {\textbar} 440 {\textbar} while interacting with the humanoid robot {\textbar} 200 {\textbar} (“Mini”) was calculated as: {\textbar} eng {\textbar} {\textbar} Mini {\textbar} , {\textbar} smell {\textbar} , {\textbar} gaze {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} gaze {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} at {\textbar} ⁢ {\textbar} ⁢ {\textbar} the {\textbar} ⁢ {\textbar} ⁢ {\textbar} smelling {\textbar} ⁢ {\textbar} station {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Mini {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} at {\textbar} smelling {\textbar} ⁢ {\textbar} ⁢ {\textbar} station {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Mini {\textbar} The aforementioned metrics enabled each sensory station {\textbar} {\textbar} 400 {\textbar} and each emotionally expressive robot {\textbar} 160 {\textbar} to be evaluated to achieve a comprehensive understanding of the potential of the disclosed system and identify areas requiring further improvement. {\textbar} The drawings may illustrate—and the description and claims may use—several geometric or relational terms and directional or positioning terms, such as upper. Those terms are merely for convenience to facilitate the description based on the embodiments shown in the figures and are not intended to limit the invention. Thus, it should be recognized that the invention can be described in other ways without those geometric, relational, directional or positioning terms. And, other suitable geometries and relationships can be provided without departing from the spirit and scope of the invention. {\textbar} {\textbar} The foregoing description and drawings should be considered as illustrative only of the principles of the disclosure, which may be configured in a variety of shapes and sizes and is not intended to be limited by the embodiment herein described. Numerous applications of the disclosure will readily occur to those skilled in the art. Therefore, it is not desired to limit the disclosure to the specific examples disclosed or the exact construction and operation shown and described. Rather, all suitable modifications and equivalents may be resorted to, falling within the scope of the disclosure. {CROSS}-{REFERENCE} {TO} {RELATED} {APPLICATIONS} {\textbar} {\textbar} This application claims priority to U.S. Prov. Pat. Appl. No. 62/967,873, filed Jan. 30, 2020, which is hereby incorporated by reference. {\textbar} {\textbar} {FEDERAL} {FUNDING} {\textbar} {\textbar} This system was made with government support from the National Institutes of Health (under Grant Number R01-{HD}082914, University Account No. 37987-1-{CCLS}29193F) and the National Science Foundation (under Grant No. 1846658, University Account No. 42008-1-{CCLS}29502F). The government has certain rights in the invention. {\textbar} {\textbar} {BACKGROUND} {\textbar} {\textbar} Children with autism spectrum disorder typically experience difficulties in social communication and interaction. As a result, they display a number of distinctive behaviors including atypical facial expressions and repetitive behaviors such as hand flapping and rocking. {\textbar} {\textbar} Sensory abnormalities are reported to be central to the autistic experience. Anecdotal accounts and clinical research both provide sufficient evidence to support this notion. One study found that, in a sample size of 200, over 90 percent of children with autism spectrum disorder had sensory abnormalities and showed symptoms in multiple sensory processing domains. The symptoms include hyposensitivity, hypersensitivity, multichannel receptivity, processing difficulties and sensory overload. A higher prevalence of unusual responses (particularly to tactile, auditory and visual stimuli) is seen in children with autism spectrum disorder when compared to their typically developing and developmentally delayed counterparts. The distress caused by some sensory stimuli can cause self-injurious and aggressive behaviors in children who may be unable to communicate their anguish. Families also report that difficulties with sensory processing and integration can restrict participation in everyday activities, resulting in social isolation for them and their child and impact social engagement. {\textbar} {\textbar} Given the subjective, cumbersome and time intensive nature of the current methods of diagnosis, there is a need for a behavior-based approach to identify children at risk for autism spectrum disorder in order to streamline the standard diagnostic procedures and facilitate rapid detection and clinical prioritization of at-risk children. Children with autism spectrum disorder have been found to show a strong interest in technology in general and robots in particular. Therefore, robot-based tools may be particularly adept at stimulating socio-emotional engagement from children with autism spectrum disorder. {\textbar} {\textbar} {SUMMARY} {\textbar} {\textbar} The disclosed system uses facial expressions and upper body movement patterns to detect autism spectrum disorder. For example, emotionally expressive robots may participate in sensory experiences by reacting to stimuli designed to resemble typical everyday experiences, such as uncontrolled sounds and light or tactile contact with different textures. The robot-child interactions elicit social engagement from the children, which is captured by a camera. A convolutional neural network, which has been trained to evaluate multimodal behavioral data collected during those robot-child interactions, identifies children that are at risk for autism spectrum disorder. {\textbar} {\textbar} The disclosed system has been shown to accurately identify children at risk for autism spectrum disorder. Meanwhile, the robot-assisted framework effectively engages the participants and models behaviors in ways that are easily interpreted by the participants. Therefore, with long-term exposure to the robots in this setting, the disclosed system may also be used to teach children with autism spectrum disorder to communicate their feelings about discomforting sensory stimulation (as modeled by the robots) instead of allowing uncomfortable experiences to escalate into extreme negative reactions (e.g., tantrums or meltdowns). {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} The accompanying drawings are incorporated in and constitute a part of this specification. It is to be understood that the drawings illustrate only some examples of the disclosure and other examples or combinations of various examples that are not specifically illustrated in the figures may still fall within the scope of this disclosure. Examples will now be described with additional detail through the use of the drawings. {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a diagram of a robot-aided platform according to an exemplary embodiment. {\textbar} {FIG}. 2 {\textbar} {\textbar} illustrates example emotions expressed by the humanoid robot according to an exemplary embodiment. {\textbar} {FIG}. 3 {\textbar} {\textbar} illustrates example emotions expressed by the facially expressive robot according to an exemplary embodiment. {\textbar} {FIG}. 4 {\textbar} {\textbar} illustrates sensory stations according to an exemplary embodiment. {\textbar} {FIG}. 5 {\textbar} {\textbar} illustrates the facial keypoints and body tracking keypoints extracted according to an exemplary embodiment. {\textbar} {FIG}. 6 {\textbar} {\textbar} is a diagram illustrating the convolutional neural network according to an exemplary embodiment. {\textbar} {FIG}. 7 {\textbar} {\textbar} illustrates a graph {\textbar} 700 {\textbar} depicting the engagement of one participant using the disclosed system according to an exemplary embodiment. {\textbar} {FIG}. 8 {\textbar} {\textbar} illustrates graphs of each target behavior during an interaction with each emotionally expressive robot. {\textbar} {DETAILED} {DESCRIPTION} {\textbar} {\textbar} In describing the illustrative, non-limiting embodiments illustrated in the drawings, specific terminology will be resorted to for the sake of clarity. However, the disclosure is not intended to be limited to the specific terms so selected, and it is to be understood that each specific term includes all technical equivalents that operate in similar manner to accomplish a similar purpose. Several embodiments are described for illustrative purposes, it being understood that the description and claims are not limited to the illustrated embodiments and other embodiments not specifically shown in the drawings may also be within the scope of this disclosure. {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} is a diagram of a robot-aided platform {\textbar} 100 {\textbar} according to an exemplary embodiment. {\textbar} As shown in {\textbar} {\textbar} {FIG}. 1 {\textbar} , the platform {\textbar} 100 {\textbar} may include a computer {\textbar} 120 {\textbar} , a database {\textbar} 130 {\textbar} , one or more networks {\textbar} 150 {\textbar} , one or more emotionally expressive robots {\textbar} 160 {\textbar} , a video camera {\textbar} 170 {\textbar} , and a number of sensory stations {\textbar} 400 {\textbar} . The one or more emotionally expressive robots {\textbar} 160 {\textbar} may include, for example, a humanoid robot {\textbar} 200 {\textbar} and a facially expressive robot {\textbar} 300 {\textbar} . {\textbar} The computer {\textbar} {\textbar} 120 {\textbar} may be any suitable computing device programmed to perform the functions described herein. The computer {\textbar} 120 {\textbar} includes at least one hardware processor and memory (i.e., non-transitory computer readable storage media). For example, the computer {\textbar} 120 {\textbar} may be a server, a personal computer, etc. {\textbar} The network(s) {\textbar} {\textbar} 150 {\textbar} may include a local area network, the Internet, etc. The computer {\textbar} 120 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} and the video camera {\textbar} 170 {\textbar} may communicate via the network(s) {\textbar} 150 {\textbar} using wired or wireless connections (e.g., ethernet, {WiFi}, etc.). {\textbar} The emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} , which are described in detail below, may be controllable via the computer {\textbar} 120 {\textbar} . Alternatively, an emotionally expressive robot {\textbar} 160 {\textbar} may be controllable via a computing device {\textbar} 124 {\textbar} (e.g., a smartphone, a tablet computer, etc.), for example via wireless communications (e.g., Bluetooth). {\textbar} The video camera {\textbar} {\textbar} 170 {\textbar} may be any suitable device configured to capture and record video images. For example, the video camera {\textbar} 170 {\textbar} may be a digital camcorder, a smartphone, etc. The video camera {\textbar} 170 {\textbar} may be configured to transfer those video images to the computer {\textbar} 120 {\textbar} via the network(s) {\textbar} 150 {\textbar} . However, as one of ordinary skill in the art would recognize, those video images may be stored by the video camera {\textbar} 170 {\textbar} and transferred to the computer {\textbar} 120 {\textbar} , for example via a wired connection or physical storage medium. {\textbar} The humanoid robot {\textbar} {\textbar} 200 {\textbar} may include a torso, arms, legs, and a face. The humanoid robot {\textbar} 200 {\textbar} may be programmable such that it mimics the expression of human emotion through gestures, speech, and/or facial expressions. The humanoid robot {\textbar} 200 {\textbar} may be a Robotis Mini available from Robotis, Inc. {\textbar} {FIG}. 2 {\textbar} {\textbar} illustrates example emotions expressed by the humanoid robot {\textbar} 200 {\textbar} according to an exemplary embodiment. {\textbar} The humanoid robot {\textbar} {\textbar} 200 {\textbar} may be programmed to portray the emotions that are commonly held to be the six basic human emotions (happiness, sadness, fear, anger, surprise and disgust) as well as additional emotional states relevant to interactions involving sensory stimulation. As shown in {\textbar} {FIG}. 2 {\textbar} , the humanoid robot {\textbar} 200 {\textbar} may be programmed to portray emotions such as dizzy {\textbar} 320 {\textbar} , happy {\textbar} 340 {\textbar} , scared {\textbar} 360 {\textbar} , and frustrated {\textbar} 380 {\textbar} . Additionally, the humanoid robot {\textbar} 200 {\textbar} may be programmed to portray additional emotions and physical states (not pictured), including unhappy, sniff, sneeze, excited, curious, wanting, celebrating, bored, sleepy, sad, nervous, tired, disgust, crying, and/or angry. {\textbar} The facially expressive robot {\textbar} {\textbar} 300 {\textbar} may include a wheeled platform and a display (e.g., a smartphone display). The facially expressive robot {\textbar} 300 {\textbar} may be programmable such that it mimics the expression of human emotion through motion, sound effects, and/or facial expressions. The facially expressive robot {\textbar} 300 {\textbar} may be a Romo, a controllable, wheeled platform for an {iPhone} that was previously available from Romotive Inc. {\textbar} {FIG}. 3 {\textbar} {\textbar} illustrates example emotions expressed by the facially expressive robot {\textbar} 300 {\textbar} according to an exemplary embodiment. In the example shown in {\textbar} {FIG}. 3 {\textbar} , the facially expressive robot {\textbar} 300 {\textbar} is programmed to display an animation that includes a custom-designed penguin avatar. {\textbar} Similar to the humanoid robot {\textbar} {\textbar} 200 {\textbar} , the facially expressive robot {\textbar} 300 {\textbar} may be programmed to portray the emotions that are commonly held to be the six basic human emotions (happiness, sadness, fear, anger, surprise and disgust) as well as additional emotional states relevant to interactions involving sensory stimulation. As shown in {\textbar} {FIG}. 3 {\textbar} , the facially expressive robot {\textbar} 300 {\textbar} may be programmed to display animations that portray emotions (and physical states) that include neutral, unhappy, sniff, sneeze, happy, excited, curious, wanting, celebrating, bored, sleepy, scared, sad, nervous, frustrated, tired, dizzy, disgust, crying, and/or angry. Each animation for each emotion or physical state may be accompanied by a dedicated background color, complementary changes in the tilt angle of the display, and/or movement of the facially expressive robot {\textbar} 300 {\textbar} (e.g., circular or back-and-forth movement of the treads). {\textbar} In either or both instances, the emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} may be programmed to depict simple but meaningful behaviors, combining all available modalities of emotional expression (e.g., movement, speech and facial expressions). The emotionally expressive robot(s) {\textbar} 160 {\textbar} may be designed to be expressive, clear and straightforward so as to facilitate interpretation in the context of the scenario being presented at the given sensory station {\textbar} 400 {\textbar} (discussed below). A humanoid robot {\textbar} 200 {\textbar} that communicates through gestures and speech is capable of responding to the sensory stimulation in a manner that resembles natural human-human communication. According, the humanoid robot {\textbar} 200 {\textbar} is capable of meaningfully responding to sensory stimulation without acting out explicit emotions. By contrast, a facially expressive robot {\textbar} 300 {\textbar} may use relatively primitive means of communication, like facial expressions, sound effects and movements. Therefore, the facially expressive robot {\textbar} 300 {\textbar} may be programmed to react to sensory stimulation through explicit emotional expressions joined one after another to form meaningful responses. {\textbar} {FIG}. 4 {\textbar} {\textbar} illustrates the sensory stations {\textbar} 400 {\textbar} according to an exemplary embodiment. {\textbar} As shown in {\textbar} {\textbar} {FIG}. 4 {\textbar} , the sensory stations {\textbar} 400 {\textbar} may include a seeing station {\textbar} 420 {\textbar} , a hearing station {\textbar} 430 {\textbar} , a smelling station {\textbar} 440 {\textbar} , a tasting station {\textbar} 450 {\textbar} , a touching station {\textbar} 460 {\textbar} , and a celebration station {\textbar} 480 {\textbar} . The sensory stations {\textbar} 400 {\textbar} are designed to resemble real world scenarios that form a typical part of one's everyday experiences, such as uncontrolled sounds and light in a public space (e.g., a mall or a park) or tactile contact with clothing made of fabrics with different textures. The emotionally expressive robot(s) {\textbar} 160 {\textbar} are programmed to interact with each sensory station {\textbar} 400 {\textbar} and react in a manner that demonstrates socially acceptable responses to each stimulation. The emotionally expressive robot(s) {\textbar} 160 {\textbar} interact with each sensory station {\textbar} 400 {\textbar} in a manner that is interactive and inclusive of the child, such that the emotionally expressive robot {\textbar} 160 {\textbar} and the child engage in a shared sensory experience. {\textbar} The seeing station {\textbar} {\textbar} 420 {\textbar} may designed to provide visual stimulus. For example, the seeing station {\textbar} 420 {\textbar} may include a flashlight inside a lidded box (e.g., constructed from a {LEGO} Mindstorm {EV}3 kit) with an infrared sensor that opens the lid of the box when movement is detected in proximity. The emotionally expressive robot {\textbar} 160 {\textbar} may be programmed to move toward the seeing station {\textbar} 420 {\textbar} at which point the lid of the box is opened and the flashlight directs a bright beam of light in the direction of the approaching emotionally expressive robot {\textbar} 160 {\textbar} . {\textbar} The hearing station {\textbar} {\textbar} 430 {\textbar} may be designed to provide an auditory stimulus. For example, the hearing station {\textbar} 430 {\textbar} may include a Bluetooth speaker play plays music. The smelling station {\textbar} 440 {\textbar} may be designed to provide olfactory stimulus. For example, the smelling station {\textbar} 440 {\textbar} may include scented artificial flowers inside a flowerpot. The tasting station {\textbar} 450 {\textbar} may be designed to provide gustatory stimulus. For example, the tasting station {\textbar} 450 {\textbar} may include two small plastic plates with two different food items. (Those food items may be modified according to likes and dislikes of each every subject child.) The touching station {\textbar} 460 {\textbar} may be designed to provide tactile stimulus. For example, the touching station may include a soft blanket {\textbar} 462 {\textbar} and a bowl of sand {\textbar} 464 {\textbar} (e.g., with golden stars hidden inside it). {\textbar} Each of the emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} may be programmed to travel (e.g., walk and/or drive) to each sensory station {\textbar} 400 {\textbar} and interact with the sensory stimuli presented at each sensory station {\textbar} 400 {\textbar} . While interacting with each sensory stimuli, the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to initiate a conversation with the child and facilitate a joint sensory experience. {\textbar} Diagnosis {\textbar} {\textbar} The video camera {\textbar} {\textbar} 170 {\textbar} records each interaction between each child and the emotionally expressive robot(s) {\textbar} 160 {\textbar} . Images of each child are then analyzed by the computer {\textbar} 120 {\textbar} . {\textbar} {FIG}. 5 {\textbar} {\textbar} illustrates facial keypoints {\textbar} 520 {\textbar} and body tracking keypoints {\textbar} 560 {\textbar} according to an exemplary embodiment. In image analysis, “keypoints” are distinctive points in an input image that are invariant to rotation, scale and distortion. Facial keypoints {\textbar} 520 {\textbar} , sometimes referred to as “facial landmarks,” are specific areas of the face (e.g., nose, eyes, mouth, etc.) identified in images of faces. Similarly, body tracking keypoints {\textbar} 560 {\textbar} are specific points of the bodies identified in images of people. Facial keypoints {\textbar} 520 {\textbar} and body tracking keypoints {\textbar} 560 {\textbar} are identified in images in order to identify the coordinates of the specified body part. Image recognition systems generally use the facial keypoints {\textbar} 520 {\textbar} to perform facial recognition, emotion recognition, etc. Similarly, body tracking keypoints {\textbar} 560 {\textbar} may be used to identify body poses and movements. {\textbar} Body tracking keypoints {\textbar} {\textbar} 560 {\textbar} and facial keypoints {\textbar} 520 {\textbar} are extracted from the video images by the computer {\textbar} 120 {\textbar} , for example using {OpenPose}. As shown in {\textbar} {FIG}. 5 {\textbar} , for example, the computer {\textbar} 120 {\textbar} may analyze a subset {\textbar} 540 {\textbar} of the facial keypoints {\textbar} 520 {\textbar} originating from the nose and eyes. Additionally, because the children may interact with the sensory stations {\textbar} 400 {\textbar} from behind a table, the computer {\textbar} 120 {\textbar} may extract only upper body keypoints {\textbar} 580 {\textbar} originating from the arms, torso, and head of the child. {\textbar} The computer {\textbar} {\textbar} 120 {\textbar} may derive movement features from the body upper body keypoints {\textbar} 580 {\textbar} , for example using Laban movement analysis, to determine the intent behind human movement. In machine learning, pattern recognition, and image processing, “feature extraction” starts from an initial set of measured data and builds derived values (“features”) intended to be informative and non-redundant, facilitating the subsequent learning and generalization steps. As described below, those movement features derived by the computer {\textbar} 120 {\textbar} may include weight, space, and time. Those movement features may be derived using a moving time window (e.g., a 1 second window) to capture the temporal nature of the data. The three derived movement features may be combined with facial keypoints (e.g., 68 facial keypoints originating from the nose and eyes) to form a dataset. Accordingly, the dataset may include a total of 71 features. {\textbar} As mentioned above, the computer may derive movement features from the upper body keypoints {\textbar} {\textbar} 580 {\textbar} . Those movement features may include weight, space, and time. {\textbar} Weight can be described as the intensity of perceived force in movement. High and constant intensity is considered high weight (strong) and the opposite is considered low weight (light). Strong weight characterizes bold, forceful, powerful, and/or determined intention. Light weight characterizes delicate, sensitive buoyant, and easy intention. Weight may be derived by the computer {\textbar} {\textbar} 120 {\textbar} as follows: {\textbar} Weight {\textbar} {\textbar} = {\textbar} ∑ {\textbar} i {\textbar} ⁢ {\textbar} τ {\textbar} i {\textbar} ⁢ {\textbar} ω {\textbar} i {\textbar} ⁡ {\textbar} ( {\textbar} t {\textbar} ) {\textbar} where: {\textbar} {\textbar} τ {\textbar} {\textbar} i {\textbar} = {\textbar} F {\textbar} * {\textbar} L {\textbar} = {\textbar} L {\textbar} 2 {\textbar} ⁢ {\textbar} ω {\textbar} i {\textbar} 2 {\textbar} ⁢ {\textbar} sin {\textbar} ⁡ {\textbar} ( {\textbar} θ {\textbar} ) {\textbar} * {\textbar} mas {\textbar} ⁢ {\textbar} s {\textbar} ω {\textbar} i {\textbar} = {\textbar} d {\textbar} ⁢ {\textbar} θ {\textbar} d {\textbar} ⁢ {\textbar} t {\textbar} i {\textbar} = {\textbar} Joint {\textbar} ⁢ {\textbar} ⁢ {\textbar} Number {\textbar} Space is a measure of the distance of the legs and arms to the body. Space is considered low (direct) when legs and arms are constantly close to the body center and is considered high (indirect) if a person is constantly using outstretched movements. Direct space is characterized by linear actions, focused and specific actions, and/or attention to a singular spatial possibility. Indirect space characterizes flexibility of the joints, three-dimensionality of space, and/or all-around awareness. Because the disclosed system may be limited to analyzing upper body keypoints {\textbar} {\textbar} 580 {\textbar} , space may be indicative of the distance of the arms of the child relative to the body of the child. Space may be derived by the computer {\textbar} 120 {\textbar} as follows: {\textbar} Space=(0.5{\textbar} {\textbar} {\textbar} {\textbar}{\textbar} {\textbar} {\textbar}sin(θ {\textbar} 1 {\textbar} ))+(0.5{\textbar} {\textbar} {\textbar}{\textbar} {\textbar} {\textbar}sin(θ {\textbar} 2 {\textbar} )) {\textbar} where {\textbar} {\textbar} =Left Shoulder to Left Hand {\textbar} =Right Shoulder to Left Shoulder {\textbar} =Right Hand to Right Shoulder {\textbar} =Left Hand to Right Hand {\textbar} θ {\textbar} 1 {\textbar} =Angle between \{right arrow over (a)\} \& \{right arrow over (d)\} {\textbar} θ {\textbar} 2 {\textbar} =Angle between \{right arrow over (c)\} \& \{right arrow over (b)\} {\textbar} Time is a measure of the distinct change from one prevailing tempo to some other tempo. Space is considered high when movements are sudden and low when movements are sustained. Sudden movements are characterized as unexpected, isolated, surprising, and/or urgent. Sustained movements are characterized as continuous, lingering, indulging in time, and/or leisurely. Time may be calculated by the computer {\textbar} {\textbar} 120 {\textbar} as follows: {\textbar} T {\textbar} {\textbar} ⁢ {\textbar} i {\textbar} ⁢ {\textbar} m {\textbar} ⁢ {\textbar} e {\textbar} i {\textbar} = {\textbar} ∑ {\textbar} i {\textbar} ⁢ {\textbar} ω {\textbar} . {\textbar} i {\textbar} ⁡ {\textbar} ( {\textbar} t {\textbar} ) {\textbar} where: {\textbar} {\textbar} \{dot over (ω)\} {\textbar} {\textbar} i {\textbar} =Angular Velocity for Joint {\textbar} i {\textbar} As described above, preferred embodiments utilize a video camera {\textbar} {\textbar} 170 {\textbar} to capture video images of children and a computer {\textbar} 120 {\textbar} to extract facial keypoints {\textbar} 520 {\textbar} and body tracking keypoints {\textbar} 560 {\textbar} and derive movement features of those children. However, the disclosed system is not limited to a video camera {\textbar} 170 {\textbar} and may instead utilize any sensor (e.g., {RADAR}, {SONAR}, {LIDAR}, etc.) suitably configured to capture data indicative of the facial keypoints {\textbar} 520 {\textbar} and body tracking keypoints {\textbar} 560 {\textbar} of the child over time. {\textbar} Referring back to {\textbar} {\textbar} {FIG}. 1 {\textbar} , the subset {\textbar} 540 {\textbar} of the facial keypoints {\textbar} 520 {\textbar} and the movement features (e.g., weight, space, and time) are stored in the database {\textbar} 130 {\textbar} . Meanwhile, the computer {\textbar} 120 {\textbar} includes a convolutional neural network {\textbar} 600 {\textbar} designed to process that data and identify children at risk for autism spectrum disorder. {\textbar} {FIG}. 6 {\textbar} {\textbar} is a diagram illustrating the convolutional neural network {\textbar} 600 {\textbar} according to an exemplary embodiment. {\textbar} As shown in {\textbar} {\textbar} {FIG}. 6 {\textbar} , convolutional neural network {\textbar} 600 {\textbar} may include two Conv1D layers (1-dimensional convolution layers) {\textbar} 620 {\textbar} to identify temporal data patterns, three dense layers {\textbar} 660 {\textbar} for classification, and multiple dropout layers {\textbar} 650 {\textbar} to avoid overfitting. {\textbar} The Conv1D layers {\textbar} {\textbar} 620 {\textbar} may include a first Conv1D layer {\textbar} 622 {\textbar} and a second Conv1D layer {\textbar} 624 {\textbar} . The first Conv1D layer {\textbar} 622 {\textbar} may include five channels with 64 filters and the second Conv1D layer {\textbar} 624 {\textbar} may include 128 filters. Each of the Conv1D layers {\textbar} 620 {\textbar} may have a kernel size of 3. The convolutional neural network {\textbar} 600 {\textbar} may include two Conv1D layers {\textbar} 620 {\textbar} to extract high-level features from the temporal data because the dataset being used has a high input dimension and a relatively small number of datapoints. {\textbar} Each dropout layer {\textbar} {\textbar} 650 {\textbar} may have a dropout rate of 20 percent. {\textbar} The dense layers {\textbar} {\textbar} 660 {\textbar} may include a first dense layer {\textbar} 662 {\textbar} , a second dense layer {\textbar} 664 {\textbar} , and a third dense layer {\textbar} 668 {\textbar} . Since the data have a non-linear structure, the first dense layer {\textbar} 662 {\textbar} and the second dense layer {\textbar} 664 {\textbar} may be used to spread the feature dimension while the third dense layer {\textbar} 668 {\textbar} generates an output dimension {\textbar} 690 {\textbar} . {\textbar} The convolutional neural network {\textbar} {\textbar} 600 {\textbar} models the risk of autism spectrum disorder as a binary classification problem. The convolutional neural network {\textbar} 600 {\textbar} is trained using a corpus of data captured by the disclosed system analyzing children that have been diagnosed with autism spectrum disorder and children having been diagnosed as not at risk for autism spectrum disorder (e.g., typically developing). The convolutional neural network {\textbar} 600 {\textbar} can then be supplied with input data {\textbar} 610 {\textbar} , for example the facial keypoints {\textbar} 520 {\textbar} and the movement features (e.g., weight, space, and time) described above. Having been trained on a dataset characterizing children of known risk, the convolutional neural network {\textbar} 600 {\textbar} is then configured to generate an output dimension {\textbar} 690 {\textbar} indicative of the subject's risk for autism spectrum disorder. {\textbar} The disclosed system has been shown to accurately identify children at risk for autism spectrum disorder. In an initial study, the convolutional neural network {\textbar} {\textbar} 600 {\textbar} was trained on 80 percent of the interaction data and the remaining 20 percent were used to validate its performance. The convolutional neural network {\textbar} 600 {\textbar} achieved high accuracy (0.8846), precision (0.8912), and recall (0.8853). {\textbar} Unlike previous methods, the disclosed system identifies children at risk for autism spectrum disorder based only on behavioral data captured through video recordings of a naturalistic interaction with social robots. The movement of the child was not restricted and no obtrusive sensors were used. Accordingly, the disclosed system and method can easily be generalized to other interactions (e.g., play time at home) increasing the utility of the disclosed method. The possibility of using the disclosed system in additional settings also raises the possibility that larger datasets may be obtained, thereby increasing the accuracy of the disclosed method. {\textbar} {\textbar} Treatment {\textbar} {\textbar} As described above, the sensory stations {\textbar} {\textbar} 400 {\textbar} closely resemble situations that children would encounter frequently in their everyday lives. Therefore, they are relatable and easy to interpret. Given the strong interest in technology from children with autism spectrum disorder, the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be used to elicit a higher level of socio-emotional engagement from these children. For example, the emotionally expressive robot(s) {\textbar} 160 {\textbar} navigating the sensory stations {\textbar} 400 {\textbar} may be used to demonstrate socially acceptable responses to stimulation and encourage children to become more receptive to a variety of sensory experiences and to effectively communicate their feelings if the experiences cause them discomfort. {\textbar} The emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} may be programmed to show both positive and negative responses at some of the sensory stations {\textbar} 400 {\textbar} with the aim of demonstrating to the children how to communicate their feelings even when experiencing discomforting or unfavorable sensory stimulation (instead of allowing the negative experience to escalate into a tantrum or meltdown). The negative reactions may be designed not to be too extreme so as to focus on the communication of one's feelings rather than encouraging intolerance of the stimulation. {\textbar} At the seeing station {\textbar} {\textbar} 420 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to demonstrate effectively handle uncomfortable visual stimuli and to communicate discomfort instead of allowing it to manifest as extreme negative reactions (tantrums/meltdowns). This can be especially useful in controlled environments like movie theaters and malls where light intensity cannot be fully regulated. {\textbar} The hearing station {\textbar} {\textbar} 430 {\textbar} may improve tolerance for sounds louder than those to which one is accustomed, to learn to not be overwhelmed by music, and to promote gross motor movements by encouraging dancing along to it. This can be especially useful in uncontrolled environments like movie theaters and malls where sounds cannot be fully regulated. {\textbar} At the smelling station {\textbar} {\textbar} 440 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to not react with extreme aversion to odors that may be disliked and to communicate the dislike instead. This can be useful for parents of children with autism spectrum disorder who are very particular about the smell of their food, clothes, and/or environments etc. {\textbar} At the tasting station {\textbar} {\textbar} 450 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to demonstrate diversifying one's food preferences instead of adhering strictly to the same ones. {\textbar} At the touching station {\textbar} {\textbar} 460 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to demonstrate acclimating oneself to different textures by engaging in tactile interactions with different materials. This is especially useful for those children with autism spectrum disorder who may be sensitive to the texture of their clothing fabrics and/or those who experience significant discomfort with wearables (e.g., hats, wrist watches, etc.). {\textbar} At the celebration station {\textbar} {\textbar} 480 {\textbar} , the emotionally expressive robot(s) {\textbar} 160 {\textbar} may be programmed to convey a sense of shared achievement while also encouraging the children to practice their motor and vestibular skills by imitating the celebration routines of the robots. {\textbar} The emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} may be particularly effective after the children have already interacted with the emotionally expressive robot(s) {\textbar} 160 {\textbar} over several sessions. Once an emotionally expressive robot {\textbar} 160 {\textbar} has formed a rapport with the child by liking and disliking the same foods as the child, for example, it could start to deviate from those responses and encourage the child to be more receptive to the foods their robot “friends” prefer. To achieve this goal, for example, different food items may be introduced in the tasting station {\textbar} 450 {\textbar} in the future sessions. {\textbar} While the disclosed system may include any emotionally expressive robot {\textbar} {\textbar} 160 {\textbar} , the humanoid robot {\textbar} 200 {\textbar} and the facially expressive robot {\textbar} 300 {\textbar} are examples of preferred emotionally expressive robots {\textbar} 160 {\textbar} for a number of reasons. The emotionally expressive robot(s) {\textbar} 160 {\textbar} are preferably not be too large in size in order to prevent children from being intimidated by them. The emotionally expressive robot(s) {\textbar} 160 {\textbar} are preferably capable of expressing emotions through different modalities such as facial expressions, gestures and speech. The emotionally expressive robot(s) {\textbar} 160 {\textbar} are preferably friendly in order to form a rapport with the children. {\textbar} The sensory stations {\textbar} {\textbar} 400 {\textbar} are preferably designed to be relatable to the children such that they are able to draw the connection between the stimulation presented to the emotionally expressive robot(s) {\textbar} 160 {\textbar} and that experienced by them in their everyday lives. The activity being conducted is preferably able to maintain a child's interest through the entire length of the interaction. Accordingly, the content (and duration) of the activity is preferably appealing to the children. {\textbar} The actions performed by the emotionally expressive robot(s) {\textbar} {\textbar} 160 {\textbar} is preferably simple and easy to understand for children in the target age range. The gestures, speech, facial expressions and/or body language emotionally expressive robot(s) {\textbar} 160 {\textbar} is preferably combined to form meaningful and easily interpretable behaviors. The emotion library of the emotionally expressive robot(s) {\textbar} 160 {\textbar} is preferably large enough to effectively convey different reactions to the stimulation but also simple enough to be easily understood by the children. {\textbar} In order to derive a meaningful quantitative measure of engagement, we utilized several key behavioral traits of social interactions, including gaze focus, vocalizations and verbalizations, smile, triadic interactions, self-initiated interactions and imitation: {\textbar} {\textbar} Behavior {\textbar} {\textbar} Description {\textbar} Eye gaze focus {\textbar} {\textbar} Deficits in social attention and establishing eye {\textbar} contact are two of the most commonly reported {\textbar} {\textbar} deficits in children with autism spectrum disorder. {\textbar} {\textbar} We therefore used the children's gaze focus on the {\textbar} {\textbar} robots and/or the setup to mark the presence of this {\textbar} {\textbar} behavior. {\textbar} {\textbar} Vocalizations/ {\textbar} {\textbar} The volubility of utterances produced by children {\textbar} verbalizations {\textbar} {\textbar} with autism spectrum disorder is low compared to {\textbar} their typically developing counterparts. Since {\textbar} {\textbar} communication is a core aspect of social {\textbar} {\textbar} responsiveness, the frequency and duration of the {\textbar} {\textbar} vocalizations and verbalizations produced by the {\textbar} {\textbar} children during the interaction is also important in {\textbar} {\textbar} computing the engagement index. {\textbar} {\textbar} Smile {\textbar} {\textbar} Smiling has also been established as an aspect of {\textbar} social responsiveness. We recorded the frequency {\textbar} {\textbar} and duration of smiles displayed by the children {\textbar} {\textbar} while interacting with the robots, as a contributing {\textbar} {\textbar} factor to the engagement index. {\textbar} {\textbar} Triadic {\textbar} {\textbar} A triadic relationship involves three agents, including {\textbar} interactions {\textbar} {\textbar} the child, the robot and a third person that may be the {\textbar} parent or the instructor. In this study, the robot acts as {\textbar} {\textbar} tool to elicit interactions between the child and other {\textbar} {\textbar} humans. An example of such interactions is the {\textbar} {\textbar} child sharing her excitement about the dancing robot {\textbar} {\textbar} by directing the parent's attention to it. {\textbar} {\textbar} Self-initiated {\textbar} {\textbar} Children with autism spectrum disorder prefer to {\textbar} interactions {\textbar} {\textbar} play alone and make fewer social initiations compared {\textbar} to their peers. Therefore, we recorded the frequency {\textbar} {\textbar} and duration of the interactions with the robot initiated {\textbar} {\textbar} by the children as factors contributing to the {\textbar} {\textbar} engagement index. Examples of self-initiated {\textbar} {\textbar} interactions can include talking to the robots, {\textbar} {\textbar} attempting to feed the robots, guiding the robots to {\textbar} {\textbar} the next station etc. without any prompts from the {\textbar} {\textbar} instructors. {\textbar} {\textbar} Imitation {\textbar} {\textbar} Infants have been found to produce and recognize {\textbar} imitation from the early stages of development, and {\textbar} {\textbar} both these skills have been linked to the development {\textbar} {\textbar} of socio-communicative abilities. In this study, we {\textbar} {\textbar} monitored a child's unprompted imitation of the {\textbar} {\textbar} robot behaviors as a measure of their engagement {\textbar} {\textbar} in the interaction. {\textbar} {\textbar} The aforementioned behaviors were selected because they have proven to be useful measures of social attention and social responsiveness from previous studies. {\textbar} {\textbar} {FIG}. 7 {\textbar} {\textbar} illustrates a graph {\textbar} 700 {\textbar} depicting the engagement of one participant using the disclosed system according to an exemplary embodiment. {\textbar} As shown in {\textbar} {\textbar} {FIG}. 7 {\textbar} , the graph includes an engagement index {\textbar} 740 {\textbar} and a general engagement trend {\textbar} 760 {\textbar} . Video data was coded for the target behaviors above (smile, eye gaze focus, vocalizations/verbalizations, triadic interaction, self-initiated interaction, and imitation) and the engagement index {\textbar} 740 {\textbar} was derived as the indicator of every child's varying social engagement throughout the interaction with the emotionally expressive robots {\textbar} 160 {\textbar} . The engagement index {\textbar} 740 {\textbar} was computed as a sum of these factors, each with the same weight, such that the maximum value of the engagement index {\textbar} 740 {\textbar} was 1. {\textbar} Each behavior contributed a factor of ⅙ to the engagement index {\textbar} {\textbar} 740 {\textbar} . For example, for a participant observed to have a smile and gaze focus while interacting with the humanoid robot {\textbar} 200 {\textbar} during the tasting station {\textbar} 450 {\textbar} but only gaze focus following the end of the station, the engagement index {\textbar} 740 {\textbar} was assigned a constant value of ⅙+⅙=⅓ for the entire duration of the station, and reduced to ⅙ immediately after its end. Any changes in engagement within an interval of 1 second were detected and reflected in the engagement index {\textbar} 740 {\textbar} . {\textbar} Time periods when each emotionally expressive robot {\textbar} {\textbar} 160 {\textbar} interacts with each sensory station {\textbar} 400 {\textbar} , including time period {\textbar} 732 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the seeing station {\textbar} 420 {\textbar} ; time period {\textbar} 733 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the hearing station {\textbar} 430 {\textbar} ; including time period {\textbar} 734 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the smelling station {\textbar} 440 {\textbar} ; including time period {\textbar} 735 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the tasting station {\textbar} 450 {\textbar} ; including time period {\textbar} 736 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the touching station {\textbar} 460 {\textbar} ; including time period {\textbar} 738 {\textbar} , when the facially expressive robot {\textbar} 300 {\textbar} interacted with the celebration station {\textbar} 480 {\textbar} ; time period {\textbar} 722 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the seeing station {\textbar} 420 {\textbar} ; time period {\textbar} 723 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the hearing station {\textbar} 430 {\textbar} ; including time period {\textbar} 724 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the smelling station {\textbar} 440 {\textbar} ; including time period {\textbar} 725 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the tasting station {\textbar} 450 {\textbar} ; including time period {\textbar} 726 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the touching station {\textbar} 460 {\textbar} ; and including time period {\textbar} 728 {\textbar} , when the humanoid robot {\textbar} 200 {\textbar} interacted with the celebration station {\textbar} 480 {\textbar} . {\textbar} Analyzing the engagement index {\textbar} {\textbar} 740 {\textbar} when each emotionally expressive robot {\textbar} 160 {\textbar} interacts with each sensory station {\textbar} 400 {\textbar} allows for a comparison of the effectiveness of each sensory station {\textbar} 400 {\textbar} in eliciting social engagement from the participants. {\textbar} {FIG}. 8 {\textbar} {\textbar} illustrates graphs {\textbar} 800 {\textbar} of each target behavior (smile, eye gaze focus, vocalizations/verbalizations, triadic interaction, self-initiated interaction, and imitation) during an interaction with each emotionally expressive robot {\textbar} 160 {\textbar} according to an exemplary embodiment. Labels for each time period {\textbar} 732 {\textbar} , {\textbar} 733 {\textbar} , etc. are omitted for clarity, but they are legibility but are the same as shown in {\textbar} {FIG}. 7 {\textbar} . By identifying the target behaviors elicited by each emotionally expressive robot {\textbar} 160 {\textbar} at each sensory station {\textbar} 400 {\textbar} , the frequency each target behavior and the sensory stations {\textbar} 400 {\textbar} emotionally expressive robot {\textbar} 160 {\textbar} responsible for eliciting them can be compared. {\textbar} Finally, the engagement generated by each emotionally expressive robot {\textbar} {\textbar} 160 {\textbar} may also be assessed individually and compared to study the social engagement potential of each emotionally expressive robots {\textbar} 160 {\textbar} in this sensory setting. {\textbar} Using the method to derive the engagement index {\textbar} {\textbar} 740 {\textbar} described above, several other metrics were also generated to evaluate various aspects of the disclosed system. First, the session comprising interactions with both emotionally expressive robots {\textbar} 160 {\textbar} was analyzed as a whole, resulting in consolidated engagement metrics. In addition, engagement resulting from each target behavior was also computed to study the contribution of each target behavior toward the engagement index. As an example, an engagement metric resulting from the vocalizations of participant X was computed as: {\textbar} eng {\textbar} {\textbar} voc {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} vocalization {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} throughout {\textbar} ⁢ {\textbar} ⁢ {\textbar} the {\textbar} ⁢ {\textbar} ⁢ {\textbar} session {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} from {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} target {\textbar} ⁢ {\textbar} ⁢ {\textbar} behaviors {\textbar} ⁢ {\textbar} ⁢ {\textbar} throughout {\textbar} ⁢ {\textbar} ⁢ {\textbar} the {\textbar} ⁢ {\textbar} ⁢ {\textbar} session {\textbar} By isolating the engagement resulting from each emotionally expressive robot {\textbar} {\textbar} 160 {\textbar} , the metrics generated by the humanoid robot {\textbar} 200 {\textbar} and the facially expressive robot {\textbar} 300 {\textbar} may be compared to evaluate the impact of each emotionally expressive robot {\textbar} 160 {\textbar} . Once again, an overall engagement index was obtained for each emotionally expressive robot {\textbar} 160 {\textbar} as an indicator of its performance throughout its interaction in addition to a breakdown in terms of the target behaviors that comprise the engagement. The engagement metric for the interaction of participant X with the facially expressive robot {\textbar} 300 {\textbar} (“Romo”) was calculated as: {\textbar} eng {\textbar} {\textbar} Romo {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} throughout {\textbar} ⁢ {\textbar} ⁢ {\textbar} interaction {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Romo {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} throughout {\textbar} session {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} both {\textbar} ⁢ {\textbar} ⁢ {\textbar} robots {\textbar} Similarly, the engagement metric resulting from the vocalizations of participant X while interacting with the facially expressive robot {\textbar} {\textbar} 300 {\textbar} (“Romo”) was calculated as: {\textbar} eng {\textbar} {\textbar} Romo {\textbar} , {\textbar} voc {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} vocalization {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} throughout {\textbar} ⁢ {\textbar} ⁢ {\textbar} interaction {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Romo {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} throughout {\textbar} session {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} both {\textbar} ⁢ {\textbar} ⁢ {\textbar} robots {\textbar} An analysis was then performed to study the differences in engagement at each sensory station {\textbar} {\textbar} 400 {\textbar} . This was analyzed separately for each emotionally expressive robot {\textbar} 160 {\textbar} so as to derive an understanding of the engagement potential of each station per robot. The engagement metric resulting from the hearing station {\textbar} 430 {\textbar} while participant X interacted with the humanoid robot {\textbar} 200 {\textbar} (“Mini”) was calculated as: {\textbar} eng {\textbar} {\textbar} Mini {\textbar} , {\textbar} hear {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} at {\textbar} ⁢ {\textbar} ⁢ {\textbar} hearing {\textbar} station {\textbar} ⁢ {\textbar} ⁢ {\textbar} during {\textbar} ⁢ {\textbar} ⁢ {\textbar} interaction {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Mini {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} throughout {\textbar} session {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Mini {\textbar} In addition, a breakdown of engagement at each sensory station {\textbar} {\textbar} 400 {\textbar} was obtained in terms of the elicited target behaviors and analyzed separately for each emotionally expressive robot {\textbar} 160 {\textbar} . This allowed for a finer-grain assessment of the capability of each sensory station {\textbar} 400 {\textbar} for eliciting the individual target behaviors. For example, the engagement metric resulting from the gaze of participant X at the smelling station {\textbar} 440 {\textbar} while interacting with the humanoid robot {\textbar} 200 {\textbar} (“Mini”) was calculated as: {\textbar} eng {\textbar} {\textbar} Mini {\textbar} , {\textbar} smell {\textbar} , {\textbar} gaze {\textbar} , {\textbar} X {\textbar} = {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} all {\textbar} ⁢ {\textbar} ⁢ {\textbar} gaze {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} at {\textbar} ⁢ {\textbar} ⁢ {\textbar} the {\textbar} ⁢ {\textbar} ⁢ {\textbar} smelling {\textbar} ⁢ {\textbar} station {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Mini {\textbar} sum {\textbar} ⁢ {\textbar} ⁢ {\textbar} of {\textbar} ⁢ {\textbar} ⁢ {\textbar} engagement {\textbar} ⁢ {\textbar} ⁢ {\textbar} factors {\textbar} ⁢ {\textbar} ⁢ {\textbar} at {\textbar} smelling {\textbar} ⁢ {\textbar} ⁢ {\textbar} station {\textbar} ⁢ {\textbar} ⁢ {\textbar} with {\textbar} ⁢ {\textbar} ⁢ {\textbar} Mini {\textbar} The aforementioned metrics enabled each sensory station {\textbar} {\textbar} 400 {\textbar} and each emotionally expressive robot {\textbar} 160 {\textbar} to be evaluated to achieve a comprehensive understanding of the potential of the disclosed system and identify areas requiring further improvement. {\textbar} The drawings may illustrate—and the description and claims may use—several geometric or relational terms and directional or positioning terms, such as upper. Those terms are merely for convenience to facilitate the description based on the embodiments shown in the figures and are not intended to limit the invention. Thus, it should be recognized that the invention can be described in other ways without those geometric, relational, directional or positioning terms. And, other suitable geometries and relationships can be provided without departing from the spirit and scope of the invention. {\textbar} {\textbar} The foregoing description and drawings should be considered as illustrative only of the principles of the disclosure, which may be configured in a variety of shapes and sizes and is not intended to be limited by the embodiment herein described. Numerous applications of the disclosure will readily occur to those skilled in the art. Therefore, it is not desired to limit the disclosure to the specific examples disclosed or the exact construction and operation shown and described. Rather, all suitable modifications and equivalents may be resorted to, falling within the scope of the disclosure.
Issue: {US}20210236032A1},
}

@patent{woburn19,
	location = {{US}},
	title = {Device and method for instilling intrinsic motivation regarding eye contact in children affected by eye contact disorders},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {This describes a treatment method for autism/{ASD} intended to encourage greater eye contact by affected children. The treatment method incorporates an artificial demonstration of the phenomenon of eye contact, and that method is described herein along with the principles of action of the treatment and the necessary procedure to perform it. Also described are two embodiments of the physical portion of the invention that can be used for the demonstration: first, an item in the form of a cuboid with animatronic eyes affixed to one side that most purely reflects the principles behind the treatment, and second, another in the form of a stuffed toy that is perhaps more practical.
This describes a treatment method for autism/{ASD} intended to encourage greater eye contact by affected children. The treatment method incorporates an artificial demonstration of the phenomenon of eye contact, and that method is described herein along with the principles of action of the treatment and the necessary procedure to perform it. Also described are two embodiments of the physical portion of the invention that can be used for the demonstration: first, an item in the form of a cuboid with animatronic eyes affixed to one side that most purely reflects the principles behind the treatment, and second, another in the form of a stuffed toy that is perhaps more practical.
This describes a treatment method for autism/{ASD} intended to encourage greater eye contact by affected children. The treatment method incorporates an artificial demonstration of the phenomenon of eye contact, and that method is described herein along with the principles of action of the treatment and the necessary procedure to perform it. Also described are two embodiments of the physical portion of the invention that can be used for the demonstration: first, an item in the form of a cuboid with animatronic eyes affixed to one side that most purely reflects the principles behind the treatment, and second, another in the form of a stuffed toy that is perhaps more practical.},
	type = {patent},
	author = {Woburn, Casey Matthew},
	urldate = {2016-06-16},
	date = {2019-07-30},
	note = {Edition: A61H000500 {\textbar} A61B0003113 {\textbar} G06F000301 {CPC} - A61H000500 {\textbar} A61B0003113 {\textbar} A63H0003003 {\textbar} A63H000340 {\textbar} A63H0013005 {\textbar} G06F0003013 {\textbar} A61H22011207 {\textbar} A61H22011673 {\textbar} A61H22015007 {\textbar} A61H22015092 {EP}; {US} {US} What is claimed: {\textbar} {\textbar} 1. A therapy method for encouraging a patient diagnosed with autism, an autism spectrum disorder, and/or a neurodevelopment disorder to make eye contact with other individuals, said therapy method comprising: {\textbar} treating the patient by placing a robot in a field of view of the patient such that the robot can interact with the patient thereby creating intrinsic motivation in the patient to make eye contact with the other individuals after a therapy session has ended, the robot comprising: {\textbar} {\textbar} prominently featured animatronic eyes on a front side thereof; {\textbar} {\textbar} a video camera; {\textbar} {\textbar} a processor configured to: {\textbar} {\textbar} process data from the video camera to determine a gaze direction of the patient during the therapy session; and {\textbar} {\textbar} select a gaze direction for the animatronic eyes based on the determined gaze direction of the patient; and {\textbar} {\textbar} an actuator that allows the interaction with the patient by controlling the animatronic eyes based on the selected gaze direction for the animatronic eyes; and {\textbar} {\textbar} refraining from providing the patient with a positive reinforcement for gazing at the animatronic eyes during the therapy session; {\textbar} {\textbar} wherein movement of the animatronic eyes constitutes the only electronically actuated movement of the robot. {\textbar} {\textbar} 2. The therapy method of {\textbar} claim 1 {\textbar} , wherein the robot is in the form of a rectangular box or of a toy dog. {\textbar} 3. The therapy method of {\textbar} claim 1 {\textbar} , wherein the gaze direction for the animatronic eyes is selected based on a score of possible gaze directions relating to an assertiveness of each of the possible gaze directions. {\textbar} 4. The therapy method of {\textbar} claim 1 {\textbar} , wherein the gaze direction for the animatronic eyes is selected based on a ranking of possible gaze directions relating to an assertiveness of each of the possible gaze directions. {\textbar} 5. The therapy method of {\textbar} claim 1 {\textbar} , wherein the gaze direction for the animatronic eyes is selected using a process comprising: {\textbar} scoring possible gaze directions based on assertiveness; {\textbar} {\textbar} excluding some of said possible gaze directions from consideration based on the scoring; and {\textbar} {\textbar} choosing randomly amongst the remaining possible gaze directions. {\textbar} {\textbar} 6. The therapy method of {\textbar} claim 1 {\textbar} , wherein the gaze direction for the animatronic eyes is selected using a process comprising: {\textbar} scoring possible gaze directions based on assertiveness; {\textbar} {\textbar} ranking possible gaze directions based on the scoring; {\textbar} {\textbar} excluding some of said possible gaze directions from consideration based on the ranking; and {\textbar} {\textbar} choosing randomly amongst the remaining possible gaze directions. {\textbar} {\textbar} 7. The therapy method of {\textbar} claim 1 {\textbar} , wherein the robot serves to evoke a concept of eye contact. {\textbar} 8. The therapy method of {\textbar} claim 1 {\textbar} , wherein the video camera is operative to capture images using infrared radiation or using radiation with wavelengths shorter than radiation that is typically visible to humans. {\textbar} 9. The therapy method of {\textbar} claim 1 {\textbar} , wherein said processor is configured to process data from the video camera to determine whether or not the patient is looking at the video camera and/or looking at the animatronic eyes and/or looking at the robot. {\textbar} 10. The therapy method of {\textbar} claim 1 {\textbar} , further comprising refraining from providing the patient with a positive reinforcement for making eye contact with people during the therapy session. {\textbar} 11. The therapy method of {\textbar} claim 1 {\textbar} , further comprising refraining from providing the patient with a positive reinforcement for making eye contact with said other individuals after the therapy session has ended. What is claimed: {\textbar} {\textbar} 1. A therapy method for encouraging a patient diagnosed with autism, an autism spectrum disorder, and/or a neurodevelopment disorder to make eye contact with other individuals, said therapy method comprising: {\textbar} treating the patient by placing a robot in a field of view of the patient such that the robot can interact with the patient thereby creating intrinsic motivation in the patient to make eye contact with the other individuals after a therapy session has ended, the robot comprising: {\textbar} {\textbar} prominently featured animatronic eyes on a front side thereof; {\textbar} {\textbar} a video camera; {\textbar} {\textbar} a processor configured to: {\textbar} {\textbar} process data from the video camera to determine a gaze direction of the patient during the therapy session; and {\textbar} {\textbar} select a gaze direction for the animatronic eyes based on the determined gaze direction of the patient; and {\textbar} {\textbar} an actuator that allows the interaction with the patient by controlling the animatronic eyes based on the selected gaze direction for the animatronic eyes; and {\textbar} {\textbar} refraining from providing the patient with a positive reinforcement for gazing at the animatronic eyes during the therapy session; {\textbar} {\textbar} wherein movement of the animatronic eyes constitutes the only electronically actuated movement of the robot. {\textbar} {\textbar} 2. The therapy method of {\textbar} claim 1 {\textbar} , wherein the robot is in the form of a rectangular box or of a toy dog. {\textbar} 3. The therapy method of {\textbar} claim 1 {\textbar} , wherein the gaze direction for the animatronic eyes is selected based on a score of possible gaze directions relating to an assertiveness of each of the possible gaze directions. {\textbar} 4. The therapy method of {\textbar} claim 1 {\textbar} , wherein the gaze direction for the animatronic eyes is selected based on a ranking of possible gaze directions relating to an assertiveness of each of the possible gaze directions. {\textbar} 5. The therapy method of {\textbar} claim 1 {\textbar} , wherein the gaze direction for the animatronic eyes is selected using a process comprising: {\textbar} scoring possible gaze directions based on assertiveness; {\textbar} {\textbar} excluding some of said possible gaze directions from consideration based on the scoring; and {\textbar} {\textbar} choosing randomly amongst the remaining possible gaze directions. {\textbar} {\textbar} 6. The therapy method of {\textbar} claim 1 {\textbar} , wherein the gaze direction for the animatronic eyes is selected using a process comprising: {\textbar} scoring possible gaze directions based on assertiveness; {\textbar} {\textbar} ranking possible gaze directions based on the scoring; {\textbar} {\textbar} excluding some of said possible gaze directions from consideration based on the ranking; and {\textbar} {\textbar} choosing randomly amongst the remaining possible gaze directions. {\textbar} {\textbar} 7. The therapy method of {\textbar} claim 1 {\textbar} , wherein the robot serves to evoke a concept of eye contact. {\textbar} 8. The therapy method of {\textbar} claim 1 {\textbar} , wherein the video camera is operative to capture images using infrared radiation or using radiation with wavelengths shorter than radiation that is typically visible to humans. {\textbar} 9. The therapy method of {\textbar} claim 1 {\textbar} , wherein said processor is configured to process data from the video camera to determine whether or not the patient is looking at the video camera and/or looking at the animatronic eyes and/or looking at the robot. {\textbar} 10. The therapy method of {\textbar} claim 1 {\textbar} , further comprising refraining from providing the patient with a positive reinforcement for making eye contact with people during the therapy session. {\textbar} 11. The therapy method of {\textbar} claim 1 {\textbar} , further comprising refraining from providing the patient with a positive reinforcement for making eye contact with said other individuals after the therapy session has ended. 1. A therapy method for encouraging a patient diagnosed with autism, an autism spectrum disorder, and/or a neurodevelopment disorder to make eye contact with other individuals, said therapy method comprising: {\textbar} treating the patient by placing a robot in a field of view of the patient such that the robot can interact with the patient thereby creating intrinsic motivation in the patient to make eye contact with the other individuals after a therapy session has ended, the robot comprising: {\textbar} {\textbar} prominently featured animatronic eyes on a front side thereof; {\textbar} {\textbar} a video camera; {\textbar} {\textbar} a processor configured to: {\textbar} {\textbar} process data from the video camera to determine a gaze direction of the patient during the therapy session; and {\textbar} {\textbar} select a gaze direction for the animatronic eyes based on the determined gaze direction of the patient; and {\textbar} {\textbar} an actuator that allows the interaction with the patient by controlling the animatronic eyes based on the selected gaze direction for the animatronic eyes; and {\textbar} {\textbar} refraining from providing the patient with a positive reinforcement for gazing at the animatronic eyes during the therapy session; {\textbar} {\textbar} wherein movement of the animatronic eyes constitutes the only electronically actuated movement of the robot. 1. A therapy method for encouraging a patient diagnosed with autism, an autism spectrum disorder, and/or a neurodevelopment disorder to make eye contact with other individuals, said therapy method comprising: {\textbar} treating the patient by placing a robot in a field of view of the patient such that the robot can interact with the patient thereby creating intrinsic motivation in the patient to make eye contact with the other individuals after a therapy session has ended, the robot comprising: {\textbar} {\textbar} prominently featured animatronic eyes on a front side thereof; {\textbar} {\textbar} a video camera; {\textbar} {\textbar} a processor configured to: {\textbar} {\textbar} process data from the video camera to determine a gaze direction of the patient during the therapy session; and {\textbar} {\textbar} select a gaze direction for the animatronic eyes based on the determined gaze direction of the patient; and {\textbar} {\textbar} an actuator that allows the interaction with the patient by controlling the animatronic eyes based on the selected gaze direction for the animatronic eyes; and {\textbar} {\textbar} refraining from providing the patient with a positive reinforcement for gazing at the animatronic eyes during the therapy session; {\textbar} {\textbar} wherein movement of the animatronic eyes constitutes the only electronically actuated movement of the robot. [Abstract] This describes a treatment method for autism/{ASD} intended to induce greater intrinsic motivation to make eye contact in affected children. The treatment method incorporates an artificial demonstration of the phenomenon of eye contact, and that method is described herein along with the principles of action of the treatment and the necessary procedure to perform it. Also described are two embodiments of a therapy tool that can be used to effect the demonstration: first, an item in the form of a cuboid with animatronic eyes affixed to one side, and second, another in the form of a stuffed dog. {\textbar} {\textbar} {FIELD} {OF} {THE} {INVENTION} {\textbar} {\textbar} The invention is in the field of medical devices and treatments. More specifically, it is a treatment that uses an accompanying device to improve eye-gaze behavior in individuals who have an aversion to eye contact due to neurodevelopmental disorders such as autism or other autism spectrum disorders ({ASD}). A novel tool for use in the therapy has characteristics such that it might be considered to be in the realms of consumer electronics, robotics, and education technology. {\textbar} {\textbar} {BACKGROUND} {AND} {RELATED} {ART} {\textbar} {\textbar} Eye contact is an important component of human-to-human communication, being used often by both children and adults to communicate with most others in their daily lives. Children who habitually fail to make eye contact often face challenges and difficulties in life that most people do not, and failing to make eye contact is a common sign of autism. In fact, according to {AutismTreatmentCenter}.org, eye contact (alongside speech) is one of the main development challenges faced by children with autism, and as such, it is not surprising that the topic has been addressed many times by numerous researchers. Here I quote a passage from a 2013 paper by Carbone et al in reference to prior research in the field in which the authors cite several other works: {\textbar} {\textbar} “It has been suggested that eye contact, sometimes referred to as (eye) gaze behavior or eye-to-face gaze (Mirenda, Donnellan, \& Yoder, 1983) serves an important social function for young children even before vocal responding begins to develop (Stern, 1985). In early development, eye contact serves to regulate face-to-face social interactions (Lee, Eskritt, Symons, \& Muir, 1998; Leekam, Baron-Cohen, Perrett, Milders, \& Brown, 1997) and contribute communicatively to social interactions (Tiegerman \& Primavera, 1984). Later, eye contact responses coordinate the visual attention between another individual and an object of interest (Arnold, Semple, Beale, \& Fletcher-Flinn, 2000) and have been found to be an influencing variable in language acquisition (Podrouzek \& Furrow, 1988). {\textbar} “Deficits in various nonverbal social-communicative behaviors, particularly in dyadic (i.e., eye-to-face) and triadic eye gaze (i.e., joint attention directed at a third party or object) are commonly identified as the earliest indicators and most noticeable deficits of developmental delays and of Autism Spectrum Disorder in particular (Baron-Cohen, Allen, \& Gillberg, 1992; Mirenda et al., 1983; Wimpory, Hobson, Williams, \& Nash, 2000; Woods \& Wetherby, 2003). Because of the various social functions eye contact may serve, failure to emit this important behavior may have significant implications for children with autism. In addition, there are possible educational concerns associated with poor eye contact. Specifically, previous research has suggested that the diversity of prelinguistic pragmatic skills exhibited (e.g., eye contact, joint attention) is predictive of the rate of subsequent vocabulary acquisition (Kleinke, 1986) and it has also been suggested that poor eye contact may adversely affect the educational gains of children with autism due to the relationship between eye contact and attending to the teacher and instructional demands (Greer \& Ross, 2007; Lovaas, 1977).” (Carbone et al, 2013) {\textbar} Autism spectrum disorders, including autism itself, are characterized by “(a) impaired social interactions and failure to develop social relationships, (b) impaired and disordered language and communication, and/or (c) occurrence of restricted and repetitive behaviors.” Boys are affected 3 to 4 times more often than girls. The cause of {ASD} is considered unknown in 90 to 95 percent of cases (Boyd et al, 2010). {\textbar} {\textbar} Ultimately, “there is no aetiology-based intervention for [{ASD}]” (Francis, 2005) and consistent with this, credible therapies tend to address the symptoms of the condition—behaviors—rather than any biological causes. Similarly, pharmacological treatments are available for “hyperactivity, impulsivity, inattention, aggression, irritability, anxiety, and withdrawal,” but do not address any root cause of the condition. (Tchaconasa and Adesman, 2013) Special diets—casein-free, gluten-free, etc.—aimed at the problem, typically have no scientific basis. Early intervention—starting when the child is as young as possible—is generally considered important in obtaining a good prognosis. {\textbar} {\textbar} There are numerous strategies that are used by psychiatrists, therapists, parents, teachers, professionals, and other caregivers in the treatment of autism. For the purposes of this discussion of prior art, I will with great generality classify these strategies as being largely of three types. First, there are those based heavily on the principles of Applied Behavior Analysis ({ABA}), principles that although they have been upheld by the medical community for decades, and have considerable research demonstrating their effectiveness statistically, are not without criticism. Second, there are many alternative therapies that often come to be favored by parents due to a somewhat softer approach to the condition. Some of these are without any scientific basis, and others simply lack hard supporting data, though more recently, some aspects of these child-directed and natural environment therapies have found better support from research. Third, there are strategies that combine aspects of each of the first two types, and such hybrid strategies are of growing popularity. After a brief overview of these strategies, I will indicate some of the ways that technology is being incorporated. {\textbar} {\textbar} The most established treatments for autism and {ASD} in children—including and especially that targeting the important symptom/cause of problem eye-gaze behavior—typically involve aggressive therapy programs based on the psychological principles of Applied Behavior Analysis ({ABA}). {ABA} has been successfully used in the treatment of autism since the 1960s (Tchaconasa and Adesman, 2013), and uses positive and negative reinforcement in order to increase or decrease the prevalence of certain behaviors. It is often effected as Discrete Trial Training ({DTT}) whereby a simple antecedent stimulus is presented to the child, and the child's response to this stimulus can immediately be reinforced appropriately. In the context of treating eye-gaze behavior specifically, this extrinsic motivation might proceed with a caregiver providing an antecedent prompt to the child “look at me,” and given a satisfactory response, the child would be given an edible reward (Brown and Bradley, 2014). Over time, after a number of discrete trials have begun to show progress towards the extinction of problem eye-gaze behavior, the use of edible rewards can be faded out. In this manner, {ABA} seeks to induce affected children to act in ways that in the future they will learn the benefits of. {\textbar} {\textbar} {ABA} has gained great respect amongst practitioners due to peer-reviewed supporting research, including the work of Ivar Levaas, who in the late 1980s, began to produce some of most compelling empirical evidence demonstrating the effectiveness of {ABA}-{DTT} techniques in treating autism. Since then, many others have found the same, and today, {ABA} techniques are unique amongst treatment tactics in that they have found widespread acceptance and endorsement. For the purposes of treating autism, {ABA} has been formerly endorsed by many medical organizations including the American Academy of Neurology, the American Academy of Family Pediatrics, the American Academy of Pediatrics, the American Psychological Association, the American Speech-Language Hearing Association, the Society for Developmental and Behavioral Pediatrics, the Autism Society of America, the National Institute of Child Health \& Human Development, and the National Institute of Mental Health; it is routinely touted by Autism Speaks, the largest autism-related nonprofit in the United States; and in 1999, it was endorsed by then United States Surgeon General Dr. David Satcher (appliedbehaviorcenter.com). {\textbar} {\textbar} However, despite this obvious and thorough acceptance of {ABA}, some aspects of it have been criticized, including {DTT} in particular. Ultimately, {ABA} is something of a “carrot-and-stick” approach, and some critics have noted the potential superiority of intrinsic motivation. Some parents have expressed worry and/or dissatisfaction regarding the results as well, claiming that {ABA} can/could make their child act in ways that might be considered “robotic”, exhibiting more desirable behaviors only because they were induced, and not as manifestations of the child's personality (iancommunity.org indicates Steege et al, 2007). In addition, while {ABA} techniques have never drawn the same level of ire as did the Behavior Modification techniques of the first half of the twentieth century, some formerly autistic children who have grown to become high-functioning adults have criticized aspects of {ABA} as unethical (Dawson, 2004). Part of this criticism is certainly due to the use of aversive consequences to discourage unwanted behaviors, techniques that-out of favor today-were notably used during Ivar Lovaas's seminal work on the subject. The following passage from a 1977 paper documents such an aversive technique: {\textbar} {\textbar} “ . . . the therapist said ‘[the child's name], you didn't look at me,’ in a stern voice and then began functional movement training . . . where the child was required to move his head in one of three directions-up, down, or straight and a verbal instruction was given for each position (e.g., ‘head up’). The child had 1 sec in which to respond to the instruction, after which the therapist began guiding his head manually in the desired direction. The therapist stood behind the child, who remained seated throughout the functional movement training period. If the child began the desired movement at any time during the guidance, the guidance was eliminated and the therapist merely shadowed the child's head with her hands. However, she reapplied the guidance whenever the desired movement ceased. The child was required to sustain each posture for 15 sec. The order of the instructions was random so that the child would attend to the verbal instruction, rather than learning a particular sequence. Approximately 20 sec after the functional movement training period had ended, a new eye-contact trial was begun.” (Foxx, 1977) {\textbar} Ultimately, some researchers continue to note that in severe cases the use of aversive consequences may yield superior results than the use of positive reinforcement alone (Foxx, 2005). However, the diagnostic criteria for autism/{ASD} are, today, broader than they used to be, and the recent explosion in autism and {ASD} cases has resulted in many children being diagnosed with {ASD} who in previous generations would have had their conditions remain unrecognized (Gernsbacher, Dawson, and Goldsmith, 2005). For these less severe cases—perhaps the bulk of the cases today—strict implementations of {ABA} complete with aversives may be less appropriate. {\textbar} {\textbar} The archetypal alternative to the strict application of {ABA}-{DTT}, might be called child-driven/directed or naturalistic. If {ABA}-{DTT} concerns a series of short iterations, each initiated by the therapist, each with a defined and measurable outcome, then a child-directed or naturalistic scheme focused around play is the opposite. Such a strategy is less rigidly defined and seeks to follow the child according to his/her interests, legitimizing those interests, and hopefully allowing for a bond to form between caregiver and subject. In the context of eye-contact, one may note the following suggestions as provided to a parent by the director of a therapy center that promotes a child-directed program: {\textbar} {\textbar} “Position yourself at or below his eye level consistently. It's less eye strain and easier [for him] to look at you this way. When you give him an object, hold it to your eyes, so that he must reach out and grab it. You are right there, behind the object! Whenever [he] does look at you, celebrate him for it! Tell him how much you appreciate him looking. He may not know how special it is to you.”—Bryn Hogan, Director, the Son-Rise Program ({AutismTreatmentCenter}.org) {\textbar} In contrast to {ABA}, in which the therapist virtually—or even literally—might instruct/order/induce a child to notice, do, or say something, it seems that practitioners of a child-directed strategy prefer to actively compete for the child's attention. This is clearly a softer, gentler, more friendly approach. {\textbar} {\textbar} Research regarding child-directed strategies is mixed, due perhaps to the significant variation between strategies. While a few child-directed programs aimed at parents tout miraculous results, often the research supporting such programs is simply anecdotal, with strict control groups typically absent, which leaves such programs unendorsed relative to {ABA}. {\textbar} {\textbar} On the other hand, some credible research, as mentioned above, backs the use of some of the characteristic alternative techniques of child-directed/naturalistic strategies. For example, imitating an affected child's behavior-what might be considered a child-directed technique by definition—was shown as early as 1984, to, in some instances, result in greater eye contact (Tiegerman and Primavera, 1984). Other studies have also found similar results: for example, one observed that children responded favorably to a protocol that included contingent imitation on the part of the practitioner, and that in response, the child subjects demonstrated increased “use of eye gaze and [reciprocated] imitation [on the part of the child] of familiar actions that generalized to novel con-texts” (Hwang and Hughes, 2000, as cited by Ingersoll, 2008). Ultimately, these and other positive findings have likely influenced specific aspects of some treatment programs directly. Such would certainly seem to be the case for one strategy known as Reciprocal Imitation Training ({RIT})—a strategy that notably contains {ABA} aspects, but also the very natural, child-driven technique of imitation. A general outline of the teaching components for {RIT} indicates specifically that in order for a caregiver to increase the level of eye contact on the part of a child that the caregiver might “imitate[s] the child's actions with toys, gestures/body movements, and vocalizations at the same time as the child.” (Ingersoll, 2008) {\textbar} {\textbar} Most recently, the trend has been toward programs that include aspects of {ABA} while also focusing more on the relationship between caregiver and subject, and expectedly, such finds more common support between professionals and parents who are both active in the treatment process. Examples include the Children's Toddler School, Project {DATA} for Toddlers, the Early Start Denver Model, the Early Social Interaction Project, and the Walden Toddler Program (Boyd et al, 2010). One resource notes that “sensory social routines such as peek-a-boo and ‘I'm gonna get you,’ provide opportunities for eye contact, child initiations to continue the activity, reciprocity, anticipation, joint attention and sensory regulation” ({JustKidsSchool}.com). Some have applied the moniker Natural Environment Teaching ({NET}), yet indicated treatment techniques such as the following: {\textbar} {\textbar} “A learner and a therapist are playing together, with the therapist tickling the learner (and tickling is preferred by the learner). The therapist then pauses tickling and looks expectantly at the learner with an anticipatory expression and hands raised in the air. After several seconds, the learner looks in the direction of the therapist, who immediately resumes the tickling activity, and praises the learner as soon as he makes eye contact.” (Granpeesheh et al, 2014) {\textbar} While the above seems far more natural than any procedure that might involve the use of edible rewards or functional movement training as described in Foxx's 1977 paper, the above suggested technique also clearly follows {ABA}'s antecedent-response-consequence framework. Despite this, proponents of {NET}, at times, deride {DTT}: “while [{DTT}'s] approach to increasing eye contact may have its benefits, it can often lead to individuals only making eye contact when instructed to do so or using patterns of eye contact that appear unnatural.” (Granpeesheh et al, 2014) Truly, such would seem less likely with {NET}. {\textbar} {\textbar} Turning now to the topic of applied technology, numerous technology products have been found helpful in both therapy as well as the education of children with autism. For example, teenagers with autism have been found to derive significant benefits from the use of Personal Digital Assistants (Gentry et al, 2010). Certain types of software that has been found to make subjects more engaged and less resistant to the learning process (Williams et al, 2002) as well as more attentive, more motivated, and ultimately apt to greater achievement (Moore and Calvert, 2000). Technology in the realm of Augmentative and Alternative Communication, especially Picture Exchange Communication Systems, has been very successful in both improving speech and facilitating alternative ways to communicate (Preston and Carter, 2009). Tablet computers have been found to be particularly useful in this context. {\textbar} {\textbar} Very few software applications seem to have addressed the problem of eye contact specifically. A collaboration between Samsung and Autism Speaks has yielded the Look At Me product, a smartphone app that seems to aim at encouraging individuals to focus on eye contact as they take photos of other people. In addition, Goatella's Eye Contact Trainer app as well as the tablet apps of the Look In My Eyes series from {FizzBrain} {LLC} have a very simple, common game format aimed at the problem. Autism Speaks indicates the research supporting the use of the Look In My Eyes series as being “anecdotal” (autismspeaks.org); however, there may be some rightful skepticism about whether time spent with such tablet apps would truly increase the amount of attention that would later be paid to caregivers and people in general. {\textbar} {\textbar} A number of robotic toys intended to help kids affected with autism have also been developed, and these developments are closely associated with the new and growing field of Socially Assistive Robotics ({SAR}). A 2012 review (Scassellati, Admoni, and Matarić, 2012) documented research regarding roughly a dozen robots of varying complexity—most having at least some anthropomorphic features—that might be used in the context of autism therapy. Most of the examples came from academic groups affiliated with universities such as the University of Southern California, the University of Hertfordshire, the University of Sherbrooke, University of Pisa, and Miyagi University. Very few of the robots discussed in this 2012 review were commercially available—perhaps limited to only two: each of “Pleo,” a robotic dinosaur, and Sony's “Aibo,” a robotic dog—and neither of these were specifically intended for therapeutic use, being preferentially aimed at a broader toy market. {\textbar} {\textbar} “The main intended role of a {SAR} system in autism therapy is to allow or encourage children to develop and employ social skills. To this end, robots can be designed to take part in numerous different interaction goals, such as capturing and maintaining attention, evoking joint attention, eliciting imitation, and mediating turn-taking.” (Scassellati, Admoni, and Matarić, 2012) {\textbar} Researchers typically give affected children the opportunity to interact with a robot in the presence of a therapist or in the presence of other children, usually over the course of several dedicated sessions during which the robot's ability to elicit effects can be assessed. The length of such sessions varies, depending most often on the attention span of the children (Cabibihan et al, 2013). Research has typically shown that—at least during the session—the robots have the distinct ability to improve socialization, not simply in relation to the robot, but in relation to other people who are present during the session. {\textbar} {\textbar} “In many studies, children with {ASD} interacting with robots show spontaneous joint attention behavior—for example, looking at an adult and back to the robot or pointing to the robot and looking at an adult or another child, with the intention of sharing some feature with that person. Children with autism show this behavior de-spite previously displayed tendencies to avoid eye contact or engagement with unknown adults.” (Scassellati, Admoni, and Matarić, 2012) {\textbar} This response on the part of affected children seems to mirror the response that would be seen in any person/group who/that might be confronted with something extremely new and different-amazement, the seeking of a sort of confirmation that their eyes are not deceiving them, and perhaps a general revelry in the experience. (For example, consider a group of people all absorbed in their own activities, work or otherwise. If a {UFO} were to suddenly land near them, it would draw all of their attention away from those individual activities, and those people would all proceed to socialize over their own amazement in the arrival of the {UFO}.) {\textbar} {\textbar} What is more, it has been implied that such robots have some distinct advantages even in relation to the capability of human caregivers to elicit certain responses, the robots exploiting a distinct tendency of affected children to show an affinity for and more easily interact with things that are somewhat less than human. {\textbar} {\textbar} “Some of these behaviors observed during interactions involving children with autism and robots can be attributed to the fact that robots provide novel sensory stimuli, but some-such as turn-taking with another child, manifestations of empathy, or initiation of physical contact with the experimenter-suggest that robots occupy a special niche between inanimate toys (which do not elicit novel social behaviors) and animate social beings (which can be a source of confusion and distress to children with autism). The goal of researchers investigating {SAR} for autism treatment is to develop robots that elicit these positive and productive interactions.” (Scassellati, Admoni, and Matarić, 2012) {\textbar} Since the 2012 review, two commercially available examples have moved to the forefront. One is Aldebaran Robotics's “{NAO}”, a robot that was initially introduced in 2007 August for the purpose of teaching older—and for the most part, neurotypical—children about technology and robotics. Similar to Pleo and Sony's Aibo, units of {NAO} have—for general, not-necessarily autism-related use—been produced in the thousands, and since 2012, {NAO} has, given its widespread availability, been harnessed by numerous universities as an object for autism related studies. Research results seem to be mixed, with some reporting of increased joint attention and positive effects on eye gaze, and others of less impact on joint attention and eye gaze effects that only occur relative to the robot, not to humans present at the time or afterward (Tapus et al, 2012). {\textbar} {\textbar} The second recent commercial robot of note—introduced in 2015—is that of {RoboKind}'s “Milo” which, unlike other commercial examples, is specifically intended for autism treatment. Milo is related to a prior product, “Zeno”, that was intended for use in robotics research and was in development since at least the mid 2000s. Peer-reviewed research on the effectiveness of Milo is not yet available, though {RoboKind}'s claims that the robot has positive effects on joint attention and eye gaze behavior is consistent with that of {SAR} research in general and the robot's anthropomorphic design. {\textbar} {\textbar} To date, robots used in autism and {ASD} therapy—even when intended to improve a subject's eye-gaze behavior—have not typically utilized animatronic eyes that duplicate the phenomenon, although some are programmed to exhibit some matter of gaze direction in the course of interacting with subjects. Two such robots are {KASPAR}, a product of the University of Hertfordshire; and {FACE}, a product of the University of Pisa. {KASPAR}, a humanoid robot about the size of a small boy, designed by its creators as “minimally expressive,” has been the subject of {SAR}/autism-related research since the mid 2000s. Consistent with much {SAR}/autism-related research, {KASPAR} has been used as a “social mediator” (Scassellati, Admoni, and Matarić, 2012; Dautenhahn et al, 2009). More relevantly, {KASPAR} was involved in a series of studies in which the robot would play “peekaboo” with subjects, a game that notably centers around eye contact, though without requiring any great degree of eye movement (Dautenhahn et al, 2009). {FACE} is also a humanoid robot, or more accurately, simply the head of one, and like {KASPAR} is capable of displaying emotions, though perhaps to a greater degree. {FACE} was also initially developed in the mid 2000s, and continues to be the subject of laboratory research, some of which has been related to autism (www.faceteam.it). {\textbar} {\textbar} Robots otherwise capable of making eye contact—outside the context of autism therapy—have been created in laboratories since at least the 1990s. Several examples have been created in a laboratory setting at the {MIT} Media Lab by Professor Cynthia Breazeal and the Personal Robots Group. these would include each of three robots named as “Lexi”, “Leonardo”, and “Kismet”. These robots often have been programmed to utilize their own robotic gaze in social interactions with people. As such, certain examples have been programmed to utilize eye gaze maneuvers to perform different functions in the context of conversation. For example, Kismet, when in the midst of a conversation where eye contact was obtained, was programmed to look to the side in order to “hold the floor” before speaking—presumably indicating to the interacting person that the robot was no longer attending to the person's speech/actions/communication, but was instead preparing to speak/communicate itself. Similarly, a gaze, by the robot, directed at a person interacting with it was intended to show that that person had the robot's attention (Breazeal, 2003). {\textbar} {\textbar} One of the most relevant examples of robots intended to make eye contact is that of “Robotinho”, a robot developed at the University of Bonn and introduced as an experiment in the role of a tour guide for children at the Deutsches Museum. Robotinho is notable, not simply for having animatronic eyes that make eye contact with people in its surroundings, but for doing so at a speed and fluidity that allows for significant engagement. Robotinho “focuses its attention on the person who has the highest importance, which means that it keeps eye-contact with this person. While focusing on one person, from time to time, [Robotinho] also looks into the direction of other people to involve them into a conversation.” (Faber et al, 2009) {\textbar} {\textbar} The invention described herein is an attempt to apply newly available technology to the problem of autism and {ASD} treatment. Some of what is described in this application would not have been possible five or ten years ago. Parts of it share some similarities with some of the aforementioned technologies, but this invention also brings a novel focus, design, and function as well. It is possible that it might be used in conjunction with some of the aforementioned treatment strategies, but it also is meant to act on its own, with an altogether different mode of action. {\textbar} {\textbar} {SUMMARY} {OF} {THE} {INVENTION} {\textbar} {\textbar} This invention is a therapy method for autism/{ASD}. The goal of the therapy is to instill in a child subject a degree of intrinsic motivation to make eye contact, with the hope that doing so will ultimately aid in the child's development by easing their interactions with caregivers that might otherwise help them. The therapy method aims to achieve this goal by exploiting a natural phenomenon—that given any cohort of people who are exposed to a concept, that a certain subset of those people will become interested in that concept—and in such pursuit, the therapy employs an artificial demonstration of eye contact using animatronic eyes that is intended to create in the subject a state of hyperawareness regarding the concept of eye contact. The therapy tools used to effect the demonstration are novel to this invention and also described in this application. {\textbar} {\textbar} For the purposes of discussion, I refer to the method of action of these therapy tools—that method being central to the therapy itself—as Demonstration-Based Concept Suggestion ({DBCS}) and describe such {DBCS} analogously as an attempt to “advertise” to the child subject a topic of interest, that topic being eye contact. The response to this “advertisement” of eye contact is internal to the child's mind and assumed to be cumulative in its effect. The response includes first a greater awareness of the concept of eye contact, followed by a greater interest in the concept as well as a desire to engage in the activity. Ultimately, it is hoped that the child will take action on their own, action arising from a sort of intrinsic motivation, and initiate eye contact themselves. Manifestations of this response—and its definitive attribution to this particular therapy method—are assuredly difficult to measure in practice, but can only be imagined to be positive. {\textbar} {\textbar} Notably, with regard to eye contact, {DBCS} is dissimilar to traditional autism/{ASD} treatment strategies. It is dissimilar to that of {ABA}-{DTT}, featuring no discrete trials, nor a focus on the subject's external behavior. {DBCS} is also dissimilar to child-driven/naturalistic strategies, featuring no legitimization of the child's interests or behaviors, and employing a display that is truly exceedingly artificial and purposefully so. Neither does {DBCS} attempt to provoke joint attention or socialization through the introduction of novel stimuli or dedicated therapy session protocols. {\textbar} {\textbar} In addition to the therapy method itself, this invention concerns two embodiments of the aforementioned therapy tool. The first of these embodiments is, quite literally, a black box with animatronic eyes affixed to one side. Apart from the animatronic eyes, the box/device is largely featureless so as to avoid any characteristics that might distract subjects from the eye contact display. The second embodiment is a stuffed dog that is perhaps more along the lines of what is expected in a consumer product for children. In both embodiments, the animatronic eyes are programmed so as to exhibit similar behaviors, engaging subjects/children with occasional glances as well as extended eye contact under some circumstances. The method by which this is effected is novel to this invention and discussed in the subsection “Rules Governing Eye Movements”. {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DIAGRAMS} {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} gives a general impression as to the outward appearance of embodiment one of the therapy tool: a rectangular box with eyeballs affixed to one side. {\textbar} {FIG}. 2 {\textbar} {\textbar} shows five pairs of eyes that illustrate the general range of movement that the animatronic eyes have. (Importantly, while the shape of the eyes in these diagrams is affected by eyelids; eyelids are not required for the invention, but may, if included, add beneficial realism.) {\textbar} {FIG}. 3 {\textbar} {\textbar} is a directed graph depicting transitions concerning two possible computational states: state C indicating eye contact between the subject and the device, and state A indicating that the subject is looking at the device but that the device's gaze is averted. {\textbar} {FIG}. 4 {\textbar} {\textbar} is a contour graph displaying example relative assertiveness scores for gaze directed at various points within a given field of fixation ({FOF}), as seen from the device, given a single subject being present in that {FOF} and the gaze direction of that subject being toward the device. {\textbar} {FIG}. 5 {\textbar} {\textbar} is a directed graph depicting transitions concerning two possible computational states: state S indicating that the device is “looking” at the subject while the subject is looking away from the device, and state M indicating that the gazes of both the subject and the device are mutually averted. {\textbar} {FIG}. 6 {\textbar} {\textbar} is a directed graph that combines the graphs of {\textbar} {FIG}. 3 {\textbar} and {\textbar} {FIG}. 5 {\textbar} , thus depicting all four computational states and all possible transitions between those states given the presence of a single stationary subject. {\textbar} {FIG}. 7 {\textbar} {\textbar} diagrams two main software processes used to calculate intermediate variables central to the software used to direct the gaze of the animatronic eyes. {\textbar} {FIG}. 8 {\textbar} {\textbar} provides a general impression as to the appearance and nature of the stuffed dog that is tool-embodiment two. {\textbar} {FIG}. 9 {\textbar} {\textbar} is a cutaway diagram loosely depicting the placement of electronic components within the stuffed dog of tool-embodiment two. {\textbar} {FIG}. 10 {\textbar} {\textbar} is a schematic showing the integration, within the dog of tool-embodiment two, of main process eye movement instructions—those derived from face detection, gaze detection, motion detection, etc.—with those instructions derived from the output of the accelerometer and gyroscope. {\textbar} {DETAILED} {DESCRIPTION} {OF} {THE} {INVENTION} {\textbar} {\textbar} Here I begin the description of the therapy method by describing a particular therapy tool central to it. This tool, alternatively referred to in this specification as “the box”, “the box/device”, and “therapy tool-embodiment one”, consists of a rectangular box of black acrylic, 12″ wide, 12″ deep, and 8″ high. On the front side of the box is placed a pair of animatronic eyes, with two degrees of freedom in each eye's movement such that their apparent gaze can be directed in various directions. Between the eyes is located a camera capable of sensing video information available in front of the box. Several inches below this camera is a second camera thus allowing for stereopsis. These two cameras are designated the “higher” and “lower” cameras, respectively. In addition, the rear of the box has a power cord attached and a vent allowing the cooling of electronic and mechanical components located inside. Otherwise, the box is featureless, and purposefully so. A perspective view showing a general impression of the front of the box is shown in {\textbar} {\textbar} {FIG}. 1 {\textbar} . (The location of the lower camera is not shown, but should otherwise be visible.) {\textbar} Physical electronic and mechanical components inside used to animate the device are not claimed nor described in detail here, but can nonetheless be thought of as consisting of (1) a set of mechanisms powered by servos for directing the apparent gaze of the animatronic eyes, as well as (2) circuitry components that include, amongst other things, both a {CPU} and {GPU} as may be found on the commercially available {NVIDIA} Jetson {TKI}, and (3) a power supply, etc. {\textbar} {\textbar} The animatronic eyes are not only capable of moving, but also capable of making eye contact with people in the immediate surroundings, and do so according to a specific novel set of rules described in the next subsection. In order to facilitate this, visual information as obtained by the cameras is processed internally such that the apparent gaze of the animatronic eyes can be directed accordingly. Importantly, the proscribed movements of the animatronic eyes are effected with both a relatively fast reaction time—reacting to new stimuli in under 20 milliseconds—as well as with rotation speeds fast enough to accurately mimic the saccades of human eyes, thus being on the order of 200° per second. Furthermore, the range of motion for the box's eyes is also similar to that of human eyes, albeit modified slightly. In general, human eyes have an ability to rotate side-to-side by about 450 of adduction/abduction, and a greater ability to rotate downward (“55°) than upward (“35°). However, for this embodiment of the invention, the eyes are set to allow a range of motion of 50° through all four possible directions. This allows for the eyes to direct their apparent gaze more effectively to the side given that, unlike humans, the box cannot make a head turn, and upward to a greater degree of sursumduction, as it seems likely that the box should more often be placed below—rather than above—the eye level of those people in its surroundings. (To imagine this one might think of the box being placed on a table where people both seated and standing would be looking downward when looking at the box.) {\textbar} {\textbar} It is no accident that this design eschews all prominent characteristics save for the animatronic eyes. The minimal and otherwise featureless design is specifically intended to draw attention to the only characteristics of note, the animatronic eyes. For the same reason, the box is indicated to have a dark exterior. It is purposeful that the dark exterior stands in stark contrast to the whites of the animatronic eyes. Importantly, these are functional aspects of the invention and not simply superficial, cosmetic characteristics. Inherently, the device is intended to highlight the phenomenon of eye contact to anyone who sees the device, and to some degree, this is accomplished by deemphasizing irrelevant aesthetic characteristics of the device, thus leaving only the eyes and their movements to remain as noteworthy. {\textbar} {\textbar} The device is aided in its function of highlighting the concept of eye contact by the very powerful innate reaction that people have to eyes that reciprocate. Fundamentally, the ability to make eye contact is a very, very unusual characteristic to find in otherwise inanimate objects. In fact, the device of this specific design should be noted as having a potential greater ability to highlight the phenomenon of eye contact than do people or animals, living things that actually possess the natural ability to make such eye contact. In the natural world, including that of human civilization, the phenomenon of eye contact is only found when juxtaposed to numerous other prominent, interesting, noteworthy, and important characteristics. When confronted with another person in human-to-human interaction, eye contact is only one of many aspects of the interaction to consider, and such is also true of less complex interactions such as those involving animals. For example, when encountering a puppy, eye contact between the observer and the puppy may occur, but there are so many other interesting, notable attributes of the puppy—big eyes, wagging tail, playful nature, surprisingly sharp claws, etc.—that the observer is unlikely to actually think about eye contact even if eye contact is made. An artificial box, that eschews prominent characteristics save for its animatronic eyes, has a greater ability to highlight the behavior of eyes than do actual eyes in the natural world—including, and especially, those of other humans. {\textbar} {\textbar} What is more, the attention of observers is brought to the phenomenon of eye contact by the box without any sort of linguistic explanation whatsoever, and this is highly valuable. The phenomenon of eye contact, itself, is of a very primal nature. It is fully recognizable between people of different cultures; it is fully recognizable between many species of the animal kingdom. It is also recognizable by developing infants long before they are able to understand language. And it is recognized by those challenged in their development so as to have severe and debilitating difficulties with communication. {\textbar} {\textbar} Because of this unparalleled ability to highlight the concept of eye contact without any sort of verbal explanation whatsoever, this box/device must be seen as somewhat unique amongst tools that might be used in therapy related to autism. This uniqueness makes the box particularly interesting in the context of therapy, and it is not hard to imagine that it might be used both in the context of {ABA}—perhaps as a prop, a stimulus prompt—as well as in the context of alternative, child-directed, natural environment programs. {\textbar} {\textbar} However, ultimately, the primary, intended use of this therapy tool is not in either of these contexts. Instead it is simply through its demonstration of eye contact that the tool/device is intended to act. In fact, the intended mechanism of action—this concept demonstration along with a subsequent and gradual afference of the concept of eye contact into the subject's mind—should not technically require the active participation of a therapist/caregiver. Instead, the invention is intended to perform its function in a way that is perhaps more akin to that of psychological suggestion (though admittedly only in the ideo-afferent sense, with only a delayed motor component). Through repeated, frequent, and obvious demonstration of the phenomenon of eye contact in a way that is wholly non-threatening, the device acts to induce in the subject a state of hyperawareness regarding eye contact with the hope that, over time, the subject may develop a newfound curiosity regarding that very concept of eye contact itself. {\textbar} {\textbar} This mechanism of Demonstration-Based Concept Suggestion ({DBCS}) is perhaps best elaborated upon by means of an example. {\textbar} {\textbar} Consider placing the device on an uncluttered shelf in a room where affected children might see the box/device often, but not for a long period of time on each occasion. I imagine a classroom used several times per week, or the waiting room at a therapist's office. Children, while they are intended to interact with it, are intended to do so only briefly, more than a few times, but only when it is convenient. Importantly, interacting with the box/device is their choice, though the device is hopefully placed where there is little else of interest surrounding it, so that it might be noticed. In this way, the box/device can easily perform its function of highlighting the concept of eye contact to any child who sees it, and the concept of eye contact is thus “advertised” repeatedly to the child. Such repeated “advertisement” will assuredly build within the child a greater awareness of the concept, and it is hoped that a greater interest will also follow. {\textbar} {\textbar} Analogously, in this example, one might consider this box/device embodiment of the therapy tool to be something akin to a billboard—a billboard advertising to the children the very concept of eye contact. Encountering a billboard, a typical consumer/customer does not see it or consider it for a long period of time. Instead, one sees a billboard for only a brief moment every time that one drives by it on a nearby road. From an advertiser's point of view, the hope is that when the time is right, the consumer will then remember the advertisement, having seen it only briefly at any given time, yet still repeatedly. Here, the same is true for this device. The box/device will hopefully place into the child's mind a different way of thinking about eye contact—building awareness and interest, and hopefully, eventually, a desire and intrinsic motivation to engage with others in exploration of the concept. If the typical eye-contact-experience is daunting, onerous, tiresome, or frightening for the child, then the box/device—being wholly non-threatening—is intended to advertise it in a way that is not. The device should repeatedly remind the child of the very concept of eye contact itself-something that an interaction with another person wouldn't necessarily do given the pervasive juxtaposition of eye contact to all sorts of other experiential characteristics. And, hopefully, such a brief reminder—effected through {DBCS}—is enough so that when the child does happen to feel slightly more confident, slightly more inclined to try something new, and slightly more interested in exploring the nature of eye contact, when the right person is there for them to engage with, that child will actively, on their own volition, seek out the opportunity to engage in eye contact specifically, and see and experience the degree to which eye contact demonstrates and represents the inherent living quality of other people. {\textbar} {\textbar} Consequently, it should be apparent that {DBCS}, the novel way that this invention is used when applied in- or out-of-therapy, differs substantially from established strategies. Although it is possible to conceive of the physical device being used as an antecedent prompt in the context of {DTT}, execution of “the billboard strategy” or {DBCS} in general is clearly not an implementation of {ABA}. Fundamentally, {DBCS}-use of the device does not request anything of the child, nor indicate that the child should engage in eye contact immediately or after a delay. It simply advertises the concept, and as such, {DBCS}-use of the device simply has very little in common with {ABA}'s core antecedent-response-consequence framework. Nor is {DBCS} very similar to alternative strategies. While {DBCS} may seek to elicit a child-directed response, it seeks to do so without any imitation of the child and without any stated or unstated legitimization of the child's actions or behavior. {DBCS} seeks only to advertise a concept such that the child may consider it. While {DBCS} is not incompatible with {NET}, ultimately, there is very little that is natural about the device or its use. To the contrary, {DBCS}-use of the device is the direct introduction to the child of an object that is exceedingly artificial—an object that has had all of its secondary characteristics hacked away such that only a single characteristic remains. And while that characteristic of eye contact is found pervasively throughout the natural world, it is never, never found in isolation. {\textbar} {\textbar} Thus as a novel technique for use regarding autism therapy, this example of {DBCS}-use of the physical device is specified as follows: {\textbar} {\textbar} 1. The device is placed such that the subject(s) comes into contact with it often, though never for a long duration. Notably, the general area around the device should be relatively free of distractions such that the device is sufficiently noticeable. In this way, the subject(s) has the opportunity, but not the obligation to interact with it. {\textbar} 2. The device through its operation and interaction with the subject(s) serves to highlight the phenomenon of eye contact to the subject(s), in a way that only a device so described can do so. {\textbar} 3. Given time for a subject(s) to consider the phenomenon, it is assumed that the resulting ideation regarding the concept of eye contact will differ from that derived from other stimuli. If successful, the child will exhibit an increased curiosity regarding eye contact, thus resulting in eye-gaze behavior that should not be subject to the “robotic” criticism of {ABA} results. Then, hopefully, when the time is right, the child will initiate eye contact on their own volition with newfound interest in the concept of eye contact and the way that people interact. It is at this point that any caregiver chosen as the object of the child's study should respond appropriately. {\textbar} The exact manner in which a caregiver should act as the object in step three is, admittedly, less defined than the rest of the procedure. For practitioners of {ABA}, the first instinct may be to provide the child with a reward. And this provokes the question, should resulting {DBCS}—inspired eye contact from the child be reinforced? {\textbar} {\textbar} Perhaps surprisingly, I believe that the answer to this question most in line with the spirit of {DBCS} is that the behavior should not be reinforced. Ultimately, when the child finally engages in {DBCS}-inspired eye contact, no reward should be necessary as the child is actively doing what the child wanted to do already. There should be no need to reward the child for a behavior that the child has chosen to effect in the pursuit their own curiosity. In fact, an inappropriate reward may, in such context, serve only to perpetuate the “robotic”, impersonal, {ABA}-induced behavioral characteristics that parents tend to dislike. {\textbar} {\textbar} Of course, in practice, the opportunity to reward a child for an overt and self-initiated display of engagement—if such success were to occur—may be an opportunity not to be missed, and of such action on the part of a caregiver, there can be no criticism. However, ultimately, {DBCS} does not call for an {ABA}-like consequence/reward in response to subsequent eye contact. Instead, given a positive {DBCS} result of child-initiated curiosity, the caregiver's course of action most in line with the spirit of {DBCS} would be relatively passive, with little to actually do than to simply be the object of the child's curiosity. {\textbar} {\textbar} Rules Governing Eye Movements {\textbar} {\textbar} Turning now to a more detailed description of the eyes' movement, while the animatronic eyes are intended to make eye contact with people in their surroundings, they are not intended to simply stare at those people. For the purposes of better drawing attention to the concept of eye contact, this invention uses a specific and novel state-based process that seeks to choose gaze directions based on several variables that are provided to it by other parts of the system software as needed. In broad terms, those variables are the following: {\textbar} {\textbar} 1. The location of the current subject in the Field of View ({FOV}) of the device, i.e. a set of coordinates (x {\textbar} S {\textbar} , y {\textbar} S {\textbar} ) designating the general direction of the subject. {\textbar} 2. The range to the subject, r {\textbar} S {\textbar} , i.e. the distance between the device and the subject. Notably, from this value r {\textbar} S {\textbar} and the {FOV} coordinates (x {\textbar} S {\textbar} , y {\textbar} S {\textbar} ), it should be possible to calculate a specific set of Euler angles (α {\textbar} L {\textbar} , β {\textbar} L {\textbar} , γ {\textbar} L {\textbar} ) and (α {\textbar} R {\textbar} , β {\textbar} R {\textbar} , γ {\textbar} R {\textbar} ) through which each of the animatronic eyes left L and right R would need to rotate in order to make eye contact with the subject. {\textbar} 3. The speed and direction in which the subject is assessed to be moving, a vector v {\textbar} S {\textbar} upon the {FOV}. {\textbar} 4. A scalar variable c {\textbar} S {\textbar} indicating the level of certainty that the current subject is looking back at the cameras/box/device. {\textbar} 5. For secondary subjects numbered n=1 to N, coordinates (x {\textbar} n {\textbar} , y {\textbar} n {\textbar} ), ranges r {\textbar} n {\textbar} , velocities v {\textbar} n {\textbar} , and gaze certainties c {\textbar} n {\textbar} designating the locations, trajectories, and gaze qualities of other people in the {FOV} besides the primary subject. {\textbar} Before proceeding to describe the eye movements and the principles behind them, I will better characterize the {FOV} as well as the related concept of the Field of Fixation ({FOF}). The {FOV} is defined as the entire area in which the cameras of the device can perceive the presence of the relevant subjects. For convenience in discussion, the {FOV} is not distinct for each eye or camera, but simply represents the overall area in which the box can “see”. This field is coordinatized with two roughly rectangular dimensions x and y, which when combined with the range coordinate r, describe a space that maps one-to-one with the actual three-dimensional space in front of the box/device. {\textbar} {\textbar} The {FOF} is related to the {FOV}, representing not the directions from which sensory information is available, but instead the set of directions to which the eyes of the box/device can be directed. By design the {FOF} is smaller than the {FOV} with the {FOF}'s specifications as indicated earlier, corresponding to a circular solid angle of 50° in radius. Importantly, the {FOV} is intended to be somewhat larger than this {FOF} so as to allow some degree of peripheral vision, alerting the box/device to subjects that may soon be within its {FOF} even though it is not possible to direct the gaze of the box/device toward them. {\textbar} {\textbar} The five pairs of eyes in {\textbar} {\textbar} {FIG}. 2 {\textbar} display something of the range of movements that the animatronic eyes are able to make. Notice that the eyes in this diagram change shape depending on their movements; this is due to the inclusion of eyelids. Eyelids are included here so as to add expressiveness, but are not essential to the design. {\textbar} Now, proceeding with the description, I will start by addressing three situations/cases in which the eye's movements are important and representative. {\textbar} {\textbar} 1. A case in which a single, stationary subject is located in the {FOF} and is looking at the device with a certain, unchanging gaze. {\textbar} 2. A case in which a single, stationary subject is located in the {FOF}, with a gaze that can change over time, but not so as to look directly at the device. {\textbar} 3. A combination of cases one and two in which the gaze direction of a single, stationary subject varies, at times being directed towards the device, and at other times, being directed elsewhere. {\textbar} {FIG}. 3 {\textbar} {\textbar} is a directed graph that shows the two possible states available to the device in case one. State C represents a state in which the device directs the gaze of the animatronic eyes back at the subject, and because the subject is here assumed to be staring at the device, state C represents eye contact. State A represents a state in which the animatronic eyes are directed in such a way that their gaze appears averted from that of the subject. Importantly, given a particular subject and subject location in the {FOF}, state C designates a particular gaze direction, whereas state A, on the other hand, represents many possible gaze directions. Edges in the directed graph in {\textbar} {FIG}. 3 {\textbar} represent saccades between these gaze directions. Notably, it is possible for the device to effect transitions both between states C and A, and also between an averted gaze in one direction to another averted gaze in a different direction, this represented by a loop connecting state A to itself. {\textbar} Unlike state C in which the gaze direction of the device eyes is indicated specifically, additional logic is required in order to choose the actual gaze direction corresponding to a particular arrival at state A. For the purposes of doing so, gaze locations are further characterized by what I will refer to as their Relative Assertiveness ({RA}) whereby potential gaze directions in the {FOF} are assigned a scalar {RA} score based on a largely preset mathematical function. {\textbar} {\textbar} The use of a mathematical function representing some characterization of relative assertiveness is inspired by some degree of relative assertiveness that seems present in human and animal gazes. It is a relatively common belief that a direct gaze of eye contact represents a degree of assertiveness and that an averted gaze is much less assertive and perhaps better-characterized as submissive. And although such assertiveness and submissiveness are not necessarily qualities that can be attributed to the box/device, such a quality of relative assertiveness is useful in providing a relative characterization of various gaze directions in order to better enable their selection. {\textbar} {\textbar} {FIG}. 4 {\textbar} {\textbar} is a contour graph that shows the {RA} scores as computed by the box/device for various gaze directions in the {FOF}. The largish, empty circle in the top-left quadrant of the graph/{FOF} indicates the location of the subject's eyes; gaze of the animatronic eyes directed at points within this circle is not considered to be averted as eye contact with the subject would then be possible. {RA} scores as depicted across other parts of the {FOF} take on values [−1, +1] and reflect several modeling assumptions: first, that the highest {RA} scores are seen just above the subject's head as well as toward the center of the {FOF}; second, that {RA} scores are lower just below the head/eyes of the subject; and third, that some of the lowest {RA} scores occur in the parts of the {FOF} that are furthest from the subject. {\textbar} Also in {\textbar} {\textbar} {FIG}. 4 {\textbar} are represented ninety-eight sampling points across the {FOF}. The selection process in State A chooses primarily from the lowest quartile of such sampled values, but, otherwise, the choice is made largely at random. In this way, the relevance of {RA} scores is only in how they compare with other {RA} scores at one point in time. {RA} scores as computed here are not intended to be compared between frames, and in general, comparisons of such {RA} scores over time would only have limited meaning. {\textbar} In general, these modeling assumptions relating to assertiveness are inspired by qualities of actual human-to-human interaction: first, that it is more assertive to look just above the head of someone with whom one is speaking with than just below; second, that all else equal, it is more assertive to simply gaze straight ahead than to avert one's gaze at all; and third, that the most submissive of gazes would be those that allow one to avert one's eyes to the greatest possible degree. Admittedly, although little more than intuition justifies these assumptions, they seem reasonable for their purpose, and seem to provide a reasonable function—the aforementioned {RA} function—that can be used to characterize the various gaze directions across the {FOF} possible for state A as well as in other states/situations yet to be described. {\textbar} {\textbar} Thus, for case one, the behavior of the device is characterized entirely by these states A and C, and the order and timing of the transitions between them, A-C, C-A, and A-A. {\textbar} {\textbar} The following quantities are used to further describe the timing of these transitions: {\textbar} {\textbar} t {\textbar} C {\textbar} , the length of time spent in state C after an A-C transition, {\textbar} t {\textbar} A {\textbar} , the length of time spend in state A after either of a C-A or A-A transition, {\textbar} which are in turn used to define the three parameters by which to control the governing process: {\textbar} {\textbar} P {\textbar} A-C {\textbar} , the probability of an A-C transition given that one is already in state A, the alternative being, of course, P {\textbar} A-A {\textbar} =1−P {\textbar} A-C {\textbar} . {\textbar} τ=(P {\textbar} A-C {\textbar} −t {\textbar} C {\textbar} +t {\textbar} A {\textbar} )/(2P {\textbar} A-C {\textbar} +1), a measure of the average time spent without changing from any particular gaze. {\textbar} ρ {\textbar} C/A {\textbar} =t {\textbar} C {\textbar} /t {\textbar} A {\textbar} , a measure denoting how much longer the average length of eye contact is relative to the time spent in independent averted gazes. {\textbar} Informal study indicates that the r values providing the most realistic feel are about three or four seconds, but can be set with lower values of one second or less—indicating a higher frequency of transition—for short periods as long as they decay to a more moderate level quickly. High τ values higher than four seconds are increasingly more boring. Low τ values for longer than a few seconds appear unnatural, sometimes greatly so. {\textbar} {\textbar} τ values are set for the device stochastically via a mean-reverting Markov process such that they change gradually over time with the exception of some occasional jumps to lower values that quickly revert to values closer to three seconds that virtually never go above four. P {\textbar} {\textbar} A-C {\textbar} values are set randomly, except when low τ values are used, at which time a low P {\textbar} A-C {\textbar} of 0.1 or 0.2 is required. ρ {\textbar} C/A {\textbar} values are also set randomly, for the most part. {\textbar} A final note regarding case one: in the event that the subject simply stares at the device for a considerable period, all three variables, ρ {\textbar} {\textbar} C/A {\textbar} , P {\textbar} A-C {\textbar} , and τ, are purposefully adjusted higher. This leads to the device returning the stare of the subject with any glances aside being brief and followed by a return to staring. In the context of the eye movements, I call this behavior “captivation” as it is intended that, despite some short-term variability, over time, the device is intended to be gradually drawn in—captivated—by the stare of the subject. {\textbar} {FIG}. 5 {\textbar} {\textbar} is a directed graph that shows the two possible states available to the device in case two. Case two is similar to case one except for the fact that the subject is, in this case, not looking at the box/device; the subject's gaze is directed elsewhere, but like case one, that gaze is unchanging. Similar to state C from case one, state S represents a state in which the box/device is “looking” at the subject. State M is similar to state A from case one in that the animatronic eyes are directed elsewhere from the subject to some other location in the {FOF}; state M thus represents a state in which both the subject's and the box's eyes are mutually averted. Unlike case one, case two also features two actions that are possible on the part of the subject—not the device—and these are represented in {\textbar} {FIG}. 5 {\textbar} by dashed self-loops. (For the purposes of notation, these loops are represented in this text as S {\textbar} ˜ {\textbar} S and M {\textbar} ˜ {\textbar} M, thus distinguishing the actions of the subject from those of the box/device such as in M-M.) {\textbar} {RA} scoring is used in the selection of specific gaze directions on arrival to state M in much the same way as was described for arrivals to state A in case one. However, here, the selected gaze directions are not so heavily weighted towards those with extremely low {RA} scores. A wider variety is allowed, the mean/median scores being chosen to be higher, and this results in eye movement patterns that are less averted from the direction of the subject. {\textbar} {\textbar} The transition rates are actually largely similar to those of case one, including occasional jumps to low τ values. However, “captivation” does not occur and there is no built in tendency for ρ {\textbar} {\textbar} C/A {\textbar} , ρ {\textbar} A-C {\textbar} , and r values to rise on average over time. {\textbar} {FIG}. 6 {\textbar} {\textbar} is a directed graph that shows all of the four possible states of case three. Notably, for the most part, {\textbar} {FIG}. 6 {\textbar} is a combination of the graphs previously indicated in regards to states one and two, but with four new edges shown so as to represent transitions that can occur due to actions of the subject: C {\textbar} ˜ {\textbar} S, S {\textbar} ˜ {\textbar} C, A {\textbar} ˜ {\textbar} M, and M {\textbar} ˜ {\textbar} A. {\textbar} What is most notable about case three is the reaction of the device to these actions of the subject, and to some degree the box/device actively acknowledges these actions. For example, given a new and relatively out of the blue S {\textbar} {\textbar} ˜ {\textbar} C transition, the box/device, in short order, responds with C-A, and a jump to a low τ value. Periodic looks at the subject by the device are then appropriate, along with a gradual slowing of the animatronic eyes' movements over time, with greater and greater attention thus being paid to the subject. This is, of course, a manifestation of the “captivation” behavior of case one featuring increasing values for P {\textbar} A-C {\textbar} , τ, and ρ {\textbar} C/A {\textbar} . Similarly, the box/device acknowledges a relatively out of the blue M {\textbar} ˜ {\textbar} A transition by effecting a low-τ jump, though it initially remains in state A. Behavior similar to that seen in case one then follows. {\textbar} With regard to subject looks away from the device, a C {\textbar} {\textbar} ˜ {\textbar} S transition is followed with an immediate S-M transition featuring a moderate τ value, a slightly increased P {\textbar} M-S {\textbar} value, and subsequent behavior similar to that of case two. Likewise, an A {\textbar} ˜ {\textbar} M transition is also met with behavior like that of case two, though no abrupt, initial S-M transition is necessary. {\textbar} Finally, while to some degree the behavior found in case three is something of a simple alternation between the aforedescribed behavior of cases one and two, the entire process is not entirely memoryless. Importantly, any gradual procession toward “captivation” that occurs because of time spent in states A and/or C is less impeded by brief moves to states M or S than memorylessness would imply. The degree to which the subject induces more frequent use of states A and C over states M and S is not immediately forgotten by the system, and the general use of A and C over M and S in the recent past causes the system to progress more quickly towards captivation. As any such progress towards captivation proceeds, so is greater attention paid to the subject not only when the subject is looking at the device, but also when the subject is looking away, and such is purposefully reflected in P {\textbar} {\textbar} A-C {\textbar} , τ, and ρ {\textbar} C/A {\textbar} values following M-S and S {\textbar} ˜ {\textbar} M transitions as appropriate. However, the prominence of this behavior on the part of the device is limited, and most importantly, without a subject-initiated return to states A and C, gradually diminishes over time. {\textbar} The three aforementioned cases describe the behavior of the box/device in a limited variety of situations in which there is a single, stationary subject in the device's {FOV}. In order to define the remainder of device behavior, I will address how that behavior changes in response to three additional possibilities: (1) that there is uncertainty with regard to whether or not the subject is looking at the device, (2) that a subject is not stationary but is instead moving slowly or briskly, and (3) that more than one possible subject is present in the {FOV}. {\textbar} {\textbar} Uncertainty regarding whether the subject is looking at the device—in the form of low c {\textbar} {\textbar} S {\textbar} scores-results in reduced use of states S and C in favor of greater use of states M and A, and this is effected through a general reduction in the values of P {\textbar} A-C {\textbar} and P {\textbar} M-S {\textbar} . {\textbar} Small amounts of movement from the subject are largely irrelevant. For the most part, the animatronic eyes of the box/device are directed in much the same way as they would be with a stationary subject with the only difference being that a moving subject is followed by the animatronic eyes of the device when in states C and S and thus in those states the eyes would not, themselves, be stationary. Updates made to the subject trajectory variables x {\textbar} {\textbar} S {\textbar} , y {\textbar} S {\textbar} , r {\textbar} S {\textbar} , and v {\textbar} S {\textbar} by the underlying software processes make this function—as specified here-straightforward and, for the purposes of the rules governing eye movements, scarcely different than that regarding a stationary subject. {\textbar} However, larger amounts of subject movement may result in a reduction in the quality of the device's sensory information, thus leading to both (I) greater uncertainty regarding the subject's gaze direction, i.e. lower c {\textbar} {\textbar} S {\textbar} values as reported by underlying software processes, and (2) greater error regarding those underlying software processes' estimates of x {\textbar} S {\textbar} , y {\textbar} S {\textbar} , r {\textbar} S {\textbar} , and v {\textbar} S {\textbar} . Any such increased error in x {\textbar} S {\textbar} , y {\textbar} S {\textbar} , r {\textbar} S {\textbar} , and v {\textbar} S {\textbar} will hopefully be unnoticeable and otherwise minimized, but on the other hand, any reduction in c {\textbar} S {\textbar} values due to subject motion are intentionally reflected in eye movements in the same way that such lower c {\textbar} S {\textbar} values would otherwise be expected to be reflected: in general, with a favoring of states M and A over states S and C. {\textbar} With the presence of two people in the {FOV}, box/device behavior remains similar, with one and only one of those two people being chosen to be the primary subject at a given point in time. Transitions between states C/A/S/M also remain similar and are determined primarily by the box/device's interaction with the primary subject alone. However, {RA} functions upon the {FOF} are computed such that the presence of the second subject is also taken into account. In general, the same principles of {RA} score calculation apply: that a direct gaze at either person would be relatively assertive, that a gaze above one a subject's head is more assertive than a gaze below, that the most submissive gazes are probably those in which the eyes of the device are averted to the greatest possible degree from both subjects, etc. In addition, in what might be called a “glance”, an entry into either of states A or M also allows the choice of a direct gaze at the secondary subject to be selected as an “averted” gaze as long as the duration of stay in that A or M state is set to be suitably brief; such glances occur with probability P {\textbar} {\textbar} G {\textbar} , but are more likely when r {\textbar} 1 {\textbar} is small and c {\textbar} 1 {\textbar} is large (r {\textbar} 1 {\textbar} and c {\textbar} 1 {\textbar} being variables that correspond to the one and only one secondary subject: n=1). {\textbar} With some frequency, the device also assesses when it is appropriate to effect a subject-change from the current primary subject to that of the alternative. In order to facilitate this periodic decision, variables x {\textbar} {\textbar} 1 {\textbar} , y {\textbar} 1 {\textbar} , r {\textbar} 1 {\textbar} , v {\textbar} 1 {\textbar} , and c {\textbar} 1 {\textbar} are made available by underlying software processes. Most important to consider is the degree to which the current primary subject is paying attention to the box/device, i.e. engaging in states C and A. More engagement in these states reduces the likelihood of switching to the new primary subject. The assessment is cumulative, in a way, with consistent and recent C/A state engagement being most important, and with only less emphasis placed on whether or not the current state is C or A. Also, a high c {\textbar} 1 {\textbar} score increases the likelihood of choosing the alternative subject as this indicates that secondary subject is currently looking at the box. The probability is higher still if the recent history of the c {\textbar} 1 {\textbar} score has been high in general, thus indicating that the secondary subject has been looking at the box frequently. {\textbar} With the presence of a third person in the {FOV}, device behavior remains similar, with one and only one of the three people in the {FOV} being chosen as the primary subject at any given time. {RA} scores reflect the presence of all three people. Low r {\textbar} {\textbar} n {\textbar} and high c {\textbar} n {\textbar} scores make a secondary subject n more likely to be chosen as either the next primary subject or for just a fleeting “glance.” The recent history of c {\textbar} n {\textbar} scores—not just the current c {\textbar} n {\textbar} score—affects the likelihood that a particular secondary subject n will be chosen as the next primary. P {\textbar} G {\textbar} is somewhat greater with the presence of three people than two. {\textbar} When the number of secondary subjects is small, the behavior of the box remains similar to that specified for the presence of one or two secondary subjects. However, ultimately, with somewhat more people present in the {FOV}, the {FOF} becomes crowded, and it becomes more difficult to specify a gaze direction that is suitably averted from all of the people present. Consequently, when the {FOF} is determined by device processes to have become too crowded to adequately represent the A and M states, the device responds with deliberately higher P {\textbar} {\textbar} G {\textbar} values, thus resulting in more quick glances to the eyes of secondary subjects in the {FOF} instead of averted gazes to relatively empty parts of the {FOF}. Ultimately, if numerous subjects are present covering most parts of the {FOF}, then the animatronic eyes cease to make averted gazes based on low {RA} scores entirely, and instead simply look periodically at each of the people present. As before, low r {\textbar} n {\textbar} scores and high c {\textbar} n {\textbar} scores make it more likely that a particular secondary subject n will be chosen for a glance or to become the next primary subject. {\textbar} Subject Detection and Gaze Classification {\textbar} {\textbar} Having concluded describing the general process and rules by which eye movements are determined, what follows is a brief discussion of the underlying software processes and their calculation of the “input variables” listed in the previous section: x {\textbar} {\textbar} S {\textbar} , y {\textbar} S {\textbar} , r {\textbar} S {\textbar} , v {\textbar} S {\textbar} , c {\textbar} S {\textbar} , etc. {\textbar} {FIG}. 7 {\textbar} shows a flow diagram indicating the two necessary processes. The first, the Subject Analysis ({SA}) process, must locate the subject within a given frame, estimate the range to the subject, and, if necessary, recognize the subject's gaze if it is directed at the box/device. The second, the {FOV} Subject Survey ({FOVSS}) process, is tasked with locating additional possible subjects within a given frame, determining their direction of travel, the range to each, and assessing if any are looking at the box/device. Importantly, in general operation, with only one subject present, the {SA} process runs most frequently—hopefully, for each and every frame, although it is acceptable if frames are dropped. The {FOVSS} process runs only less frequently. {\textbar} Notably, both of the above processes—{SA} and {FOVSS}-require face detection. {\textbar} {\textbar} The problem of face detection, being one of the first addressed problems of artificial intelligence as far back as the 1960s (Zafeiriou et al, 2015 indicates Bledsoe and Chan, 1965), has been attacked with numerous different algorithms, some of which have risen to particular prominence as of 2016 such as those using the Viola-Jones object detection framework (Viola and Jones, 2001) and those using convolutional neural networks (Zafeiriou et al, 2015). Here, for neither of the {SA} nor {FOVSS} processes is any one particular face detection algorithm indicated; however, in general, it is important to choose an algorithm that will deliver strong performance given the characteristics of the problem. In the context of the {SA} process, it is necessary to allow for fairly quick location of the subject such that second stage gaze recognition can commence as soon as possible. In which context perhaps the most notable characteristic of the {SA} face detection task is that the relevant images are sourced from a video feed, and as such, there is a sequential continuity between them. Thus the location of the subject in one frame provides a good indication as to the general area where the subject may be found in the next frame. Optimizations based on this principle have been found highly effective in shortening both computation time and increasing the reliability of face detection. In a similar vein, searching frames for face shapes that are similar to the shapes representing the subject in previous frames is also likely helpful, particularly so given that the orientation of a person's head can change over time resulting in considerably different images representing even the same person. Other algorithms address aspects of similar face tracking problems that are indeed unnecessary here, such as those that aim to track specific facial features such as the nose, mouth, cheekbones, etc. (Milborrow and Nicolls, 2008). Of course, the chosen algorithm for the {SA} process should take advantage of the relevant characteristics of the problem, and avoid focus on unneeded features. {\textbar} {\textbar} In the context of the {FOVSS} process, the same continuity between video frames is available, but because no particular subject has been previously identified, it is less practical to look for a subject in a specific location as the introduction of a new subject elsewhere might be missed altogether. Instead, a broad survey of each frame is reasonable and no such optimization is sought. One might expect this to cause the overall process to be too expensive computationally; however, conveniently, here the constraints of the task are less onerous than with the {SA} process. First, failure to find any particular face in any particular frame is not of great concern given that no particular subject is of particular interest, i.e. any subject will do. Second, the device is not tasked with reacting quickly to the actions of alternative, secondary, possible subjects, and consequently it is not necessary that the process run for each and every frame. Because of these relatively lax requirements, truly any decent face detection algorithm will work for this purpose. Ultimately, the very popular, tried and tested {OpenCV} implementation of the Viola-Jones algorithm may be a convenient choice. {\textbar} {\textbar} The {SA} process is, of course, a two stage process, with the second stage being that of gaze recognition ({GR}), defined here as recognizing that a particular face in the {FOV}, already located, is looking at the device, and thus it is either making or inviting eye contact Although similar gaze analysis problems have often been addressed by researchers (Hennessey, Noureddin, and Lawrence, 2006 indicate Morimoto and Mimica, 2005), the problem of identifying specifically whether or not a subject is looking back at a computer's camera has not been a common/identifiable topic of published research. There are no off-the-shelf open source utilities to handle the problem. In fact, researchers indicate that similar—but perhaps somewhat more complex-problems are often considered quite challenging (Lu et al, 2011). However, ultimately, this second-stage {GR} problem is still a variation on the more common problem of image classification, and the simple output required here is not as complex as those sought by researchers of the more difficult “gaze tracking” problem. {\textbar} {\textbar} Historically, image classification has been considered a difficult computer vision problem in general due to the difficulty of formulating a priori rules on which to base an algorithm. Because of this characteristic, the two most prominent and effective cutting-edge ways of approaching image classification—deep convolutional neural networks ({DCNN}) and support vector machines ({SVM})—are both nonparametric and rely on training a relatively generic system that can learn iteratively the correct output behavior. These two approaches are certainly the best options from which to choose in order to solve this problem of gaze recognition. {\textbar} {\textbar} Suggested characteristics of a {DCNN} constructed for the job would be those consistent with a similar system recently used at Microsoft for the purposes of determining head pose/orientation—i.e. the direction towards which a recognized head is turned—consisting of an initial face detection stage followed by subsequent processing by a {DCNN} “post-filter” (Zhang and Zhang, 2014). In Microsoft's system, cropped subimages containing facial close-ups arising after the initial face detection stage are resized to a standard 32×32 pixel format and analyzed by a {DCNN} trained on 1+ million facial images (about 120,000 original images plus various transpositions of those originals). The network itself consists of a 5×5×1 convolutional layer, followed by a max pooling layer, more convolutional layers, and finally a fully connected layer. {\textbar} {\textbar} The exact specifications of a {DCNN} are typically massaged by the builders until the problem is solved satisfactorily, and notably, the here problem of gaze recognition differs slightly from that of head pose/orientation estimation as faced by Microsoft. Making the here problem of gaze recognition harder is the fact that the cropped image features that might indicate whether a person is looking at the box/device—i.e. whether their pupils are pointed in the right direction—are far more subtle than those that would denote head pose/orientation. As such, data reduction techniques such as principal component analysis that can be used to reduce the dimensionality of other problems may be less effective here, as focusing on “low-frequency” components of the input images would likely prove insufficient; this may mean that the “volume” of a networks hidden layers must be larger, using more kernels. It may also be necessary to use larger input images as well, e.g. cropped, scaled facial images of 64×64 pixels, instead of the popular 32×32 format. Such a change in the size of the input images would likely require similar adjustments broadening the sizes of subsequent network layers and requiring that aggregation layers operate over larger areas. It may also be necessary to use more training images; this reflects the assumptions of some researchers addressing similar—but notably more complex—problems, that have referred to the number of required training images for “gaze tracking” to be “prohibitively” high (Lu et al, 2011). On the other hand, making this here problem of gaze recognition easier is the fact that the answer to whether or not a particular person is looking at the device is ultimately boolean and a simple yes or no answer will suffice. {\textbar} {\textbar} Both {DCNN} and {SVM} take advantage of parallel computation in order to solve image classification problems, and as such, the performance of each is improved by using hardware capable of exploiting this characteristic. Consequently, the box that is this first embodiment of the therapy tool uses a Graphics Processing Unit ({GPU}) in order to allow gaze recognition routines to run as fast as possible. Such use speeds not only the running of the {DCNN}, but also the execution of the Viola-Jones algorithm suggested for face detection, as well as many other relevant computer vision processes. It is notable that the relevant hardware for these purposes-such as the {NVIDIA} Jetson {TKI} as mentioned earlier—is commercially available and that the use of the {GPU} component on that specified {NVIDIA} product by Intel's {OpenCV} can be facilitated using {NVIDIA}'s {CUDA} platform. {\textbar} {\textbar} This same {DCNN} utility described above can also be used, when appropriate, to recognize the gaze of other possible subjects, not simply that of primary focus, and such information is made available to the aforedescribed algorithm based on the relative assertiveness of gazes in the form of N variables numbered 1 to N, c {\textbar} {\textbar} 1 {\textbar} to c {\textbar} N {\textbar} , for the purposes of governing the eye movements. However, it should also be noted that calculation of a full set of c {\textbar} n {\textbar} values c {\textbar} 1 {\textbar} to c {\textbar} N {\textbar} is probably unnecessary in pursuit of the relevant therapeutic goals. {\textbar} The subject's velocity v {\textbar} {\textbar} S {\textbar} upon the {FOF}/{FOV} is estimated using a Kalman filter. This allows the integration of current observational data regarding the current location of the subject from the {SA} process, (x {\textbar} S {\textbar} , y {\textbar} S {\textbar} ), to be combined with a priori velocity estimates based on the data from previous observations. This process is robust in the event that results from a small number of frames must be dropped from the data sequence. That the time between frames is not constant will not prevent the calculation of a reasonable and mathematically smooth subject trajectory and projected subject locations. Furthermore, while some errors in subject identification are likely when multiple people are present in close proximity to the subject, such is not expected often enough to affect the outward behavior of the device in a notably detrimental way. {\textbar} A rectangular xy-coordinatization of the {FOV}/{FOF} is used rather than one that is polar-based—something that might seem counterintuitive given that the animatronic eyes rotate to direct their gaze, and of course, do so through amounts measured as angles. Such is more convenient for use with the Kalman filter making trajectory estimation less error prone given that the basis vectors for such an xy-coordinatization are more consistent and not subject to great variation around any pole/zenith. {\textbar} {\textbar} Velocities v {\textbar} {\textbar} 1 {\textbar} to v {\textbar} N {\textbar} for secondary subjects n=1 to N are performed quite differently than the analogous calculations for v {\textbar} S {\textbar} regarding the primary subject. The reason for this is not related so much to the added computational expense as it is to the fact that these secondary subjects are not tracked from one frame to the next like the primary subject is and thus determining which detected secondary face corresponds to which from prior frames is problematic. Some faces detected in one frame may not even be detected at all in others causing significant complications with regard to determining their correspondence. Better is simply measuring the optical flow in the regions of each face. Such is certainly an imperfect measure, but does allow estimating the velocity of each detected face without relying on information in other frames in order to do so. {\textbar} Algorithms that calculate the optical flow over the entirety of a frame such as those of Lucas-Kanade (Lucas and Kanade, 1981) and Horn-Schunck (Horn and Schunck, 1981) can usually do so only slowly. Clearly, in this case, doing so over the entire frame is not necessary given that the location of each face is known beforehand, and instead, execution is only performed local to any given face of particular interest, and even then, only when necessary. Again, Intel's {OpenCV} may be useful in this context and the choice of the {NVIDIA} platform is also appropriate. {\textbar} {\textbar} Range values r {\textbar} {\textbar} S {\textbar} indicating the amount of physical distance that separates the device/box and the subject are calculated using a Kalman filter integrating information from two sources: (1) the size of the subject's face as it appears in the {FOV} as determined by the {SA} process, and (2) coincidence rangefinding given stereoscopic information from each of the higher and lower cameras. Notably, the size of the subject's face as indicated by the {SA} process is available as a byproduct of the same face tracking operation that indicates (x {\textbar} S {\textbar} , y {\textbar} S {\textbar} ), and as such it is available frequently and at very little additional computational cost. On the other hand, this information alone is not sufficient to determine subject range. For example, while adult human head sizes vary within a more narrow range than one might otherwise expect—the 99th percentile being only about 20\% to 30\% larger than the 1st—child head sizes vary considerably given age and differ significantly from those of adults. Another complicating issue is the fact that if the subject makes a head turn orienting, thus, in a different direction, the chosen face detection/tracking algorithm may register a different size, even for the same person at a given range. Consequently, while face size is seen as a possible means of updating the range coordinate r {\textbar} S {\textbar} from frame to frame with little other information, stereo correspondence information from the cameras is also incorporated when possible in order to improve the estimate, as well as to simply calibrate it given that the face sizes of individuals varies. {\textbar} In coincidence range finding, image depth and subject range are inversely proportional to the binocular disparity as measured in pixels of displacement. For this general problem, and related problems, many, many different algorithms and solutions have been developed, some focusing on the edges between regions of different depths, others on the “dense” problem of computing the pixel disparity for each and every pixel of a region (Scharstein and Szeliski, 2002), and yet, others being optimized for targets that are mere points in a camera's {FOV}. However, despite the significant research that has gone into the problem, stereo correspondence algorithms that operate over the entirety of an entire frame remain quite time-consuming, and consequently, it is fortunate that estimating r {\textbar} {\textbar} S {\textbar} is less critical than estimating other more important variables such as (x {\textbar} S {\textbar} , y {\textbar} S {\textbar} ). {\textbar} If development finds that relatively infrequent stereopsic assessment is insufficient, then some aspects of the here problem will allow for improvements in computation time. Just as the {SA} process face detection algorithm can be improved by taking into account the temporal continuity between video frames, so can the same temporal continuity be taken advantage of in order to guess the subject range; prior knowledge of where the subject appears in an image sourced from the upper camera allows a guess—given a prior range estimate—as to where the subject should appear in the corresponding frame from the lower camera. Consequently, minimizing the sum of squared differences in pixel intensity may be a fairly quick process as the initial guess may be fairly good. A good guess as to the subject location in the lower camera's frame, and a subsequent discovery that, in that region, the gradient of the {SSD} function with respect to the binocular disparity in pixels is low or near zero, may be enough to provide a reasonable r {\textbar} {\textbar} S {\textbar} value. What is more, this stereopsic assessment need not be performed for the entire frame, but only in the region of the subject. Of course, such customized development is hopefully unnecessary. {\textbar} Rangefinding for secondary subjects is somewhat different. Similar to v {\textbar} {\textbar} n {\textbar} values, it is not clear that calculation of numerous r {\textbar} n {\textbar} values will be greatly beneficial. If so, then they may be calculated similarly to r {\textbar} S {\textbar} though it must be assumed that face size data will be significantly less predictive given the difficulty of determining temporal correspondence between face detections. Possible solutions would include a simple assumption that the head sizes of people in a given frame are all the same as those of the subject—introducing some error given that the head sizes of children can be half that of adults—or a simple decision to only rely on the stereo correspondence information for the purposes of calculating r {\textbar} n {\textbar} values, which would, of course, limit the frequency with which r {\textbar} n {\textbar} values could be updated. {\textbar} Therapy Tool Embodiment Two {\textbar} {\textbar} A second embodiment of the therapy tool consists of a simple stuffed dog that features animatronic eyes capable of making eye contact in much the same way as do the animatronic eyes of the first embodiment. {\textbar} {\textbar} {FIG}. 8 {\textbar} displays an impression of this stuffed dog, the dog being approximately one foot in length, front paws to tip-of-tail. Notably, the eyes are quite prominent as part of the dog's aesthetic design. {\textbar} Similar to the box of tool-embodiment one, the dog of tool-embodiment two eschews unnecessary secondary characteristics with the aim of drawing people's attention to its eyes (although notably to a lesser degree). Save for the dog's eyes, the dog has no moving external parts. The dog makes no sounds: no barks, howls, or anthropomorphic vocalizations. The dog's coat should be of a simple design: probably a solid color, perhaps dark, and certainly not a detailed spotty pattern that would present little contrast to the eyes. {\textbar} {\textbar} These design choices reflect the same goals driving the minimal design of tool-embodiment one: that the purpose of the device is to highlight the concept of eye contact and that this is best done by a device that eschews irrelevant characteristics. Obviously, the dog of tool-embodiment two is a less pure realization of this. However, the sacrifice here is with purpose, two-fold: first, to realize the tool/device such that a child of exceedingly young age may be allowed to hold and handle it at will, and second, to realize the tool/device in a form that people commonly see as appropriate for children. As such, the dog of tool-embodiment two sacrifices some degree of minimalism in favor of being soft, portable, cute, as well as child-safe to the point that a toddler or infant might be allowed to gnaw on it without danger. {\textbar} {\textbar} {FIG}. 9 {\textbar} {\textbar} displays a cutaway diagram of the dog of tool-embodiment two. Not intended to be a detailed depiction of the dog's interior, this diagram of {\textbar} {FIG}. 9 {\textbar} simply indicates the general location of two electronic components within the dog that are together joined by a multichannel wire. One component that I will call the “eye assembly” or “animatronic eye assembly” is located in the head, and this component includes the animatronic eyes as well as the accelerometer and gyroscope intended to measure the dog's rotational and translational movements. Notably, this first component is affixed to the exterior of the dog using a rigid bracket that is capable of holding the component in place such that the eyeballs are appropriately aligned with the eyeholes of the “stuffed-dog-body,” i.e. the stuffing and outer skin comprising the legs, tail, ears, and, in general, the soft, furry, plush exterior of the dog. The second component, which I will call the “processor assembly,” is slightly larger and is located within the chest/belly of the dog. It houses all processing components, {CPU}, {GPU}, {RAM}, and flash memory, as well as the battery. Also notable is the presence of a camera in the nose of the dog, and that this nose tip device is affixed firmly and directly to the anterior portion of the same rigid bracket that holds the eye assembly in place. Importantly, it is possible to remove all three of these electronic components from the stuffed-dog-body such that the body can be machine-washed or replaced if it becomes soiled or excessively worn. {\textbar} The function of the rigid bracket in the snout of the dog is threefold. First, to hold the animatronic eyes in place relative to the eyeholes of the dog. Second, to hold the camera in the nose of the dog in rigid alignment with two cameras placed within the animatronic eyes themselves. And third, to facilitate the passage of power and communication channels to the nose tip camera, that camera being otherwise separated from all other electronic components including the battery. In order to perform this third function, the rigid bracket is equipped with some form of wire that passes along its length, either interior to the bracket, or affixed to one side. {\textbar} {\textbar} The function of the dog of tool-embodiment two is much the same as the box of tool-embodiment one. The dog is intended to, via {DBCS}, induce in an affected child—perhaps one of very young age—an enhanced awareness of, interest in, and curiosity regarding eye movements and the concept/phenomenon of eye contact, specifically. As before, it is ultimately hoped that, over time, such increased awareness and interest will lead to an increased desire—a degree of intrinsic motivation—to participate and engage others in such eye contact. {\textbar} {\textbar} Construction of the stuffed dog of tool-embodiment two is substantially more complicated than the box of tool-embodiment one due to several reasons. First, space within the dog is limited. In order to fit within the dog, both the eye and processor assemblies must be quite small, and this means that the battery, processors, and memory, etc., as well as the eye movement mechanisms and other parts must fit within a much smaller space. Second, a greater energy efficiency is required. In the case of the box, it is assumed that the device might be plugged into a wall outlet. However, the dog must rely on battery power. This places considerable constraint on the design of the animatronic eyes, as physical movement of the eyes is assumed to occur with great frequency and all angular acceleration must be effected using energy sourced from the battery. Third, a greater standard of durability is necessary. In order to derive the dog's intended benefits, its use cannot be limited to it being viewed upon a shelf. Instead the dog must be suitable for children to handle directly, and as such, the dog must capable of withstanding occasional impacts due to—for example—being thrown from one side of the room to the other. Fourth, the dog's design must also solve what might be called the Vestibulo-Ocular Reflex ({VOR}) problem, a problem that in this context is defined as that problem concerning the ability of the stuffed dog's animatronic eyes to remain fixated on a particular point in space—particularly that corresponding to the eyes of a person with which it is engaged in eye contact—given any rotational or translational movement of the dog/tool. {\textbar} {\textbar} In order to tackle these considerable necessities of (1) compactness, (2) efficiency, (3) durability, and (4) solving the {VOR} problem, the design of this stuffed dog of tool-embodiment two employs the animatronic eye design of U.S. Pat. No. 8,715,033, thus keeping the number of moving parts to a minimum, while simultaneously being lightweight and efficient. The reader is referred to that patent for greater detail. Very generally, the eye design of that patent consists of three concentric spheres: a clear plastic inner sphere and a clear plastic outer sphere, each connected to the other at the back of the eye, with a transparent fluid located between them, and suspended in the fluid a third sphere—actually a hemisphere—that is free to move from one side to the other as well as up and down. It is on this middle sphere on which the “eye graphic”—a white portion, as well as colored iris—is painted, and this middle sphere being eggshell-thin, is driven in its motion within the fluid by a set of four permanent magnets attached to it, each magnet located at 90° from the location of the pupil, and 90° from the nearest magnet. The magnets on the middle (hemi-)sphere are acted upon by electromagnets located on the outside of the outer sphere—also located at roughly 900 from the pupil and 90° from each other—and it is through the variable control of these exterior electromagnetic magnets that the eye graphic painted on the middle (hemi-)sphere may be directed this way and that. {\textbar} {\textbar} The animatronic eye design of U.S. Pat. No. 8,715,033 also features a camera in the center of the eye. Visual input to the camera is obscured by the opaque painting on the middle sphere of the iris and white of the eye graphic. However the pupil of the middle (hemi-)sphere is transparent, as are the inner and outer spheres as well as the suspension fluid, and thus, the camera is able to “see” through the pupil. Importantly, the camera of this animatronic eye design does not move with the directed gaze of the eye, and the narrow tunnel of vision possible for each animatronic eye moves as a circle across the internal camera's {FOV}. {\textbar} {\textbar} Ultimately, in this eye design, the eggshell-thin middle (hemi-)sphere is the only moving part. Being so thin, the middle (hemi-)sphere's moment of inertia is tiny, and this, in addition to the fact that its movement as suspended in the fluid is virtually frictionless, means that even its quick and frequent acceleration places only minimal demand on battery resources. Because no unusual stresses are placed upon this single moving part, and the only other components are the rather unbreakable electromagnets and enclosing plastic spheres, this design is just about as durable as can be imagined given the requirements and far more durable than the circuitry that is otherwise required for the stuffed dog tool-embodiment. Furthermore, due to the compactness of the electromagnetic drive—consisting only of four, relatively small electromagnets—the entire eye assembly for the dog need only be scarcely bigger than the dog's eyeballs themselves, an accelerometer and gyroscope easily fitting into the posterior portion of the eye assembly. {\textbar} {\textbar} It should also be noted that the use of a nontoxic suspension fluid will ensure product safety given handling of the dog by very young children, and because the only moving parts of the eyes are housed within the protective outer plastic spheres, any force put on the dog's exterior through normal play should not prove damaging as it might be if there were external, moving pieces. Thus, the use of the U.S. Pat. No. 8,715,033 eye design along with a nontoxic suspension fluid ensures that the eyeballs themselves are of comparatively less concern in ensuring product safety than the internal circuitry components, such circuitry components being not unlike those of a myriad of electronic stuffed toys in the marketplace and for which established manufacturing safety standards/procedures/protocols already exist. {\textbar} {\textbar} Also, due to the middle (hemi-)sphere's low moment of inertia combined with the inherent efficiency of using an electromagnetic drive, the design is also useful in solving the {VOR} problem. {\textbar} {\textbar} In people, the {VOR}—that reflex that allows people to maintain gaze upon a fixed point as the head rotates—is necessarily effected by the contraction/relaxation of the muscles surrounding the eye. Medical science has determined that, in people, this reflex is necessarily effected in response to sensations in the inner ear that are caused due to changes in head orientation and head acceleration, and that this {VOR} response actually occurs faster than it is possible for human eyes to detect changes in motion visually. Interestingly, such would also be true for electronic components given today's technology, and in order to solve the {VOR} problem, this design of tool-embodiment two “short-circuits” a “reflex” response in the eye movements directly to the detected motion originating from an accelerometer and gyroscope located in the animatronic eye assembly, bypassing software aimed at face detection, gaze detection, motion detection, etc., that is otherwise the focus of most of the computational components. {\textbar} {\textbar} {FIG}. 10 {\textbar} {\textbar} displays a schematic that displays the general process by which the dog's apparent gaze is determined. The circular shapes toward the bottom represent software processes that run on the hardware located in the processor assembly; these include each of the {SA} and {FOVSS} processes (marked accordingly), as well as their Kalman filter subprocesses (each marked as “{KF}”), and an implementation of the rules as were described in the subsection of this document “Rules Governing Eye Movements” (marked “Rules”). Above those is a section indicating the comprising components of the eye assembly: the accelerometer (marked as “Acc.”), the gyroscope (marked as “Gyr.”), and the two animatronic eyes. Above these is depicted the nose of the toy including the nose-tip camera. And at the very top of the diagram is represented the subject to which the dog/tool's attention is directed. {\textbar} Incoming data from the accelerometer and gyroscope is immediately processed to give the best possible indication as to the rotational and translational movement of the toy through three-dimensional space. No compass is included as the permanent and electromagnetic components of the animatronic eyes would cause sufficient field disturbances so as to render it useless. Quick re-estimation of (x {\textbar} {\textbar} S {\textbar} , y {\textbar} S {\textbar} ) and v {\textbar} S {\textbar} is effected in response to accelerometer and gyroscope output in the same Kalman filter as used by the {SA} Process, and as such these estimates are also corrected periodically by the more definitive information being computed by the higher-level {SA}-process vision components. In effect, this process allows the gaze of the dog/tool to be adjusted as fast as information from the accelerometer/gyroscope becomes available. Consequently, most of the time, between frames/assessments by the higher-level functions, the gaze direction of the dog/tool is actually selected via a comparison of a prior indication of the subject's location/velocity in/upon the {FOF}/{FOV} and more frequent updates to dog/tool-orientation data as provided by the accelerometer and gyroscope. {\textbar} For this second tool-embodiment, coordinatization of the {FOF}/{FOV} using xy-coordinates remains more convenient than using polar coordinates. {\textbar} {\textbar} Image data arrives for processing at the processor assembly from three sources: one video camera that is affixed to the stuffed dog's nose, and two cameras—one located in each animatronic eye—as are found as part of U.S. Pat. No. 8,715,033. Notably, there is a significant quality difference between these feeds, as the eyes' video capability is impaired in two ways. First, the internal eye cameras' views are impeded by both the plastic of the inner and outer spheres as well as by the fluid between them. And although these portions of each eye are intended to be as transparent as possible, they are presumably still subject to the effects of small deformities in the plastic. Such deformities are likely very difficult to remove entirely given the need to keep production costs low while ensuring that there is an absolute minimal possibility of shatter. Ultimately, the distance between the inner and outer spheres is only held steady by the joining of the spheres towards the rear of each animatronic eye, and even if the refractive index of the internal fluid is carefully matched with the plastic's refractive index, the video quality as provided by these cameras' remains impaired as the width of this fluid layer will be subject to any slight manufacturing deformity as well as those that might arise due pressure through normal play as well as changes in temperature. Presumably, these reasons are the cause of the reduced image quality as seen in photos taken by a prototype as distributed by the inventors (Bassett, Hammond, Smoot, 2009). {\textbar} {\textbar} Second, as mentioned before, the {FOV} of the eye cameras is also obscured by the painted eye white and iris portions of the eye graphic on the eggshell-thin middle sphere. In regions outside the pupil, this obscuration is to opacity, and thus it is only in a narrow region of the {FOV} in which the images from these cameras can be used. This means that only a small portion of the internal cameras' image sensors can be used at any given time, and thus the pixel resolution available for any given image is simply less that it otherwise would be were the cameras' {FOV} more efficiently used. {\textbar} {\textbar} In comparison, image data that arrives from the nose camera is not compromised in these ways. However, given the nose's location several centimeters away from the animatronic eyes, and the fact that stuffed toys in general are often played with in very close proximity to the children's eyes intended to view them—perhaps only a few inches or less—the resulting parallax errors will often be immense. Consequently, this particular trinocular arrangement results in the situation in which two sets of images are available: (1) images sourced from the animatronic eyes themselves, that while free of parallax errors, are only useful in the assessment of nearby subjects as their resolution is quite low, and (2) images sourced from the nose tip camera that have a substantially higher resolution and are thus able to assess faraway objects well, but for which substantial parallax errors will interfere with the assessment of the nearby subjects. The use of these two relatively imperfect video sources by the dog of tool-embodiment two (one low-resolution, binocular source comprised of the eye cameras together, and a supplementary, high-resolution monocular source, i.e. that of the nose tip camera alone) contrasts with the more standard setup used by the box of tool-embodiment one (one relatively high-resolution binocular camera arrangement). {\textbar} {\textbar} However, despite the differences, vision processing in the dog of tool-embodiment two remains substantially similar to that in the box of tool-embodiment one. Notably, processing is performed using each of two main processes—an {SA} process and an {FOVSS} process—and the components of each are substantially similar to the similarly-named processes in the box. {\textbar} {\textbar} In the context of the {FOVSS} process, faraway faces are detected in the image sourced from the nose tip camera, and nearby faces in each of two images sourced from each of the eye cameras. The problem of determining facial correspondence between feeds is thus more complicated than in tool-embodiment one, yet remains conceptually similar. {\textbar} {\textbar} Face tracking by the {SA} process is, of course, complicated by the use of two feeds. Beyond a certain preset distance from the device d {\textbar} {\textbar} far {\textbar} , analysis of the subject can proceed simply with information derived solely from the monocular nose-tip feed; and within a certain preset distance, d {\textbar} near {\textbar} , analysis can proceed with information derived from the binocular eye cameras. However, between these two distances—given that, by design, d {\textbar} near {\textbar} d {\textbar} far {\textbar} , the cropped face image is chosen from the monocular nose tip feed. If d {\textbar} near {\textbar} d {\textbar} far {\textbar} , the cropped face image is chosen from the monocular nose tip feed. If d {\textbar} near {\textbar}
Issue: {US}10363192B2},
}

@patent{karam_etal17a,
	location = {{US}},
	title = {Mood monitoring of bipolar disorder using speech analysis},
	url = {https://www.derwentinnovation.com/tip-innovation/},
	abstract = {A system that monitors and assesses the moods of subjects with neurological disorders, like bipolar disorder, by analyzing normal conversational speech to identify speech data that is then analyzed through an automated speech data classifier. The classifier may be based on a vector, separator, hyperplane, decision boundary, or other set of rules to classify one or more mood states of a subject. The system classifier is used to assess current mood state, predicted instability, and/or a change in future mood state, in particular for subjects with bipolar disorder.
A system that monitors and assesses the moods of subjects with neurological disorders, like bipolar disorder, by analyzing normal conversational speech to identify speech data that is then analyzed through an automated speech data classifier. The classifier may be based on a vector, separator, hyperplane, decision boundary, or other set of rules to classify one or more mood states of a subject. The system classifier is used to assess current mood state, predicted instability, and/or a change in future mood state, in particular for subjects with bipolar disorder.
A system that monitors and assesses the moods of subjects with neurological disorders, like bipolar disorder, by analyzing normal conversational speech to identify speech data that is then analyzed through an automated speech data classifier. The classifier may be based on a vector, separator, hyperplane, decision boundary, or other set of rules to classify one or more mood states of a subject. The system classifier is used to assess current mood state, predicted instability, and/or a change in future mood state, in particular for subjects with bipolar disorder.},
	type = {patent},
	author = {Karam, Zahi N. and Baveja, Satinder Singh and Mcinnis, Melvin and Provost, Emily Mower},
	urldate = {2015-05-01},
	date = {2017-06-20},
	note = {Edition: G10L001500 {\textbar} A61B000500 {\textbar} A61B000516 {\textbar} G10L001522 {\textbar} G10L001726 {\textbar} G10L002500 {\textbar} G10L002548 {\textbar} G10L002566 {\textbar} G10L002503 {\textbar} G10L002527 {CPC}  - G10L002566 {\textbar} A61B0005165 {\textbar} A61B00054803 {\textbar} A61B00056898 {\textbar} A61B00057246 {\textbar} A61B00057264 {\textbar} A61B00057267 {\textbar} G10L001522 {\textbar} G10L001726 {\textbar} G10L002548 {\textbar} G10L002503 {\textbar} G10L002527 {\textbar} G16H005020 {\textbar} G16H005070 {EP}; {US} {EP}; {US} {US} {US}
Issue: {US}9685174B2
Number Of Volumes: 001001 What is claimed: {\textbar} {\textbar} 1. A method of detecting a speech-identifiable condition of a subject, the method comprising: {\textbar} recording speech data of the subject via a communication device input that receives the speech data for the subject while not receiving speech data for anyone else talking to the subject; {\textbar} {\textbar} transmitting, by the communication device, the recorded speech data to a mood detection machine that includes a feature extraction module and a decision module; {\textbar} {\textbar} performing, in the feature extraction module, a low-level feature extraction on the speech data over a plurality of short-time segments to develop low-level feature data; {\textbar} {\textbar} performing, in the feature extraction module, a segment-level feature extraction on the low-level feature data over a window of time to develop segment-level feature data, where the window of time comprises the plurality of short time segments, and {\textbar} {\textbar} wherein the low-level feature extraction combined with the segment-level feature extraction masks out words contained in the speech data such that the segment-level feature data is non-lexical data; {\textbar} {\textbar} applying the segment-level feature data to the decision module that includes a database of one or more classifiers, each classifier from among the classifiers corresponding to a different classification of the speech-identifiable condition; and {\textbar} {\textbar} determining, in the decision module, the classification of the speech-identifiable condition of the subject from the segment-level feature data. {\textbar} {\textbar} 2. The method of {\textbar} claim 1 {\textbar} , wherein the speech-identifiable condition is a mood state of the subject. {\textbar} 3. The method of {\textbar} claim 2 {\textbar} , wherein the subject has bipolar disorder and the mood state comprises one or more of depression, hypomania/mania, and euthymia. {\textbar} 4. The method of {\textbar} claim 3 {\textbar} , wherein the one or more classifiers comprises a classifier for identifying each of depression, hypomania/mania, and euthymia from the speech data. {\textbar} 5. The method of {\textbar} claim 1 {\textbar} , wherein the speech data is unstructured speech data. {\textbar} 6. The method of {\textbar} claim 1 {\textbar} , wherein the speech data is structured speech data. {\textbar} 7. The method of {\textbar} claim 1 {\textbar} , wherein the low-level feature data includes one or more of pitch, energy, spectrum, zero-crossing rate, maximum waveform amplitude value, and minimum waveform amplitude value. {\textbar} 8. The method of {\textbar} claim 1 {\textbar} , wherein the segment-level feature data includes one or more of mean, variance, jitter, and shimmer. {\textbar} 9. The method of {\textbar} claim 1 {\textbar} , wherein each of the plurality of short time segments is 25 ms or less. {\textbar} 10. The method of {\textbar} claim 9 {\textbar} , wherein the window of time is 3 s or greater. {\textbar} 11. The method of {\textbar} claim 10 {\textbar} , wherein the window of time is from 3 s to 30 s. {\textbar} 12. The method of {\textbar} claim 1 {\textbar} , wherein each of the one or more classification rules are support vector machine ({SVMs}). {\textbar} 13. The method of {\textbar} claim 12 {\textbar} , further comprising: {\textbar} developing each of the one or more classifiers based on more than one of the segment-level data. {\textbar} {\textbar} 14. The method of {\textbar} claim 1 {\textbar} , wherein determining, in the decision module, the classification of the speech-identifiable condition of the subject from the segment-level feature data comprises determining an expected future change in the speech-identifiable condition of the subject. {\textbar} 15. The method of {\textbar} claim 1 {\textbar} , wherein the speech-identifiable condition includes one or more of psychiatrically diagnosed conditions, pain, depression, physical conditions, congenital heart disorders, coughing, lung related disorders, lung cancer, oncological disorders, Grave's disease, hearing impairment, neuromuscular disorders, and neurological disorders. {\textbar} 16. A mood detection machine to detect a speech-identifiable condition of a subject, comprising: {\textbar} a processor; {\textbar} {\textbar} a memory; {\textbar} {\textbar} a feature extraction module stored on the memory and adapted to cause the processor to: {\textbar} {\textbar} receive recorded speech data of the subject, the recorded speech data being transmitted by a communication device and recorded by an input of the communication device that receives the speech data for the subject while not receiving speech data for anyone else talking to the subject; {\textbar} {\textbar} perform, on the recorded speech data, a low-level feature extraction over a plurality of short-time segments to develop low-level feature data, and {\textbar} {\textbar} perform a segment-level feature extraction on the low-level feature data over a window of time to develop segment-level feature data, where the window of time comprises the plurality of short time segments contained therein, {\textbar} {\textbar} wherein the low-level feature extraction combined with the segment-level feature extraction masks out words contained in the recorded speech data such that the segment-level feature data is non-lexical data; and {\textbar} {\textbar} a decision module stored on the memory and adapted to cause the processor to: {\textbar} {\textbar} access a database of one or more classifiers, each classifier from among the classifiers corresponding to a different classification of the speech-identifiable condition; and {\textbar} {\textbar} determining the classification of the speech-identifiable condition of the subject from the segment-level feature data. {\textbar} {\textbar} 17. The mood detection machine of {\textbar} claim 16 {\textbar} , wherein the segment-level feature data is non-lexical data. {\textbar} 18. The mood detection machine of {\textbar} claim 16 {\textbar} , wherein the communication device is a cellular phone or a smart phone located remotely with respect to the mood detection machine, and {\textbar} wherein the communication device input is a microphone associated with the communication device. {\textbar} {\textbar} 19. The mood detection machine of {\textbar} claim 16 {\textbar} , wherein the recorded speech data in unstructured speech data. {\textbar} 20. The method of {\textbar} claim 1 {\textbar} , wherein the communication device is a cellular phone or a smart phone located remotely with respect to the mood detection machine, and {\textbar} wherein the communication device input is a microphone. What is claimed: {\textbar} {\textbar} 1. A method of detecting a speech-identifiable condition of a subject, the method comprising: {\textbar} recording speech data of the subject via a communication device input that receives the speech data for the subject while not receiving speech data for anyone else talking to the subject; {\textbar} {\textbar} transmitting, by the communication device, the recorded speech data to a mood detection machine that includes a feature extraction module and a decision module; {\textbar} {\textbar} performing, in the feature extraction module, a low-level feature extraction on the speech data over a plurality of short-time segments to develop low-level feature data; {\textbar} {\textbar} performing, in the feature extraction module, a segment-level feature extraction on the low-level feature data over a window of time to develop segment-level feature data, where the window of time comprises the plurality of short time segments, and {\textbar} {\textbar} wherein the low-level feature extraction combined with the segment-level feature extraction masks out words contained in the speech data such that the segment-level feature data is non-lexical data; {\textbar} {\textbar} applying the segment-level feature data to the decision module that includes a database of one or more classifiers, each classifier from among the classifiers corresponding to a different classification of the speech-identifiable condition; and {\textbar} {\textbar} determining, in the decision module, the classification of the speech-identifiable condition of the subject from the segment-level feature data. {\textbar} {\textbar} 2. The method of {\textbar} claim 1 {\textbar} , wherein the speech-identifiable condition is a mood state of the subject. {\textbar} 3. The method of {\textbar} claim 2 {\textbar} , wherein the subject has bipolar disorder and the mood state comprises one or more of depression, hypomania/mania, and euthymia. {\textbar} 4. The method of {\textbar} claim 3 {\textbar} , wherein the one or more classifiers comprises a classifier for identifying each of depression, hypomania/mania, and euthymia from the speech data. {\textbar} 5. The method of {\textbar} claim 1 {\textbar} , wherein the speech data is unstructured speech data. {\textbar} 6. The method of {\textbar} claim 1 {\textbar} , wherein the speech data is structured speech data. {\textbar} 7. The method of {\textbar} claim 1 {\textbar} , wherein the low-level feature data includes one or more of pitch, energy, spectrum, zero-crossing rate, maximum waveform amplitude value, and minimum waveform amplitude value. {\textbar} 8. The method of {\textbar} claim 1 {\textbar} , wherein the segment-level feature data includes one or more of mean, variance, jitter, and shimmer. {\textbar} 9. The method of {\textbar} claim 1 {\textbar} , wherein each of the plurality of short time segments is 25 ms or less. {\textbar} 10. The method of {\textbar} claim 9 {\textbar} , wherein the window of time is 3 s or greater. {\textbar} 11. The method of {\textbar} claim 10 {\textbar} , wherein the window of time is from 3 s to 30 s. {\textbar} 12. The method of {\textbar} claim 1 {\textbar} , wherein each of the one or more classification rules are support vector machine ({SVMs}). {\textbar} 13. The method of {\textbar} claim 12 {\textbar} , further comprising: {\textbar} developing each of the one or more classifiers based on more than one of the segment-level data. {\textbar} {\textbar} 14. The method of {\textbar} claim 1 {\textbar} , wherein determining, in the decision module, the classification of the speech-identifiable condition of the subject from the segment-level feature data comprises determining an expected future change in the speech-identifiable condition of the subject. {\textbar} 15. The method of {\textbar} claim 1 {\textbar} , wherein the speech-identifiable condition includes one or more of psychiatrically diagnosed conditions, pain, depression, physical conditions, congenital heart disorders, coughing, lung related disorders, lung cancer, oncological disorders, Grave's disease, hearing impairment, neuromuscular disorders, and neurological disorders. {\textbar} 16. A mood detection machine to detect a speech-identifiable condition of a subject, comprising: {\textbar} a processor; {\textbar} {\textbar} a memory; {\textbar} {\textbar} a feature extraction module stored on the memory and adapted to cause the processor to: {\textbar} {\textbar} receive recorded speech data of the subject, the recorded speech data being transmitted by a communication device and recorded by an input of the communication device that receives the speech data for the subject while not receiving speech data for anyone else talking to the subject; {\textbar} {\textbar} perform, on the recorded speech data, a low-level feature extraction over a plurality of short-time segments to develop low-level feature data, and {\textbar} {\textbar} perform a segment-level feature extraction on the low-level feature data over a window of time to develop segment-level feature data, where the window of time comprises the plurality of short time segments contained therein, {\textbar} {\textbar} wherein the low-level feature extraction combined with the segment-level feature extraction masks out words contained in the recorded speech data such that the segment-level feature data is non-lexical data; and {\textbar} {\textbar} a decision module stored on the memory and adapted to cause the processor to: {\textbar} {\textbar} access a database of one or more classifiers, each classifier from among the classifiers corresponding to a different classification of the speech-identifiable condition; and {\textbar} {\textbar} determining the classification of the speech-identifiable condition of the subject from the segment-level feature data. {\textbar} {\textbar} 17. The mood detection machine of {\textbar} claim 16 {\textbar} , wherein the segment-level feature data is non-lexical data. {\textbar} 18. The mood detection machine of {\textbar} claim 16 {\textbar} , wherein the communication device is a cellular phone or a smart phone located remotely with respect to the mood detection machine, and {\textbar} wherein the communication device input is a microphone associated with the communication device. {\textbar} {\textbar} 19. The mood detection machine of {\textbar} claim 16 {\textbar} , wherein the recorded speech data in unstructured speech data. {\textbar} 20. The method of {\textbar} claim 1 {\textbar} , wherein the communication device is a cellular phone or a smart phone located remotely with respect to the mood detection machine, and {\textbar} wherein the communication device input is a microphone. 1. A method of detecting a speech-identifiable condition of a subject, the method comprising: {\textbar} recording speech data of the subject via a communication device input that receives the speech data for the subject while not receiving speech data for anyone else talking to the subject; {\textbar} {\textbar} transmitting, by the communication device, the recorded speech data to a mood detection machine that includes a feature extraction module and a decision module; {\textbar} {\textbar} performing, in the feature extraction module, a low-level feature extraction on the speech data over a plurality of short-time segments to develop low-level feature data; {\textbar} {\textbar} performing, in the feature extraction module, a segment-level feature extraction on the low-level feature data over a window of time to develop segment-level feature data, where the window of time comprises the plurality of short time segments, and {\textbar} {\textbar} wherein the low-level feature extraction combined with the segment-level feature extraction masks out words contained in the speech data such that the segment-level feature data is non-lexical data; {\textbar} {\textbar} applying the segment-level feature data to the decision module that includes a database of one or more classifiers, each classifier from among the classifiers corresponding to a different classification of the speech-identifiable condition; and {\textbar} {\textbar} determining, in the decision module, the classification of the speech-identifiable condition of the subject from the segment-level feature data. 1. A method of detecting a speech-identifiable condition of a subject, the method comprising: {\textbar} recording speech data of the subject via a communication device input that receives the speech data for the subject while not receiving speech data for anyone else talking to the subject; {\textbar} {\textbar} transmitting, by the communication device, the recorded speech data to a mood detection machine that includes a feature extraction module and a decision module; {\textbar} {\textbar} performing, in the feature extraction module, a low-level feature extraction on the speech data over a plurality of short-time segments to develop low-level feature data; {\textbar} {\textbar} performing, in the feature extraction module, a segment-level feature extraction on the low-level feature data over a window of time to develop segment-level feature data, where the window of time comprises the plurality of short time segments, and {\textbar} {\textbar} wherein the low-level feature extraction combined with the segment-level feature extraction masks out words contained in the speech data such that the segment-level feature data is non-lexical data; {\textbar} {\textbar} applying the segment-level feature data to the decision module that includes a database of one or more classifiers, each classifier from among the classifiers corresponding to a different classification of the speech-identifiable condition; and {\textbar} {\textbar} determining, in the decision module, the classification of the speech-identifiable condition of the subject from the segment-level feature data. {STATEMENT} {OF} {GOVERNMENTAL} {INTEREST} {\textbar} {\textbar} This invention was made with government support under {MH}100404 and {TR}000433 awarded by the National Institutes of Health. The Government has certain rights in the invention. {\textbar} {\textbar} {CROSS} {REFERENCE} {TO} {RELATED} {APPLICATION} {\textbar} {\textbar} This application claims the benefit of U.S. Provisional Patent Application No. 61/987,871 entitled “Mood Monitoring Of Bipolar Disorder Using Speech Analysis,” filed May 2, 2014, the disclosure of which is hereby expressly incorporated by reference in its entirety. {\textbar} {\textbar} {BRIEF} {DESCRIPTION} {OF} {THE} {DRAWINGS} {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} illustrates an example system for mood detection that analyzes speech data from a subject and determines a subject's mood based on classifiers determined by or accessed by the system, in accordance with an example. {\textbar} {FIG}. 2 {\textbar} {\textbar} illustrates a process, implemented by the system of {\textbar} {FIG}. 1 {\textbar} , to develop classifiers (i.e., classification rules) for analyzing speech data. {\textbar} {FIG}. 3 {\textbar} {\textbar} illustrates example speech data that is used by the system of {\textbar} {FIG}. 1 {\textbar} in performing low-level feature extraction using millisecond time measurement filters for mood classification, in accordance with an example. {\textbar} {FIG}. 4 {\textbar} {\textbar} is an illustration of a plot indicating an example classifier (i.e., classification rule) as determined by the system of {\textbar} {FIG}. 1 {\textbar} during a training procedure, in an example. {\textbar} {FIELD} {OF} {THE} {INVENTION} {\textbar} {\textbar} The present disclosure relates to assessing patients with speech-identifiable disorders and, more particularly, to monitoring mood of patients with bipolar disorder through speech analysis. {\textbar} {\textbar} {BACKGROUND} {\textbar} {\textbar} The background description provided herein is for the purpose of generally presenting the context of the disclosure. Work of the presently named inventor, to the extent it is described in this background section, as well as aspects of the description that may not otherwise qualify as prior art at the time of filing, are neither expressly nor impliedly admitted as prior art against the present disclosure. {\textbar} {\textbar} Bipolar disorder ({BP}) is a common and severe psychiatric illness characterized by pathological swings of mania and depression and is associated with devastating personal, social, and vocational consequences (suicide occurs in up to 20\% of cases, by some reports). Bipolar disorder is among the leading causes of disability worldwide. The cost in the United States alone was estimated at \$45 billion annually (in 1991 dollars). These economic and human costs, along with the rapidly increasing price of health care provide the impetus for a major paradigm shift in health care service delivery, namely to monitor and prioritize care with a focus on prevention. {\textbar} {\textbar} Speech patterns have been effectively used in clinical assessment for both medical and psychiatric disorders. Clinicians are trained to record their observations of speech and language, which become a critical component of the diagnostic process. Recently, there have been research efforts exploring computational speech analysis as a way to assess and monitor the mental state of individuals suffering from a variety of psychological illnesses, specifically major depression ({MD}), autism, and post-traumatic stress disorder ({PTSD}). {\textbar} {\textbar} For example, stress and anxiety have been studied extensively and elements of speech have been correlated with subjectively reported stress in {PTSD}. Other research efforts have demonstrated the efficacy of speech-based assessments for autism focusing on diagnosis, in addition to predicting the course and severity of the illness. Variations in speech patterns have also been used for computational detection and severity assessment in major depressive disorder. {\textbar} {\textbar} However, most work in these areas focuses on the assessment of participants over short periods of time, at most several weeks, rendering it challenging to measure the natural fluctuations that accompany illness trajectories. Additionally, the speech input is often highly structured and collected in controlled environments. This limitation in speech collection precludes an understanding of how acoustic patterns characteristic of natural speech variation correlate with mood symptomology. {\textbar} {\textbar} {SUMMARY} {\textbar} {\textbar} The present techniques provide for estimating the mood state (including affect) of individuals with neurological disorders, like bipolar disorder ({BP}). Bipolar disorder is characterized by fluctuating mood state, including periods of depression (lowered mood state), mania (elevated mood state), and euthymia (neither mania nor depression). We monitored patients over the course of six months to a year, using normal conversation analysis, to assess the dynamic nature of the symptoms of {BP}. In addition to mood state, the present techniques can identify, more broadly, the mental state or neurophysiological state of a subject associated with speech-identifiable conditions. {\textbar} {\textbar} As we show, the techniques were successful in detecting the presence of mania and depression in normal, unobtrusive, and unstructured speech-based communications of individuals. We were able to assess the underlying mood of the individual from the speech collected. As described, the techniques, as applied, provide evidence that mood-related variations recorded both from structured and unstructured speech-based communications (e.g., cell phone conversation data) are reflective of underlying mood symptomology and that the acoustic variations indicative of mood patterns across these conversation types differ. {\textbar} {\textbar} The present techniques are also able to highlight the features of the speech that are most correlated with the clinical assessment of manic and depressive mood states. {\textbar} {\textbar} The techniques herein provide for longitudinal, ecological (e.g., with minimally added effort and fitting within the daily routine of the subject), and continuous collection of unstructured speech in diverse environments and in the acoustic analysis of the {BP} participant population that exhibit dimensional mood-states with two extremes of a continuous mood-state spectrum: depression and mania. These results show that this style of data collection can be effectively used, highlighting the potential for autonomous ecologically valid monitoring for mental health assessment. {\textbar} {\textbar} In accordance with an example, a method of detecting a speech-identifiable condition of a subject, the method comprises: receiving speech data of the subject; performing, in a feature extraction module, a low-level feature extraction on the speech data over a plurality of short-time segments to develop low-level feature data; performing, in the feature extraction module, a statistical analysis of the low-level feature data over a window of time to develop segment-level feature data, where the window of time comprises the plurality of low-level feature time segments contained therein, and wherein the segment-level feature data is non-lexical data; applying the segment-level feature data to a decision module having a database of one or more classification rules, each classification rule corresponding to a different classification of the speech-identifiable condition; and determining, in the decision module, the classification of the speech-identifiable condition of the subject from the segment-level feature data. {\textbar} {\textbar} In accordance with another example, a system to detect a speech-identifiable condition of a subject, the system comprises: a processor; a memory; a feature extraction module stored on the memory and adapted to cause the processor to, perform, on speech data, a low-level feature extraction over a plurality short-time segments to develop low-level feature data, and performing a statistical analysis of the low-level feature data over a window of time to develop segment-level feature data, where the window of time comprises the plurality of low-level feature time segments contained therein, and wherein the segment-level feature data is non-lexical data; and a decision module stored on the memory and adapted to cause the processor to, access a database of one or more classification rules, each classification rule corresponding to a different classification of the speech-identifiable condition; and determining the classification of the speech-identifiable condition of the subject from the segment-level feature data. {\textbar} {\textbar} {DETAILED} {DESCRIPTION} {\textbar} {\textbar} Described herein is a new framework for ecological long-term monitoring of mood states for individuals with bipolar disorder. The techniques provide ecological data collection that does not request subjects to interact in constrained clinical environments but rather monitors subjects during normal conversation. The techniques, unlike speech recognition (and related technologies), provide non-lexical monitoring and analysis of subjects. Speech data is analyzed over short-time windows and then a statistical analysis is applied that makes lexical reconstruction either extremely difficult or not available. This provides subjects with a level of privacy against speech (lexical) reconstruction, which may also allow for more natural speech for the subject and thus more accurate monitoring and assessment of mood state. This promotes more continuous use of the techniques, which allows for increased probability of predicting a mood shift, as the subject will be encouraged to use the technique all the time. The techniques here promote personalized classifiers of mood state, allowing subjects to have tailored monitoring and assessment of current and predicted future mood states. Moreover, the techniques are extensible to any number of speech-identifiable ailments and conditions. {\textbar} {\textbar} More specifically, the techniques herein involve collecting speech data, using a collection paradigm and developing a classification rule (or vector or separator or hyperplane or decision boundary) or set of classification rules to classify one or more mood states of the subject providing that speech data. The classification rule may then be used to assess current mood state or, in some instances, predicted instability or a change in future mood state. The results, as we show for example subjects with bipolar disorder, demonstrate that mania, hypomania (i.e., a lower level of intensity of manic symptoms), and depression can be differentiated from euthymia using speech-based classifiers trained on both structured interactions (e.g., monitoring weekly clinical speech-based interactions) and unstructured (e.g., monitoring normal patient telephone calls) cell phone recordings. By assessing structured interactions to identify a patient's mood and labeling those moods, we demonstrate that the present techniques can produce classification rules that detect (or classifications that indicate) the presence of hypomania when performing speech-analysis of only unstructured data collected. Classification rules for mania, hypomania, and depression have been developed. The classification rule is an example of a classifier; and the techniques herein may be used to train classifiers more broadly. {\textbar} {\textbar} {EXAMPLE} {\textbar} {\textbar} Experimental Setup {\textbar} {\textbar} In developing the assessment method and systems herein, we developed an acoustic database (termed {UM}-{AD} herein), which contains longitudinally collected speech from individuals diagnosed with bipolar disorder participating as part of a bipolar longitudinal study (the Prechter {BP} Longitudinal Study), which is a multi-year study that takes a multidimensional, biological, clinical, and environmental, approach to the study of bipolar disorder. {\textbar} {\textbar} {UM}-{AD} includes speech data collected from six participants, four women and two men (average age 41±11.2) diagnosed with bipolar disorder type I and with a history of rapid cycling, characterized by 4 or more episodes per year of mania, hypomania, or depression. Participants are recruited from the {BP} longitudinal study and enrolled for 6 months to a year. {\textbar} {\textbar} For the initial protocol, each participant was provided with a smart phone mobile device and an unlimited call/data plan for personal use and encouraged to use the phone as their primary mode of contact. While a smart-phone was used in the described example, the present techniques may be implemented through any speech-based device, whether involving conversational speech, between two people, or a device measuring speech of a single person, for example, talking into a recording device. The speech device may be self-contained, that is, performing recording, storage, and speech analysis. But in the examples detailed below, one or more of these operations (recording, storage, or analysis) is performed over distributed processing devices/systems connected to each other over a network, wired or wireless connection. Some example speech-based devices include are illustrated in {\textbar} {\textbar} {FIG}. 1 {\textbar} . {\textbar} In any event, for this discussed example, a smart phone was pre-loaded with an application (stored on a computer readable memory in the smart phone and executable by one or more processors therein) that instructs the smart phone to record only the participant's outgoing speech (i.e., no incoming speech is captured or recorded). The application automatically launches on the smart phone and runs persistently. The speech is stored on the smart phone at a recorded frequency, e.g., 8 {KHz}, and occurs whenever the participant makes or receives a phone call. The collected speech is then encrypted on the smart phone and securely transmitted over a network to an external processing system for analysis. The application, data transfer, and data handling followed strict security and encryption guidelines to ensure that the integrity and privacy of the collected data is not compromised. {\textbar} {\textbar} During a training/testing protocol, weekly mood-state labels were determined for subjects. For example, ground truth measures of a participant's mood-state were obtained using weekly phone-based interactions with a clinician associated with this project. These interactions were structured (also termed constrained) and involved a clinician administering a twenty-minute recorded assessment that measured the mood-state of the participant over the past week. The assessments included the 17-item Hamilton Rating Scale for Depression ({HAMD}) as well as the Young Mania Rating Scale ({YMRS}) to assess the level of depression and mania, respectively. In the example experiment, no participant exhibited symptom severity associated with a manic episode. Therefore, for this particular implementation, detection of hypomania (elevated mood state not reaching the severity of mania) was the objective. {\textbar} {\textbar} The mood assessment labels were categorized using thresholds set by the clinical team. The final labels were as follows: Hypomanic: {YMRS}{\textgreater}10 and {HAMD}{\textless}10. Depressed: {HAMD}{\textgreater}10 and {YMRS}{\textless}10. Euthymic: {YMRS}{\textless}6 and {HAMD}{\textless}6. Mixed: {YMRS}{\textgreater}10 and {HAMD}{\textgreater}10. The mixed mood-state was not included in this particular example, due to its rarity in the collected data. {\textbar} {\textbar} The weekly clinical assessments (“evaluation call”) provide a measure both of the participant's mood-state over the past week and of the clinician's perception of the participant's current (during evaluation call) mood-state. From this data, we sought to examine the hypothesis that the labels obtained during an evaluation call will be most strongly associated with the participant's mood during that evaluation call and thus with the mood-related modulations of the speech recorded during the call. We further sought to examine the hypothesis that the set of calls disjoint from the evaluation calls, i.e., the unstructured calls recorded outside of a clinical interaction, will possess a more subtle expression of mood symptomology, may involve masking of symptomology, but will, under our examination techniques, correlate (albeit less strongly) with the clinically assessed labels. {\textbar} {\textbar} Statistics on Recorded Calls: A total of 221.2 hours was recorded from 3,588 phone calls. On average participants made 4.9±4.3 calls per day, with an average duration of 222.0±480.7 seconds and a median of 67.4 seconds. {\textbar} {\textbar} The number of weeks of data available varied by participant: participant 1 had 31 weeks of data, while participant {\textbar} {\textbar} 5 {\textbar} had 6 weeks of data, for example. Each participant's data included euthymic weeks and at least one hypomanic and/or depressive week. Table 1 provides an overview of the collected data for each participant, showing the number of weeks of collected data with categorized assessment labels of euthymic, hypomanic, and depressive. {\textbar} {TABLE} 1 {\textbar} {\textbar} Summary of collected data. \#E, \#H, \#D are the number {\textbar} {\textbar} of weeks in Euthymic, Hypomanic, and Depressive states. {\textbar} {\textbar} Part. \# {\textbar} {\textbar} 1 {\textbar} {\textbar} 2 {\textbar} 3 {\textbar} 4 {\textbar} 5 {\textbar} 6 {\textbar} \#(E:H:D) {\textbar} {\textbar} 22:2:7 {\textbar} 9:0:4 {\textbar} 21:1:3 {\textbar} 10:9:1 {\textbar} 2:4:0 {\textbar} 3:0:4 {\textbar} The experiment sought to use the speech data collected in an unobtrusive manner and in unstructured environments to: (1) estimate the clinical assessment made during the participant-clinician weekly evaluation call; (2) determine the feasibility of detecting the mood state assessed during the evaluation call using unstructured personal cell phone (i.e., “smart phone”) recordings from the same day as the evaluation call; and (3) apply this detection to cell phone recordings from days preceding or following the evaluation call. The experiment also conducted feature analyses to identify the speech features that are most informative for mood classification. {\textbar} {\textbar} Datasets: The {UM}-{AD} dataset was partitioned based on proximity to evaluation call. Recall that the evaluation calls are the only recordings that are labeled. Further, the temporal consistency of mania and depression are variable and person dependent. Therefore, it was expected that the labels of the evaluation call are more strongly associated with calls recorded on the day of the evaluation as opposed to the day(s) before or after it. {\textbar} {\textbar} The data was partitioned into the following disjoint datasets. Table 2 describes the per-participant summary of the number of calls assigned each of the three labels. The datasets include: {\textbar} {\textbar} Evaluation calls: Speech collected during evaluation calls labeled as hypomanic/depressed/euthymic based on the clinical assessment. {\textbar} Day-of calls: Speech collected from all calls recorded on the day of the clinical assessment, excluding the evaluation call. {\textbar} Day before/after (B/A) calls: Speech collected from all calls made or received only on the adjacent day (before or after). {\textbar} {TABLE} 2 {\textbar} {\textbar} Number of calls assigned each of the categorical labels: {\textbar} {\textbar} Part. \# {\textbar} {\textbar} 1 {\textbar} {\textbar} 2 {\textbar} 3 {\textbar} 4 {\textbar} 5 {\textbar} 6 {\textbar} Eval {\textbar} {\textbar} Euthymic {\textbar} 18 {\textbar} 8 {\textbar} 21 {\textbar} 6 {\textbar} 1 {\textbar} 2 {\textbar} Hypomanic {\textbar} {\textbar} 2 {\textbar} 0 {\textbar} 1 {\textbar} 3 {\textbar} 3 {\textbar} 0 {\textbar} Depressed {\textbar} {\textbar} 6 {\textbar} 4 {\textbar} 3 {\textbar} 1 {\textbar} 0 {\textbar} 3 {\textbar} Day-Of {\textbar} {\textbar} Euthymic {\textbar} 52 {\textbar} 227 {\textbar} 127 {\textbar} 11 {\textbar} 10 {\textbar} 17 {\textbar} Hypomanic {\textbar} {\textbar} 13 {\textbar} 0 {\textbar} 5 {\textbar} 14 {\textbar} 11 {\textbar} 0 {\textbar} Depressed {\textbar} {\textbar} 22 {\textbar} 114 {\textbar} 21 {\textbar} 1 {\textbar} 0 {\textbar} 22 {\textbar} Day-B/A {\textbar} {\textbar} Euthymic {\textbar} 77 {\textbar} 202 {\textbar} 271 {\textbar} 25 {\textbar} 5 {\textbar} 60 {\textbar} Hypomanic {\textbar} {\textbar} 7 {\textbar} 0 {\textbar} 11 {\textbar} 22 {\textbar} 12 {\textbar} 0 {\textbar} Depressed {\textbar} {\textbar} 29 {\textbar} 100 {\textbar} 47 {\textbar} 2 {\textbar} 0 {\textbar} 41 {\textbar} Training Methodology: The techniques included training classification algorithms based collected data, including the labels of the structured speech data. In this example implementation, the classification algorithms were trained using participant-independent modeling, capturing the variations associated with populations of individuals, rather than specific individuals. For the initial test of viability, the goal of participant-independent modeling was to understand how speech is modulated as a function of mood state while mitigating the effects of individual variability. We tested our models using the leave-one-participant-out cross-validation framework, where each participant is held out for testing and the remaining participants are used for training. The validation set is obtained using leave-one-training-participant out cross-validation within the training set. We trained the models using all data from the categories of euthymia, hypomania, and depression. We evaluated the performance of our depression and hypomania classifiers only for participants with at least two weeks of evaluation calls labeled as either depressed or hypomanic. {\textbar} {\textbar} We protected the privacy of the participants given the sensitive nature of speech collected from personal phone calls. This was done through the use of statistics extracted from low-level audio features, rather than from using the features themselves. The statistics were calculated over windows of time longer than approximately 3 seconds, and in some examples from 3 seconds to 30 seconds, although the exact statistical window is not limited to this range. By applying a statistical window to our extraction and classification modeling, we developed a technique that obscured the lexical content of the original speech, rendering it extremely challenging to reconstruct the individual words. In some instances, reconstruction is not possible. {\textbar} {\textbar} As discussed further below, we use a feature extraction module to extract low-level features. For example, in an implementation, we extracted 23 low-level features ({LLF}) using the {openSMILE} toolkit. For each recorded call, the speech data was first windowed into 25 ms frames overlapping by 15 ms, with the following (short-time) features extracted per frame: {\textbar} {\textbar} Pitch, computed using the autocorrelation/cepstrum method, which yields the pitch over voiced windows. For unvoiced windows the pitch was set to 0. Whether a window was voiced was determined by a voicing probability measure, which we also include in the {LLF}. {\textbar} {RMS} energy, zero-crossing rate, and the maximum and minimum value of the amplitude of the speech waveform. {\textbar} Three voiced activity detection ({VAD}) measures: fuzzy, smoothed, binary. The fuzzy measure is computed using line-spectral frequencies, Mel spectra, and energy. The smoothed measure is the result of smoothing the fuzzy measure using a 10-point moving average. The binary measure is a 1/0 feature, determined by thresholding the fuzzy measure to assess presence of speech. The magnitude of Mel spectrum over 14 bands ranged from 50 Hz to 4 {KHz}. {\textbar} The low-level (short time) ({LLF}) features include pitch, voicing probability, {RMS} energy, zero-crossing rate, max/min amplitude, fuzzy voiced activity detection ({VAD}), smoothed {VAD}, binary {VAD}, +14 features from 14 band Mel-spectrum. {\textbar} {\textbar} From these low-level feature extractions, statistical extractions were performed (what we term segment-level feature extractions). The {VAD} measures and voicing probability provide an estimate of the location of speech and silence regions of the input speech waveform. We used these measures to group the speech into contiguous segments of participant speech ranging from 3 seconds to at most 30 seconds. We divided the call into segments by finding non-overlapping regions of at least 3 seconds. We first identified 3 consecutive frames whose energy, voicing probability, and fuzzy {VAD} were all above the 40 {\textbar} {\textbar} th {\textbar} percentile of their values over the whole call. We ended a segment when 30 consecutive frames had energy, voicing probability, and fuzzy {VAD} measures that fell below the 40 {\textbar} th {\textbar} percentile of their values over the whole call. If the segment length exceeded 30-seconds before reaching the stopping criteria, then the segment was ended and a new one started; this occurred for less than 3.5\% of the segments. Each call had on average 24.3±46.6 segments with a median of 8. {\textbar} We represented each segment by a 51-dimensional feature vector obtained from the statistics of the {LLFs} over the segment. This included 46 mean and standard deviation values of each {LLF} computed over the segment (for the pitch, these were computed only for frames with voiced speech), the segment length, and 4 segment-level features: relative and absolute jitter and shimmer measures. Each recorded call, C {\textbar} {\textbar} i {\textbar} , is represented by N {\textbar} i {\textbar} feature vectors, where N {\textbar} i {\textbar} is the number of segments for call i. {\textbar} Analysis of the segment-level features led to the development of classifier rules to determine the mood state of a subject. The classifier used in this example analysis was a support vector machine ({SVM}) with linear and radial-basis-function ({RBF}) kernels, implemented using {LIBLINEAR} and {LIBSVM}, respectively. The {RBF} kernel parameter was tuned over the range γε\{0.0001, 0.001, 0.01, 0.1, 1\} on the participant-independent validation set. The regularization values were tuned for both the linear and {RBF} implementations over the set Cε\{100, 10, 1, 0.1, 0.01\}. The classifiers were trained on the segment-level 51-dimensional features. {\textbar} {\textbar} For each test call (C {\textbar} {\textbar} i {\textbar} ), we independently classified each of its N {\textbar} i {\textbar} segments s {\textbar} i,j {\textbar} (j=1, . . . N {\textbar} i {\textbar} ). A test call could be either 1) a structured assessment call that is used to gather objective clinical assessment data for the purpose of establishing ground truth, or 2) an unstructured personal call that occurs “ecologically” in the course of daily life of the individual. For each segment, we calculated its signed distance to the hyperplane, d {\textbar} i,j {\textbar} . We aggregated each distance into a vector D {\textbar} i {\textbar} . The score for each call was associated with the p {\textbar} th {\textbar} percentile of D {\textbar} i {\textbar} . The percentile was chosen using the validation set over the range pε\{10, 20, 30, 40, 50, 60, 70, 80, 90\}. {\textbar} The techniques demonstrated efficacy in differentiating between hypomanic and euthymic as well as depressed and euthymic speech using a participant-independent training, testing, and validation methodology. Performance was evaluated using the call-level area under the receiver operating characteristic curve ({AUC}). {\textbar} {\textbar} Evaluation of Datasets: Table 3 presents the results across the three datasets. The results demonstrate that we are able to detect the mood state of individuals for calls recorded during the clinical interactions. For the first call type, i.e., the structured assessment call speech data, we obtained an average {AUC} of 0.81±0.17 in detecting hypomania and an average {AUC} of 0.67±0.18 in detecting depression across all participants. {\textbar} {\textbar} We use two training scenarios for the calls recorded on the day of the evaluation and the days before/after the evaluation (the unstructured datasets): (1) classifier training using only the evaluation call dataset, testing on both unstructured datasets; and (2) classifier training over each unstructured dataset individually and testing with held out parts of the same dataset (e.g., training and testing on the day-of assessment calls). Method one asserts that the acoustic modulations that are indicative of mood state in the evaluation call will also be present in the unstructured calls, even if they are subtler. Method two asserts that even if the symptomology is present in the unstructured calls, the modulations may be different from those exhibited in the evaluation call. Therefore, in order to detect the mood state, the acoustic patterns in the unstructured data must be modeled directly. If the performance between methods one and two is similar, there is evidence for modulation consistency. If method two outperforms method one, there is evidence for modulation variability. {\textbar} {\textbar} {TABLE} 3 {\textbar} {\textbar} Call-level {AUC} of binary modd-state classification. Train:Test {\textbar} {\textbar} indicates which dataset (Evaluation (Eval), Day-of ({DOf}), Day- {\textbar} {\textbar} B/A ({BD}/A)), was used for training and which for testing: {\textbar} {\textbar} Part. \# {\textbar} {\textbar} Train:Test {\textbar} {\textbar} 1 {\textbar} 2 {\textbar} 3 {\textbar} 4 {\textbar} 5 {\textbar} 6 {\textbar} μ ± σ {\textbar} Hypomanic vs Euthymic {\textbar} {\textbar} Eval: Eval {\textbar} {\textbar} .78 {\textbar} — {\textbar} — {\textbar} .67 {\textbar} 1.0 {\textbar} — {\textbar} .81 ± .17 {\textbar} Eval:{DOf} {\textbar} {\textbar} .69 {\textbar} — {\textbar} — {\textbar} .63 {\textbar} .51 {\textbar} — {\textbar} .61 ± .09 {\textbar} {DOf}:{DOf} {\textbar} {\textbar} .66 {\textbar} — {\textbar} — {\textbar} .50 {\textbar} .79 {\textbar} — {\textbar} .65 ± .14 {\textbar} Eval:{DB}/A {\textbar} {\textbar} .48 {\textbar} — {\textbar} — {\textbar} .52 {\textbar} .43 {\textbar} — {\textbar} .47 ± .05 {\textbar} {DB}/A:{DB}/A {\textbar} {\textbar} .41 {\textbar} — {\textbar} — {\textbar} .62 {\textbar} .57 {\textbar} — {\textbar} .53 ± .11 {\textbar} Depressed vs Euthymic {\textbar} {\textbar} Eval: Eval {\textbar} {\textbar} .42 {\textbar} .82 {\textbar} .78 {\textbar} — {\textbar} — {\textbar} .67 {\textbar} .67 ± .18 {\textbar} Eval:{DOf} {\textbar} {\textbar} .49 {\textbar} .60 {\textbar} .43 {\textbar} — {\textbar} — {\textbar} .43 {\textbar} .49 ± .08 {\textbar} {DOf}:{DOf} {\textbar} {\textbar} .68 {\textbar} .68 {\textbar} .40 {\textbar} — {\textbar} — {\textbar} .60 {\textbar} .59 ± .13 {\textbar} Eval:{DB}/A {\textbar} {\textbar} .5 {\textbar} .47 {\textbar} .42 {\textbar} — {\textbar} — {\textbar} .61 {\textbar} .52 ± .09 {\textbar} {DB}/A:{DB}/A {\textbar} {\textbar} .50 {\textbar} .52 {\textbar} .53 {\textbar} — {\textbar} — {\textbar} .34 {\textbar} .52 ± .13 {\textbar} The results in Table 3 demonstrate that both method one and method two can be used to detect hypomania during the second call type data (i.e., unstructured personal calls) recorded on the day of the evaluation with an {AUC} of 0.61±0.09 and 0.65±0.14, respectively. The {AUC} for detecting depression was 0.49±0.08 and 0.59±0.13, for methods one and two, respectively. The results suggest that most individuals express mania and depression differently in clinical interactions compared to their personal life. {\textbar} {\textbar} Most Informative Features: We examined the segment-level features that are most informative for classification using feature selection to further our understanding for how speech is affected by hypomanic and depressed mood states. To increase the robustness of the feature selection, we combined the two best performing datasets: evaluation calls and day-of calls, into a single set that contains all calls recorded on the day of the assessment. We performed feature selection using the leave-one-subject-out cross-validation paradigm using greedy forward feature selection for each of the hypomanic vs. euthymic and the depressed vs. euthymic classification problems. The selection only includes features that improve the average and minimum training participant segment-level {AUCs} and terminates when a further addition no longer yields improvement. The selected features were then used to train a classifier which was evaluated on the held out test participant. {\textbar} {\textbar} The feature selection process yields different sets of features for each held out participant. Overall, the hypomanic vs. euthymic selection yields an average of 8.3±5.7 features and depressed vs. euthymic 5.2±4.0 features. Of the selected features, the segment-average of the binary {VAD} was common to all cross-validation folds for both hypomanic and depressed vs. euthymic. An additional three features were common to 3 out of 4 folds of hypomanic classification: standard deviation of the pitch, segment-average of the zero-crossing rate and of the smoothed {VAD}. While there were two additional features common to 3 of the 5 folds in the depressed classification: absolute jitter and the segment-average of the magnitude of Mel spectrum over the first band. Table 4 presents the resulting call-level {AUCs} for classifiers trained with only the selected features as well as those trained with all 51 features. The 51 segment-level features include mean of each of the {LLF} features, standard deviation of each of the {LLF} features, segment length, relative jitter, absolute jitter, relative shimmer, and absolute shimmer. {\textbar} {\textbar} {TABLE} 4 {\textbar} {\textbar} Call-level {AUC} of binary mood-state classification {\textbar} {\textbar} using all features or only selected features: {\textbar} {\textbar} Part. \# {\textbar} {\textbar} Train:Test {\textbar} {\textbar} 1 {\textbar} 2 {\textbar} 3 {\textbar} 4 {\textbar} 5 {\textbar} 6 {\textbar} μ ± σ {\textbar} Hypomanic vs Euthymic {\textbar} {\textbar} All Feats {\textbar} {\textbar} .61 {\textbar} — {\textbar} — {\textbar} .37 {\textbar} .84 {\textbar} — {\textbar} .61 ± .24 {\textbar} Sel. Feats {\textbar} {\textbar} .63 {\textbar} — {\textbar} — {\textbar} .59 {\textbar} .67 {\textbar} — {\textbar} .63 ± .04 {\textbar} Depressed vs Euthymic {\textbar} {\textbar} All Feats {\textbar} {\textbar} .62 {\textbar} .65 {\textbar} .42 {\textbar} — {\textbar} — {\textbar} .65 {\textbar} .59 ± .11 {\textbar} Sel. Feats {\textbar} {\textbar} .63 {\textbar} .82 {\textbar} .43 {\textbar} — {\textbar} — {\textbar} .67 {\textbar} .64 ± .16 {\textbar} The results demonstrate that with robust feature selection it is possible to separate euthymic speech from hypomanic and depressed mood states using on average approximately 5-8 segment-level features. Thus, feature selection improves our ability to detect depression, while reducing the variance across participants in the detection of hypomania, and thus improves the classification rules we develop. {\textbar} {\textbar} The feature selection results highlight the importance of the average binary {VAD} for the detection of hypomanic and depressed moods. The mean binary {VAD} is correlated with the vocalization/pause ratio measure, which has been shown to be lower for depressed speech. Our examination of this measure showed a similar pattern for depressed speech, and also that it tends to be higher for hypomanic speech: we do this by first removing all instances of the feature ≧90\% since a majority of the segments tend to be significantly voiced regardless of the label, and find that the feature is lowest for depressed (median(M)=0.51μ±σ=0.46±0.32), higher for euthymic (M=0.63μ±σ=0.52±0.33), and the highest for hypomanic (M=0.76μ±σ=0.69±0.21). {\textbar} {\textbar} As we show, the techniques provide a cost effective way to collect and scale continuous, unobtrusive speech data, from which the techniques monitor and assess mood of a subject. We can analyze non-clinical speech data, i.e., normal phone calls of a subject. In the discussed examples, subjects with bipolar disorder were examined, and different rules for mood states for hypomania, mania, and depression were developed. However, the above implementations are provided by way of example. The present techniques may be implemented in other ways and to identify any number of speech-affected conditions using rules based or other classifiers. Moreover, classification rules are developed for determining mood states in these examples; however, the classification rules may be to detect any number of states of health of patient. Such detections can be affected from using one or both of a low-level and segment-level feature extraction and analysis. The present techniques are extensible and may be used to develop classification rules for other conditions, including psychiatrically diagnosed conditions, pain, depression, physical conditions such as asthma, congenital heart disorders, coughing, lung related disorders, lung cancer, oncological disorders, grave's disease, hearing impairment, neuromuscular disorders, and neurological disorders. {\textbar} {\textbar} The techniques can be used to produce a personalized signature, as a classification rule tailored for each subject. The techniques operate from statistical analysis over long chronological periods of very short time-interval measurements. In this way, the techniques may be lexicon-neutral—they don't need a patient to speak specific words or words at all. Classification rules can look at private, non-lexical speech data, from statistical measures over longer windows of time of features extracted from miniature milliseconds of filtered speech within that window. The techniques can monitor and assess changes in speech over the window periods of time, without doing any speech recognition or short-time speech pattern matching and lexical information analysis. And the techniques are able to do this from ecological speech data, i.e., collected during normal speech and daily life of the subject. {\textbar} {\textbar} The techniques allow for near real time predictions of current mood state and can be used to predict the onset of changes in mood state with suitable classification rules developed from the speech data. This ability to predict mood onset can be used to flag health care providers and subjects themselves (and family and friends) when their speech data from normal conversations suggests that a change in mood is approaching, whether at that moment, an hour into the future, a day, several days, or otherwise. {\textbar} {\textbar} {FIG}. 1 {\textbar} {\textbar} illustrates an example system {\textbar} 100 {\textbar} for mood detection of a subject {\textbar} 102 {\textbar} . In the illustrated example, the subject {\textbar} 102 {\textbar} is described as having diagnosed bipolar disorder, although the system may be used to detect mood and other speech-identifiable condition state for any subject. The subject {\textbar} 102 {\textbar} communicates via speech through a communication device {\textbar} 104 {\textbar} that is adapted to collect and store speech data, for communication to a mood detection machine {\textbar} 106 {\textbar} , through a network {\textbar} 108 {\textbar} . The communication device {\textbar} 104 {\textbar} may be a cellular or mobile phone {\textbar} 104 {\textbar} a {\textbar} , smart phone {\textbar} 104 {\textbar} b {\textbar} , or landline telephone {\textbar} 104 {\textbar} c {\textbar} . In other examples, the device {\textbar} 104 {\textbar} may be a laptop computer {\textbar} 104 {\textbar} d {\textbar} or desktop computer {\textbar} 104 {\textbar} e {\textbar} , {\textbar} 104 {\textbar} f {\textbar} , with speech collection capabilities, e.g., a microphone. The device {\textbar} 104 {\textbar} may store the speech data and encrypt that speech data, e.g., using a public-key encryption protocol, before transmitting it to the detection machine {\textbar} 106 {\textbar} . {\textbar} The mood detection machine {\textbar} {\textbar} 106 {\textbar} contains a communication interface {\textbar} 110 {\textbar} for communicating over the network {\textbar} 108 {\textbar} and collecting speech data collected from the device {\textbar} 104 {\textbar} . The machine {\textbar} 106 {\textbar} further includes a central processing unit {\textbar} 112 {\textbar} for executing instructions such as those from applications stored on a memory {\textbar} 114 {\textbar} . The memory {\textbar} 114 {\textbar} includes a feature extraction module {\textbar} 116 {\textbar} , a mood-state classification module {\textbar} 118 {\textbar} , ground truth module {\textbar} 120 {\textbar} , and mood-state decision module {\textbar} 122 {\textbar} . The memory further includes a speech data memory {\textbar} 124 {\textbar} that stores received speech data from the device {\textbar} 104 {\textbar} , such as, for example, structure and unstructured voice call recordings. The recordings can be created at the device {\textbar} 104 {\textbar} and transmitted over the network {\textbar} 108 {\textbar} to the machine {\textbar} 106 {\textbar} ; while in other examples, such as for analysis of real time phone calls, speech (i.e., voice) data may be received at the communication interface {\textbar} 110 {\textbar} continuously during a conversation, albeit preferably still by using encryption to deliver the data in real time. From here, the module {\textbar} 116 {\textbar} may store, in real time, the received speech data in the memory {\textbar} 124 {\textbar} . In some examples the machine {\textbar} 106 {\textbar} and the device {\textbar} 104 {\textbar} may be integrated as part of a single device. For example, all recording, feature extraction, and classification processes herein may be performed on a smart phone. {\textbar} {FIG}. 2 {\textbar} {\textbar} illustrates a process {\textbar} 200 {\textbar} that may be implemented by the system {\textbar} 100 {\textbar} of {\textbar} {FIG}. 1 {\textbar} , specifically in a training example, where the system {\textbar} 100 {\textbar} is developing classification rules to be applied to ecological speech data. The process {\textbar} 200 {\textbar} includes a training procedure by which a first call type is used and assessed to determine a baseline mood state correlating to collected speech data, i.e., the mood state for the subject {\textbar} 102 {\textbar} with {BP}. At a block {\textbar} 202 {\textbar} , the process {\textbar} 200 {\textbar} begins by conducting the first call type. This call may be a voice call where the speech of the participant is examined in a structured (i.e., constrained) environment, meaning an environment in which the nature of the call and at least some of what is discussed or elicited is established in a pre-structured manner, by a health care professional or other professional charged with assisting in the direct examination of the subject {\textbar} 102 {\textbar} . The block {\textbar} 202 {\textbar} may be implemented by the subject {\textbar} 102 {\textbar} calling in to a professional using the device {\textbar} 104 {\textbar} , where the professional is connected to the network {\textbar} 108 {\textbar} separately or through the machine {\textbar} 106 {\textbar} . When a structured call, the first call type will be designed to allow the professional sufficient data to assess the mood state. For example, the structured call may be set to a predetermined minimum length, may include a structured conversation, questions/answers, uttering a given phrase, using a long set of vowels, etc. to allow for assessment. {\textbar} While a call is illustrated (at the block {\textbar} {\textbar} 202 {\textbar} ), instead the speech may be from direct, in-person interaction between the subject and the professional, for example, having the subject {\textbar} 102 {\textbar} visit the offices of the professional using the machine {\textbar} 106 {\textbar} . {\textbar} In any event, at a block {\textbar} {\textbar} 204 {\textbar} , the process {\textbar} 200 {\textbar} enters into a baselining procedure, where the process {\textbar} 200 {\textbar} determines a ground truth or initial mood state of the individual. For example, at the block {\textbar} 204 {\textbar} , the process {\textbar} 200 {\textbar} may assess a first call to identify a mood state of the subject. This may occur in a completely manual process, with the professional making an objective determination of mood state from their professional experience in assessing speech patterns and making such diagnoses. In other examples, the block {\textbar} 204 {\textbar} may be implemented in a partially manual and partially automated manner, for example, with the professional collecting speech information and providing some guidelines to a detection system (such as the system {\textbar} 106 {\textbar} ) that then determines the mood state based on the speech data and the professional's input. In yet other examples, the block {\textbar} 204 {\textbar} may be implemented entirely automatically, as occurs with the block {\textbar} 214 {\textbar} described further below. In the example of ground truth, the mood state data can be obtained by short messaging service ({SMS}) or email questionnaire or through an application on the device {\textbar} 104 {\textbar} , e.g., that shows different pictures and asks which picture best represents how the subject feels. {\textbar} The ground truth assessment module {\textbar} {\textbar} 120 {\textbar} assesses the first call type and provides an identified mood state (e.g., for bipolar subjects—depression (lowered mood state), and hypomania (elevated mood state)) to the mood-state classification module {\textbar} 118 {\textbar} which stores the identified mood state. The ground truth assessment may be from an expert assessment, self-assessment of the subject, from a hospitalization assessment of the subject, or otherwise. {\textbar} The blocks {\textbar} {\textbar} 202 {\textbar} - {\textbar} 206 {\textbar} provide a baselining portion of a training mode of the process {\textbar} 200 {\textbar} . {\textbar} Later, a second call type data is received at a block {\textbar} {\textbar} 208 {\textbar} . This call type data can result from an actual phone call, i.e., with the subject {\textbar} 102 {\textbar} using the device {\textbar} 104 {\textbar} and calling over the network {\textbar} 108 {\textbar} . Such data may be received real time, where the system device {\textbar} 104 {\textbar} is adapted to monitor, record, and transmit over the network {\textbar} 108 {\textbar} the speech of the subject {\textbar} 102 {\textbar} in real time. The call data may be speech data stored on the device {\textbar} 104 {\textbar} and encrypted and sent to the machine {\textbar} 106 {\textbar} at period times or in response from polling from the machine, either automatically in response to polling or after the device receives the polling request, notifies the subject, and the subject authorizes transmission. The call data may result from an evaluation call or a personal call of the subject. {\textbar} In any event, the device {\textbar} {\textbar} 104 {\textbar} may be adapted to send only the speech of the subject {\textbar} 102 {\textbar} and not that of the other person (or persons) on the telephone call with the subject. This will not only avoid privacy concerns, and some limitations against recording of others, but it will provide cleaner speech data, data without need of specific voice filtering or removal. If the device {\textbar} 104 {\textbar} is recording a live conversation between the subject in-person with another, then the device {\textbar} 104 {\textbar} may be adapted to record only the speech of the subject (e.g., through collecting speech data using a wireless or wired headset and microphone). In other examples, all speech data from the call may be recorded, whether structured or unstructured, for all the subjects and then the desired subject speech data is filtered out for analysis. It is noted that the reference to speech data as used herein includes all voice related data for a subject, whether that voice data is in discernible speech or fragments of discernible speech, or other audible cues that can provide sufficient speech data for analysis. In any event, in examples where the machine {\textbar} 106 {\textbar} is integrated into existing wireless (or wired) phone networking equipment, then the monitoring and recording of the speech can be done at the machine {\textbar} 106 {\textbar} , for example, in the extraction module {\textbar} 116 {\textbar} . In other examples, as note, the machine {\textbar} 106 {\textbar} may be incorporated into the device {\textbar} 104 {\textbar} Through the feature extraction module {\textbar} {\textbar} 116 {\textbar} (blocks {\textbar} 210 {\textbar} and {\textbar} 212 {\textbar} ), the process {\textbar} 200 {\textbar} then performs the low-level and segment-level feature extraction on the second call data from block {\textbar} 208 {\textbar} . For example, in reference to {\textbar} {FIG}. 3 {\textbar} , speech data {\textbar} 300 {\textbar} from a second call is provided to the engine {\textbar} 116 {\textbar} , where at the block {\textbar} 210 {\textbar} , the engine performs initial low-level feature extraction using millisecond short-time measurements {\textbar} 302 {\textbar} (only some of which are labeled). Example low-level features include pitch of the speech data {\textbar} 302 {\textbar} , the energy, spectrum, amplitude, zero crossing rate, voice activity level, and others mentioned herein or otherwise known. {\textbar} The feature extraction module {\textbar} {\textbar} 116 {\textbar} also performs segment-level (or statistical) feature extraction over a window of time {\textbar} 304 {\textbar} , at a block {\textbar} 212 {\textbar} . Example statistical feature extractions include long-time frame metrics include mean, variance, jitter, shimmer, entropy, kurtosis, any measure of fluctuations in the {LLF} over the window, and others mentioned herein or otherwise known. Other segment-level features include entropy, kurtosis, skew, or any other measures of fluctuations in the low-level features over the window. An advantage of this procedure of going from block {\textbar} 210 {\textbar} to {\textbar} 212 {\textbar} is that data is further privatized against lexical reconstruction. By performing low-level feature extraction at block {\textbar} 210 {\textbar} and then higher-level (statistical) feature extraction of that data, the process {\textbar} 200 {\textbar} does not examine raw speech data. The actual words used by the subject are essentially masked out by the blocks {\textbar} 210 {\textbar} and {\textbar} 212 {\textbar} , in this particular implementation. In other examples, the processes herein may use feature extraction at the segment level that do not result from feature extraction at the low level, for example, by doing an analysis over an entire 3-30 second window. {\textbar} The feature extraction module {\textbar} {\textbar} 116 {\textbar} provides the extracted segment-level (statistics or long-time) features data to the classification module {\textbar} 118 {\textbar} , which along with the mood-state classification data from the ground truth assessment module {\textbar} 120 {\textbar} , passes the data to a mood-state decision module {\textbar} 112 {\textbar} . Both data may be transmitted in a training mode, when the device {\textbar} 116 {\textbar} is training its classification rules. Once the device {\textbar} 116 {\textbar} has classification rules in place these algorithms may be applied directly to extracted low-level and segment-level data received directly from the module {\textbar} 116 {\textbar} , from received, unstructured speech data. {\textbar} The mood state decision module (block {\textbar} {\textbar} 214 {\textbar} ) assesses the received data and develops classification rules, for example training a support vector machine ({SVM}) that, when applied to extracted speech data, automatically identifies, with a desired level of certainty, a determined mood state of the subject from the unstructured speech data. The resulting trained {SVM} classification rules are developed and stored at block {\textbar} 214 {\textbar} for later use by the machine {\textbar} 116 {\textbar} . {\textbar} The term second call type includes a call type that is different than first. An example would be when the second call is an unstructured call, such as a normal call from the subject to a non-professional or not explicitly for the purposes of mood-state assessment. The term second call type, however, may include a second call that is of the same type as the first (i.e., where both are structure or unstructured). After the training procedure now described, any speech data from a subject (unstructured, structured, some combination thereof, etc.) may be analyzed by the machine {\textbar} {\textbar} 106 {\textbar} and trained mood-state decision module {\textbar} 122 {\textbar} may assess mood state. The trained classification rules are stored at a rules database {\textbar} 126 {\textbar} . {\textbar} {FIG}. 4 {\textbar} illustrates an example {SVM} based classification rule, specifically for assessing hypomanic versus euthymic mood state, using statistical feature extractions of average energy and average speaking rate over a sample window. {\textbar} Actual future mood determinations are made by the module {\textbar} {\textbar} 122 {\textbar} accessing the classification rules from database {\textbar} 126 {\textbar} . Depending on the nature of the classification rules, and the desired certainty of their determinations, the module {\textbar} 122 {\textbar} may not only be able to assess current mood state but predict upcoming changes in mood state, as well. {\textbar} The automatically determined mood state data may be communicated to the subject, health care professional, hospital administration system, pharmacy prescription system, insurance processing system, or other external system or entity. The mood state data may be communicated to family or personal support network. Additionally the mood state may be used to take action: for example schedule an appointment, ask the subject questions about sleep patterns and stress levels, launch an application designed to reduce mood-states, send email/{SMS} or notification suggestions reminding the subject to take medication sleep well eat well exercise. {\textbar} {\textbar} It will be appreciated that the above descriptions are provided by way of example and that numerous modifications may be made within context of the present techniques. {\textbar} {\textbar} More generally, the various blocks, operations, and techniques described above may be implemented in hardware, firmware, software, or any combination of hardware, firmware, and/or software. When implemented in hardware, some or all of the blocks, operations, techniques, etc. may be implemented in, for example, a custom integrated circuit ({IC}), an application specific integrated circuit ({ASIC}), a field programmable logic array ({FPGA}), a programmable logic array ({PLA}), etc. {\textbar} {\textbar} When implemented in software, the software may be stored in any computer readable memory such as on a magnetic disk, an optical disk, or other storage medium, in a {RAM} or {ROM} or flash memory of a computer, processor, hard disk drive, optical disk drive, tape drive, etc. Likewise, the software may be delivered to a user or a system via any known or desired delivery method including, for example, on a computer readable disk or other transportable computer storage mechanism or via communication media. Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism. The term “modulated data signal” means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency, infrared and other wireless media. Thus, the software may be delivered to a user or a system via a communication channel such as a telephone line, a {DSL} line, a cable television line, a wireless communication channel, the Internet, etc. (which are viewed as being the same as or interchangeable with providing such software via a transportable storage medium). {\textbar} {\textbar} Moreover, while the present invention has been described with reference to specific examples, which are intended to be illustrative only and not to be limiting of the invention, it will be apparent to those of ordinary skill in the art that changes, additions and/or deletions may be made to the disclosed embodiments without departing from the spirit and scope of the invention. {\textbar} {\textbar} Thus, although certain apparatus constructed in accordance with the teachings of the invention have been described herein, the scope of coverage of this patent is not limited thereto. On the contrary, this patent covers all embodiments of the teachings of the invention fairly falling within the scope of the appended claims either literally or under the doctrine of equivalents.},
}

@patent{holsboer_muller-myhsok20a,
	title = {Method for predicting a treatment response to a {CRHR}1 antagonist and/or a V1B antagonist in a patient with depressive and/or anxiety symptoms},
	url = {https://patents.google.com/patent/US10837062B2/en?oq=US10837062B2},
	holder = {Max Planck Gesellschaft zur Foerderung der Wissenschaften {eV}},
	type = {patentus},
	number = {10837062B2},
	author = {Holsboer, Florian and Müller-Myhsok, Bertram},
	urldate = {2023-01-23},
	date = {2020-11-17},
	langid = {english},
	keywords = {nucleotide, seq, snp, alleles, wild},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/GJUK8MKY/Holsboer and Müller-Myhsok - 2020 - Method for predicting a treatment response to a CR.pdf:application/pdf},
}

@patent{perez_etal19c,
	title = {Systems and methods for using transcutaneous electrical stimulation to enable dietary interventions},
	url = {https://patents.google.com/patent/US10335302B2/en?oq=US10335302B2},
	holder = {Elira Inc},
	type = {patentus},
	number = {10335302B2},
	author = {Perez, Raul E. and Hong, Peter I. and Diianni, Steven and Malave, Luis Jose and Stengel, Brad},
	urldate = {2023-01-23},
	date = {2019-07-02},
	langid = {english},
	keywords = {patient, appetite, electrical, optionally, stimulation},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/6LEMUVIT/Perez et al. - 2019 - Systems and methods for using transcutaneous elect.pdf:application/pdf},
}

@patent{poltorak22a,
	title = {Method and apparatus for neuroenhancement to enhance emotional response},
	url = {https://patents.google.com/patent/US11273283B2/en?oq=US11273283B2},
	holder = {Neuroenhancement Lab {LLC}},
	type = {patentus},
	number = {11273283B2},
	author = {Poltorak, Alexander},
	urldate = {2023-01-23},
	date = {2022-03-15},
	langid = {english},
	keywords = {brain, subject, stimulation, emotional state, stimulus},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/8M3Y7A7J/Poltorak - 2022 - Method and apparatus for neuroenhancement to enhan.pdf:application/pdf},
}

@patent{shriberg_etal20a,
	title = {Systems and methods for mental health assessment},
	url = {https://patents.google.com/patent/US10748644B2/en?oq=US10748644B2},
	holder = {Ellipsis Health Inc},
	type = {patentus},
	number = {10748644B2},
	author = {Shriberg, Elizabeth E. and Aratow, Michael and Islam, Mainul and Torbati, Amir Hossein Harati Nejad and Rutowski, Tomasz and Lin, David and Lu, Yang and Haque, Farshid and Rogers, Robert D.},
	urldate = {2023-01-23},
	date = {2020-08-18},
	langid = {english},
	keywords = {patient, data, model, subject, models},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/9BRE7LLA/Shriberg et al. - 2020 - Systems and methods for mental health assessment.pdf:application/pdf},
}

@patent{neumann20a,
	title = {Artificial intelligence advisory systems and methods for vibrant constitutional guidance},
	url = {https://patents.google.com/patent/US20200320363A1/en?oq=US20200320363A1},
	holder = {{KPN} Innovations {LLC}},
	type = {patentus},
	number = {20200320363A1},
	author = {Neumann, Kenneth},
	urldate = {2023-01-23},
	date = {2020-10-08},
	langid = {english},
	keywords = {data, user, ameliorative, label, prognostic},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/LELE24IF/Neumann - 2020 - Artificial intelligence advisory systems and metho.pdf:application/pdf},
}

@patent{williams19a,
	title = {Systems and methods of using wireless location, context, and/or one or more communication networks for monitoring for, preempting, and/or mitigating pre-identified behavior},
	url = {https://patents.google.com/patent/US10477342B2/en?oq=US10477342B2},
	holder = {Individual},
	type = {patentus},
	number = {10477342B2},
	author = {Williams, David H.},
	urldate = {2023-01-23},
	date = {2019-11-12},
	langid = {english},
	keywords = {addiction, behavior, location, addict, identified},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/YFHN39BU/Williams - 2019 - Systems and methods of using wireless location, co.pdf:application/pdf},
}

@patent{williams22a,
	title = {Systems and methods for monitoring for and lowering the risk of addiction-related or restriction violation-related behavior(s)},
	url = {https://patents.google.com/patent/US11388546B2/en?oq=US11388546B2},
	holder = {Conquer your Addiction {LLC}},
	type = {patentus},
	number = {11388546B2},
	author = {Williams, David H.},
	urldate = {2023-01-23},
	date = {2022-07-12},
	langid = {english},
	keywords = {behavior, context, location, addict, person},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/E99SECKC/Williams - 2022 - Systems and methods for monitoring for and lowerin.pdf:application/pdf},
}

@patent{chekroud_etal20a,
	title = {Methods and apparatus for predicting depression treatment outcomes},
	url = {https://patents.google.com/patent/US20200143922A1/en?oq=US20200143922A1},
	holder = {Spring Care Inc, Yale University},
	type = {patentus},
	number = {20200143922A1},
	author = {Chekroud, Adam and Krystal, John H. and Gueorguieva, Ralitza and Chandra, Abhishek},
	urldate = {2023-01-23},
	date = {2020-05-07},
	keywords = {patient, symptom, treatment, statistical model, information},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/ZPRZJ8JR/Chekroud et al. - 2020 - Methods and apparatus for predicting depression tr.pdf:application/pdf},
}

@patent{mason21a,
	title = {Method and system for describing and recommending optimal treatment plans in adaptive telemedical or other contexts},
	url = {https://patents.google.com/patent/US11107591B1/en?oq=US11107591B1},
	holder = {Rom Technologies Inc},
	type = {patentus},
	number = {11107591B1},
	author = {Mason, Steven},
	urldate = {2023-01-23},
	date = {2021-08-31},
	keywords = {patient, medical, information, people, treatment plan},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/5ES8Y9CC/Mason - 2021 - Method and system for describing and recommending .pdf:application/pdf},
}

@patent{mason_etal22a,
	title = {Remote examination through augmented reality},
	url = {https://patents.google.com/patent/US11284797B2/en?oq=US11284797B2},
	holder = {Rom Technologies Inc},
	type = {patentus},
	number = {11284797B2},
	author = {Mason, Steven and Posnack, Daniel and Arn, Peter and Para, Wendy and Hacking, S. Adam and Mueller, Micheal and {GUANERI}, Joseph and Greene, Jonathan},
	urldate = {2023-01-23},
	date = {2022-03-29},
	langid = {english},
	keywords = {patient, slave, pressure, master, sensor data},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/DB2D9JEY/Mason et al. - 2022 - Remote examination through augmented reality.pdf:application/pdf},
}

@patent{komogortsev21a,
	title = {Health assessment via eye movement biometrics},
	url = {https://patents.google.com/patent/US10966605B2/en?oq=US10966605B2},
	holder = {Texas State University San Marcos},
	type = {patentus},
	number = {10966605B2},
	author = {Komogortsev, Oleg V.},
	urldate = {2023-01-23},
	date = {2021-04-06},
	langid = {english},
	keywords = {eye, eye movement, person, saccade, saccades},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/EYTT8CF2/Komogortsev - 2021 - Health assessment via eye movement biometrics.pdf:application/pdf},
}

@patent{saito22a,
	title = {Methods and systems of extended reality environment interaction based on eye motions},
	url = {https://patents.google.com/patent/US11392198B2/en?oq=US11392198B2},
	holder = {Rovi Guides Inc},
	type = {patentus},
	number = {11392198B2},
	author = {Saito, Sakura},
	urldate = {2023-01-23},
	date = {2022-07-19},
	langid = {english},
	keywords = {time, user, display, field, view},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/XFQJHGLG/Saito - 2022 - Methods and systems of extended reality environmen.pdf:application/pdf},
}

@patent{vayrynen_kortelainen22a,
	title = {Apparatus and method for electroencephalographic measurement},
	url = {https://patents.google.com/patent/US11406316B2/en?oq=US11406316B2},
	holder = {Cerenion Oy},
	type = {patentus},
	number = {11406316B2},
	author = {{VÄYRYNEN}, Eero and {KORTELAINEN}, Jukka},
	urldate = {2023-01-23},
	date = {2022-08-09},
	langid = {english},
	keywords = {brain, information, comparison, coupling, phase},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/CC2J89HV/VÄYRYNEN and KORTELAINEN - 2022 - Apparatus and method for electroencephalographic m.pdf:application/pdf},
}

@article{benjamens_etal20,
	title = {The state of artificial intelligence-based {FDA}-approved medical devices and algorithms: an online database},
	volume = {3},
	rights = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-00324-0},
	doi = {10.1038/s41746-020-00324-0},
	shorttitle = {The state of artificial intelligence-based {FDA}-approved medical devices and algorithms},
	abstract = {At the beginning of the artificial intelligence ({AI})/machine learning ({ML}) era, the expectations are high, and experts foresee that {AI}/{ML} shows potential for diagnosing, managing and treating a wide variety of medical conditions. However, the obstacles for implementation of {AI}/{ML} in daily clinical practice are numerous, especially regarding the regulation of these technologies. Therefore, we provide an insight into the currently available {AI}/{ML}-based medical devices and algorithms that have been approved by the {US} Food \& Drugs Administration ({FDA}). We aimed to raise awareness of the importance of regulatory bodies, clearly stating whether a medical device is {AI}/{ML} based or not. Cross-checking and validating all approvals, we identified 64 {AI}/{ML} based, {FDA} approved medical devices and algorithms. Out of those, only 29 (45\%) mentioned any {AI}/{ML}-related expressions in the official {FDA} announcement. The majority (85.9\%) was approved by the {FDA} with a 510(k) clearance, while 8 (12.5\%) received de novo pathway clearance and one (1.6\%) premarket approval ({PMA}) clearance. Most of these technologies, notably 30 (46.9\%), 16 (25.0\%), and 10 (15.6\%) were developed for the fields of Radiology, Cardiology and Internal Medicine/General Practice respectively. We have launched the first comprehensive and open access database of strictly {AI}/{ML}-based medical technologies that have been approved by the {FDA}. The database will be constantly updated.},
	pages = {1--8},
	number = {1},
	journaltitle = {npj Digital Medicine},
	shortjournal = {npj Digit. Med.},
	author = {Benjamens, Stan and Dhunnoo, Pranavsingh and Meskó, Bertalan},
	urldate = {2023-01-24},
	date = {2020-09-11},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Health services, Outcomes research},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/87W7JKYZ/Benjamens et al. - 2020 - The state of artificial intelligence-based FDA-app.pdf:application/pdf},
}

@report{rcoreteam22b,
	location = {Vienna, Austria},
	title = {R: A language and environment for statistical computing},
	url = {https://www.R-project.org/},
	type = {manual},
	author = {{R Core Team}},
	date = {2022},
	note = {tex.organization: R Foundation for Statistical Computing},
}

@patent{wall16,
	title = {Enhancing diagnosis of disorder through artificial intelligence and mobile health technologies without compromising accuracy},
	url = {https://patents.google.com/patent/US9443205B2/en?oq=US9443205B2},
	holder = {Harvard College},
	type = {patentus},
	number = {9443205B2},
	author = {Wall, Dennis},
	urldate = {2023-03-07},
	date = {2016-09-13},
	langid = {english},
	keywords = {classifier, autism, subject, diagnostic, questions},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/S3XYI6RF/Wall - 2016 - Enhancing diagnosis of disorder through artificial.pdf:application/pdf},
}

@patent{kulkarni_krenn21,
	title = {Techniques for treating mental health disorders using digital therapeutics},
	url = {https://patents.google.com/patent/WO2021214554A1/en?oq=WO2021214554A1},
	holder = {The Joan and Irwin Jacobs Technion-Cornell Institute},
	type = {patent},
	number = {{WO}2021214554A1},
	author = {Kulkarni, Prathamesh and Krenn, Wilfred},
	urldate = {2023-03-07},
	date = {2021-10-28},
	langid = {english},
	keywords = {mental health, patient, digital therapeutics, health disorder, task},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/FJ8XIEWK/Kulkarni and KRENN - 2021 - Techniques for treating mental health disorders us.pdf:application/pdf},
}

@patent{kang_etal20,
	title = {Antidepressant recommendation method and system},
	url = {https://patents.google.com/patent/WO2020091375A2/en?oq=WO2020091375A2},
	holder = {Kore University},
	type = {patent},
	number = {{WO}2020091375A2},
	author = {Kang, Jae Woo and Choi, Yong Hwa and Lee, Jun Hyun and Jeon, Min Ji and Chang, Bu Ru},
	urldate = {2023-03-07},
	date = {2020-05-07},
	keywords = {patient, prescription, information, antidepressant, drug},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/GIG4A4IE/강재우 et al. - 2020 - 항우울제 추천 방법 및 시스템.pdf:application/pdf},
}

@article{lin_etal20e,
	title = {Precision psychiatry applications with pharmacogenomics: Artificial intelligence and machine learning approaches},
	volume = {21},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1422-0067},
	url = {https://www.mdpi.com/1422-0067/21/3/969},
	doi = {10.3390/ijms21030969},
	shorttitle = {Precision Psychiatry Applications with Pharmacogenomics},
	abstract = {A growing body of evidence now suggests that precision psychiatry, an interdisciplinary field of psychiatry, precision medicine, and pharmacogenomics, serves as an indispensable foundation of medical practices by offering the accurate medication with the accurate dose at the accurate time to patients with psychiatric disorders. In light of the latest advancements in artificial intelligence and machine learning techniques, numerous biomarkers and genetic loci associated with psychiatric diseases and relevant treatments are being discovered in precision psychiatry research by employing neuroimaging and multi-omics. In this review, we focus on the latest developments for precision psychiatry research using artificial intelligence and machine learning approaches, such as deep learning and neural network algorithms, together with multi-omics and neuroimaging data. Firstly, we review precision psychiatry and pharmacogenomics studies that leverage various artificial intelligence and machine learning techniques to assess treatment prediction, prognosis prediction, diagnosis prediction, and the detection of potential biomarkers. In addition, we describe potential biomarkers and genetic loci that have been discovered to be associated with psychiatric diseases and relevant treatments. Moreover, we outline the limitations in regard to the previous precision psychiatry and pharmacogenomics studies. Finally, we present a discussion of directions and challenges for future research.},
	pages = {969},
	number = {3},
	journaltitle = {International Journal of Molecular Sciences},
	author = {Lin, Eugene and Lin, Chieh-Hsin and Lane, Hsien-Yuan},
	urldate = {2023-03-08},
	date = {2020-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial intelligence, machine learning, precision psychiatry, deep learning, precision medicine, neuroimaging, neural networks, biomarker, pharmacogenomics, multi-omics},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/9D5ZVMER/Lin et al. - 2020 - Precision Psychiatry Applications with Pharmacogen.pdf:application/pdf},
}

@article{kang_etal15c,
	title = {A Patent Trend Analysis for Technological Convergence of {IoT} and Wearables},
	volume = {25},
	issn = {1976-9172},
	url = {https://koreascience.kr/article/JAKO201524848648292.page},
	doi = {10.5391/JKIIS.2015.25.3.306},
	abstract = {본 연구는 협력적특허분류({CPC})를 활용한 '사물인터넷({IoT})' 과 '웨어러블(wearables)' 의 기술융합동향 분석에 관한 것이다. 국내 도입 분야가 점차 확대되고 있는 {CPC는} 기존의 국제특허분류({IPC})보다 세분화된 분류를 제공해 기술 특성을 더 세밀하고 정확하게 반영할 수 있어 특허정보 분석 시 활용도를 배가시킬 것으로 기대된다. 아직까지 {CPC를} 특허정보 분석에 활용한 연구가 드물며, 특허분류코드를 활용해 기술융합현상을 분석한 선행연구들 대부분이 {IPC코드를} 활용하였다. 본 연구에서는 {CPC를} 활용하여 wearable {IoT} 영역의 기술융합동향분석을 실시하였고, 이를 위한 사전분석으로서 각 특허에 할당된 {CPC와} {IPC를} 비교분석하였다. 연관규칙 마이닝 기법을 활용한 {CPC} 코드분석을 통해 융합이 활발하게 발생하는 기술영역들을 도출하고 시간에 따른 추세변화를 파악하였다. This study aims at analyzing the convergence of Internet-of-Things and wearables technologies using cooperative patent classification({CPC}). {CPC}, introduced to an increasing number of technological fields of Korean patents, is expected to be widely used in Patent Informatics because the classification codes in {CPC} are more specific than those of {IPC}, which reflect the characteristics of technologies in detail with accuracy. {CPC} has seldom been used up to date and most of the previous researches on technological convergence used {IPC}. As a pre-analysis step for analyzing the trend of technological convergence of {IoT} and wearables, {CPC} and {IPC} codes assigned to each patent were compared. By applying association rule mining to the analysis of {CPC} codes, we identified the technological fields where convergence frequently takes place and examined the trend of technological convergence over time.},
	pages = {306--311},
	number = {3},
	journaltitle = {Journal of the Korean Institute of Intelligent Systems},
	author = {Kang, Ji Ho and Kim, Jong Chan and Lee, Jun Hyuck and Park, Sang Sung and Jang, Dong Sik},
	urldate = {2023-03-08},
	date = {2015},
	note = {Publisher: Korean Institute of Intelligent Systems},
	file = {Full Text PDF:/Users/annekleine/Zotero/storage/RXW6L57W/Kang et al. - 2015 - A Patent Trend Analysis for Technological Converge.pdf:application/pdf},
}

@article{nguyen_moehrle21,
	title = {Combining the Analysis of Vertical and Horizontal Technology Convergence: Insights From the Case of Urban Innovation},
	volume = {{PP}},
	doi = {10.1109/TEM.2021.3086320},
	shorttitle = {Combining the Analysis of Vertical and Horizontal Technology Convergence},
	abstract = {Technology convergence is “the blurring of boundaries” between many sectors of technologies, resulting in the emergence of several new technologies. This phenomenon has been happening in many fields. While technology convergence has been analyzed often on a horizontal level, the whole landscape of technology movement among and within different system levels is still a question. Answers to this question can lead to an improvement of theory as well as new approaches for practitioners working in this field. We select urban innovation with its complex infrastructure as a test-bed in order to answer the question in a case study. We apply the Cooperative Patent Classification co-classification analysis to the {USA} patent data related to urban innovation in a systematic view from 1976 to 2018. Our study provides some insights into technology convergence in urban innovation based on the analysis of different system levels (vertical convergence) and within the super-system regarding city infrastructures (horizontal convergence). We find that both types of technology convergence occur in parallel. While some technological movements seem to be related to each other, others do not. This leads to the conclusion that at least in the case of related technology movements, researchers should integrate different system levels in their analysis.},
	pages = {1--14},
	journaltitle = {{IEEE} Transactions on Engineering Management},
	shortjournal = {{IEEE} Transactions on Engineering Management},
	author = {Nguyen, Ngoc Uyen Phuong and Moehrle, Martin},
	date = {2021-07-02},
}

@article{haupt_etal07,
	title = {Patent indicators for the technology life cycle development},
	volume = {36},
	issn = {00487333},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0048733307000054},
	doi = {10.1016/j.respol.2006.12.004},
	abstract = {Investments in a technology have to consider its current life cycle stage. The widespread approach of studying technology life cycles by measuring patent activity indices, especially patent applications, raises a practical problem: it requires the survey of all applications and applicants on a technological ﬁeld. On the basis of an empirical study on pacemaker technology the paper identiﬁes several patent indices as appropriate life cycle stage indicators which do not require the survey of the complete patent activity.},
	pages = {387--398},
	number = {3},
	journaltitle = {Research Policy},
	shortjournal = {Research Policy},
	author = {Haupt, Reinhard and Kloyer, Martin and Lange, Marcus},
	urldate = {2023-03-08},
	date = {2007-04},
	langid = {english},
	file = {Haupt et al. - 2007 - Patent indicators for the technology life cycle de.pdf:/Users/annekleine/Zotero/storage/6B29HUFR/Haupt et al. - 2007 - Patent indicators for the technology life cycle de.pdf:application/pdf},
}

@article{probst_etal21,
	title = {Global trends in the invention and diffusion of climate change mitigation technologies},
	volume = {6},
	rights = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2058-7546},
	url = {https://www.nature.com/articles/s41560-021-00931-5},
	doi = {10.1038/s41560-021-00931-5},
	abstract = {Increasing the development and diffusion of climate change mitigation technologies on a global scale is critical to reaching net-zero emissions. We have analysed over a quarter of a million high-value inventions in all major climate change mitigation technologies patented from 1995 to 2017 by inventors located in 170 countries. Our analysis shows an annual growth rate of 10\% from 1995 to 2012 in these high-value inventions. Yet, from 2013 to 2017, the growth rate of these inventions fell by around 6\% annually, likely driven by declining fossil fuel prices, low carbon prices and increasing technological maturity for some technologies, such as solar photovoltaics. Invention has remained highly concentrated geographically over the past decade, with inventors in Germany, Japan and the United States accounting for more than half of global inventions, and the top ten countries for almost 90\%. Except for inventors in China, most middle-income economies have not caught up and remain less specialized in low-carbon technologies than high-income economies.},
	pages = {1077--1086},
	number = {11},
	journaltitle = {Nature Energy},
	shortjournal = {Nat Energy},
	author = {Probst, Benedict and Touboul, Simon and Glachant, Matthieu and Dechezleprêtre, Antoine},
	urldate = {2023-03-09},
	date = {2021-11},
	langid = {english},
	note = {Number: 11
Publisher: Nature Publishing Group},
	keywords = {Economics, Business and management, Energy science and technology, Intellectual-property rights},
	file = {210923_Global_invention_rev3_vf_accepted.pdf:/Users/annekleine/Zotero/storage/PP5MRUEA/210923_Global_invention_rev3_vf_accepted.pdf:application/pdf;Accepted Version:/Users/annekleine/Zotero/storage/XVBJMH4Z/Probst et al. - 2021 - Global trends in the invention and diffusion of cl.pdf:application/pdf},
}

@article{curran_etal10,
	title = {Anticipating converging industries using publicly available data},
	volume = {77},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162509001425},
	doi = {10.1016/j.techfore.2009.10.002},
	abstract = {Industry convergence, described as the blurring of boundaries between industries, plays an increasingly pivotal role in shaping markets and industries. Traditionally, this phenomenon has been discussed in respect to telecommunications, information technologies and electronics, but more recently also the chemical and its related industries find themselves affected by a larger convergence process. With the primary example of phytosterols in the two converging industries of Cosmeceuticals and of Nutraceuticals and Functional Foods, we analyze 7455 scientific and patent references in respect to first indicators for signs of convergence. Furthermore, we present and discuss a multiple indicator concept for monitoring convergence in an R\&D-intensive field on the basis of publicly available data.},
	pages = {385--395},
	number = {3},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Curran, Clive-Steven and Bröring, Stefanie and Leker, Jens},
	urldate = {2023-03-09},
	date = {2010-03-01},
	langid = {english},
	keywords = {Patent analysis, Bibliometrics, Chemical industry, Converging industries, Cosmeceuticals, Nutraceuticals and Functional Foods, Phytosterols},
	file = {ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/TQYXPKNB/S0040162509001425.html:text/html},
}

@report{researchandmarkets22b,
	title = {Precision Psychiatry Market - Global Industry Size, Share, Trends, Opportunity, and Forecast, 2017-2027},
	url = {https://www.researchandmarkets.com/reports/5689413/precision-psychiatry-market-global-industry},
	abstract = {Precision Psychiatry Market - Global Industry Size, Share, Trends, Opportunity, and Forecast, 2017-2027 Segmented By Biomarkers (Genetic v/s Protein), By Sample (Blood Based v/s Non-Blood-Based), By Technology, By Application, By End User, By Company and By Region},
	institution = {{TechSci} Research},
	author = {Research \{and\} Markets, Inc.},
	urldate = {2023-03-06},
	date = {2022-11},
	file = {Snapshot:/Users/annekleine/Zotero/storage/L444HK3R/precision-psychiatry-market-global-industry.html:text/html},
}

@article{witteveen_etal22,
	title = {Remote mental health care interventions during the {COVID}-19 pandemic: An umbrella review},
	volume = {159},
	issn = {0005-7967},
	url = {https://www.sciencedirect.com/science/article/pii/S0005796722001978},
	doi = {10.1016/j.brat.2022.104226},
	shorttitle = {Remote mental health care interventions during the {COVID}-19 pandemic},
	abstract = {Mitigating the {COVID}-19 related disruptions in mental health care services is crucial in a time of increased mental health disorders. Numerous reviews have been conducted on the process of implementing technology-based mental health care during the pandemic. The research question of this umbrella review was to examine what the impact of {COVID}-19 was on access and delivery of mental health services and how mental health services have changed during the pandemic. A systematic search for systematic reviews and meta-analyses was conducted up to August 12, 2022, and 38 systematic reviews were identified. Main disruptions during {COVID}-19 were reduced access to outpatient mental health care and reduced admissions and earlier discharge from inpatient care. In response, synchronous telemental health tools such as videoconferencing were used to provide remote care similar to pre-{COVID} care, and to a lesser extent asynchronous virtual mental health tools such as apps. Implementation of synchronous tools were facilitated by time-efficiency and flexibility during the pandemic but there was a lack of accessibility for specific vulnerable populations. Main barriers among practitioners and patients to use digital mental health tools were poor technological literacy, particularly when preexisting inequalities existed, and beliefs about reduced therapeutic alliance particularly in case of severe mental disorders. Absence of organizational support for technological implementation of digital mental health interventions due to inadequate {IT} infrastructure, lack of funding, as well as lack of privacy and safety, challenged implementation during {COVID}-19. Reviews were of low to moderate quality, covered heterogeneously designed primary studies and lacked findings of implementation in low- and middle-income countries. These gaps in the evidence were particularly prevalent in studies conducted early in the pandemic. This umbrella review shows that during the {COVID}-19 pandemic, practitioners and mental health care institutions mainly used synchronous telemental health tools, and to a lesser degree asynchronous tools to enable continued access to mental health care for patients. Numerous barriers to these tools were identified, and call for further improvements. In addition, more high quality research into comparative effectiveness and working mechanisms may improve scalability of mental health care in general and in future infectious disease outbreaks.},
	pages = {104226},
	journaltitle = {Behaviour Research and Therapy},
	shortjournal = {Behaviour Research and Therapy},
	author = {Witteveen, A. B. and Young, S. and Cuijpers, P. and Ayuso-Mateos, J. L. and Barbui, C. and Bertolini, F. and Cabello, M. and Cadorin, C. and Downes, N. and Franzoi, D. and Gasior, M. and John, A. and Melchior, M. and {McDaid}, D. and Palantza, C. and Purgato, M. and Van der Waerden, J. and Wang, S. and Sijbrandij, M.},
	urldate = {2023-03-10},
	date = {2022-12-01},
	langid = {english},
	keywords = {Continuity of care, {COVID}-19, e-mental health psychological interventions, Implementation, Mental health service delivery, Scalability},
	file = {ScienceDirect Full Text PDF:/Users/annekleine/Zotero/storage/EU2Y6Y4W/Witteveen et al. - 2022 - Remote mental health care interventions during the.pdf:application/pdf;ScienceDirect Snapshot:/Users/annekleine/Zotero/storage/L2I3PC8X/S0005796722001978.html:text/html},
}
